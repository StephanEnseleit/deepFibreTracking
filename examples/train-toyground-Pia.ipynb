{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import os, sys\n",
    "sys.path.insert(0,'..')\n",
    "\n",
    "from collections import deque \n",
    "\n",
    "from dfibert.tracker.nn.rl import Agent, Action_Scheduler, DQN\n",
    "import dfibert.envs.RLtractEnvironment as RLTe\n",
    "from dfibert.envs._state import TractographyState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on Lunar Lander to check functionality of agent\n",
    "#env = gym.make('LunarLander-v2')\n",
    "#n_actions= env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_steps = 3000000\n",
    "replay_memory_size = 300000\n",
    "agent_history_length = 1\n",
    "evaluate_every = 10000\n",
    "eval_runs = 20\n",
    "network_update_every = 100\n",
    "start_learning = 2000\n",
    "eps_annealing_steps = 150000\n",
    "\n",
    "max_episode_length = 250\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#batch_size = 64\n",
    "#learning_rate = 0.0000000625\n",
    "batch_size = 32\n",
    "learning_rate = 0.000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading precomputed streamlines (data/HCP307200_DTI_smallSet.vtk) for ID 100307\n"
     ]
    }
   ],
   "source": [
    "env = RLTe.RLtractEnvironment(stepWidth=0.81, device = 'cpu')\n",
    "n_actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_transition():\n",
    "    state = env.reset()[:2]\n",
    "    #transition = deque(maxlen=12)\n",
    "    #while len(transition) < 12:\n",
    "        #for i in range(len(state.getCoordinate())):\n",
    "        #    transition.append(state.getCoordinate()[i].item())\n",
    "    transition = deque(maxlen=8)\n",
    "    while len(transition) < 8:\n",
    "        for i in range(len(state)):\n",
    "            transition.append(state[i])\n",
    "    return transition\n",
    "\n",
    "def add_to_transition(state, transition):\n",
    "    #for i in range(len(state.getCoordinate())):\n",
    "    #        transition.append(state.getCoordinate()[i].item())\n",
    "    for i in range(len(state)):\n",
    "            transition.append(state[i])                   \n",
    "    return transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([46.1923, 58.1386, 18.6595])\n",
      "[46.192337 58.13857  18.659458  0.      ]\n"
     ]
    }
   ],
   "source": [
    "state = env.reset()\n",
    "print(state.getCoordinate())\n",
    "current_index = np.min([env.stepCounter,len(env.referenceStreamline_ijk)-1])\n",
    "qry_pt = state.getCoordinate().view(-1,3)\n",
    "distance = torch.sum((env.referenceStreamline_ijk[current_index] - qry_pt)**2)\n",
    "state = np.array([*state.getCoordinate(), distance])\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deque([73.6513442993164, 107.88105773925781, 93.29415130615234, 73.6513442993164, 107.88105773925781, 93.29415130615234, 73.6513442993164, 107.88105773925781, 93.29415130615234, 73.6513442993164, 107.88105773925781, 93.29415130615234], maxlen=12)\n",
      "[ 73.6513443  107.88105774  93.29415131  73.6513443  107.88105774\n",
      "  93.29415131  73.6513443  107.88105774  93.29415131  74.58926433\n",
      " 108.1431821   93.52130066]\n"
     ]
    }
   ],
   "source": [
    "transition = init_transition()\n",
    "print(transition)\n",
    "next_state, _, _ = env.step(42)\n",
    "next_transition = add_to_transition(next_state, transition)\n",
    "print(np.array(next_transition))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 12])\n",
      "tensor([[ 61.8814,  53.5273,  65.1122,  59.5295,  63.2473,  63.3582,  49.6618,\n",
      "          57.5226,  56.9831,  61.0424,  49.2360,  45.0796,  60.3465,  55.7477,\n",
      "          60.6391,  54.9909,  55.8694,  60.2220,  35.0820,  47.0737,  53.0218,\n",
      "          56.9755,  60.0529,  32.3047,  20.4098,  58.4533,  59.7584,  63.0841,\n",
      "          54.4836,  43.6310,  57.3373,  22.6192,  32.9992,  61.3936,  32.4899,\n",
      "          60.6012,   8.0376,  39.1546,  58.7364,  28.7151,  25.3395,  59.5876,\n",
      "          13.1139,  54.3735,  25.8479,  10.7677,  54.2027,  11.2558,  38.6437,\n",
      "          60.1825,  22.2333,  24.1235,   8.7726,  27.5614,   2.9120,  12.3545,\n",
      "          26.7937,  17.6043,  34.9672, -12.4343,  23.0219,  27.1385, -15.7887,\n",
      "          61.7124,  42.1585,  20.3453,  24.3167,  -4.8190,  43.8532,  45.2633,\n",
      "          13.3825,  64.5126,   0.7540,  17.9066,  45.4248,  -8.3953,  60.9557,\n",
      "          51.1121,  22.9783,  49.9606,   8.7290,   3.0979,  55.1753,  -3.8223,\n",
      "          64.8611,  28.4904,  43.0782,  48.9762,  12.0101,  67.0276,  12.0111,\n",
      "          23.9232,  59.5696,  21.2108,  39.0073,  46.0813,  14.7475,  61.6706,\n",
      "          39.2160,  29.3636,  35.8707]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor([[ 63.6283,  55.3608,  66.8185,  61.1888,  66.2913,  66.0564,  51.9236,\n",
      "          59.3875,  59.3944,  63.5277,  53.6934,  48.2030,  63.8540,  58.4446,\n",
      "          63.3026,  58.4384,  57.4725,  62.1727,  37.2078,  49.2459,  56.9622,\n",
      "          60.5168,  62.6494,  35.4438,  22.5426,  62.1371,  62.0415,  65.8335,\n",
      "          57.5910,  46.8625,  60.4251,  26.2690,  36.7441,  63.1429,  35.5379,\n",
      "          64.3739,  12.9968,  41.9775,  61.7111,  33.1583,  29.6506,  61.3467,\n",
      "          15.9077,  56.4057,  30.3011,  13.3768,  56.7660,  14.4481,  40.0194,\n",
      "          63.0712,  27.3223,  26.0509,  11.5913,  33.8582,  10.7094,  15.7474,\n",
      "          31.1777,  20.3366,  38.5003,  -7.2658,  26.0212,  29.5287, -11.0445,\n",
      "          66.1286,  46.5212,  23.9947,  28.5018,   0.2056,  49.2398,  46.6589,\n",
      "          17.8200,  68.1692,   5.3408,  20.7294,  46.7196,  -2.4405,  65.7757,\n",
      "          53.7897,  25.3095,  52.4488,  13.9321,   5.8551,  57.1451,   0.3461,\n",
      "          71.6645,  32.7234,  46.6471,  51.2306,  16.3589,  71.9192,  16.1005,\n",
      "          27.7186,  63.3874,  24.3338,  41.3170,  49.6902,  19.2401,  71.4144,\n",
      "          42.2975,  31.2736,  38.9589]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "<dfibert.envs._state.TractographyState object at 0x2aaab54c11c0> 0.9 False\n",
      "tensor([[ 61.8814,  53.5273,  65.1122,  59.5295,  63.2473,  63.3582,  49.6618,\n",
      "          57.5226,  56.9831,  61.0424,  49.2360,  45.0796,  60.3465,  55.7477,\n",
      "          60.6391,  54.9909,  55.8694,  60.2220,  35.0820,  47.0737,  53.0218,\n",
      "          56.9755,  60.0529,  32.3047,  20.4098,  58.4533,  59.7584,  63.0841,\n",
      "          54.4836,  43.6310,  57.3373,  22.6192,  32.9992,  61.3936,  32.4899,\n",
      "          60.6012,   8.0376,  39.1546,  58.7364,  28.7151,  25.3395,  59.5876,\n",
      "          13.1139,  54.3735,  25.8479,  10.7677,  54.2027,  11.2558,  38.6437,\n",
      "          60.1825,  22.2333,  24.1235,   8.7726,  27.5614,   2.9120,  12.3545,\n",
      "          26.7937,  17.6043,  34.9672, -12.4343,  23.0219,  27.1385, -15.7887,\n",
      "          61.7124,  42.1585,  20.3453,  24.3167,  -4.8190,  43.8532,  45.2633,\n",
      "          13.3825,  64.5126,   0.7540,  17.9066,  45.4248,  -8.3953,  60.9557,\n",
      "          51.1121,  22.9783,  49.9606,   8.7290,   3.0979,  55.1753,  -3.8223,\n",
      "          64.8611,  28.4904,  43.0782,  48.9762,  12.0101,  67.0276,  12.0111,\n",
      "          23.9232,  59.5696,  21.2108,  39.0073,  46.0813,  14.7475,  61.6706,\n",
      "          39.2160,  29.3636,  35.8707]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor([53.5273], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "Argmax actions:  tensor([2], device='cuda:0')\n",
      "tensor([54.0936], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([54.0936], device='cuda:0', grad_fn=<IndexPutBackward>)\n",
      "tensor([54.4527], device='cuda:0')\n",
      "tensor(0.4282, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor([[69.8217, 62.7116, 72.9487, 67.3711, 70.8939, 71.1167, 57.6730, 65.5343,\n",
      "         64.8148, 68.7852, 56.6590, 52.5855, 67.8952, 63.3010, 68.3314, 62.3348,\n",
      "         63.6183, 67.6165, 42.4274, 54.9824, 60.3265, 64.3770, 67.3753, 39.9209,\n",
      "         28.0862, 65.7306, 67.4345, 70.9891, 61.7090, 51.1367, 64.6862, 29.8620,\n",
      "         40.6824, 68.7255, 39.7542, 67.9210, 15.2490, 46.6965, 66.0314, 35.6698,\n",
      "         32.9140, 66.8376, 20.4195, 61.6589, 32.8767, 18.2042, 61.3629, 18.4511,\n",
      "         46.3521, 67.3684, 28.9866, 31.0500, 15.8538, 34.3417,  9.6600, 19.4795,\n",
      "         33.3326, 25.0639, 42.1582, -5.5555, 30.0898, 34.0673, -8.8221, 68.8530,\n",
      "         49.1213, 27.6719, 31.1747,  2.1985, 50.7622, 52.4861, 20.5302, 71.4381,\n",
      "          7.7528, 25.3170, 52.6153, -1.3586, 68.0895, 58.1571, 30.3286, 57.2420,\n",
      "         15.6469, 10.5821, 62.2527,  3.3277, 71.8068, 35.5090, 50.3183, 56.1360,\n",
      "         19.3133, 73.9992, 18.8239, 31.1360, 66.8728, 28.4109, 46.6219, 53.2537,\n",
      "         22.0076, 67.9159, 46.1737, 36.9736, 43.1922]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor([[ 63.6283,  55.3608,  66.8185,  61.1888,  66.2913,  66.0564,  51.9236,\n",
      "          59.3875,  59.3944,  63.5277,  53.6934,  48.2030,  63.8540,  58.4446,\n",
      "          63.3026,  58.4384,  57.4725,  62.1727,  37.2078,  49.2459,  56.9622,\n",
      "          60.5168,  62.6494,  35.4438,  22.5426,  62.1371,  62.0415,  65.8335,\n",
      "          57.5910,  46.8625,  60.4251,  26.2690,  36.7441,  63.1429,  35.5379,\n",
      "          64.3739,  12.9968,  41.9775,  61.7111,  33.1583,  29.6506,  61.3467,\n",
      "          15.9077,  56.4057,  30.3011,  13.3768,  56.7660,  14.4481,  40.0194,\n",
      "          63.0712,  27.3223,  26.0509,  11.5913,  33.8582,  10.7094,  15.7474,\n",
      "          31.1777,  20.3366,  38.5003,  -7.2658,  26.0212,  29.5287, -11.0445,\n",
      "          66.1286,  46.5212,  23.9947,  28.5018,   0.2056,  49.2398,  46.6589,\n",
      "          17.8200,  68.1692,   5.3408,  20.7294,  46.7196,  -2.4405,  65.7757,\n",
      "          53.7897,  25.3095,  52.4488,  13.9321,   5.8551,  57.1451,   0.3461,\n",
      "          71.6645,  32.7234,  46.6471,  51.2306,  16.3589,  71.9192,  16.1005,\n",
      "          27.7186,  63.3874,  24.3338,  41.3170,  49.6902,  19.2401,  71.4144,\n",
      "          42.2975,  31.2736,  38.9589]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Debugging the optimization of the agent\n",
    "\n",
    "#state = env.reset()\n",
    "#state = torch.tensor([state]).to(device).float()\n",
    "transition = init_transition()\n",
    "state = torch.FloatTensor([np.array(transition)]).to(device)\n",
    "print(state.shape)\n",
    "print(agent.main_dqn(state))\n",
    "print(agent.target_dqn(state))\n",
    "\n",
    "action = 1\n",
    "\n",
    "next_state, reward, done = env.step(action)\n",
    "print(next_state, reward, done)\n",
    "\n",
    "action = torch.tensor([action]).to(device)\n",
    "#next_state = torch.tensor([next_state]).float().to(device)\n",
    "next_state = add_to_transition(next_state, transition)\n",
    "next_state = torch.FloatTensor([np.array(next_state)]).to(device)\n",
    "reward = torch.tensor([reward]).float().to(device)\n",
    "done = torch.BoolTensor([done]).to(device)\n",
    "state_action_values = agent.main_dqn(state)\n",
    "print(state_action_values)\n",
    "state_action_values = state_action_values[0][action]\n",
    "print(state_action_values)\n",
    "\n",
    "next_state_actions = agent.main_dqn(next_state).max(1)[1]\n",
    "print(\"Argmax actions: \", next_state_actions)\n",
    "next_state_values = agent.target_dqn(next_state)[0][next_state_actions]\n",
    "print(next_state_values)\n",
    "next_state_values[done] = 0.0\n",
    "print(next_state_values)\n",
    "expected_state_action_values = next_state_values.detach() * 0.99 + reward\n",
    "print(expected_state_action_values)\n",
    "\n",
    "agent.optimizer.zero_grad()\n",
    "loss = torch.nn.SmoothL1Loss()(state_action_values, expected_state_action_values)\n",
    "print(loss)\n",
    "loss.backward()\n",
    "agent.optimizer.step()\n",
    "\n",
    "print(agent.main_dqn(state))\n",
    "print(agent.target_dqn(state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3) 0.9927266036305109\n",
      "53\n"
     ]
    }
   ],
   "source": [
    "state = env.reset()\n",
    "env.stepCounter += 1\n",
    "state = env.state = TractographyState(env.referenceStreamline_ijk[1], env.interpolateDWIatState)\n",
    "best_actions = []\n",
    "    #path_vectors = []\n",
    "    #reference_vectors = []\n",
    "    #cosine_sims = []\n",
    "    #distances = []\n",
    "rewards = []\n",
    "all_states = []\n",
    "all_states.append(state.getCoordinate())\n",
    "for i in range(n_actions):\n",
    "    #print(state.getCoordinate(), env.state.getCoordinate())\n",
    "    #print(env.stepCounter)\n",
    "    next_state, reward,_ = env.step(i)\n",
    "    all_states.append(next_state.getCoordinate())\n",
    "    all_states.append(state.getCoordinate())\n",
    "    rewards.append(reward)\n",
    "    #print(reward)\n",
    "    best_actions.append(reward)\n",
    "    env.state = state\n",
    "    env.stepCounter -= 1\n",
    "best_action= torch.argmax(torch.tensor(best_actions))\n",
    "#return best_action, rewards[best_action]\n",
    "print(best_action, float(rewards[best_action]))\n",
    "print(np.argmin(rewards))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cos = torch.nn.CosineSimilarity(dim=0)\n",
    "\n",
    "def get_best_action(state, env):\n",
    "    best_actions = []\n",
    "    #path_vectors = []\n",
    "    #reference_vectors = []\n",
    "    #cosine_sims = []\n",
    "    #distances = []\n",
    "    rewards = []\n",
    "    for i in range(n_actions):\n",
    "        #print(state.getCoordinate(), env.state.getCoordinate())\n",
    "        #print(env.stepCounter)\n",
    "        next_state, reward,_ = env.step(i)\n",
    "        #print(env.stepCounter)\n",
    "        #current_index = np.min([env.stepCounter,len(env.referenceStreamline_ijk)-1])\n",
    "        #print(current_index)\n",
    "        #path_vector = next_state.getCoordinate() - state.getCoordinate().squeeze(0)\n",
    "        #print(path_vector)\n",
    "        #path_vectors.append(path_vector.numpy())\n",
    "        #reference_vector = env.referenceStreamline_ijk[current_index]-env.referenceStreamline_ijk[current_index-1]\n",
    "        #print(reference_vector)\n",
    "        #reference_vectors.append(reference_vector.numpy())\n",
    "        #cosine_sim = cos(path_vector, reference_vector)\n",
    "        #cosine_sims.append(cosine_sim.item())\n",
    "        #print(cosine_sim)\n",
    "        #dist = torch.sum((env.referenceStreamline_ijk[current_index] - next_state.getCoordinate())**2)\n",
    "        #if dist < 0.1:\n",
    "        #    dist = 0\n",
    "        #else:\n",
    "        #    dist = dist - 0.1\n",
    "        #print(dist)\n",
    "        #distances.append(dist.item())\n",
    "\n",
    "        #reward = cosine_sim - dist\n",
    "        rewards.append(float(reward))\n",
    "        #print(reward)\n",
    "        best_actions.append(reward)\n",
    "        env.state = state\n",
    "        env.stepCounter -= 1\n",
    "\n",
    "    #best_actions = torch.topk(torch.tensor(best_actions), k=0)[1].numpy()\n",
    "    #random_action = np.random.choice(best_actions, size=1)\n",
    "    best_action= torch.argmax(torch.tensor(best_actions))\n",
    "    return best_action, rewards[best_action]#random_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New run\n",
      "0 [43.4998  94.53768 24.26608]\n",
      "1 [43.29119233 94.16509197 24.95438249] tensor(0.7652, dtype=torch.float64) tensor(0.7786, dtype=torch.float64) False\n",
      "2 [42.72683425 94.16310479 25.53541262] tensor(0.9863, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "3 [42.16247616 94.1611176  26.11644274] tensor(0.9863, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "4 [42.58868676 93.71840502 26.64412645] tensor(-1.6293, dtype=torch.float64) tensor(-1.6252, dtype=torch.float64) False\n",
      "5 [43.34130514 93.65398249 26.93655646] tensor(-8.6558, dtype=torch.float64) tensor(-8.0003, dtype=torch.float64) False\n",
      "6 [43.24986661 94.30478423 27.41004995] tensor(-10.4995, dtype=torch.float64) tensor(-3.3497, dtype=torch.float64) False\n",
      "7 [43.70944068 93.69284061 27.67541137] tensor(-19.9590, dtype=torch.float64) tensor(-10.7563, dtype=torch.float64) False\n",
      "8 [44.18737204 93.98184884 27.08876339] tensor(-29.1352, dtype=torch.float64) tensor(-13.1668, dtype=torch.float64) False\n",
      "9 [43.44978137 94.04268204 27.41794316] tensor(-22.7587, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "10 [42.86132353 94.3302084  27.89454148] tensor(-18.0710, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "11 [43.44070405 94.15345569 28.43229301] tensor(-23.6602, dtype=torch.float64) tensor(-8.8847, dtype=torch.float64) False\n",
      "12 [44.2146272  93.92593524 28.50562373] tensor(-35.1334, dtype=torch.float64) tensor(-15.2290, dtype=torch.float64) False\n",
      "13 [43.62616936 94.2134616  28.98222206] tensor(-28.5671, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "14 [43.25537571 94.69768497 29.51526971] tensor(-22.7096, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "15 [42.88458206 95.18190834 30.04831736] tensor(-17.8020, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "16 [43.62217273 95.12107515 29.71913758] tensor(-28.9087, dtype=torch.float64) tensor(-13.4464, dtype=torch.float64) False\n",
      "17 [43.25137908 95.60529852 30.25218523] tensor(-24.1313, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "18 [43.23629104 95.41716542 31.03988967] tensor(-24.2855, dtype=torch.float64) tensor(-3.1631, dtype=torch.float64) False\n",
      "19 [42.80678347 95.33111822 30.35855339] tensor(-35.1505, dtype=torch.float64) tensor(-13.9221, dtype=torch.float64) False\n",
      "20 [42.03286031 95.55863867 30.28522267] tensor(-40.5407, dtype=torch.float64) tensor(-8.7935, dtype=torch.float64) False\n",
      "21 [41.39782105 96.05990625 30.24577721] tensor(-45.2930, dtype=torch.float64) tensor(-7.7059, dtype=torch.float64) False\n",
      "22 [41.7686147  95.57568288 29.71272956] tensor(-62.4398, dtype=torch.float64) tensor(-20.4682, dtype=torch.float64) False\n",
      "23 [42.22818876 94.96373926 29.97809098] tensor(-75.6296, dtype=torch.float64) tensor(-17.5101, dtype=torch.float64) False\n",
      "24 [42.36271933 95.7058968  30.27339373] tensor(-69.6617, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "25 [42.4972499  96.44805434 30.56869647] tensor(-66.0625, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "26 [42.92675747 96.53410154 31.25003275] tensor(-70.1506, dtype=torch.float64) tensor(-6.9151, dtype=torch.float64) False\n",
      "27 [43.06128803 97.27625908 31.5453355 ] tensor(-66.5113, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "28 [43.17298452 98.07820093 31.52268249] tensor(-64.0323, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "29 [43.28468102 98.88014278 31.50002949] tensor(-61.9091, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "30 [42.95006499 99.08612054 30.79171792] tensor(-72.1356, dtype=torch.float64) tensor(-12.1561, dtype=torch.float64) False\n",
      "31 [43.06176148 99.88806239 30.76906491] tensor(-67.3303, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "32 [43.65021932 99.60053602 30.29246658] tensor(-80.7993, dtype=torch.float64) tensor(-17.1149, dtype=torch.float64) False\n",
      "33 [ 43.76191581 100.40247788  30.26981358] tensor(-75.2850, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "34 [ 43.87361231 101.20441973  30.24716057] tensor(-71.4038, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "35 [ 43.9853088  102.00636158  30.22450756] tensor(-68.4673, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "36 [ 44.00039685 102.19449468  29.43680312] tensor(-76.9320, dtype=torch.float64) tensor(-9.7807, dtype=torch.float64) False\n",
      "37 [ 43.68885694 102.11083132  30.1797993 ] tensor(-95.0001, dtype=torch.float64) tensor(-18.4581, dtype=torch.float64) False\n",
      "38 [ 43.21092557 101.82182309  30.76644728] tensor(-120.6000, dtype=torch.float64) tensor(-26.4038, dtype=torch.float64) False\n",
      "39 [ 43.32262206 102.62376494  30.74379427] tensor(-118.6818, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "40 [ 43.64613361 103.33253191  30.5222324 ] tensor(-118.7082, dtype=torch.float64) tensor(0.2850, dtype=torch.float64) False\n",
      "41 [ 44.2842523  103.44495641  31.00830367] tensor(-132.9434, dtype=torch.float64) tensor(-13.9450, dtype=torch.float64) False\n",
      "42 [ 44.39594879 104.24689826  30.98565066] tensor(-131.1848, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "43 [ 43.80749095 104.53442462  31.46224899] tensor(-129.9358, dtype=torch.float64) tensor(-15.7979, dtype=torch.float64) False\n",
      "44 [ 43.68610802 105.32261987  31.60407436] tensor(-113.5127, dtype=torch.float64) tensor(-1.2640, dtype=torch.float64) False\n",
      "45 [ 44.00961957 106.03138684  31.38251249] tensor(-96.8166, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "46 [ 44.12131606 106.83332869  31.35985948] tensor(-81.5407, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "47 [ 43.36160083 106.62100796  31.17586851] tensor(-90.2927, dtype=torch.float64) tensor(-21.7735, dtype=torch.float64) False\n",
      "48 [ 42.60898245 106.6854305   30.8834385 ] tensor(-93.0858, dtype=torch.float64) tensor(-18.1371, dtype=torch.float64) False\n",
      "49 [ 42.93249399 107.39419747  30.66187663] tensor(-76.7798, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "50 [ 43.36200156 107.48024467  31.34321291] tensor(-75.1463, dtype=torch.float64) tensor(-11.0396, dtype=torch.float64) False\n",
      "51 [ 43.68551311 108.18901164  31.12165105] tensor(-60.9746, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "52 [ 43.53822543 108.60786303  30.44417791] tensor(-54.7237, dtype=torch.float64) tensor(-5.0120, dtype=torch.float64) False\n",
      "53 [ 43.86173697 109.31663     30.22261604] tensor(-42.6610, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "54 [ 44.18524852 110.02539697  30.00105417] tensor(-32.5089, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "55 [ 44.04162302 109.71520033  29.2667179 ] tensor(-38.0184, dtype=torch.float64) tensor(-13.3691, dtype=torch.float64) False\n",
      "56 [ 44.41343856 110.42773414  29.36745901] tensor(-27.0661, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "57 [ 44.7852541  111.14026795  29.46820012] tensor(-18.8626, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "58 [ 45.43084035 110.76942195  29.78724815] tensor(-21.7265, dtype=torch.float64) tensor(-8.7553, dtype=torch.float64) False\n",
      "59 [ 45.05699669 110.98787019  30.47180735] tensor(-21.1952, dtype=torch.float64) tensor(-6.7392, dtype=torch.float64) False\n",
      "60 [ 45.38050824 111.69663716  30.25024548] tensor(-13.1659, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "61 [ 45.49220473 112.49857901  30.22759247] tensor(-7.3340, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "62 [ 44.79877859 112.29123629  30.59128078] tensor(-12.5222, dtype=torch.float64) tensor(-8.7903, dtype=torch.float64) False\n",
      "63 [ 45.12229014 113.00000326  30.36971891] tensor(-5.4633, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "64 [ 45.55179771 113.08605046  31.05105519] tensor(-6.2774, dtype=torch.float64) tensor(-3.9945, dtype=torch.float64) False\n",
      "65 [ 45.87530925 113.79481743  30.82949332] tensor(-1.5985, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "66 [ 46.43966734 113.79680461  30.2484632 ] tensor(-0.8750, dtype=torch.float64) tensor(-0.8292, dtype=torch.float64) False\n",
      "67 [ 46.01015977 113.71075741  29.56712692] tensor(-1.5315, dtype=torch.float64) tensor(-1.5262, dtype=torch.float64) False\n",
      "68 [ 46.38197531 114.42329122  29.66786803] tensor(0.9948, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defi stopped at/close to the terminal state!\n",
      "69 [ 46.94407554 114.88476913  29.31124292] tensor(0.8157, dtype=torch.float64) tensor(0.8157, dtype=torch.float64) False\n",
      "Defi stopped at/close to the terminal state!\n",
      "Defi stopped at/close to the terminal state!\n",
      "70 [ 46.94407554 114.88476913  29.31124292] 1.0 1.0 True\n",
      "1 -3320.8259851139405\n",
      "New run\n",
      "0 [47.870224 74.80299  26.640089]\n",
      "1 [47.13263333 74.86382697 26.96926881] tensor(0.5242, dtype=torch.float64) tensor(0.5259, dtype=torch.float64) False\n",
      "2 [46.73619767 74.26427052 26.59581088] tensor(0.9960, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "3 [46.90065931 74.82407477 27.15765745] tensor(-3.4145, dtype=torch.float64) tensor(-3.4105, dtype=torch.float64) False\n",
      "4 [47.66037454 75.0363955  27.34164843] tensor(-10.6591, dtype=torch.float64) tensor(-8.3526, dtype=torch.float64) False\n",
      "5 [47.80400003 75.34659214 28.0759847 ] tensor(-22.8400, dtype=torch.float64) tensor(-13.0927, dtype=torch.float64) False\n",
      "6 [47.40756437 74.74703568 27.70252678] tensor(-20.9048, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "7 [47.08273208 74.18032566 28.18150875] tensor(-26.9755, dtype=torch.float64) tensor(-5.1718, dtype=torch.float64) False\n",
      "8 [47.49929281 73.48614123 28.15533369] tensor(-32.5478, dtype=torch.float64) tensor(-5.0766, dtype=torch.float64) False\n",
      "9 [46.88062532 72.98572663 28.00388811] tensor(-33.6384, dtype=torch.float64) tensor(-0.6035, dtype=torch.float64) False\n",
      "10 [46.71616368 72.42592237 27.44204155] tensor(-33.3168, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "11 [46.55170203 71.86611811 26.88019498] tensor(-32.8435, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "12 [46.21708601 72.07209587 26.17188342] tensor(-38.0253, dtype=torch.float64) tensor(-4.6123, dtype=torch.float64) False\n",
      "13 [46.0197255  72.84202526 26.01581433] tensor(-56.5926, dtype=torch.float64) tensor(-18.3794, dtype=torch.float64) False\n",
      "14 [45.88519493 72.09986772 25.72051159] tensor(-54.7027, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "15 [45.72073329 71.54006347 25.15866502] tensor(-54.4498, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "16 [45.58620272 70.79790593 24.86336227] tensor(-53.9758, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "17 [45.45167215 70.05574839 24.56805952] tensor(-53.6101, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "18 [45.31714159 69.31359085 24.27275678] tensor(-52.8860, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "19 [45.40858012 68.6627891  23.79926329] tensor(-52.2366, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "20 [45.50001864 68.01198736 23.3257698 ] tensor(-51.6957, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "21 [45.59145717 67.36118561 22.85227631] tensor(-50.5629, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "22 [45.98789283 67.96074207 23.22573424] tensor(-75.5754, dtype=torch.float64) tensor(-25.1300, dtype=torch.float64) False\n",
      "23 [45.85336227 67.21858453 22.93043149] tensor(-71.9535, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "24 [45.26490443 67.50611089 23.40702981] tensor(-95.4622, dtype=torch.float64) tensor(-24.1952, dtype=torch.float64) False\n",
      "25 [45.35634296 66.85530914 22.93353632] tensor(-91.6316, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "26 [44.76788512 67.14283551 23.41013465] tensor(-118.9730, dtype=torch.float64) tensor(-28.1871, dtype=torch.float64) False\n",
      "27 [45.13867877 66.65861214 22.877087  ] tensor(-116.4966, dtype=torch.float64) tensor(-0.7718, dtype=torch.float64) False\n",
      "28 [45.2600617  65.87041689 22.73526162] tensor(-112.8097, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "29 [45.58121045 65.1941101  22.42611344] tensor(-108.4399, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "30 [45.70259338 64.40591485 22.28428807] tensor(-104.5799, dtype=torch.float64) tensor(0.9706, dtype=torch.float64) False\n",
      "31 [46.39601952 64.61325757 21.92059976] tensor(-115.1892, dtype=torch.float64) tensor(-14.3127, dtype=torch.float64) False\n",
      "32 [46.51740245 63.82506233 21.77877439] tensor(-110.0580, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "33 [46.63878538 63.03686708 21.63694901] tensor(-104.8013, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "34 [47.05534612 62.34268265 21.61077396] tensor(-98.6257, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "35 [47.47190685 61.64849822 21.5845989 ] tensor(-91.6455, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "36 [47.63636849 62.20830248 22.14644546] tensor(-109.5331, dtype=torch.float64) tensor(-24.5794, dtype=torch.float64) False\n",
      "37 [48.05292923 61.51411805 22.12027041] tensor(-100.9384, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "38 [48.46948996 60.81993362 22.09409535] tensor(-92.5974, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "39 [48.8860507  60.12574919 22.06792029] tensor(-86.6859, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "40 [49.34562476 59.51380557 22.33328171] tensor(-80.3552, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "41 [48.78126668 59.51181839 22.91431184] tensor(-95.2302, dtype=torch.float64) tensor(-19.3926, dtype=torch.float64) False\n",
      "42 [49.24084075 58.89987477 23.17967326] tensor(-89.1375, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "43 [49.70041481 58.28793115 23.44503468] tensor(-84.6163, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "44 [50.33545408 57.78666357 23.48448014] tensor(-80.7189, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "45 [50.79502814 57.17471995 23.74984156] tensor(-77.4668, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "46 [51.48845428 57.38206267 23.38615325] tensor(-84.8360, dtype=torch.float64) tensor(-9.1372, dtype=torch.float64) False\n",
      "47 [52.13404052 57.01121667 23.70520128] tensor(-81.7999, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "48 [52.77962677 56.64037067 24.02424931] tensor(-79.4756, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "49 [52.40781123 55.92783685 23.9235082 ] tensor(-91.8528, dtype=torch.float64) tensor(-13.8343, dtype=torch.float64) False\n",
      "50 [53.05339747 55.55699085 24.24255623] tensor(-87.9952, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "51 [53.69898371 55.18614485 24.56160426] tensor(-85.7608, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "52 [54.39240985 55.39348757 24.19791595] tensor(-94.2557, dtype=torch.float64) tensor(-9.3875, dtype=torch.float64) False\n",
      "53 [54.95451008 55.85496548 23.84129084] tensor(-108.7464, dtype=torch.float64) tensor(-15.4793, dtype=torch.float64) False\n",
      "54 [55.71422531 56.06728621 24.02528182] tensor(-112.1659, dtype=torch.float64) tensor(-4.6094, dtype=torch.float64) False\n",
      "55 [55.57059982 55.75708958 23.29094554] tensor(-138.9835, dtype=torch.float64) tensor(-27.3563, dtype=torch.float64) False\n",
      "56 [55.45888555 55.88855496 24.08235996] tensor(-147.8681, dtype=torch.float64) tensor(-10.3504, dtype=torch.float64) False\n",
      "57 [55.78239709 56.59732193 23.86079809] tensor(-173.4678, dtype=torch.float64) tensor(-25.8435, dtype=torch.float64) False\n",
      "58 [56.20860769 56.15460935 24.3884818 ] tensor(-151.8601, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "59 [55.65509906 55.5727167  24.49397656] tensor(-154.8327, dtype=torch.float64) tensor(-21.1460, dtype=torch.float64) False\n",
      "60 [56.23447957 55.395964   25.03172809] tensor(-134.4820, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "61 [56.81386008 55.21921129 25.56947961] tensor(-116.5393, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "62 [56.50232017 55.13554792 26.31247579] tensor(-112.5423, dtype=torch.float64) tensor(-11.6444, dtype=torch.float64) False\n",
      "63 [56.87311382 54.65132455 25.77942814] tensor(-109.2651, dtype=torch.float64) tensor(-12.6619, dtype=torch.float64) False\n",
      "64 [57.59894609 54.34704732 25.58790038] tensor(-97.9838, dtype=torch.float64) tensor(-4.9761, dtype=torch.float64) False\n",
      "65 [58.17832661 54.17029461 26.1256519 ] tensor(-82.0025, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "66 [58.57622104 54.53777613 26.72792871] tensor(-73.6296, dtype=torch.float64) tensor(-4.7076, dtype=torch.float64) False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67 [58.37886052 55.30770552 26.57185963] tensor(-85.5689, dtype=torch.float64) tensor(-24.3566, dtype=torch.float64) False\n",
      "68 [58.80507112 54.86499295 27.09954334] tensor(-69.8693, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "69 [59.23128171 54.42228037 27.62722706] tensor(-56.9122, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "70 [59.62771737 55.02183682 28.00068498] tensor(-55.2908, dtype=torch.float64) tensor(-9.0382, dtype=torch.float64) False\n",
      "71 [59.1982098  54.93578963 27.3193487 ] tensor(-65.9700, dtype=torch.float64) tensor(-21.5757, dtype=torch.float64) False\n",
      "72 [58.56317054 55.43705721 27.27990324] tensor(-77.8497, dtype=torch.float64) tensor(-25.2129, dtype=torch.float64) False\n",
      "73 [59.20875678 55.0662112  27.59895127] tensor(-62.8109, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "74 [58.43483362 55.29373166 27.52562054] tensor(-75.9736, dtype=torch.float64) tensor(-24.5027, dtype=torch.float64) False\n",
      "75 [59.08041987 54.92288565 27.84466858] tensor(-60.9769, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "76 [58.6509123  54.83683845 27.16333229] tensor(-72.7328, dtype=torch.float64) tensor(-22.9187, dtype=torch.float64) False\n",
      "77 [59.29649854 54.46599245 27.48238032] tensor(-57.8398, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "78 [58.55890787 54.52682565 27.8115601 ] tensor(-65.0423, dtype=torch.float64) tensor(-18.0593, dtype=torch.float64) False\n",
      "79 [58.23775912 55.20313244 28.12070828] tensor(-72.3742, dtype=torch.float64) tensor(-19.9483, dtype=torch.float64) False\n",
      "80 [58.88334536 54.83228644 28.43975631] tensor(-58.1389, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "81 [59.5289316  54.46144044 28.75880434] tensor(-46.1685, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "82 [60.17451784 54.09059443 29.07785237] tensor(-35.5104, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "83 [60.82010408 53.71974843 29.3969004 ] tensor(-26.1644, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "84 [61.46569033 53.34890243 29.71594843] tensor(-18.1307, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "85 [61.58762106 52.92507205 29.0365364 ] tensor(-19.7630, dtype=torch.float64) tensor(-7.3539, dtype=torch.float64) False\n",
      "86 [61.21682741 53.40929542 29.56958405] tensor(-21.4139, dtype=torch.float64) tensor(-8.8846, dtype=torch.float64) False\n",
      "87 [61.26574725 54.15406523 29.25490201] tensor(-27.9210, dtype=torch.float64) tensor(-13.4013, dtype=torch.float64) False\n",
      "88 [61.69195784 53.71135265 29.78258573] tensor(-18.5534, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "89 [61.49459733 54.48128204 29.62651664] tensor(-27.1995, dtype=torch.float64) tensor(-14.3231, dtype=torch.float64) False\n",
      "90 [61.17108578 53.77251507 29.84807851] tensor(-22.7322, dtype=torch.float64) tensor(-3.8465, dtype=torch.float64) False\n",
      "91 [60.84757424 53.0637481  30.06964038] tensor(-20.2617, dtype=torch.float64) tensor(-4.5310, dtype=torch.float64) False\n",
      "92 [61.27378483 52.62103552 30.59732409] tensor(-13.0295, dtype=torch.float64) tensor(0.4801, dtype=torch.float64) False\n",
      "93 [62.03350006 52.83335625 30.78131507] tensor(-9.3651, dtype=torch.float64) tensor(-1.1268, dtype=torch.float64) False\n",
      "94 [62.6790863  52.46251025 31.1003631 ] tensor(-4.2267, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "95 [62.79080057 52.33104486 30.30894869] tensor(-6.4966, dtype=torch.float64) tensor(-4.8877, dtype=torch.float64) False\n",
      "96 [63.21701116 51.88833228 30.8366324 ] tensor(-0.9609, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "97 [63.55162719 51.68235453 31.54494397] tensor(0.9867, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "Defi stopped at/close to the terminal state!\n",
      "Defi stopped at/close to the terminal state!\n",
      "98 [63.55162719 51.68235453 31.54494397] 1.0 1.0 True\n",
      "2 -4971.155473458521\n",
      "New run\n",
      "0 [ 73.651344 107.88106   93.29415 ]\n",
      "1 [ 74.38893497 107.82022454  92.96497153] tensor(0.9861, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "2 [ 75.12652564 107.75939134  92.63579176] tensor(0.9951, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "3 [ 75.03508711 108.41019309  93.10928525] tensor(-0.3727, dtype=torch.float64) tensor(-0.3594, dtype=torch.float64) False\n",
      "4 [ 74.47706227 108.93310281  93.37625661] tensor(-4.9641, dtype=torch.float64) tensor(-4.9593, dtype=torch.float64) False\n",
      "5 [ 75.21465294 108.87226961  93.04707683] tensor(-3.0769, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "6 [ 75.77901103 108.87425679  92.46604671] tensor(-2.6114, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "7 [ 76.34336911 108.87624398  91.88501659] tensor(-2.3126, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "8 [ 77.03679525 109.0835867   91.52132828] tensor(-1.9739, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "9 [ 77.73022139 109.29092943  91.15763997] tensor(-1.7382, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "10 [ 78.42364753 109.49827216  90.79395167] tensor(-1.5473, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "11 [ 78.58810917 110.05807641  91.35579823] tensor(-6.9520, dtype=torch.float64) tensor(-4.6375, dtype=torch.float64) False\n",
      "12 [ 79.06604054 110.34708464  90.76915025] tensor(-5.7114, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "13 [ 79.54397191 110.63609286  90.18250227] tensor(-5.5546, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "14 [ 80.10833    110.63808005  89.60147215] tensor(-5.5049, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "15 [ 80.19976852 109.9872783   89.12797866] tensor(-9.3728, dtype=torch.float64) tensor(-3.0897, dtype=torch.float64) False\n",
      "16 [ 80.67769989 110.27628652  88.54133068] tensor(-8.5270, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "17 [ 79.91798466 110.0639658   88.3573397 ] tensor(-19.4577, dtype=torch.float64) tensor(-10.5386, dtype=torch.float64) False\n",
      "18 [ 80.48234275 110.06595298  87.77630958] tensor(-17.4142, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "19 [ 79.89388491 110.35347934  88.2529079 ] tensor(-34.7416, dtype=torch.float64) tensor(-17.0523, dtype=torch.float64) False\n",
      "20 [ 80.45824299 110.35546653  87.67187778] tensor(-31.6843, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "21 [ 81.02260108 110.35745371  87.09084766] tensor(-30.7053, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "22 [ 81.58695916 110.3594409   86.50981753] tensor(-29.5150, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "23 [ 82.15131725 110.36142808  85.92878741] tensor(-28.6557, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "24 [ 82.5251609  110.14297984  85.24422822] tensor(-27.9509, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "25 [ 82.89900455 109.9245316   84.55966902] tensor(-26.5390, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "26 [ 83.2728482  109.70608336  83.87510983] tensor(-24.7480, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "27 [ 83.64669186 109.48763512  83.19055063] tensor(-21.4259, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "28 [ 83.75840612 109.35616974  82.39913622] tensor(-18.0547, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "29 [ 83.87012039 109.22470435  81.60772181] tensor(-15.0750, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "30 [ 84.46903112 109.5983139   82.00498978] tensor(-26.8269, dtype=torch.float64) tensor(-13.2529, dtype=torch.float64) False\n",
      "31 [ 84.32540563 109.28811727  81.27065351] tensor(-23.2780, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "32 [ 84.21370913 108.48617542  81.29330651] tensor(-28.3916, dtype=torch.float64) tensor(-5.3973, dtype=torch.float64) False\n",
      "33 [ 83.78420156 108.40012822  80.61197023] tensor(-26.8494, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "34 [ 84.40286905 108.90054282  80.76341581] tensor(-43.4293, dtype=torch.float64) tensor(-16.5066, dtype=torch.float64) False\n",
      "35 [ 83.97336148 108.81449562  80.08207953] tensor(-40.6578, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "36 [ 83.54385391 108.72844842  79.40074325] tensor(-39.7561, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 [ 83.37939227 108.16864417  78.83889669] tensor(-40.2734, dtype=torch.float64) tensor(-0.7922, dtype=torch.float64) False\n",
      "38 [ 82.9498847  108.08259697  78.15756041] tensor(-39.0704, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "39 [ 82.31176601 107.97017248  77.67148914] tensor(-37.8985, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "40 [ 83.04629254 108.29810313  77.57645087] tensor(-57.3958, dtype=torch.float64) tensor(-19.6488, dtype=torch.float64) False\n",
      "41 [ 83.69187878 107.92725713  77.8954989 ] tensor(-79.7409, dtype=torch.float64) tensor(-24.4366, dtype=torch.float64) False\n",
      "42 [ 83.05376009 107.81483263  77.40942764] tensor(-76.0080, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "43 [ 82.41564141 107.70240814  76.92335637] tensor(-74.0522, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "44 [ 81.77752272 107.58998365  76.43728511] tensor(-72.5038, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "45 [ 81.02490434 107.65440618  76.1448551 ] tensor(-70.4472, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "46 [ 80.6530888  106.94187237  76.04411399] tensor(-76.2125, dtype=torch.float64) tensor(-6.5527, dtype=torch.float64) False\n",
      "47 [ 80.06463096 107.22939874  76.52071232] tensor(-81.9418, dtype=torch.float64) tensor(-7.5811, dtype=torch.float64) False\n",
      "48 [ 79.42959169 107.73066632  76.48126685] tensor(-83.5457, dtype=torch.float64) tensor(-3.1749, dtype=torch.float64) False\n",
      "49 [ 78.67697331 107.79508885  76.18883685] tensor(-81.0573, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "50 [ 79.42959169 107.73066632  76.48126685] tensor(-111.0844, dtype=torch.float64) tensor(-32.2845, dtype=torch.float64) False\n",
      "51 [ 78.67697331 107.79508885  76.18883685] tensor(-106.0909, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "52 [ 77.92435493 107.85951138  75.89640684] tensor(-101.6839, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "53 [ 77.36633009 108.3824211   76.1633782 ] tensor(-103.3423, dtype=torch.float64) tensor(-5.0537, dtype=torch.float64) False\n",
      "54 [ 77.95478793 108.09489474  75.68677988] tensor(-123.9718, dtype=torch.float64) tensor(-27.1248, dtype=torch.float64) False\n",
      "55 [ 78.28940395 107.88891698  76.39509145] tensor(-146.3529, dtype=torch.float64) tensor(-31.0086, dtype=torch.float64) False\n",
      "56 [ 77.53678557 107.95333952  76.10266144] tensor(-135.7934, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "57 [ 76.89119933 108.32418552  75.78361341] tensor(-129.7773, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "58 [ 76.51938379 107.61165171  75.6828723 ] tensor(-144.1094, dtype=torch.float64) tensor(-16.1338, dtype=torch.float64) False\n",
      "59 [ 75.74546063 107.83917216  75.60954157] tensor(-140.7928, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "60 [ 74.97153748 108.06669261  75.53621085] tensor(-138.8294, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "61 [ 74.83700691 107.32453507  75.2409081 ] tensor(-160.8257, dtype=torch.float64) tensor(-23.8752, dtype=torch.float64) False\n",
      "62 [ 74.20196765 107.82580265  75.20146264] tensor(-157.0469, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "63 [ 73.56692838 108.32707023  75.16201718] tensor(-154.0511, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "64 [ 72.93188912 108.82833781  75.12257172] tensor(-150.2733, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "65 [ 72.29684985 109.32960539  75.08312626] tensor(-143.8722, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "66 [ 72.6706935  109.11115716  74.39856706] tensor(-167.1626, dtype=torch.float64) tensor(-31.6070, dtype=torch.float64) False\n",
      "67 [ 72.27279907 108.74367563  73.79629026] tensor(-173.9174, dtype=torch.float64) tensor(-19.6495, dtype=torch.float64) False\n",
      "68 [ 71.71477423 109.26658535  74.06326161] tensor(-156.9389, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "69 [ 70.98024771 108.9386547   74.15829988] tensor(-151.0700, dtype=torch.float64) tensor(-10.4843, dtype=torch.float64) False\n",
      "70 [ 71.17760822 108.1687253   74.31436896] tensor(-170.2211, dtype=torch.float64) tensor(-34.8096, dtype=torch.float64) False\n",
      "71 [ 70.61325014 108.16673812  74.89539909] tensor(-159.1534, dtype=torch.float64) tensor(-6.0918, dtype=torch.float64) False\n",
      "72 [ 70.29210138 108.84304491  75.20454727] tensor(-140.7991, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "73 [ 70.29210138 108.84304491  75.20454727] tensor(-140.9885, dtype=torch.float64) tensor(-17.6797, dtype=torch.float64) False\n",
      "74 [ 69.97095263 109.51935171  75.51369545] tensor(-123.3183, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "75 [ 69.64980388 110.1956585   75.82284363] tensor(-105.5387, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "76 [ 69.45244337 110.9655879   75.66677455] tensor(-89.9427, dtype=torch.float64) tensor(-3.2815, dtype=torch.float64) False\n",
      "77 [ 69.36100484 111.61638964  76.14026804] tensor(-69.6602, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "78 [ 69.26956631 112.26719139  76.61376153] tensor(-51.0394, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "79 [ 69.59071506 111.59088459  76.30461334] tensor(-56.3189, dtype=torch.float64) tensor(-19.5043, dtype=torch.float64) False\n",
      "80 [ 68.85312439 111.65171779  76.63379312] tensor(-47.3221, dtype=torch.float64) tensor(-5.7567, dtype=torch.float64) False\n",
      "81 [ 69.59071506 111.59088459  76.30461334] tensor(-45.8113, dtype=torch.float64) tensor(-11.8174, dtype=torch.float64) False\n",
      "82 [ 69.4561845  110.84872705  76.0093106 ] tensor(-51.0841, dtype=torch.float64) tensor(-18.4151, dtype=torch.float64) False\n",
      "83 [ 69.62064614 111.40853131  76.57115716] tensor(-35.1351, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "84 [ 69.78510778 111.96833557  77.13300373] tensor(-21.3116, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "85 [ 69.77001974 111.78020246  77.92070817] tensor(-13.3289, dtype=torch.float64) tensor(-2.2492, dtype=torch.float64) False\n",
      "86 [ 70.36893046 112.15381201  78.31797614] tensor(-4.8080, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "87 [ 70.16032116 111.78122241  79.00627778] tensor(-5.2933, dtype=torch.float64) tensor(-2.8987, dtype=torch.float64) False\n",
      "88 [ 70.77898865 112.28163701  79.15772336] tensor(-1.8980, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "89 [ 71.51351517 112.60956766  79.06268509] tensor(-0.0062, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "Defi stopped at/close to the terminal state!\n",
      "90 [ 71.83466393 111.93326086  78.75353691] tensor(-1.3887, dtype=torch.float64) tensor(-1.3887, dtype=torch.float64) False\n",
      "91 [ 71.6117467  112.57518394  78.31269376] tensor(-1.7035, dtype=torch.float64) tensor(-0.0338, dtype=torch.float64) False\n",
      "92 [ 71.94636272 112.36920618  79.02100533] tensor(-0.4519, dtype=torch.float64) tensor(0.6978, dtype=torch.float64) False\n",
      "93 [ 72.27119501 112.9359162   78.54202336] tensor(-0.2223, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "Defi stopped at/close to the terminal state!\n",
      "Defi stopped at/close to the terminal state!\n",
      "94 [ 72.27119501 112.9359162   78.54202336] 1.0 1.0 True\n",
      "3 -5186.195168626943\n",
      "New run\n",
      "0 [ 73.651344 107.88106   93.29415 ]\n",
      "1 [ 74.38893497 107.82022454  92.96497153] tensor(0.9861, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "2 [ 75.12652564 107.75939134  92.63579176] tensor(0.9951, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "3 [ 74.90360841 108.40131441  92.19494861] tensor(0.1905, dtype=torch.float64) tensor(0.2039, dtype=torch.float64) False\n",
      "4 [ 75.59703455 108.60865714  91.83126031] tensor(0.9951, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "5 [ 76.05660862 107.99671352  92.09662173] tensor(0.1527, dtype=torch.float64) tensor(0.1576, dtype=torch.float64) False\n",
      "6 [ 75.72199259 108.20269128  91.38831016] tensor(-1.5909, dtype=torch.float64) tensor(-1.5815, dtype=torch.float64) False\n",
      "7 [ 76.09583625 107.98424304  90.70375096] tensor(-2.6098, dtype=torch.float64) tensor(-0.9687, dtype=torch.float64) False\n",
      "8 [ 76.83036277 108.31217369  90.6087127 ] tensor(-2.0816, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 [ 76.50685123 107.60340672  90.83027456] tensor(-12.5032, dtype=torch.float64) tensor(-9.5779, dtype=torch.float64) False\n",
      "10 [ 77.06895146 108.06488462  90.47364945] tensor(-10.7107, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "11 [ 77.63105169 108.52636253  90.11702434] tensor(-10.6565, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "12 [ 78.19315192 108.98784044  89.76039922] tensor(-10.3672, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "13 [ 78.56699557 108.7693922   89.07584003] tensor(-13.1596, dtype=torch.float64) tensor(-2.3720, dtype=torch.float64) False\n",
      "14 [ 79.1290958  109.23087011  88.71921492] tensor(-11.6314, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "15 [ 79.24079229 110.03281196  88.69656191] tensor(-14.0486, dtype=torch.float64) tensor(-3.0228, dtype=torch.float64) False\n",
      "16 [ 80.00050752 110.24513269  88.88055289] tensor(-14.6875, dtype=torch.float64) tensor(-1.6297, dtype=torch.float64) False\n",
      "17 [ 80.63862621 110.35755718  89.36662415] tensor(-20.6220, dtype=torch.float64) tensor(-6.3162, dtype=torch.float64) False\n",
      "18 [ 81.20298429 110.35954437  88.78559403] tensor(-19.1871, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "19 [ 81.0912878  109.55760251  88.80824704] tensor(-29.9727, dtype=torch.float64) tensor(-10.0476, dtype=torch.float64) False\n",
      "20 [ 81.65564588 109.5595897   88.22721691] tensor(-28.2891, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "21 [ 82.29068515 109.05832212  88.26666237] tensor(-34.8363, dtype=torch.float64) tensor(-6.2796, dtype=torch.float64) False\n",
      "22 [ 82.60222506 109.14198549  87.52366619] tensor(-33.0065, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "23 [ 81.86463439 109.20281868  87.85284597] tensor(-52.6642, dtype=torch.float64) tensor(-19.7749, dtype=torch.float64) False\n",
      "24 [ 82.17617429 109.28648205  87.10984978] tensor(-50.0198, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "25 [ 81.85266275 108.57771508  87.33141165] tensor(-66.8779, dtype=torch.float64) tensor(-17.7045, dtype=torch.float64) False\n",
      "26 [ 82.16420266 108.66137845  86.58841547] tensor(-62.7168, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "27 [ 82.62377672 108.04943483  86.85377689] tensor(-71.7680, dtype=torch.float64) tensor(-14.0941, dtype=torch.float64) False\n",
      "28 [ 82.73549099 107.91796944  86.06236248] tensor(-64.2424, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "29 [ 81.97577576 107.70564871  85.8783715 ] tensor(-70.1416, dtype=torch.float64) tensor(-11.7870, dtype=torch.float64) False\n",
      "30 [ 82.08749003 107.57418333  85.08695708] tensor(-63.2442, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "31 [ 81.97577576 107.70564871  85.8783715 ] tensor(-85.7609, dtype=torch.float64) tensor(-27.6235, dtype=torch.float64) False\n",
      "32 [ 82.08749003 107.57418333  85.08695708] tensor(-78.4689, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "33 [ 81.91882401 107.54716314  84.29517322] tensor(-73.3219, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "34 [ 81.75015798 107.52014294  83.50338936] tensor(-68.9833, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "35 [ 81.58149195 107.49312275  82.7116055 ] tensor(-64.0040, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "36 [ 81.41282593 107.46610256  81.91982164] tensor(-59.6506, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "37 [ 80.98661534 107.90881514  81.39213793] tensor(-59.0645, dtype=torch.float64) tensor(-3.0569, dtype=torch.float64) False\n",
      "38 [ 80.81794931 107.88179494  80.60035407] tensor(-54.8883, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "39 [ 80.70623504 108.01326033  81.39176848] tensor(-75.9792, dtype=torch.float64) tensor(-24.5021, dtype=torch.float64) False\n",
      "40 [ 80.27672747 107.92721313  80.7104322 ] tensor(-70.1119, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "41 [ 79.63860879 107.81478864  80.22436094] tensor(-66.0400, dtype=torch.float64) tensor(-0.3190, dtype=torch.float64) False\n",
      "42 [ 79.20910122 107.72874144  79.54302466] tensor(-59.9431, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "43 [ 79.37356286 108.2885457   80.10487122] tensor(-79.5643, dtype=torch.float64) tensor(-24.1836, dtype=torch.float64) False\n",
      "44 [ 79.26184859 108.42001108  80.89628563] tensor(-100.5341, dtype=torch.float64) tensor(-26.6362, dtype=torch.float64) False\n",
      "45 [ 78.86395416 108.05252956  80.29400883] tensor(-92.9215, dtype=torch.float64) tensor(0.0514, dtype=torch.float64) False\n",
      "46 [ 78.43444659 107.96648236  79.61267255] tensor(-86.0561, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "47 [ 77.84598875 108.25400872  80.08927087] tensor(-94.3008, dtype=torch.float64) tensor(-14.2041, dtype=torch.float64) False\n",
      "48 [ 78.491575   107.88316272  80.4083189 ] tensor(-117.9902, dtype=torch.float64) tensor(-29.7992, dtype=torch.float64) False\n",
      "49 [ 77.85345631 107.77073823  79.92224764] tensor(-109.6309, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "50 [ 77.21533762 107.65831374  79.43617637] tensor(-102.0542, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "51 [ 77.54016991 108.22502376  78.9571944 ] tensor(-112.4173, dtype=torch.float64) tensor(-15.9466, dtype=torch.float64) False\n",
      "52 [ 77.70883594 108.25204395  79.74897826] tensor(-135.1233, dtype=torch.float64) tensor(-29.9593, dtype=torch.float64) False\n",
      "53 [ 78.1052716  108.85160041  80.12243618] tensor(-158.9103, dtype=torch.float64) tensor(-31.2876, dtype=torch.float64) False\n",
      "54 [ 78.74031087 108.35033283  80.16188165] tensor(-185.1412, dtype=torch.float64) tensor(-36.2751, dtype=torch.float64) False\n",
      "55 [ 78.16093035 108.52708554  79.62413012] tensor(-173.0884, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "56 [ 78.01364267 108.94593693  78.94665698] tensor(-169.0557, dtype=torch.float64) tensor(-5.5445, dtype=torch.float64) False\n",
      "57 [ 77.37552398 108.83351243  78.46058572] tensor(-162.3815, dtype=torch.float64) tensor(-0.3587, dtype=torch.float64) False\n",
      "58 [ 77.53998563 109.39331669  79.02243228] tensor(-185.1774, dtype=torch.float64) tensor(-27.3602, dtype=torch.float64) False\n",
      "59 [ 77.76290286 108.75139362  79.46327543] tensor(-218.1228, dtype=torch.float64) tensor(-38.1843, dtype=torch.float64) False\n",
      "60 [ 77.11731661 109.12223962  79.1442274 ] tensor(-211.1613, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "61 [ 77.11731661 109.12223962  79.1442274 ] tensor(-228.3677, dtype=torch.float64) tensor(-23.1979, dtype=torch.float64) False\n",
      "62 [ 76.47173037 109.49308562  78.82517937] tensor(-220.9204, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "63 [ 75.82614413 109.86393163  78.50613134] tensor(-213.3391, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "64 [ 75.0664289  109.6516109   78.32214036] tensor(-208.7737, dtype=torch.float64) tensor(-3.1354, dtype=torch.float64) False\n",
      "65 [ 74.84351167 110.29353397  77.88129721] tensor(-204.0602, dtype=torch.float64) tensor(-6.6123, dtype=torch.float64) False\n",
      "66 [ 75.40153651 109.77062425  77.61432586] tensor(-231.5560, dtype=torch.float64) tensor(-42.7360, dtype=torch.float64) False\n",
      "67 [ 74.62761336 109.9981447   77.54099513] tensor(-209.7522, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "68 [ 73.99257409 110.49941228  77.50154967] tensor(-185.5542, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "69 [ 73.35753483 111.00067986  77.46210421] tensor(-160.2957, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "70 [ 72.89796076 111.61262349  77.19674279] tensor(-139.7212, dtype=torch.float64) tensor(-1.6376, dtype=torch.float64) False\n",
      "71 [ 72.98939929 110.96182174  76.7232493 ] tensor(-147.7013, dtype=torch.float64) tensor(-29.0694, dtype=torch.float64) False\n",
      "72 [ 72.78078999 110.58923213  77.41155094] tensor(-140.8225, dtype=torch.float64) tensor(-15.6978, dtype=torch.float64) False\n",
      "73 [ 72.22276515 111.11214185  77.67852229] tensor(-117.2843, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "74 [ 71.6647403  111.63505157  77.94549365] tensor(-96.2202, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "75 [ 71.10671546 112.15796128  78.21246501] tensor(-76.1279, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76 [ 70.93804944 112.13094109  77.42068115] tensor(-72.1814, dtype=torch.float64) tensor(-15.3816, dtype=torch.float64) False\n",
      "77 [ 71.57616813 112.24336558  77.90675241] tensor(-63.8901, dtype=torch.float64) tensor(-11.2295, dtype=torch.float64) False\n",
      "78 [ 71.25501937 112.91967238  78.21590059] tensor(-44.4191, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "79 [ 71.45237989 112.14974299  78.37196968] tensor(-43.0947, dtype=torch.float64) tensor(-14.5209, dtype=torch.float64) False\n",
      "80 [ 70.89435505 112.6726527   78.63894103] tensor(-27.7468, dtype=torch.float64) tensor(0.4742, dtype=torch.float64) False\n",
      "81 [ 70.80291652 113.32345445  79.11243452] tensor(-14.6658, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "Defi stopped at/close to the terminal state!\n",
      "Defi stopped at/close to the terminal state!\n",
      "82 [ 70.80291652 113.32345445  79.11243452] 1.0 1.0 True\n",
      "4 -5620.5610323018645\n",
      "New run\n",
      "0 [ 73.651344 107.88106   93.29415 ]\n",
      "1 [ 74.28638356 107.37979016  93.33359677] tensor(0.7515, dtype=torch.float64) tensor(0.7655, dtype=torch.float64) False\n",
      "2 [ 75.03900195 107.31536762  93.62602677] tensor(0.7143, dtype=torch.float64) tensor(0.7193, dtype=torch.float64) False\n",
      "3 [ 75.60336003 107.31735481  93.04499665] tensor(0.9866, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "4 [ 75.40599952 108.0872842   92.88892757] tensor(0.0836, dtype=torch.float64) tensor(0.0885, dtype=torch.float64) False\n",
      "5 [ 76.09942566 108.29462693  92.52523926] tensor(0.9951, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "6 [ 76.7928518  108.50196965  92.16155096] tensor(0.9906, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "7 [ 77.48627793 108.70931238  91.79786265] tensor(0.9906, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "8 [ 77.82089396 108.50333463  92.50617422] tensor(-4.5442, dtype=torch.float64) tensor(-4.5295, dtype=torch.float64) False\n",
      "9 [ 78.29882533 108.79234285  91.91952624] tensor(-2.8891, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "10 [ 78.7767567  109.08135107  91.33287826] tensor(-2.4990, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "11 [ 79.25468807 109.3703593   90.74623028] tensor(-2.2432, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "12 [ 79.73261943 109.65936752  90.1595823 ] tensor(-2.1455, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "13 [ 79.85455017 109.23553715  89.48017027] tensor(-5.7244, dtype=torch.float64) tensor(-2.6515, dtype=torch.float64) False\n",
      "14 [ 80.4166504  109.69701505  89.12354515] tensor(-4.6665, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "15 [ 80.97875063 110.15849296  88.76692004] tensor(-4.0966, dtype=torch.float64) tensor(0.7237, dtype=torch.float64) False\n",
      "16 [ 81.53225926 110.74038561  88.66142528] tensor(-5.4912, dtype=torch.float64) tensor(-0.9888, dtype=torch.float64) False\n",
      "17 [ 82.09661734 110.7423728   88.08039516] tensor(-4.8129, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "18 [ 82.65464218 110.21946308  87.8134238 ] tensor(-6.9739, dtype=torch.float64) tensor(-1.2156, dtype=torch.float64) False\n",
      "19 [ 82.96618209 110.30312645  87.07042762] tensor(-6.4503, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "20 [ 82.40182401 110.30113926  87.65145775] tensor(-20.3483, dtype=torch.float64) tensor(-13.1769, dtype=torch.float64) False\n",
      "21 [ 82.71336391 110.38480263  86.90846156] tensor(-18.2575, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "22 [ 83.10979958 110.98435909  87.28191949] tensor(-29.9474, dtype=torch.float64) tensor(-11.1111, dtype=torch.float64) False\n",
      "23 [ 83.48364323 110.76591085  86.59736029] tensor(-28.2783, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "24 [ 83.85748688 110.54746261  85.9128011 ] tensor(-28.1517, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "25 [ 83.96920115 110.41599722  85.12138669] tensor(-27.7694, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "26 [ 84.08091542 110.28453184  84.32997227] tensor(-27.0642, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "27 [ 84.19262968 110.15306645  83.53855786] tensor(-24.7838, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "28 [ 83.554511   110.04064196  83.05248659] tensor(-26.5942, dtype=torch.float64) tensor(-3.3524, dtype=torch.float64) False\n",
      "29 [ 83.67644173 109.61681158  82.37307456] tensor(-23.2514, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "30 [ 83.82372941 109.19796019  83.0505477 ] tensor(-35.8230, dtype=torch.float64) tensor(-14.6328, dtype=torch.float64) False\n",
      "31 [ 84.22162384 109.56544172  83.65282451] tensor(-53.8488, dtype=torch.float64) tensor(-21.0748, dtype=torch.float64) False\n",
      "32 [ 84.07799835 109.25524508  82.91848823] tensor(-49.6485, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "33 [ 83.90933233 109.22822489  82.12670437] tensor(-48.0352, dtype=torch.float64) tensor(0.6630, dtype=torch.float64) False\n",
      "34 [ 83.44975826 109.84016851  81.86134295] tensor(-55.8827, dtype=torch.float64) tensor(-8.5718, dtype=torch.float64) False\n",
      "35 [ 83.30613277 109.52997187  81.12700668] tensor(-53.1372, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "36 [ 83.8596414  110.11186452  81.02151192] tensor(-70.7963, dtype=torch.float64) tensor(-18.7466, dtype=torch.float64) False\n",
      "37 [ 84.25607706 110.71142098  81.39496985] tensor(-96.0393, dtype=torch.float64) tensor(-28.4054, dtype=torch.float64) False\n",
      "38 [ 83.85818262 110.34393946  80.79269304] tensor(-91.6963, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "39 [ 83.46028819 109.97645793  80.19041623] tensor(-88.7552, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "40 [ 83.06239376 109.60897641  79.58813943] tensor(-85.8945, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "41 [ 82.42427507 109.49655192  79.10206816] tensor(-82.9889, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "42 [ 81.78615639 109.38412742  78.6159969 ] tensor(-79.2907, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "43 [ 82.16000004 109.16567918  77.93143771] tensor(-87.2843, dtype=torch.float64) tensor(-10.9458, dtype=torch.float64) False\n",
      "44 [ 81.52188135 109.05325469  77.44536644] tensor(-83.0218, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "45 [ 80.88376266 108.9408302   76.95929518] tensor(-79.3067, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "46 [ 80.24564398 108.82840571  76.47322391] tensor(-76.1467, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "47 [ 80.80366882 108.30549599  76.20625255] tensor(-95.1280, dtype=torch.float64) tensor(-21.0835, dtype=torch.float64) False\n",
      "48 [ 80.05105044 108.36991852  75.91382255] tensor(-91.0155, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "49 [ 79.9291197  108.7937489   76.59323458] tensor(-109.1398, dtype=torch.float64) tensor(-19.2322, dtype=torch.float64) False\n",
      "50 [ 79.17650132 108.85817144  76.30080457] tensor(-104.6251, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "51 [ 79.55034497 108.6397232   75.61624538] tensor(-122.7206, dtype=torch.float64) tensor(-20.6475, dtype=torch.float64) False\n",
      "52 [ 78.79772659 108.70414573  75.32381538] tensor(-116.6379, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "53 [ 78.04510821 108.76856826  75.03138537] tensor(-111.7212, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "54 [ 77.29248983 108.8329908   74.73895537] tensor(-103.3474, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "55 [ 76.51856667 109.06051125  74.66562464] tensor(-94.5328, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "56 [ 76.71592718 108.29058186  74.82169372] tensor(-110.7947, dtype=torch.float64) tensor(-24.2776, dtype=torch.float64) False\n",
      "57 [ 75.94200403 108.51810231  74.748363  ] tensor(-103.7913, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "58 [ 75.16808088 108.74562276  74.67503227] tensor(-101.4621, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "59 [ 75.16808088 108.74562276  74.67503227] tensor(-117.5717, dtype=torch.float64) tensor(-16.9025, dtype=torch.float64) False\n",
      "60 [ 74.39415772 108.97314321  74.60170154] tensor(-114.9769, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61 [ 73.62023457 109.20066367  74.52837082] tensor(-112.6397, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "62 [ 72.84631141 109.42818412  74.45504009] tensor(-110.5932, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "63 [ 72.07238826 109.65570457  74.38170937] tensor(-108.2130, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "64 [ 71.43734899 110.15697215  74.34226391] tensor(-105.3460, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "65 [ 70.70282247 109.8290415   74.43730217] tensor(-107.5030, dtype=torch.float64) tensor(-5.9714, dtype=torch.float64) False\n",
      "66 [ 70.0677832  110.33030908  74.39785671] tensor(-99.9086, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "67 [ 69.50975836 110.8532188   74.66482807] tensor(-90.7061, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "68 [ 68.95173352 111.37612851  74.93179943] tensor(-79.2692, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "69 [ 69.53111404 111.19937581  75.46955095] tensor(-88.6336, dtype=torch.float64) tensor(-20.6924, dtype=torch.float64) False\n",
      "70 [ 68.9730892  111.72228552  75.73652231] tensor(-75.6650, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "71 [ 68.41506435 112.24519524  76.00349367] tensor(-62.9620, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "72 [ 67.83568384 112.42194795  75.46574214] tensor(-60.5148, dtype=torch.float64) tensor(-8.4507, dtype=torch.float64) False\n",
      "73 [ 68.41506435 112.24519524  76.00349367] tensor(-62.6372, dtype=torch.float64) tensor(-13.0602, dtype=torch.float64) False\n",
      "74 [ 68.0442707  112.72941861  76.53654132] tensor(-52.2518, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "75 [ 67.70965468 112.93539636  75.82822975] tensor(-55.5053, dtype=torch.float64) tensor(-12.9943, dtype=torch.float64) False\n",
      "76 [ 67.37503865 113.14137412  75.11991818] tensor(-59.0605, dtype=torch.float64) tensor(-15.5436, dtype=torch.float64) False\n",
      "77 [ 67.25310792 113.5652045   75.79933021] tensor(-45.1281, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "78 [ 66.82689733 114.00791707  75.27164649] tensor(-46.7758, dtype=torch.float64) tensor(-12.7172, dtype=torch.float64) False\n",
      "79 [ 66.91833585 113.35711533  74.798153  ] tensor(-56.2045, dtype=torch.float64) tensor(-19.7233, dtype=torch.float64) False\n",
      "80 [ 66.78380529 112.61495779  74.50285025] tensor(-65.7146, dtype=torch.float64) tensor(-20.4595, dtype=torch.float64) False\n",
      "81 [ 67.18169972 112.98243931  75.10512706] tensor(-53.5189, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "82 [ 67.57959415 113.34992084  75.70740387] tensor(-41.0557, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "83 [ 67.00021364 113.52667355  75.16965234] tensor(-47.8475, dtype=torch.float64) tensor(-17.7378, dtype=torch.float64) False\n",
      "84 [ 67.56231387 113.98815145  74.81302723] tensor(-43.2087, dtype=torch.float64) tensor(-7.0855, dtype=torch.float64) False\n",
      "85 [ 67.00021364 113.52667355  75.16965234] tensor(-42.1876, dtype=torch.float64) tensor(-10.7186, dtype=torch.float64) False\n",
      "86 [ 67.63833233 113.63909804  75.65572361] tensor(-30.5226, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "87 [ 68.27645101 113.75152253  76.14179487] tensor(-21.9758, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "88 [ 68.85583153 113.57476982  76.6795464 ] tensor(-14.6623, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "89 [ 68.6329143  114.21669289  76.23870325] tensor(-19.3839, dtype=torch.float64) tensor(-9.4793, dtype=torch.float64) False\n",
      "90 [ 68.6329143  114.21669289  76.23870325] tensor(-18.8468, dtype=torch.float64) tensor(-5.8452, dtype=torch.float64) False\n",
      "91 [ 68.52121781 113.41475104  76.26135626] tensor(-18.8619, dtype=torch.float64) tensor(-5.8603, dtype=torch.float64) False\n",
      "92 [ 67.90255032 112.91433644  76.10991068] tensor(-25.5384, dtype=torch.float64) tensor(-11.6552, dtype=torch.float64) False\n",
      "93 [ 68.6551687  112.8499139   76.40234068] tensor(-18.5966, dtype=torch.float64) tensor(0.4858, dtype=torch.float64) False\n",
      "94 [ 69.02901235 112.63146566  75.71778149] tensor(-21.2995, dtype=torch.float64) tensor(-8.0733, dtype=torch.float64) False\n",
      "95 [ 69.45851992 112.71751286  76.39911777] tensor(-15.0513, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "96 [ 70.09663861 112.82993736  76.88518904] tensor(-9.1883, dtype=torch.float64) tensor(0.9289, dtype=torch.float64) False\n",
      "97 [ 70.52614618 112.91598455  77.56652532] tensor(-4.6388, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "98 [ 70.09993558 113.35869713  77.0388416 ] tensor(-7.6868, dtype=torch.float64) tensor(-5.4401, dtype=torch.float64) False\n",
      "99 [ 70.52944315 113.44474433  77.72017788] tensor(-3.1925, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "100 [ 71.10882367 113.26799162  78.25792941] tensor(-0.1411, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "101 [ 71.75440991 112.89714562  78.57697744] tensor(0.4813, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "Defi stopped at/close to the terminal state!\n",
      "102 [ 72.08902593 112.69116786  79.28528901] tensor(-0.0143, dtype=torch.float64) tensor(-0.0143, dtype=torch.float64) False\n",
      "Defi stopped at/close to the terminal state!\n",
      "Defi stopped at/close to the terminal state!\n",
      "103 [ 72.08902593 112.69116786  79.28528901] 1.0 1.0 True\n",
      "5 -5499.989241535338\n",
      "Replay memory ready\n"
     ]
    }
   ],
   "source": [
    "state = env.reset().getValue()\n",
    "agent = Agent(n_actions=n_actions, inp_size=state.shape, device=device, hidden=10, gamma=0.9, agent_history_length=agent_history_length, memory_size=replay_memory_size, batch_size=32, learning_rate=learning_rate)\n",
    "\n",
    "overall_runs = 0\n",
    "overall_reward = []\n",
    "while agent.replay_memory.current < 400:\n",
    "    state = env.reset()\n",
    "    #episode_step_counter = 0\n",
    "    episode_reward = 0\n",
    "    terminal = False\n",
    "    print(\"New run\")\n",
    "    print(env.stepCounter, state.getCoordinate().numpy())\n",
    "    while not terminal:\n",
    "        #print(env.stepCounter)\n",
    "        action, optimal_reward = get_best_action(state,env)\n",
    "        if np.random.rand(1) < 0.5: \n",
    "            action = np.random.randint(0, n_actions)\n",
    "        next_state, reward, terminal = env.step(action)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #terminal = False\n",
    "\n",
    "        current_index = np.min([env.stepCounter,len(env.referenceStreamline_ijk)-1])\n",
    "        #path_vector = (next_state.getCoordinate() - state.getCoordinate()).squeeze(0)\n",
    "        #reference_vector = env.referenceStreamline_ijk[current_index]-env.referenceStreamline_ijk[current_index-1]\n",
    "        #    #print(path_vector, reference_vector)\n",
    "        #cosine_sim = cos(path_vector, reference_vector)\n",
    "        dist = torch.sum((env.referenceStreamline_ijk[current_index] - next_state.getCoordinate())**2)\n",
    "        #if dist > 3*0.81:\n",
    "        #    env.stepCounter -= 1\n",
    "        #if dist < 0.1:\n",
    "        #    dist = 0\n",
    "        #else:\n",
    "        #    dist = dist - 0.1\n",
    "        #reward = cosine_sim - dist\n",
    "        reward_old = 1 - (optimal_reward - reward)\n",
    "        print(env.stepCounter, next_state.getCoordinate().numpy(), reward, reward_old, terminal)\n",
    "        #if action == 100 and dist==0:\n",
    "        #    terminal = True\n",
    "\n",
    "        #if env.stepCounter == 200:\n",
    "        #    terminal = True\n",
    "            \n",
    "        agent.replay_memory.add_experience(action=action,\n",
    "                                state = state.getValue(),\n",
    "                                reward=reward_old,\n",
    "                                new_state = next_state.getValue(),\n",
    "                                terminal=terminal)\n",
    "        \n",
    "        episode_reward += reward_old\n",
    "        \n",
    "        state = next_state\n",
    "        \n",
    "        if terminal == True:\n",
    "            overall_runs += 1\n",
    "            overall_reward.append(episode_reward)\n",
    "            print(overall_runs, np.mean(overall_reward[-100:]))\n",
    "print(\"Replay memory ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terminal = False\n",
    "index = 0\n",
    "while not terminal:\n",
    "    states.append(agent.replay_memory.states[index])\n",
    "    actions.append()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Not enough memories to get a minibatch",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-adac9d7c299f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminal_flags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplay_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_minibatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/fibre_tracking/deepFibreTracking/dfibert/tracker/nn/rl.py\u001b[0m in \u001b[0;36mget_minibatch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \"\"\"\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Not enough memories to get a minibatch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Not enough memories to get a minibatch"
     ]
    }
   ],
   "source": [
    "states, actions, rewards, next_states, terminal_flags = agent.replay_memory.get_minibatch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 -33.590794\n",
      "47 1.0\n",
      "66 1.0\n",
      "35 1.0\n",
      "21 1.0\n",
      "58 1.0\n",
      "48 -98.96326\n",
      "97 1.0\n",
      "39 1.0\n",
      "86 -114.20049\n",
      "15 1.0\n",
      "23 1.0\n",
      "89 1.0\n",
      "13 1.0\n",
      "74 1.0\n",
      "23 1.0\n",
      "34 1.0\n",
      "100 1.0\n",
      "12 1.0\n",
      "16 1.0\n",
      "67 -90.898346\n",
      "66 1.0\n",
      "77 1.0\n",
      "20 1.0\n",
      "84 1.0\n",
      "65 1.0\n",
      "75 1.0\n",
      "81 -78.17227\n",
      "100 1.0\n",
      "47 1.0\n",
      "38 1.0\n",
      "8 1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(actions)):\n",
    "    \n",
    "    print(actions[i], rewards[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(87) tensor(1., dtype=torch.float64)\n",
      "tensor(74) tensor(1., dtype=torch.float64)\n",
      "tensor(74) tensor(1., dtype=torch.float64)\n",
      "tensor(95) tensor(1., dtype=torch.float64)\n",
      "26 tensor(-0.0516, dtype=torch.float64)\n",
      "16 tensor(-5.0898, dtype=torch.float64)\n",
      "tensor(74) tensor(1., dtype=torch.float64)\n",
      "tensor(74) tensor(1., dtype=torch.float64)\n",
      "tensor(74) tensor(1., dtype=torch.float64)\n",
      "23 tensor(-4.8973, dtype=torch.float64)\n",
      "tensor(66) tensor(1., dtype=torch.float64)\n",
      "52 tensor(-2.4171, dtype=torch.float64)\n",
      "56 tensor(-0.4509, dtype=torch.float64)\n",
      "tensor(74) tensor(1., dtype=torch.float64)\n",
      "tensor(61) tensor(1., dtype=torch.float64)\n",
      "tensor(82) tensor(1., dtype=torch.float64)\n",
      "76 tensor(-6.9983, dtype=torch.float64)\n",
      "96 tensor(-11.1269, dtype=torch.float64)\n",
      "tensor(82) tensor(1., dtype=torch.float64)\n",
      "tensor(82) tensor(1., dtype=torch.float64)\n",
      "2 tensor(-11.4447, dtype=torch.float64)\n",
      "58 tensor(-5.5460, dtype=torch.float64)\n",
      "tensor(90) tensor(1., dtype=torch.float64)\n",
      "58 tensor(-7.6450, dtype=torch.float64)\n",
      "21 tensor(-13.7875, dtype=torch.float64)\n",
      "tensor(90) tensor(1., dtype=torch.float64)\n",
      "78 tensor(-23.3532, dtype=torch.float64)\n",
      "tensor(90) tensor(1., dtype=torch.float64)\n",
      "tensor(90) tensor(1., dtype=torch.float64)\n",
      "tensor(90) tensor(1., dtype=torch.float64)\n",
      "54 tensor(-12.5380, dtype=torch.float64)\n",
      "tensor(98) tensor(1., dtype=torch.float64)\n",
      "tensor(98) tensor(1., dtype=torch.float64)\n",
      "70 tensor(-23.8422, dtype=torch.float64)\n",
      "tensor(44) tensor(1., dtype=torch.float64)\n",
      "tensor(44) tensor(1., dtype=torch.float64)\n",
      "tensor(31) tensor(1., dtype=torch.float64)\n",
      "tensor(31) tensor(1., dtype=torch.float64)\n",
      "43 tensor(-26.8080, dtype=torch.float64)\n",
      "tensor(31) tensor(1., dtype=torch.float64)\n",
      "tensor(31) tensor(1., dtype=torch.float64)\n",
      "tensor(31) tensor(1., dtype=torch.float64)\n",
      "tensor(31) tensor(1., dtype=torch.float64)\n",
      "tensor(26) tensor(1., dtype=torch.float64)\n",
      "63 tensor(-31.4326, dtype=torch.float64)\n",
      "80 tensor(-8.2605, dtype=torch.float64)\n",
      "tensor(26) tensor(1., dtype=torch.float64)\n",
      "tensor(26) tensor(1., dtype=torch.float64)\n",
      "36 tensor(-6.9691, dtype=torch.float64)\n",
      "tensor(26) tensor(1., dtype=torch.float64)\n",
      "30 tensor(-28.7272, dtype=torch.float64)\n",
      "tensor(26) tensor(1., dtype=torch.float64)\n",
      "tensor(13) tensor(1., dtype=torch.float64)\n",
      "62 tensor(-20.8588, dtype=torch.float64)\n",
      "64 tensor(-18.3900, dtype=torch.float64)\n",
      "51 tensor(-34.5201, dtype=torch.float64)\n",
      "tensor(13) tensor(1., dtype=torch.float64)\n",
      "tensor(13) tensor(1., dtype=torch.float64)\n",
      "tensor(13) tensor(1., dtype=torch.float64)\n",
      "3 tensor(-7.1229, dtype=torch.float64)\n",
      "tensor(13) tensor(1., dtype=torch.float64)\n",
      "80 tensor(-10.9215, dtype=torch.float64)\n",
      "tensor(13) tensor(1., dtype=torch.float64)\n",
      "tensor(13) tensor(1., dtype=torch.float64)\n",
      "tensor(13) tensor(1., dtype=torch.float64)\n",
      "12 tensor(-10.8467, dtype=torch.float64)\n",
      "21 tensor(-0.5004, dtype=torch.float64)\n",
      "86 tensor(-20.5187, dtype=torch.float64)\n",
      "tensor(18) tensor(1., dtype=torch.float64)\n",
      "43 tensor(-20.5456, dtype=torch.float64)\n",
      "tensor(13) tensor(1., dtype=torch.float64)\n",
      "45 tensor(-11.5853, dtype=torch.float64)\n",
      "72 tensor(-7.7041, dtype=torch.float64)\n",
      "tensor(18) tensor(1., dtype=torch.float64)\n",
      "68 tensor(-21.9951, dtype=torch.float64)\n",
      "95 tensor(-10.9242, dtype=torch.float64)\n",
      "19 tensor(-11.7694, dtype=torch.float64)\n",
      "tensor(18) tensor(1., dtype=torch.float64)\n",
      "tensor(18) tensor(1., dtype=torch.float64)\n",
      "29 tensor(-3.1502, dtype=torch.float64)\n",
      "91 tensor(-8.7938, dtype=torch.float64)\n",
      "tensor(18) tensor(1., dtype=torch.float64)\n",
      "tensor(18) tensor(1., dtype=torch.float64)\n",
      "tensor(18) tensor(1., dtype=torch.float64)\n",
      "tensor(31) tensor(1., dtype=torch.float64)\n",
      "55 tensor(-7.4275, dtype=torch.float64)\n",
      "84 tensor(-9.0900, dtype=torch.float64)\n",
      "tensor(18) tensor(1., dtype=torch.float64)\n",
      "tensor(18) tensor(1., dtype=torch.float64)\n",
      "tensor(5) tensor(1., dtype=torch.float64)\n",
      "Defi stopped at/close to the terminal state!\n",
      "Defi stopped at/close to the terminal state!\n",
      "tensor(100) 1.0\n"
     ]
    }
   ],
   "source": [
    "state = env.reset()\n",
    "terminal = False\n",
    "all_states = []\n",
    "all_states.append(state.getCoordinate())\n",
    "\n",
    "while not terminal:\n",
    "    action, optimal_reward  = get_best_action(state, env)\n",
    "    if np.random.rand(1) < .5: \n",
    "        action = np.random.randint(0, n_actions)\n",
    "    #print(\"Action:\", action)\n",
    "    next_state, reward, terminal = env.step(action)\n",
    "    #print(\"Step counter: \", env.stepCounter)\n",
    "    current_index = np.min([env.stepCounter,len(env.referenceStreamline_ijk)-1])\n",
    "    #print(\"Current index: \", current_index)\n",
    "    #print(\"state.getCoordinate(): \", state.getCoordinate().numpy())\n",
    "    #print(\"env.state.getCoordinate(): \", env.state.getCoordinate().numpy())\n",
    "    #print(\"next_state.getCoordinate(): \", next_state.getCoordinate().numpy())\n",
    "    #path_vector = next_state.getCoordinate() - state.getCoordinate().squeeze(0)\n",
    "    #print(\"path vector: \", path_vector)\n",
    "    #reference_vector = env.referenceStreamline_ijk[current_index]-env.referenceStreamline_ijk[current_index-1]\n",
    "    #print(\"reference_vector: \", reference_vector)\n",
    "    #cosine_sim = F.cosine_similarity(path_vector, reference_vector, dim=0)\n",
    "    #print(\"cosine_sim: \", cosine_sim)\n",
    "    dist = torch.sum((env.referenceStreamline_ijk[current_index] - next_state.getCoordinate())**2)\n",
    "    #if dist > 3.:\n",
    "    #    env.stepCounter -= 1\n",
    "    #print(\"distance: \", dist)\n",
    "    all_states.append(next_state.getCoordinate())\n",
    "    state = next_state\n",
    "    print(action, 1-(optimal_reward-reward))#cosine_sim.item(), dist.item(), 1-(optimal_reward-(cosine_sim-dist)))\n",
    "    #if action == 100 and 1-(optimal_reward-(cosine_sim-dist)) == 1:\n",
    "    #    terminal = True\n",
    "    #else:\n",
    "    #    terminal = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "200, done 1 episodes, -200.0, current eps 1 200.0\n",
      "400, done 2 episodes, -200.0, current eps 1 200.0\n",
      "600, done 3 episodes, -200.0, current eps 1 200.0\n",
      "800, done 4 episodes, -199.6938458680446, current eps 1 200.0\n",
      "1000, done 5 episodes, -199.6069619252578, current eps 1 200.0\n",
      "1200, done 6 episodes, -199.0946853387038, current eps 1 200.0\n",
      "1400, done 7 episodes, -198.89439511863483, current eps 1 200.0\n",
      "1600, done 8 episodes, -199.03259572880546, current eps 1 200.0\n",
      "1800, done 9 episodes, -198.91805372084576, current eps 1 200.0\n",
      "2000, done 10 episodes, -198.82719350356274, current eps 1 200.0\n",
      "2077, done 11 episodes, -187.52001710350652, current eps 0.999544 188.8181818181818\n",
      "2277, done 12 episodes, -188.52157678042292, current eps 0.998344 189.75\n",
      "2477, done 13 episodes, -189.26190847663977, current eps 0.997144 190.53846153846155\n",
      "2677, done 14 episodes, -190.02891501402266, current eps 0.995944 191.21428571428572\n",
      "2877, done 15 episodes, -190.61524195022628, current eps 0.994744 191.8\n",
      "3077, done 16 episodes, -191.14981592304278, current eps 0.993544 192.3125\n",
      "3147, done 17 episodes, -184.0233561628638, current eps 0.993124 185.11764705882354\n",
      "3347, done 18 episodes, -184.91094748714914, current eps 0.991924 185.94444444444446\n",
      "3547, done 19 episodes, -185.65128608701767, current eps 0.990724 186.68421052631578\n",
      "3747, done 20 episodes, -186.35011332123855, current eps 0.989524 187.35\n",
      "3947, done 21 episodes, -187.0001079249891, current eps 0.988324 187.95238095238096\n",
      "4147, done 22 episodes, -187.5910121102169, current eps 0.987124 188.5\n",
      "4347, done 23 episodes, -188.0316813429508, current eps 0.985924 189.0\n",
      "4547, done 24 episodes, -188.47024735608113, current eps 0.984724 189.45833333333334\n",
      "4747, done 25 episodes, -188.8758017920113, current eps 0.9835240000000001 189.88\n",
      "4947, done 26 episodes, -189.30365556924164, current eps 0.982324 190.26923076923077\n",
      "5147, done 27 episodes, -189.69981647408454, current eps 0.981124 190.62962962962962\n",
      "5347, done 28 episodes, -190.06768017143867, current eps 0.979924 190.96428571428572\n",
      "5547, done 29 episodes, -190.38293674266203, current eps 0.978724 191.27586206896552\n",
      "5747, done 30 episodes, -190.65811989687163, current eps 0.9775240000000001 191.56666666666666\n",
      "5947, done 31 episodes, -190.9594708679403, current eps 0.976324 191.83870967741936\n",
      "6147, done 32 episodes, -191.17372492600498, current eps 0.975124 192.09375\n",
      "6347, done 33 episodes, -191.44118780703513, current eps 0.973924 192.33333333333334\n",
      "6478, done 34 episodes, -189.66350581271058, current eps 0.9731380000000001 190.52941176470588\n",
      "6678, done 35 episodes, -189.9588342180617, current eps 0.971938 190.8\n",
      "6878, done 36 episodes, -190.23775548978222, current eps 0.970738 191.05555555555554\n",
      "6998, done 37 episodes, -188.33943777384215, current eps 0.970018 189.13513513513513\n",
      "7198, done 38 episodes, -188.6462946745305, current eps 0.968818 189.42105263157896\n",
      "7398, done 39 episodes, -188.85217938473804, current eps 0.967618 189.69230769230768\n",
      "7598, done 40 episodes, -189.08741960382514, current eps 0.966418 189.95\n",
      "7798, done 41 episodes, -189.3535801012928, current eps 0.965218 190.1951219512195\n",
      "7998, done 42 episodes, -189.57068098069988, current eps 0.964018 190.42857142857142\n",
      "8198, done 43 episodes, -189.8132232834743, current eps 0.962818 190.65116279069767\n",
      "8398, done 44 episodes, -190.0447409361226, current eps 0.961618 190.86363636363637\n",
      "8598, done 45 episodes, -190.19077756093526, current eps 0.960418 191.06666666666666\n",
      "8798, done 46 episodes, -190.3945960260826, current eps 0.959218 191.2608695652174\n",
      "8998, done 47 episodes, -190.5278392450035, current eps 0.958018 191.4468085106383\n",
      "9198, done 48 episodes, -190.62176292468064, current eps 0.9568180000000001 191.625\n",
      "9398, done 49 episodes, -190.81315551805451, current eps 0.955618 191.79591836734693\n",
      "9598, done 50 episodes, -190.9773809956014, current eps 0.954418 191.96\n",
      "9798, done 51 episodes, -191.11592624013306, current eps 0.953218 192.11764705882354\n",
      "9998, done 52 episodes, -191.24831590608676, current eps 0.952018 192.26923076923077\n",
      "10198, done 53 episodes, -191.39643694204673, current eps 0.950818 192.41509433962264\n",
      "Evaluation score: -195.095300496758\n",
      "0 of 20 episodes ended close to / at the final state.\n",
      "10398, done 54 episodes, -191.53973117547022, current eps 0.949618 192.55555555555554\n",
      "10598, done 55 episodes, -191.66826530417686, current eps 0.948418 192.6909090909091\n",
      "10798, done 56 episodes, -191.81704628088795, current eps 0.947218 192.82142857142858\n",
      "10998, done 57 episodes, -191.87760340773534, current eps 0.946018 192.94736842105263\n",
      "11198, done 58 episodes, -191.9884724693802, current eps 0.944818 193.06896551724137\n",
      "11398, done 59 episodes, -192.11885222585997, current eps 0.9436180000000001 193.1864406779661\n",
      "11598, done 60 episodes, -192.24832350105768, current eps 0.942418 193.3\n",
      "11798, done 61 episodes, -192.33789114379206, current eps 0.941218 193.40983606557376\n",
      "11998, done 62 episodes, -192.46147354469863, current eps 0.940018 193.51612903225808\n",
      "12198, done 63 episodes, -192.56402297887652, current eps 0.938818 193.61904761904762\n",
      "12258, done 64 episodes, -190.46250052058582, current eps 0.938458 191.53125\n",
      "12458, done 65 episodes, -190.60923128180758, current eps 0.937258 191.66153846153847\n",
      "12658, done 66 episodes, -190.75151565632564, current eps 0.9360580000000001 191.78787878787878\n",
      "12858, done 67 episodes, -190.86628280693222, current eps 0.934858 191.91044776119404\n",
      "13058, done 68 episodes, -190.98646582987266, current eps 0.933658 192.02941176470588\n",
      "13258, done 69 episodes, -191.1170967598745, current eps 0.932458 192.14492753623188\n",
      "13446, done 70 episodes, -191.0362388322789, current eps 0.93133 192.0857142857143\n",
      "13646, done 71 episodes, -191.14102204820998, current eps 0.93013 192.19718309859155\n",
      "13846, done 72 episodes, -191.23016601720298, current eps 0.92893 192.30555555555554\n",
      "14046, done 73 episodes, -191.33322960679428, current eps 0.92773 192.41095890410958\n",
      "14246, done 74 episodes, -191.44708351378495, current eps 0.92653 192.51351351351352\n",
      "14446, done 75 episodes, -191.56112240026783, current eps 0.92533 192.61333333333334\n",
      "14646, done 76 episodes, -191.6721602634222, current eps 0.92413 192.71052631578948\n",
      "14846, done 77 episodes, -191.77424486852178, current eps 0.92293 192.80519480519482\n",
      "15046, done 78 episodes, -191.8797032676433, current eps 0.92173 192.89743589743588\n",
      "15246, done 79 episodes, -191.9769595001666, current eps 0.9205300000000001 192.9873417721519\n",
      "15446, done 80 episodes, -192.07113927107548, current eps 0.91933 193.075\n",
      "15646, done 81 episodes, -192.1690264405684, current eps 0.91813 193.1604938271605\n",
      "15846, done 82 episodes, -192.26452611812243, current eps 0.91693 193.2439024390244\n",
      "16046, done 83 episodes, -192.35379683103568, current eps 0.91573 193.32530120481928\n",
      "16246, done 84 episodes, -192.4215276838414, current eps 0.9145300000000001 193.4047619047619\n",
      "16446, done 85 episodes, -192.4920864075659, current eps 0.91333 193.48235294117646\n",
      "16646, done 86 episodes, -192.57938772840816, current eps 0.91213 193.5581395348837\n",
      "16846, done 87 episodes, -192.6490227654972, current eps 0.91093 193.632183908046\n",
      "17046, done 88 episodes, -192.72637632167996, current eps 0.90973 193.70454545454547\n",
      "17246, done 89 episodes, -192.80810243042512, current eps 0.9085300000000001 193.77528089887642\n",
      "17446, done 90 episodes, -192.8797333889558, current eps 0.90733 193.84444444444443\n",
      "17646, done 91 episodes, -192.95797807698926, current eps 0.90613 193.9120879120879\n",
      "17846, done 92 episodes, -193.0295994591364, current eps 0.90493 193.97826086956522\n",
      "18046, done 93 episodes, -193.0855689911466, current eps 0.90373 194.04301075268816\n",
      "18246, done 94 episodes, -193.156141528101, current eps 0.90253 194.10638297872342\n",
      "18398, done 95 episodes, -192.71433190120564, current eps 0.901618 193.66315789473686\n",
      "18598, done 96 episodes, -192.78957147073865, current eps 0.900418 193.72916666666666\n",
      "18638, done 97 episodes, -191.21442124939082, current eps 0.900178 192.1443298969072\n",
      "18838, done 98 episodes, -191.2870122999138, current eps 0.898978 192.22448979591837\n",
      "19038, done 99 episodes, -191.34864716953984, current eps 0.897778 192.3030303030303\n",
      "19238, done 100 episodes, -191.4195432984691, current eps 0.896578 192.38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19438, done 101 episodes, -191.38703345188296, current eps 0.895378 192.38\n",
      "19638, done 102 episodes, -191.38703345188296, current eps 0.894178 192.38\n",
      "19838, done 103 episodes, -191.36844094196996, current eps 0.892978 192.38\n",
      "20038, done 104 episodes, -191.3806871072482, current eps 0.891778 192.38\n",
      "20238, done 105 episodes, -191.37633103627783, current eps 0.890578 192.38\n",
      "Evaluation score: -195.32131847258228\n",
      "0 of 20 episodes ended close to / at the final state.\n",
      "20438, done 106 episodes, -191.40127096389313, current eps 0.889378 192.38\n",
      "20638, done 107 episodes, -191.40963276107698, current eps 0.888178 192.38\n",
      "20838, done 108 episodes, -191.3949738795899, current eps 0.886978 192.38\n",
      "21038, done 109 episodes, -191.41495670301822, current eps 0.885778 192.38\n",
      "21238, done 110 episodes, -191.3970180048894, current eps 0.884578 192.38\n",
      "21438, done 111 episodes, -192.65253547385998, current eps 0.883378 193.61\n",
      "21638, done 112 episodes, -192.65500022134896, current eps 0.882178 193.61\n",
      "21838, done 113 episodes, -192.64315317279394, current eps 0.880978 193.61\n",
      "22038, done 114 episodes, -192.63788149089095, current eps 0.879778 193.61\n",
      "22238, done 115 episodes, -192.63436231779505, current eps 0.878578 193.61\n",
      "22438, done 116 episodes, -192.64267806264215, current eps 0.877378 193.61\n",
      "22638, done 117 episodes, -193.91821005192327, current eps 0.876178 194.91\n",
      "22781, done 118 episodes, -193.31450060898845, current eps 0.87532 194.34\n",
      "22981, done 119 episodes, -193.31014740776507, current eps 0.87412 194.34\n",
      "23181, done 120 episodes, -193.31386910005074, current eps 0.87292 194.34\n",
      "23381, done 121 episodes, -193.30532810866623, current eps 0.87172 194.34\n",
      "23581, done 122 episodes, -193.29717037839666, current eps 0.87052 194.34\n",
      "23781, done 123 episodes, -193.31372701556225, current eps 0.86932 194.34\n",
      "23981, done 124 episodes, -193.3008875578971, current eps 0.86812 194.34\n",
      "24181, done 125 episodes, -193.2979080034543, current eps 0.86692 194.34\n",
      "24381, done 126 episodes, -193.29650216955633, current eps 0.86572 194.34\n",
      "24581, done 127 episodes, -193.25968707971282, current eps 0.86452 194.34\n",
      "24781, done 128 episodes, -193.25968707971282, current eps 0.86332 194.34\n",
      "24981, done 129 episodes, -193.26067206612265, current eps 0.86212 194.34\n",
      "25181, done 130 episodes, -193.25928056036645, current eps 0.86092 194.34\n",
      "25381, done 131 episodes, -193.25928056036645, current eps 0.85972 194.34\n",
      "25581, done 132 episodes, -193.28070597171268, current eps 0.85852 194.34\n",
      "25781, done 133 episodes, -193.2807059717127, current eps 0.85732 194.34\n",
      "25981, done 134 episodes, -193.93204425208597, current eps 0.85612 195.03\n",
      "26181, done 135 episodes, -193.9202181640906, current eps 0.85492 195.03\n",
      "26381, done 136 episodes, -193.87454019059828, current eps 0.85372 195.03\n",
      "26581, done 137 episodes, -194.67454019059832, current eps 0.85252 195.83\n",
      "26781, done 138 episodes, -194.67454019059826, current eps 0.85132 195.83\n",
      "26981, done 139 episodes, -194.6915709952265, current eps 0.85012 195.83\n",
      "27181, done 140 episodes, -194.7089531137443, current eps 0.84892 195.83\n",
      "27381, done 141 episodes, -194.6920332035757, current eps 0.84772 195.83\n",
      "27581, done 142 episodes, -194.70731503321178, current eps 0.8465199999999999 195.83\n",
      "27781, done 143 episodes, -194.70302365600296, current eps 0.8453200000000001 195.83\n",
      "27981, done 144 episodes, -194.66577047327866, current eps 0.84412 195.83\n",
      "28181, done 145 episodes, -194.69960658275173, current eps 0.84292 195.83\n",
      "28381, done 146 episodes, -194.6807610581922, current eps 0.84172 195.83\n",
      "28581, done 147 episodes, -194.69622708809777, current eps 0.84052 195.83\n",
      "28781, done 148 episodes, -194.68806764865622, current eps 0.8393200000000001 195.83\n",
      "28981, done 149 episodes, -194.67661455157932, current eps 0.83812 195.83\n",
      "29181, done 150 episodes, -194.65255481733925, current eps 0.83692 195.83\n",
      "29381, done 151 episodes, -194.67212293267212, current eps 0.83572 195.83\n",
      "29581, done 152 episodes, -194.6565700556903, current eps 0.83452 195.83\n",
      "29781, done 153 episodes, -194.6655827475707, current eps 0.8333200000000001 195.83\n",
      "29981, done 154 episodes, -194.67423949210155, current eps 0.83212 195.83\n",
      "30181, done 155 episodes, -194.68814840955815, current eps 0.83092 195.83\n",
      "30381, done 156 episodes, -194.6428390017923, current eps 0.82972 195.83\n",
      "Evaluation score: -195.26956628241464\n",
      "0 of 20 episodes ended close to / at the final state.\n",
      "30581, done 157 episodes, -194.68160998529595, current eps 0.82852 195.83\n",
      "30781, done 158 episodes, -194.6985298954646, current eps 0.82732 195.83\n",
      "30981, done 159 episodes, -194.69765746067355, current eps 0.82612 195.83\n",
      "31181, done 160 episodes, -194.69878617329633, current eps 0.82492 195.83\n",
      "31381, done 161 episodes, -194.70651366669838, current eps 0.82372 195.83\n",
      "31581, done 162 episodes, -194.698575744308, current eps 0.82252 195.83\n",
      "31781, done 163 episodes, -194.66337720515173, current eps 0.82132 195.83\n",
      "31981, done 164 episodes, -196.05726815084614, current eps 0.82012 197.23\n",
      "32181, done 165 episodes, -196.03103464623993, current eps 0.81892 197.23\n",
      "32381, done 166 episodes, -196.03103464623993, current eps 0.81772 197.23\n",
      "32581, done 167 episodes, -196.04662549877023, current eps 0.81652 197.23\n",
      "32781, done 168 episodes, -195.99272261819996, current eps 0.81532 197.23\n",
      "32981, done 169 episodes, -195.95332537697857, current eps 0.81412 197.23\n",
      "33181, done 170 episodes, -196.0818748939068, current eps 0.81292 197.35\n",
      "33381, done 171 episodes, -196.04315451075027, current eps 0.81172 197.35\n",
      "33494, done 172 episodes, -195.1926869348595, current eps 0.811042 196.48\n",
      "33694, done 173 episodes, -195.20514885428577, current eps 0.809842 196.48\n",
      "33894, done 174 episodes, -195.18889854543266, current eps 0.808642 196.48\n",
      "34094, done 175 episodes, -195.18889854543266, current eps 0.807442 196.48\n",
      "34294, done 176 episodes, -195.1726859482781, current eps 0.806242 196.48\n",
      "34494, done 177 episodes, -195.14559084471273, current eps 0.805042 196.48\n",
      "34694, done 178 episodes, -195.14184857138093, current eps 0.803842 196.48\n",
      "34894, done 179 episodes, -195.1462191150111, current eps 0.802642 196.48\n",
      "35094, done 180 episodes, -195.1307993722927, current eps 0.801442 196.48\n",
      "35294, done 181 episodes, -195.11689045483607, current eps 0.800242 196.48\n",
      "35494, done 182 episodes, -195.10542819071208, current eps 0.799042 196.48\n",
      "35694, done 183 episodes, -195.0950645973644, current eps 0.7978419999999999 196.48\n",
      "35894, done 184 episodes, -195.1144535259772, current eps 0.7966420000000001 196.48\n",
      "36094, done 185 episodes, -195.086134542242, current eps 0.795442 196.48\n",
      "36294, done 186 episodes, -195.086134542242, current eps 0.794242 196.48\n",
      "36494, done 187 episodes, -195.09975818269046, current eps 0.793042 196.48\n",
      "36694, done 188 episodes, -195.09635497509242, current eps 0.791842 196.48\n",
      "36894, done 189 episodes, -195.07444852871217, current eps 0.7906420000000001 196.48\n",
      "37094, done 190 episodes, -195.07737109407557, current eps 0.789442 196.48\n",
      "37294, done 191 episodes, -195.06720156086993, current eps 0.788242 196.48\n",
      "37494, done 192 episodes, -195.07173010852478, current eps 0.787042 196.48\n",
      "37694, done 193 episodes, -195.03575406884195, current eps 0.785842 196.48\n",
      "37894, done 194 episodes, -195.0210151438303, current eps 0.7846420000000001 196.48\n",
      "38094, done 195 episodes, -195.47028481847946, current eps 0.783442 196.96\n",
      "38294, done 196 episodes, -195.47091151271567, current eps 0.782242 196.96\n",
      "38494, done 197 episodes, -197.0709115127157, current eps 0.781042 198.56\n",
      "38547, done 198 episodes, -195.61670303367723, current eps 0.780724 197.09\n",
      "38603, done 199 episodes, -194.2028143897483, current eps 0.780388 195.65\n",
      "38803, done 200 episodes, -194.20263520501453, current eps 0.779188 195.65\n",
      "39003, done 201 episodes, -194.21822137815442, current eps 0.777988 195.65\n",
      "39203, done 202 episodes, -194.20687130387682, current eps 0.776788 195.65\n",
      "39403, done 203 episodes, -194.1847539913542, current eps 0.7755879999999999 195.65\n",
      "39603, done 204 episodes, -194.16744710491847, current eps 0.774388 195.65\n",
      "39803, done 205 episodes, -194.10629726582502, current eps 0.773188 195.65\n",
      "40003, done 206 episodes, -194.07867845482716, current eps 0.771988 195.65\n",
      "40203, done 207 episodes, -194.09339011966114, current eps 0.770788 195.65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40403, done 208 episodes, -194.0979695255004, current eps 0.7695879999999999 195.65\n",
      "Evaluation score: -184.7861879811921\n",
      "0 of 20 episodes ended close to / at the final state.\n",
      "40603, done 209 episodes, -194.0592371966606, current eps 0.7683880000000001 195.65\n",
      "40803, done 210 episodes, -194.08251489661342, current eps 0.767188 195.65\n",
      "41003, done 211 episodes, -194.05391804221316, current eps 0.765988 195.65\n",
      "41203, done 212 episodes, -194.04078137080967, current eps 0.764788 195.65\n",
      "41403, done 213 episodes, -194.027195911323, current eps 0.763588 195.65\n",
      "41603, done 214 episodes, -194.01471358426178, current eps 0.7623880000000001 195.65\n",
      "41803, done 215 episodes, -194.0251446029187, current eps 0.761188 195.65\n",
      "42003, done 216 episodes, -193.99653569344503, current eps 0.759988 195.65\n",
      "42203, done 217 episodes, -194.00528066746972, current eps 0.758788 195.65\n",
      "42403, done 218 episodes, -194.55349333100546, current eps 0.7575879999999999 196.22\n",
      "42603, done 219 episodes, -194.53710822645348, current eps 0.7563880000000001 196.22\n",
      "42803, done 220 episodes, -194.48444400956114, current eps 0.755188 196.22\n",
      "43003, done 221 episodes, -194.48044602657575, current eps 0.753988 196.22\n",
      "43203, done 222 episodes, -194.4886037568453, current eps 0.752788 196.22\n",
      "43231, done 223 episodes, -192.77478307504873, current eps 0.7526200000000001 194.5\n",
      "43431, done 224 episodes, -192.80204987613308, current eps 0.75142 194.5\n",
      "43631, done 225 episodes, -192.81893834803253, current eps 0.75022 194.5\n",
      "43831, done 226 episodes, -192.7880198783763, current eps 0.74902 194.5\n",
      "44031, done 227 episodes, -192.79983852415936, current eps 0.7478199999999999 194.5\n",
      "44231, done 228 episodes, -192.76092255379376, current eps 0.7466200000000001 194.5\n",
      "44431, done 229 episodes, -192.75255453037866, current eps 0.74542 194.5\n",
      "44631, done 230 episodes, -192.7398986952131, current eps 0.74422 194.5\n",
      "44831, done 231 episodes, -192.66827474899182, current eps 0.74302 194.5\n",
      "45031, done 232 episodes, -192.64882708063732, current eps 0.7418199999999999 194.5\n",
      "45231, done 233 episodes, -192.61861426223498, current eps 0.7406200000000001 194.5\n",
      "45431, done 234 episodes, -192.65727598186172, current eps 0.73942 194.5\n",
      "45631, done 235 episodes, -192.6327200325247, current eps 0.73822 194.5\n",
      "45831, done 236 episodes, -192.6422305466832, current eps 0.73702 194.5\n",
      "45981, done 237 episodes, -192.14223054668324, current eps 0.73612 194.0\n",
      "46181, done 238 episodes, -192.14019340770304, current eps 0.73492 194.0\n",
      "46381, done 239 episodes, -192.13482574234536, current eps 0.7337199999999999 194.0\n",
      "46581, done 240 episodes, -192.12338638707396, current eps 0.7325200000000001 194.0\n",
      "46781, done 241 episodes, -192.14030629724255, current eps 0.73132 194.0\n",
      "46981, done 242 episodes, -192.1227612468794, current eps 0.73012 194.0\n",
      "47181, done 243 episodes, -192.1073119043339, current eps 0.72892 194.0\n",
      "47381, done 244 episodes, -192.14456508705817, current eps 0.7277199999999999 194.0\n",
      "47581, done 245 episodes, -192.10873801627378, current eps 0.72652 194.0\n",
      "47781, done 246 episodes, -192.07666783810805, current eps 0.72532 194.0\n",
      "47981, done 247 episodes, -192.05125159682623, current eps 0.72412 194.0\n",
      "48181, done 248 episodes, -192.10374492044863, current eps 0.72292 194.0\n",
      "48381, done 249 episodes, -192.10544231147958, current eps 0.72172 194.0\n",
      "48535, done 250 episodes, -191.6792577517656, current eps 0.720796 193.54\n",
      "48735, done 251 episodes, -191.66925775176557, current eps 0.719596 193.54\n",
      "48935, done 252 episodes, -191.6800562753523, current eps 0.718396 193.54\n",
      "49135, done 253 episodes, -191.67307276201677, current eps 0.717196 193.54\n",
      "49335, done 254 episodes, -191.67307276201677, current eps 0.7159960000000001 193.54\n",
      "49535, done 255 episodes, -191.67307276201677, current eps 0.714796 193.54\n",
      "49735, done 256 episodes, -191.67594195337773, current eps 0.713596 193.54\n",
      "49935, done 257 episodes, -191.6781622370878, current eps 0.712396 193.54\n",
      "50135, done 258 episodes, -191.6540737175471, current eps 0.7111959999999999 193.54\n",
      "50335, done 259 episodes, -191.6405923209582, current eps 0.7099960000000001 193.54\n",
      "50535, done 260 episodes, -191.6212581774409, current eps 0.708796 193.54\n",
      "Evaluation score: -83.6314426980479\n",
      "0 of 20 episodes ended close to / at the final state.\n",
      "50735, done 261 episodes, -191.63023176094083, current eps 0.707596 193.54\n",
      "50935, done 262 episodes, -191.5801588315011, current eps 0.706396 193.54\n",
      "51135, done 263 episodes, -191.62613649167832, current eps 0.7051959999999999 193.54\n",
      "51335, done 264 episodes, -191.63348751515366, current eps 0.7039960000000001 193.54\n",
      "51535, done 265 episodes, -191.63973819633148, current eps 0.702796 193.54\n",
      "51735, done 266 episodes, -191.62576962283728, current eps 0.701596 193.54\n",
      "51935, done 267 episodes, -191.62576962283728, current eps 0.700396 193.54\n",
      "52135, done 268 episodes, -191.68928521973876, current eps 0.6991959999999999 193.54\n",
      "52335, done 269 episodes, -191.71025677796626, current eps 0.6979960000000001 193.54\n",
      "52535, done 270 episodes, -191.72713684275624, current eps 0.696796 193.54\n",
      "52735, done 271 episodes, -191.7810987542789, current eps 0.695596 193.54\n",
      "52935, done 272 episodes, -192.65597245201263, current eps 0.694396 194.41\n",
      "53135, done 273 episodes, -192.65597245201263, current eps 0.6931959999999999 194.41\n",
      "53335, done 274 episodes, -192.67463857362472, current eps 0.691996 194.41\n",
      "53535, done 275 episodes, -192.6681214557561, current eps 0.690796 194.41\n",
      "53735, done 276 episodes, -192.67508257327827, current eps 0.689596 194.41\n",
      "53935, done 277 episodes, -192.6972068275603, current eps 0.688396 194.41\n",
      "54135, done 278 episodes, -192.70015179404584, current eps 0.687196 194.41\n",
      "54335, done 279 episodes, -192.6943918414124, current eps 0.685996 194.41\n",
      "54535, done 280 episodes, -192.71469817240202, current eps 0.684796 194.41\n",
      "54735, done 281 episodes, -192.716659591375, current eps 0.683596 194.41\n",
      "54935, done 282 episodes, -192.70952788232987, current eps 0.682396 194.41\n",
      "55135, done 283 episodes, -192.71520551082406, current eps 0.681196 194.41\n",
      "55335, done 284 episodes, -192.69605055402673, current eps 0.679996 194.41\n",
      "55535, done 285 episodes, -192.72164337411883, current eps 0.678796 194.41\n",
      "55735, done 286 episodes, -192.6347573706991, current eps 0.677596 194.41\n",
      "55935, done 287 episodes, -192.6005608402376, current eps 0.676396 194.41\n",
      "56135, done 288 episodes, -192.5552428786082, current eps 0.675196 194.41\n",
      "56335, done 289 episodes, -192.57714932498843, current eps 0.673996 194.41\n",
      "56535, done 290 episodes, -192.58167787264318, current eps 0.672796 194.41\n",
      "56735, done 291 episodes, -192.56773188832125, current eps 0.6715960000000001 194.41\n",
      "56935, done 292 episodes, -192.5347084803698, current eps 0.670396 194.41\n",
      "57135, done 293 episodes, -192.58400113026883, current eps 0.669196 194.41\n",
      "57335, done 294 episodes, -192.5362969413896, current eps 0.667996 194.41\n",
      "57535, done 295 episodes, -192.53925419459355, current eps 0.6667959999999999 194.41\n",
      "57735, done 296 episodes, -192.51859601869842, current eps 0.6655960000000001 194.41\n",
      "57935, done 297 episodes, -192.44541489786215, current eps 0.664396 194.41\n",
      "58135, done 298 episodes, -193.9038009605243, current eps 0.663196 195.88\n",
      "58335, done 299 episodes, -195.30217986380615, current eps 0.661996 197.32\n",
      "58535, done 300 episodes, -195.29903754730267, current eps 0.6607959999999999 197.32\n",
      "58735, done 301 episodes, -195.2770452503833, current eps 0.6595960000000001 197.32\n",
      "58935, done 302 episodes, -195.28709042559314, current eps 0.658396 197.32\n",
      "59135, done 303 episodes, -195.31028520104522, current eps 0.657196 197.32\n",
      "59335, done 304 episodes, -195.3145486771319, current eps 0.655996 197.32\n",
      "59535, done 305 episodes, -195.37074222398354, current eps 0.6547959999999999 197.32\n",
      "59735, done 306 episodes, -195.40468335539506, current eps 0.6535960000000001 197.32\n",
      "59935, done 307 episodes, -195.3729544886988, current eps 0.652396 197.32\n",
      "60053, done 308 episodes, -194.5188238149741, current eps 0.651688 196.5\n",
      "60253, done 309 episodes, -194.55755614381385, current eps 0.650488 196.5\n",
      "60453, done 310 episodes, -194.5492843973838, current eps 0.649288 196.5\n",
      "60653, done 311 episodes, -194.49901559676044, current eps 0.648088 196.5\n",
      "Evaluation score: -115.43967652151537\n",
      "0 of 20 episodes ended close to / at the final state.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60853, done 312 episodes, -194.51430018840992, current eps 0.646888 196.5\n",
      "61053, done 313 episodes, -194.55742156365935, current eps 0.645688 196.5\n",
      "61253, done 314 episodes, -194.5423663358063, current eps 0.644488 196.5\n",
      "61453, done 315 episodes, -194.5300035226088, current eps 0.6432880000000001 196.5\n",
      "61653, done 316 episodes, -194.5270669766998, current eps 0.642088 196.5\n",
      "61853, done 317 episodes, -194.5234558698768, current eps 0.640888 196.5\n",
      "62053, done 318 episodes, -194.55540003913953, current eps 0.639688 196.5\n",
      "62253, done 319 episodes, -194.5752955093353, current eps 0.6384879999999999 196.5\n",
      "62453, done 320 episodes, -194.52751450163836, current eps 0.6372880000000001 196.5\n",
      "62653, done 321 episodes, -194.52373423868372, current eps 0.636088 196.5\n",
      "62853, done 322 episodes, -194.50530855568985, current eps 0.634888 196.5\n",
      "63053, done 323 episodes, -196.19111202522836, current eps 0.633688 198.22\n",
      "63253, done 324 episodes, -196.18730138338623, current eps 0.6324879999999999 198.22\n",
      "63453, done 325 episodes, -196.1812605049815, current eps 0.6312880000000001 198.22\n",
      "63653, done 326 episodes, -196.18925471431706, current eps 0.630088 198.22\n",
      "63853, done 327 episodes, -196.14724199528246, current eps 0.628888 198.22\n",
      "64053, done 328 episodes, -196.16627884712278, current eps 0.627688 198.22\n",
      "64253, done 329 episodes, -196.14968322047062, current eps 0.6264879999999999 198.22\n",
      "64453, done 330 episodes, -196.16599140857272, current eps 0.6252880000000001 198.22\n",
      "64653, done 331 episodes, -196.2094811318472, current eps 0.624088 198.22\n",
      "64853, done 332 episodes, -196.1805379852524, current eps 0.622888 198.22\n",
      "65053, done 333 episodes, -196.1739103445394, current eps 0.621688 198.22\n",
      "65253, done 334 episodes, -196.1490323572161, current eps 0.6204879999999999 198.22\n",
      "65453, done 335 episodes, -196.11509523776752, current eps 0.6192880000000001 198.22\n",
      "65653, done 336 episodes, -196.13169972211824, current eps 0.618088 198.22\n",
      "65853, done 337 episodes, -196.6224438799697, current eps 0.616888 198.72\n",
      "66053, done 338 episodes, -196.62448101894992, current eps 0.615688 198.72\n",
      "66253, done 339 episodes, -196.61687094864013, current eps 0.6144879999999999 198.72\n",
      "66453, done 340 episodes, -196.6084048193917, current eps 0.613288 198.72\n",
      "66653, done 341 episodes, -196.57269293905486, current eps 0.612088 198.72\n",
      "66853, done 342 episodes, -196.59023798941797, current eps 0.610888 198.72\n",
      "67053, done 343 episodes, -196.58341339776507, current eps 0.609688 198.72\n",
      "67253, done 344 episodes, -196.5481337866303, current eps 0.6084879999999999 198.72\n",
      "67453, done 345 episodes, -196.54847803302889, current eps 0.607288 198.72\n",
      "67653, done 346 episodes, -196.54989348553738, current eps 0.606088 198.72\n",
      "67853, done 347 episodes, -196.53500057891574, current eps 0.604888 198.72\n",
      "68053, done 348 episodes, -196.45215809445344, current eps 0.603688 198.72\n",
      "68253, done 349 episodes, -196.42984433675403, current eps 0.602488 198.72\n",
      "68453, done 350 episodes, -196.8749685132642, current eps 0.601288 199.18\n",
      "68653, done 351 episodes, -196.8337783384968, current eps 0.600088 199.18\n",
      "68853, done 352 episodes, -196.80339546776312, current eps 0.598888 199.18\n",
      "69053, done 353 episodes, -196.75359180603806, current eps 0.597688 199.18\n",
      "69253, done 354 episodes, -196.73379542983326, current eps 0.596488 199.18\n",
      "69453, done 355 episodes, -196.7337954298333, current eps 0.595288 199.18\n",
      "69653, done 356 episodes, -196.7611268656647, current eps 0.594088 199.18\n",
      "69853, done 357 episodes, -196.74746474991076, current eps 0.5928880000000001 199.18\n",
      "70053, done 358 episodes, -196.69536324558257, current eps 0.591688 199.18\n",
      "70253, done 359 episodes, -196.6755682900201, current eps 0.590488 199.18\n",
      "70453, done 360 episodes, -196.64338547901477, current eps 0.589288 199.18\n",
      "70653, done 361 episodes, -196.64249138258066, current eps 0.5880879999999999 199.18\n",
      "Evaluation score: -192.07630976884238\n",
      "0 of 20 episodes ended close to / at the final state.\n",
      "70853, done 362 episodes, -196.616334467717, current eps 0.5868880000000001 199.18\n",
      "71053, done 363 episodes, -196.57736353993812, current eps 0.585688 199.18\n",
      "71253, done 364 episodes, -196.5829167399159, current eps 0.584488 199.18\n",
      "71453, done 365 episodes, -196.60289956334418, current eps 0.583288 199.18\n",
      "71653, done 366 episodes, -196.61686813683843, current eps 0.5820879999999999 199.18\n",
      "71853, done 367 episodes, -196.59755524492704, current eps 0.5808880000000001 199.18\n",
      "72053, done 368 episodes, -196.5428916323574, current eps 0.579688 199.18\n",
      "72253, done 369 episodes, -196.46974755197112, current eps 0.578488 199.18\n",
      "72453, done 370 episodes, -196.39659353542893, current eps 0.577288 199.18\n",
      "72653, done 371 episodes, -196.33462218876448, current eps 0.5760879999999999 199.18\n",
      "72853, done 372 episodes, -196.32824592790413, current eps 0.5748880000000001 199.18\n",
      "73053, done 373 episodes, -196.3096457561981, current eps 0.573688 199.18\n",
      "73253, done 374 episodes, -196.3096457561981, current eps 0.572488 199.18\n",
      "73453, done 375 episodes, -196.25523878812294, current eps 0.571288 199.18\n",
      "73599, done 376 episodes, -195.7051695244956, current eps 0.5704119999999999 198.64\n",
      "73799, done 377 episodes, -195.67508444139662, current eps 0.569212 198.64\n",
      "73999, done 378 episodes, -195.6552766120242, current eps 0.568012 198.64\n",
      "74199, done 379 episodes, -195.62511782526096, current eps 0.566812 198.64\n",
      "74399, done 380 episodes, -195.6005124652964, current eps 0.565612 198.64\n",
      "74599, done 381 episodes, -195.5486704165889, current eps 0.564412 198.64\n",
      "74799, done 382 episodes, -195.5640731707749, current eps 0.563212 198.64\n",
      "74999, done 383 episodes, -195.5522228065243, current eps 0.562012 198.64\n",
      "75199, done 384 episodes, -195.57155695004158, current eps 0.560812 198.64\n",
      "75399, done 385 episodes, -195.57392076377155, current eps 0.559612 198.64\n",
      "75599, done 386 episodes, -195.62523954351877, current eps 0.558412 198.64\n",
      "75799, done 387 episodes, -195.64178373334116, current eps 0.557212 198.64\n",
      "75999, done 388 episodes, -195.68718330687543, current eps 0.556012 198.64\n",
      "76199, done 389 episodes, -195.63536294609872, current eps 0.554812 198.64\n",
      "76399, done 390 episodes, -195.6159738191924, current eps 0.553612 198.64\n",
      "76599, done 391 episodes, -195.62029831979723, current eps 0.552412 198.64\n",
      "76799, done 392 episodes, -195.6439372347132, current eps 0.551212 198.64\n",
      "76999, done 393 episodes, -195.56952078251277, current eps 0.550012 198.64\n",
      "77199, done 394 episodes, -195.56986582647082, current eps 0.5488120000000001 198.64\n",
      "77399, done 395 episodes, -195.5466728589456, current eps 0.547612 198.64\n",
      "77599, done 396 episodes, -195.51459286542726, current eps 0.546412 198.64\n",
      "77799, done 397 episodes, -195.55769858779075, current eps 0.545212 198.64\n",
      "77999, done 398 episodes, -195.57023756216063, current eps 0.5440119999999999 198.64\n",
      "78199, done 399 episodes, -195.57629143520626, current eps 0.5428120000000001 198.64\n",
      "78399, done 400 episodes, -195.539963235767, current eps 0.541612 198.64\n",
      "78599, done 401 episodes, -195.57269988792916, current eps 0.540412 198.64\n",
      "78799, done 402 episodes, -195.53717837199366, current eps 0.539212 198.64\n",
      "78999, done 403 episodes, -195.5546934189772, current eps 0.5380119999999999 198.64\n",
      "79199, done 404 episodes, -195.54937785502187, current eps 0.5368120000000001 198.64\n",
      "79399, done 405 episodes, -195.56609595669295, current eps 0.535612 198.64\n",
      "79599, done 406 episodes, -195.56819243774189, current eps 0.534412 198.64\n",
      "79799, done 407 episodes, -195.5652992327631, current eps 0.533212 198.64\n",
      "79999, done 408 episodes, -196.39216937621006, current eps 0.5320119999999999 199.46\n",
      "80199, done 409 episodes, -196.35225562331993, current eps 0.5308120000000001 199.46\n",
      "80399, done 410 episodes, -196.32991896279978, current eps 0.529612 199.46\n",
      "80599, done 411 episodes, -196.38688317926437, current eps 0.528412 199.46\n",
      "80799, done 412 episodes, -196.3744602622993, current eps 0.527212 199.46\n",
      "Evaluation score: -187.52427759327153\n",
      "0 of 20 episodes ended close to / at the final state.\n",
      "80999, done 413 episodes, -196.3430896799081, current eps 0.5260119999999999 199.46\n",
      "81199, done 414 episodes, -196.34953720624412, current eps 0.5248120000000001 199.46\n",
      "81399, done 415 episodes, -196.30952368274765, current eps 0.523612 199.46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81599, done 416 episodes, -196.27651611818416, current eps 0.522412 199.46\n",
      "81799, done 417 episodes, -196.24268215056807, current eps 0.521212 199.46\n",
      "81999, done 418 episodes, -196.2209241259037, current eps 0.5200119999999999 199.46\n",
      "82199, done 419 episodes, -196.2319931526367, current eps 0.518812 199.46\n",
      "82399, done 420 episodes, -196.28458430580346, current eps 0.517612 199.46\n",
      "82599, done 421 episodes, -196.30090354312804, current eps 0.516412 199.46\n",
      "82799, done 422 episodes, -196.31932922612188, current eps 0.515212 199.46\n",
      "82999, done 423 episodes, -196.30475198711767, current eps 0.514012 199.46\n",
      "83199, done 424 episodes, -196.23736474362718, current eps 0.512812 199.46\n",
      "83399, done 425 episodes, -196.18494505285344, current eps 0.511612 199.46\n",
      "83599, done 426 episodes, -196.20927514707208, current eps 0.510412 199.46\n",
      "83799, done 427 episodes, -196.27628431016714, current eps 0.509212 199.46\n",
      "83999, done 428 episodes, -196.2501938414537, current eps 0.508012 199.46\n",
      "84199, done 429 episodes, -196.22582651578938, current eps 0.506812 199.46\n",
      "84399, done 430 episodes, -196.14053029627004, current eps 0.505612 199.46\n",
      "84599, done 431 episodes, -196.15052869582377, current eps 0.504412 199.46\n",
      "84799, done 432 episodes, -196.12263576767916, current eps 0.503212 199.46\n",
      "84999, done 433 episodes, -196.13269310352808, current eps 0.502012 199.46\n",
      "85199, done 434 episodes, -196.11296892319166, current eps 0.500812 199.46\n",
      "85399, done 435 episodes, -196.1665715219791, current eps 0.49961199999999995 199.46\n",
      "85599, done 436 episodes, -196.15990236091093, current eps 0.49841199999999997 199.46\n",
      "85799, done 437 episodes, -196.16915820305945, current eps 0.497212 199.46\n",
      "85999, done 438 episodes, -196.16915820305945, current eps 0.496012 199.46\n",
      "86199, done 439 episodes, -196.14539054327307, current eps 0.49481200000000003 199.46\n",
      "86399, done 440 episodes, -196.08085150562067, current eps 0.49361200000000005 199.46\n",
      "86599, done 441 episodes, -196.09658056252917, current eps 0.49241199999999996 199.46\n",
      "86799, done 442 episodes, -196.08628821790361, current eps 0.491212 199.46\n",
      "86999, done 443 episodes, -196.09989904284782, current eps 0.490012 199.46\n",
      "87199, done 444 episodes, -196.1303049562488, current eps 0.488812 199.46\n",
      "87399, done 445 episodes, -196.16578778063467, current eps 0.48761200000000005 199.46\n",
      "87599, done 446 episodes, -196.14265819179826, current eps 0.48641199999999996 199.46\n",
      "87799, done 447 episodes, -196.13065539474144, current eps 0.485212 199.46\n",
      "87999, done 448 episodes, -196.2157671405903, current eps 0.484012 199.46\n",
      "88199, done 449 episodes, -196.1829611700666, current eps 0.482812 199.46\n",
      "88399, done 450 episodes, -196.19783699355645, current eps 0.48161200000000004 199.46\n",
      "88599, done 451 episodes, -196.19416085817164, current eps 0.48041199999999995 199.46\n",
      "88799, done 452 episodes, -196.22909776824395, current eps 0.47921199999999997 199.46\n",
      "88999, done 453 episodes, -196.25371413325874, current eps 0.478012 199.46\n",
      "89199, done 454 episodes, -196.2505923452274, current eps 0.476812 199.46\n",
      "89399, done 455 episodes, -196.17087088224798, current eps 0.47561200000000003 199.46\n",
      "89599, done 456 episodes, -196.08290064761033, current eps 0.47441199999999994 199.46\n",
      "89799, done 457 episodes, -196.0653432002066, current eps 0.47321199999999997 199.46\n",
      "89999, done 458 episodes, -196.13834200509245, current eps 0.472012 199.46\n",
      "90199, done 459 episodes, -196.12019279600477, current eps 0.470812 199.46\n",
      "90399, done 460 episodes, -196.1352536095155, current eps 0.46961200000000003 199.46\n",
      "90599, done 461 episodes, -196.0007109960326, current eps 0.46841200000000005 199.46\n",
      "90799, done 462 episodes, -196.06054866850783, current eps 0.46721199999999996 199.46\n",
      "Evaluation score: -189.32415572961082\n",
      "0 of 20 episodes ended close to / at the final state.\n",
      "90999, done 463 episodes, -196.0608594592111, current eps 0.466012 199.46\n",
      "91199, done 464 episodes, -196.0722770759444, current eps 0.464812 199.46\n",
      "91399, done 465 episodes, -196.07227707594433, current eps 0.463612 199.46\n",
      "91599, done 466 episodes, -195.99755432776058, current eps 0.46241200000000005 199.46\n",
      "91799, done 467 episodes, -195.93962396909384, current eps 0.46121199999999996 199.46\n",
      "91999, done 468 episodes, -195.9942875816635, current eps 0.460012 199.46\n",
      "92199, done 469 episodes, -195.96859785986138, current eps 0.458812 199.46\n",
      "92399, done 470 episodes, -196.00494461459502, current eps 0.457612 199.46\n",
      "92599, done 471 episodes, -196.05736323298333, current eps 0.45641200000000004 199.46\n",
      "92799, done 472 episodes, -196.00856494758034, current eps 0.45521199999999995 199.46\n",
      "92999, done 473 episodes, -196.00965007230275, current eps 0.45401199999999997 199.46\n",
      "93199, done 474 episodes, -195.9315291626998, current eps 0.452812 199.46\n",
      "93399, done 475 episodes, -195.94846158714742, current eps 0.451612 199.46\n",
      "93599, done 476 episodes, -196.48788532825793, current eps 0.45041200000000003 200.0\n",
      "93799, done 477 episodes, -196.47641142034058, current eps 0.44921199999999994 200.0\n",
      "93999, done 478 episodes, -196.47564112925488, current eps 0.44801199999999997 200.0\n",
      "94199, done 479 episodes, -196.4739450448579, current eps 0.446812 200.0\n",
      "94399, done 480 episodes, -196.48339739530311, current eps 0.445612 200.0\n",
      "94599, done 481 episodes, -196.44815319901235, current eps 0.44441200000000003 200.0\n",
      "94799, done 482 episodes, -196.40496332942973, current eps 0.44321200000000005 200.0\n",
      "94999, done 483 episodes, -196.3860082691304, current eps 0.44201199999999996 200.0\n",
      "95199, done 484 episodes, -196.38600826913043, current eps 0.440812 200.0\n",
      "95399, done 485 episodes, -196.35087489238828, current eps 0.439612 200.0\n",
      "95599, done 486 episodes, -196.35787321354212, current eps 0.438412 200.0\n",
      "95799, done 487 episodes, -196.36376374475202, current eps 0.43721200000000005 200.0\n",
      "95999, done 488 episodes, -196.36614772248922, current eps 0.43601199999999996 200.0\n",
      "96199, done 489 episodes, -196.26229847314136, current eps 0.434812 200.0\n",
      "96399, done 490 episodes, -196.28023322720236, current eps 0.433612 200.0\n",
      "96599, done 491 episodes, -196.26102454343138, current eps 0.432412 200.0\n",
      "96799, done 492 episodes, -196.27040903646682, current eps 0.43121200000000004 200.0\n",
      "96999, done 493 episodes, -196.32705677475272, current eps 0.43001199999999995 200.0\n",
      "97199, done 494 episodes, -196.2810935636461, current eps 0.42881199999999997 200.0\n",
      "97399, done 495 episodes, -196.2463354958037, current eps 0.427612 200.0\n",
      "97599, done 496 episodes, -196.27916818069735, current eps 0.426412 200.0\n",
      "97799, done 497 episodes, -196.25460855206674, current eps 0.42521200000000003 200.0\n",
      "97999, done 498 episodes, -196.2518143276965, current eps 0.42401199999999994 200.0\n",
      "98199, done 499 episodes, -196.23211445131713, current eps 0.42281199999999997 200.0\n",
      "98399, done 500 episodes, -196.26806080810923, current eps 0.421612 200.0\n",
      "98599, done 501 episodes, -196.24326922649882, current eps 0.420412 200.0\n",
      "98799, done 502 episodes, -196.24115778573278, current eps 0.41921200000000003 200.0\n",
      "98999, done 503 episodes, -196.19976053740254, current eps 0.41801200000000005 200.0\n",
      "99199, done 504 episodes, -196.20734039068594, current eps 0.41681199999999996 200.0\n",
      "99399, done 505 episodes, -196.1697113832032, current eps 0.415612 200.0\n",
      "99599, done 506 episodes, -196.13144495627864, current eps 0.414412 200.0\n",
      "99799, done 507 episodes, -196.1315398146432, current eps 0.413212 200.0\n",
      "99999, done 508 episodes, -196.12290931274782, current eps 0.41201200000000004 200.0\n",
      "100199, done 509 episodes, -196.08277944925095, current eps 0.41081199999999995 200.0\n",
      "100399, done 510 episodes, -196.08967412583957, current eps 0.409612 200.0\n",
      "100599, done 511 episodes, -196.1099208874604, current eps 0.408412 200.0\n",
      "100799, done 512 episodes, -196.06707670437353, current eps 0.407212 200.0\n",
      "Evaluation score: -171.67609181306545\n",
      "0 of 20 episodes ended close to / at the final state.\n",
      "100999, done 513 episodes, -196.0992995312446, current eps 0.40601200000000004 200.0\n",
      "101199, done 514 episodes, -196.07102621462235, current eps 0.40481199999999995 200.0\n",
      "101399, done 515 episodes, -196.12825251518453, current eps 0.40361199999999997 200.0\n",
      "101599, done 516 episodes, -196.19280553513065, current eps 0.402412 200.0\n",
      "101799, done 517 episodes, -196.13897215688547, current eps 0.401212 200.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101999, done 518 episodes, -196.16215102605176, current eps 0.40001200000000003 200.0\n",
      "102199, done 519 episodes, -196.06585997864013, current eps 0.39881199999999994 200.0\n",
      "102399, done 520 episodes, -196.05609045694692, current eps 0.39761199999999997 200.0\n",
      "102599, done 521 episodes, -196.05609045694692, current eps 0.396412 200.0\n",
      "102799, done 522 episodes, -196.0175328299628, current eps 0.395212 200.0\n",
      "102999, done 523 episodes, -196.0202748201433, current eps 0.39401200000000003 200.0\n",
      "103199, done 524 episodes, -196.03222473820827, current eps 0.39281200000000005 200.0\n",
      "103399, done 525 episodes, -196.05496465373344, current eps 0.39161199999999996 200.0\n",
      "103599, done 526 episodes, -195.96895475901022, current eps 0.390412 200.0\n",
      "103799, done 527 episodes, -195.94962061549293, current eps 0.389212 200.0\n",
      "103999, done 528 episodes, -195.8538389736285, current eps 0.388012 200.0\n",
      "104199, done 529 episodes, -195.9100837555811, current eps 0.38681200000000004 200.0\n",
      "104399, done 530 episodes, -195.94753336782676, current eps 0.38561199999999995 200.0\n",
      "104599, done 531 episodes, -195.93204751594382, current eps 0.384412 200.0\n",
      "104799, done 532 episodes, -195.9906576660837, current eps 0.383212 200.0\n",
      "104999, done 533 episodes, -195.9684863365522, current eps 0.382012 200.0\n",
      "105199, done 534 episodes, -195.91151614642047, current eps 0.38081200000000004 200.0\n",
      "105399, done 535 episodes, -195.87587061326147, current eps 0.37961199999999995 200.0\n",
      "105599, done 536 episodes, -195.76205221079897, current eps 0.37841199999999997 200.0\n",
      "105799, done 537 episodes, -195.73845304647853, current eps 0.377212 200.0\n",
      "105999, done 538 episodes, -195.71668863903196, current eps 0.376012 200.0\n",
      "106199, done 539 episodes, -195.69184716078001, current eps 0.37481200000000003 200.0\n",
      "106399, done 540 episodes, -195.73918947975798, current eps 0.37361199999999994 200.0\n",
      "106599, done 541 episodes, -195.71573312471952, current eps 0.37241199999999997 200.0\n",
      "106799, done 542 episodes, -195.70490981083947, current eps 0.371212 200.0\n",
      "106999, done 543 episodes, -195.67889336952368, current eps 0.370012 200.0\n",
      "107199, done 544 episodes, -195.65825841092024, current eps 0.36881200000000003 200.0\n",
      "107399, done 545 episodes, -195.65825841092024, current eps 0.36761200000000005 200.0\n",
      "107599, done 546 episodes, -195.70839400896332, current eps 0.36641199999999996 200.0\n",
      "107799, done 547 episodes, -195.75970387423942, current eps 0.365212 200.0\n",
      "107999, done 548 episodes, -195.69702583109975, current eps 0.364012 200.0\n",
      "108199, done 549 episodes, -195.71807407541917, current eps 0.362812 200.0\n",
      "108399, done 550 episodes, -195.66343904831578, current eps 0.36161200000000004 200.0\n",
      "108599, done 551 episodes, -195.6651405053572, current eps 0.36041199999999995 200.0\n",
      "108799, done 552 episodes, -195.6733266095173, current eps 0.359212 200.0\n",
      "108999, done 553 episodes, -195.6742880012637, current eps 0.358012 200.0\n",
      "109199, done 554 episodes, -195.51688080647128, current eps 0.356812 200.0\n",
      "109399, done 555 episodes, -195.59660226945067, current eps 0.35561200000000004 200.0\n",
      "109599, done 556 episodes, -195.68094164138245, current eps 0.35441199999999995 200.0\n",
      "109799, done 557 episodes, -195.65002555589527, current eps 0.35321199999999997 200.0\n",
      "109999, done 558 episodes, -195.62196533290643, current eps 0.352012 200.0\n",
      "110199, done 559 episodes, -195.6223211997919, current eps 0.350812 200.0\n",
      "110399, done 560 episodes, -195.5859465222154, current eps 0.34961200000000003 200.0\n",
      "110599, done 561 episodes, -195.69822989855282, current eps 0.34841199999999994 200.0\n",
      "110799, done 562 episodes, -195.67809392659314, current eps 0.34721199999999997 200.0\n",
      "Evaluation score: -190.30340620740736\n",
      "0 of 20 episodes ended close to / at the final state.\n",
      "110999, done 563 episodes, -195.63332502059475, current eps 0.346012 200.0\n",
      "111199, done 564 episodes, -195.5889322143965, current eps 0.344812 200.0\n",
      "111399, done 565 episodes, -195.4895614601962, current eps 0.34361200000000003 200.0\n",
      "111599, done 566 episodes, -195.52782806736806, current eps 0.34241199999999994 200.0\n",
      "111799, done 567 episodes, -195.58521127700106, current eps 0.34121199999999996 200.0\n",
      "111999, done 568 episodes, -195.58357433651682, current eps 0.340012 200.0\n",
      "112199, done 569 episodes, -195.69944525347165, current eps 0.338812 200.0\n",
      "112399, done 570 episodes, -195.73625251528028, current eps 0.337612 200.0\n",
      "112599, done 571 episodes, -195.72366931451847, current eps 0.33641200000000004 200.0\n",
      "112799, done 572 episodes, -195.77772250314527, current eps 0.33521199999999995 200.0\n",
      "112999, done 573 episodes, -195.7753713003807, current eps 0.334012 200.0\n",
      "113199, done 574 episodes, -195.7748202381216, current eps 0.332812 200.0\n",
      "113399, done 575 episodes, -195.74291272285492, current eps 0.331612 200.0\n",
      "113599, done 576 episodes, -195.74573533702633, current eps 0.33041200000000004 200.0\n",
      "113799, done 577 episodes, -195.7745182677861, current eps 0.32921199999999995 200.0\n",
      "113999, done 578 episodes, -195.7383767758729, current eps 0.32801199999999997 200.0\n",
      "114199, done 579 episodes, -195.77599159966644, current eps 0.326812 200.0\n",
      "114399, done 580 episodes, -195.73567701267143, current eps 0.325612 200.0\n",
      "114599, done 581 episodes, -195.72268569084156, current eps 0.32441200000000003 200.0\n",
      "114799, done 582 episodes, -195.67876361240812, current eps 0.32321199999999994 200.0\n",
      "114999, done 583 episodes, -195.71578158857625, current eps 0.32201199999999996 200.0\n",
      "115199, done 584 episodes, -195.6778492894799, current eps 0.320812 200.0\n",
      "115399, done 585 episodes, -195.72388808814, current eps 0.319612 200.0\n",
      "115599, done 586 episodes, -195.75245699065866, current eps 0.31841200000000003 200.0\n",
      "115799, done 587 episodes, -195.68183667376107, current eps 0.31721199999999994 200.0\n",
      "115999, done 588 episodes, -195.65739069832554, current eps 0.31601199999999996 200.0\n",
      "116199, done 589 episodes, -195.7885713492993, current eps 0.314812 200.0\n",
      "116399, done 590 episodes, -195.6015055352899, current eps 0.313612 200.0\n",
      "116599, done 591 episodes, -195.63862706604016, current eps 0.312412 200.0\n",
      "116799, done 592 episodes, -195.54098236674665, current eps 0.31121200000000004 200.0\n",
      "116999, done 593 episodes, -195.56308681108396, current eps 0.31001199999999995 200.0\n",
      "117199, done 594 episodes, -195.6349189628232, current eps 0.308812 200.0\n",
      "117399, done 595 episodes, -195.62160830504985, current eps 0.307612 200.0\n",
      "117599, done 596 episodes, -195.60502886878083, current eps 0.306412 200.0\n",
      "117799, done 597 episodes, -195.62487328538845, current eps 0.30521200000000004 200.0\n",
      "117999, done 598 episodes, -195.62766750975865, current eps 0.30401199999999995 200.0\n",
      "118199, done 599 episodes, -195.676188258469, current eps 0.30281199999999997 200.0\n",
      "118399, done 600 episodes, -195.60424617039942, current eps 0.301612 200.0\n",
      "118599, done 601 episodes, -195.56407543096785, current eps 0.300412 200.0\n",
      "118799, done 602 episodes, -195.525680337398, current eps 0.29921200000000003 200.0\n",
      "118999, done 603 episodes, -195.4942467671398, current eps 0.29801199999999994 200.0\n",
      "119199, done 604 episodes, -195.4481946520739, current eps 0.29681199999999996 200.0\n",
      "119399, done 605 episodes, -195.45943022242153, current eps 0.295612 200.0\n",
      "119599, done 606 episodes, -195.41144983205425, current eps 0.294412 200.0\n",
      "119799, done 607 episodes, -195.42876426829906, current eps 0.29321200000000003 200.0\n",
      "119999, done 608 episodes, -195.44574632868526, current eps 0.29201199999999994 200.0\n",
      "120199, done 609 episodes, -195.50599356886744, current eps 0.29081199999999996 200.0\n",
      "120399, done 610 episodes, -195.44865607571543, current eps 0.289612 200.0\n",
      "120599, done 611 episodes, -195.3920379078094, current eps 0.288412 200.0\n",
      "120799, done 612 episodes, -195.40996500193572, current eps 0.287212 200.0\n",
      "Evaluation score: -150.8655136569397\n",
      "0 of 20 episodes ended close to / at the final state.\n",
      "120999, done 613 episodes, -195.3494620275759, current eps 0.28601200000000004 200.0\n",
      "121199, done 614 episodes, -195.3124319258212, current eps 0.28481199999999995 200.0\n",
      "121399, done 615 episodes, -195.21004583114006, current eps 0.283612 200.0\n",
      "121599, done 616 episodes, -195.1516503368797, current eps 0.282412 200.0\n",
      "121799, done 617 episodes, -195.1183648903468, current eps 0.281212 200.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121999, done 618 episodes, -195.12118376406994, current eps 0.28001200000000004 200.0\n",
      "122199, done 619 episodes, -195.14569749435861, current eps 0.27881199999999995 200.0\n",
      "122399, done 620 episodes, -195.20193602585823, current eps 0.27761199999999997 200.0\n",
      "122599, done 621 episodes, -195.10594877501757, current eps 0.276412 200.0\n",
      "122799, done 622 episodes, -195.04605986813033, current eps 0.275212 200.0\n",
      "122999, done 623 episodes, -195.09209164741554, current eps 0.27401200000000003 200.0\n",
      "123199, done 624 episodes, -195.10146018196355, current eps 0.27281199999999994 200.0\n",
      "123399, done 625 episodes, -195.06001811298185, current eps 0.27161199999999996 200.0\n",
      "123599, done 626 episodes, -195.1460280077051, current eps 0.270412 200.0\n",
      "123799, done 627 episodes, -195.16107077401358, current eps 0.269212 200.0\n",
      "123999, done 628 episodes, -195.19988367166258, current eps 0.26801200000000003 200.0\n",
      "124199, done 629 episodes, -195.1808400470233, current eps 0.26681199999999994 200.0\n",
      "124399, done 630 episodes, -195.1736210819161, current eps 0.26561199999999996 200.0\n",
      "124599, done 631 episodes, -195.19775213484442, current eps 0.264412 200.0\n",
      "124799, done 632 episodes, -195.16827518929847, current eps 0.263212 200.0\n",
      "124999, done 633 episodes, -195.14834609297301, current eps 0.262012 200.0\n",
      "125199, done 634 episodes, -195.1814620944451, current eps 0.26081200000000004 200.0\n",
      "125399, done 635 episodes, -195.23382418559774, current eps 0.25961199999999995 200.0\n",
      "125599, done 636 episodes, -195.3738747241115, current eps 0.258412 200.0\n",
      "125799, done 637 episodes, -195.37168952314627, current eps 0.257212 200.0\n",
      "125999, done 638 episodes, -195.27028576481138, current eps 0.256012 200.0\n",
      "126199, done 639 episodes, -195.21233971672973, current eps 0.25481200000000004 200.0\n",
      "126399, done 640 episodes, -195.09257632123328, current eps 0.25361199999999995 200.0\n",
      "126599, done 641 episodes, -195.03144900772193, current eps 0.25241199999999997 200.0\n",
      "126799, done 642 episodes, -194.97631765942486, current eps 0.251212 200.0\n",
      "126999, done 643 episodes, -194.9496294646256, current eps 0.250012 200.0\n",
      "127199, done 644 episodes, -194.86862026029814, current eps 0.24881200000000003 200.0\n",
      "127399, done 645 episodes, -194.8131207553306, current eps 0.24761199999999994 200.0\n",
      "127599, done 646 episodes, -194.7056172722766, current eps 0.24641199999999996 200.0\n",
      "127799, done 647 episodes, -194.7077029841117, current eps 0.24521199999999999 200.0\n",
      "127999, done 648 episodes, -194.6444614543537, current eps 0.244012 200.0\n",
      "128199, done 649 episodes, -194.62171737965477, current eps 0.24281200000000003 200.0\n",
      "128399, done 650 episodes, -194.56983454609343, current eps 0.24161199999999994 200.0\n",
      "128599, done 651 episodes, -194.5230458017647, current eps 0.24041199999999996 200.0\n",
      "128799, done 652 episodes, -194.49826284548124, current eps 0.23921199999999998 200.0\n",
      "128999, done 653 episodes, -194.47505405663654, current eps 0.238012 200.0\n",
      "129199, done 654 episodes, -194.5486488204108, current eps 0.23681200000000002 200.0\n",
      "129399, done 655 episodes, -194.46762627526405, current eps 0.23561200000000004 200.0\n",
      "129599, done 656 episodes, -194.41654623222274, current eps 0.23441199999999995 200.0\n",
      "129799, done 657 episodes, -194.36595801587063, current eps 0.23321199999999997 200.0\n",
      "129999, done 658 episodes, -194.36657320604394, current eps 0.232012 200.0\n",
      "130199, done 659 episodes, -194.34887573558316, current eps 0.23081200000000002 200.0\n",
      "130399, done 660 episodes, -194.26631285541924, current eps 0.22961200000000004 200.0\n",
      "130599, done 661 episodes, -194.22964342873172, current eps 0.22841199999999995 200.0\n",
      "130799, done 662 episodes, -194.23510979421633, current eps 0.22721199999999997 200.0\n",
      "Evaluation score: -175.7387960298816\n",
      "0 of 20 episodes ended close to / at the final state.\n",
      "130999, done 663 episodes, -194.26166084926302, current eps 0.226012 200.0\n",
      "131199, done 664 episodes, -194.287378636893, current eps 0.224812 200.0\n",
      "131399, done 665 episodes, -194.34901740657114, current eps 0.22361200000000003 200.0\n",
      "131599, done 666 episodes, -194.36291928457723, current eps 0.22241199999999994 200.0\n",
      "131799, done 667 episodes, -194.32459814298326, current eps 0.22121199999999996 200.0\n",
      "131999, done 668 episodes, -194.22940813278313, current eps 0.22001199999999999 200.0\n",
      "132199, done 669 episodes, -194.13614936627172, current eps 0.218812 200.0\n",
      "132399, done 670 episodes, -194.12701594355428, current eps 0.21761200000000003 200.0\n",
      "132599, done 671 episodes, -194.07632105400376, current eps 0.21641199999999994 200.0\n",
      "132799, done 672 episodes, -194.0774424116403, current eps 0.21521199999999996 200.0\n",
      "132999, done 673 episodes, -193.94709557558045, current eps 0.21401199999999998 200.0\n",
      "133199, done 674 episodes, -193.9325560278426, current eps 0.212812 200.0\n",
      "133399, done 675 episodes, -193.9328334376749, current eps 0.21161200000000002 200.0\n",
      "133599, done 676 episodes, -193.94135898024467, current eps 0.21041200000000004 200.0\n",
      "133799, done 677 episodes, -193.925119004148, current eps 0.20921199999999995 200.0\n",
      "133999, done 678 episodes, -193.88024982868458, current eps 0.20801199999999997 200.0\n",
      "134199, done 679 episodes, -193.8163127640563, current eps 0.206812 200.0\n",
      "134399, done 680 episodes, -193.83374863158096, current eps 0.20561200000000002 200.0\n",
      "134599, done 681 episodes, -193.88009472587882, current eps 0.20441200000000004 200.0\n",
      "134799, done 682 episodes, -193.77697201989997, current eps 0.20321199999999995 200.0\n",
      "134999, done 683 episodes, -193.68379003219016, current eps 0.20201199999999997 200.0\n",
      "135199, done 684 episodes, -193.70344852151067, current eps 0.200812 200.0\n",
      "135399, done 685 episodes, -193.58064410494254, current eps 0.199612 200.0\n",
      "135599, done 686 episodes, -193.42542626603273, current eps 0.19841200000000003 200.0\n",
      "135799, done 687 episodes, -193.43056914333084, current eps 0.19721199999999994 200.0\n",
      "135999, done 688 episodes, -193.30144082081333, current eps 0.19601199999999996 200.0\n",
      "136199, done 689 episodes, -193.1926914964148, current eps 0.19481199999999999 200.0\n",
      "136399, done 690 episodes, -193.25067598827, current eps 0.193612 200.0\n",
      "136599, done 691 episodes, -193.22838695867722, current eps 0.19241200000000003 200.0\n",
      "136799, done 692 episodes, -193.06479741538854, current eps 0.19121199999999994 200.0\n",
      "136999, done 693 episodes, -193.05566399267107, current eps 0.19001199999999996 200.0\n",
      "137199, done 694 episodes, -192.97888995551114, current eps 0.18881199999999998 200.0\n",
      "137399, done 695 episodes, -192.98999310390676, current eps 0.187612 200.0\n",
      "137599, done 696 episodes, -192.8903971104612, current eps 0.18641200000000002 200.0\n",
      "137799, done 697 episodes, -192.89321649242888, current eps 0.18521200000000004 200.0\n",
      "137999, done 698 episodes, -192.8107788611804, current eps 0.18401199999999995 200.0\n",
      "138199, done 699 episodes, -192.7141384298214, current eps 0.18281199999999997 200.0\n",
      "138399, done 700 episodes, -192.71583325180785, current eps 0.181612 200.0\n",
      "138599, done 701 episodes, -192.63621866675734, current eps 0.18041200000000002 200.0\n",
      "138799, done 702 episodes, -192.63176781758742, current eps 0.17921200000000004 200.0\n",
      "138999, done 703 episodes, -192.66800066211988, current eps 0.17801199999999995 200.0\n",
      "139199, done 704 episodes, -192.5086639704711, current eps 0.17681199999999997 200.0\n",
      "139399, done 705 episodes, -192.44399429572158, current eps 0.175612 200.0\n",
      "139599, done 706 episodes, -192.48491638889647, current eps 0.174412 200.0\n",
      "139799, done 707 episodes, -192.41573140515348, current eps 0.17321200000000003 200.0\n",
      "139999, done 708 episodes, -192.4446449781537, current eps 0.17201199999999994 200.0\n",
      "140199, done 709 episodes, -192.33750935166347, current eps 0.17081199999999996 200.0\n",
      "140399, done 710 episodes, -192.3894858639253, current eps 0.16961199999999999 200.0\n",
      "140599, done 711 episodes, -192.3430109131774, current eps 0.168412 200.0\n",
      "140799, done 712 episodes, -192.25589770167335, current eps 0.16721200000000003 200.0\n",
      "Evaluation score: -184.23320833279323\n",
      "0 of 20 episodes ended close to / at the final state.\n",
      "140999, done 713 episodes, -192.2462344003648, current eps 0.16601199999999994 200.0\n",
      "141199, done 714 episodes, -192.23892954754692, current eps 0.16481199999999996 200.0\n",
      "141399, done 715 episodes, -192.28470629390904, current eps 0.16361199999999998 200.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141599, done 716 episodes, -192.28926757306272, current eps 0.162412 200.0\n",
      "141799, done 717 episodes, -192.3723769925147, current eps 0.16121200000000002 200.0\n",
      "141999, done 718 episodes, -192.23216348358247, current eps 0.16001200000000004 200.0\n",
      "142199, done 719 episodes, -192.22694403016686, current eps 0.15881199999999995 200.0\n",
      "142399, done 720 episodes, -192.1900280955212, current eps 0.15761199999999997 200.0\n",
      "142599, done 721 episodes, -192.21051011571518, current eps 0.156412 200.0\n",
      "142799, done 722 episodes, -192.17546119634633, current eps 0.15521200000000002 200.0\n",
      "142999, done 723 episodes, -192.04773376038702, current eps 0.15401200000000004 200.0\n",
      "143199, done 724 episodes, -191.793774736549, current eps 0.15281199999999995 200.0\n",
      "143399, done 725 episodes, -191.75098340156026, current eps 0.15161199999999997 200.0\n",
      "143599, done 726 episodes, -191.64855572444455, current eps 0.150412 200.0\n",
      "143799, done 727 episodes, -191.56178398976877, current eps 0.149212 200.0\n",
      "143999, done 728 episodes, -191.53231251472187, current eps 0.14801200000000003 200.0\n",
      "144199, done 729 episodes, -191.41049603991812, current eps 0.14681199999999994 200.0\n",
      "144399, done 730 episodes, -191.348228838772, current eps 0.14561199999999996 200.0\n",
      "144599, done 731 episodes, -191.34800611203912, current eps 0.14441199999999998 200.0\n",
      "144799, done 732 episodes, -191.32050972273683, current eps 0.143212 200.0\n",
      "144999, done 733 episodes, -191.2983301599757, current eps 0.14201200000000003 200.0\n",
      "145199, done 734 episodes, -191.27972012462294, current eps 0.14081199999999994 200.0\n",
      "145399, done 735 episodes, -191.166662025284, current eps 0.13961199999999996 200.0\n",
      "145599, done 736 episodes, -190.97214816118762, current eps 0.13841199999999998 200.0\n",
      "145799, done 737 episodes, -190.94561778138433, current eps 0.137212 200.0\n",
      "145999, done 738 episodes, -191.03026980754075, current eps 0.13601200000000002 200.0\n",
      "146199, done 739 episodes, -191.14610845645396, current eps 0.13481200000000004 200.0\n",
      "146399, done 740 episodes, -191.18684647074693, current eps 0.13361199999999995 200.0\n",
      "146599, done 741 episodes, -191.16057746702518, current eps 0.13241199999999997 200.0\n",
      "146799, done 742 episodes, -191.1042113581417, current eps 0.131212 200.0\n",
      "146999, done 743 episodes, -190.97300977939557, current eps 0.13001200000000002 200.0\n",
      "147199, done 744 episodes, -190.98846452817568, current eps 0.12881200000000004 200.0\n",
      "147399, done 745 episodes, -190.74866139969336, current eps 0.12761199999999995 200.0\n",
      "147599, done 746 episodes, -190.7946410881666, current eps 0.12641199999999997 200.0\n",
      "147799, done 747 episodes, -190.74499335709487, current eps 0.125212 200.0\n",
      "147999, done 748 episodes, -190.8483099380683, current eps 0.12401200000000001 200.0\n",
      "148199, done 749 episodes, -190.8134874000133, current eps 0.12281200000000003 200.0\n",
      "148399, done 750 episodes, -190.83456277203015, current eps 0.12161199999999994 200.0\n",
      "148599, done 751 episodes, -190.80508167511718, current eps 0.12041199999999996 200.0\n",
      "148799, done 752 episodes, -190.78069137211654, current eps 0.11921199999999998 200.0\n",
      "148999, done 753 episodes, -190.63884710910042, current eps 0.118012 200.0\n",
      "149199, done 754 episodes, -190.62630897234095, current eps 0.11681200000000003 200.0\n",
      "149399, done 755 episodes, -190.63099125440425, current eps 0.11561199999999994 200.0\n",
      "149599, done 756 episodes, -190.6075591863515, current eps 0.11441199999999996 200.0\n",
      "149799, done 757 episodes, -190.47596324409668, current eps 0.11321199999999998 200.0\n",
      "149999, done 758 episodes, -190.34116510517927, current eps 0.112012 200.0\n",
      "150199, done 759 episodes, -190.3599212439299, current eps 0.11081200000000002 200.0\n",
      "150399, done 760 episodes, -190.35837129951736, current eps 0.10961200000000004 200.0\n",
      "150599, done 761 episodes, -190.29120011318182, current eps 0.10841199999999995 200.0\n",
      "150799, done 762 episodes, -190.19608185223126, current eps 0.10721199999999997 200.0\n",
      "Evaluation score: -185.6821476267387\n",
      "0 of 20 episodes ended close to / at the final state.\n",
      "150999, done 763 episodes, -190.16272065741524, current eps 0.106012 200.0\n",
      "151199, done 764 episodes, -190.0760187776568, current eps 0.10481200000000002 200.0\n",
      "151399, done 765 episodes, -189.98001912697083, current eps 0.10361200000000004 200.0\n",
      "151599, done 766 episodes, -189.96152763877816, current eps 0.10241199999999995 200.0\n",
      "151799, done 767 episodes, -189.92130056946542, current eps 0.10121199999999997 200.0\n",
      "151999, done 768 episodes, -189.9149194175248, current eps 0.10001199999999999 200.0\n",
      "152199, done 769 episodes, -189.85266930008925, current eps 0.0999944382022472 200.0\n",
      "152399, done 770 episodes, -189.69658262226952, current eps 0.0999888202247191 200.0\n",
      "152599, done 771 episodes, -189.6261828100292, current eps 0.09998320224719101 200.0\n",
      "152799, done 772 episodes, -189.58824769188294, current eps 0.09997758426966293 200.0\n",
      "152999, done 773 episodes, -189.63306653393448, current eps 0.09997196629213484 200.0\n",
      "153199, done 774 episodes, -189.43551449285167, current eps 0.09996634831460674 200.0\n",
      "153399, done 775 episodes, -189.35150682307238, current eps 0.09996073033707865 200.0\n",
      "153599, done 776 episodes, -189.3040410634069, current eps 0.09995511235955057 200.0\n",
      "153799, done 777 episodes, -189.2790714239452, current eps 0.09994949438202247 200.0\n",
      "153999, done 778 episodes, -189.09683255878787, current eps 0.09994387640449438 200.0\n",
      "154199, done 779 episodes, -189.11439526706775, current eps 0.0999382584269663 200.0\n",
      "154399, done 780 episodes, -189.09780166028696, current eps 0.0999326404494382 200.0\n",
      "154599, done 781 episodes, -189.0209683460186, current eps 0.09992702247191011 200.0\n",
      "154799, done 782 episodes, -189.1564141774668, current eps 0.09992140449438203 200.0\n",
      "154999, done 783 episodes, -189.17489157018926, current eps 0.09991578651685393 200.0\n",
      "155199, done 784 episodes, -189.02773098924916, current eps 0.09991016853932584 200.0\n",
      "155399, done 785 episodes, -189.03983317116433, current eps 0.09990455056179776 200.0\n",
      "155599, done 786 episodes, -189.03342843528645, current eps 0.09989893258426967 200.0\n",
      "155799, done 787 episodes, -189.0332017781419, current eps 0.09989331460674157 200.0\n",
      "155999, done 788 episodes, -189.09246182883544, current eps 0.09988769662921348 200.0\n",
      "156199, done 789 episodes, -189.21896461844983, current eps 0.0998820786516854 200.0\n",
      "156399, done 790 episodes, -189.25450871649508, current eps 0.0998764606741573 200.0\n",
      "156599, done 791 episodes, -189.14837780116432, current eps 0.09987084269662921 200.0\n",
      "156799, done 792 episodes, -189.23565829263885, current eps 0.09986522471910113 200.0\n",
      "156999, done 793 episodes, -189.1868123191073, current eps 0.09985960674157303 200.0\n",
      "157199, done 794 episodes, -189.18256471514636, current eps 0.09985398876404494 200.0\n",
      "157399, done 795 episodes, -189.15487699541384, current eps 0.09984837078651686 200.0\n",
      "157599, done 796 episodes, -189.1998947977637, current eps 0.09984275280898877 200.0\n",
      "157799, done 797 episodes, -189.0667053663285, current eps 0.09983713483146067 200.0\n",
      "157999, done 798 episodes, -188.97597453397674, current eps 0.09983151685393259 200.0\n",
      "158199, done 799 episodes, -188.91324551156166, current eps 0.0998258988764045 200.0\n",
      "158399, done 800 episodes, -188.8302635583606, current eps 0.0998202808988764 200.0\n",
      "158599, done 801 episodes, -188.88446477896971, current eps 0.09981466292134832 200.0\n",
      "158799, done 802 episodes, -188.84539813209128, current eps 0.09980904494382023 200.0\n",
      "158999, done 803 episodes, -188.792518475368, current eps 0.09980342696629213 200.0\n",
      "159199, done 804 episodes, -188.95905088015581, current eps 0.09979780898876404 200.0\n",
      "159399, done 805 episodes, -188.92161076257017, current eps 0.09979219101123596 200.0\n",
      "159599, done 806 episodes, -188.96801989296762, current eps 0.09978657303370786 200.0\n",
      "159799, done 807 episodes, -188.88070495050198, current eps 0.09978095505617977 200.0\n",
      "159999, done 808 episodes, -188.70850797690508, current eps 0.09977533707865169 200.0\n",
      "160199, done 809 episodes, -188.69630439960932, current eps 0.0997697191011236 200.0\n",
      "160399, done 810 episodes, -188.6697303263507, current eps 0.0997641011235955 200.0\n",
      "160599, done 811 episodes, -188.69672067375987, current eps 0.09975848314606742 200.0\n",
      "160799, done 812 episodes, -188.6557395004735, current eps 0.09975286516853933 200.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score: -120.04285150445409\n",
      "0 of 20 episodes ended close to / at the final state.\n",
      "160999, done 813 episodes, -188.52855079005514, current eps 0.09974724719101123 200.0\n",
      "161199, done 814 episodes, -188.48371628769746, current eps 0.09974162921348315 200.0\n",
      "161399, done 815 episodes, -188.39961031901427, current eps 0.09973601123595506 200.0\n",
      "161599, done 816 episodes, -188.22137235286274, current eps 0.09973039325842697 200.0\n",
      "161799, done 817 episodes, -188.23303537031293, current eps 0.09972477528089888 200.0\n",
      "161999, done 818 episodes, -188.32207306696225, current eps 0.09971915730337079 200.0\n",
      "162199, done 819 episodes, -188.18334136033025, current eps 0.0997135393258427 200.0\n",
      "162399, done 820 episodes, -188.08859146495118, current eps 0.0997079213483146 200.0\n",
      "162599, done 821 episodes, -187.8922542249822, current eps 0.09970230337078652 200.0\n",
      "162799, done 822 episodes, -187.798918980773, current eps 0.09969668539325843 200.0\n",
      "162999, done 823 episodes, -187.7963893788106, current eps 0.09969106741573033 200.0\n",
      "163199, done 824 episodes, -188.02388757228485, current eps 0.09968544943820225 200.0\n",
      "163399, done 825 episodes, -188.04291847411002, current eps 0.09967983146067416 200.0\n",
      "163599, done 826 episodes, -188.04060364834302, current eps 0.09967421348314606 200.0\n",
      "163799, done 827 episodes, -188.12739597764684, current eps 0.09966859550561798 200.0\n",
      "163999, done 828 episodes, -188.15675820602567, current eps 0.09966297752808989 200.0\n",
      "164199, done 829 episodes, -188.1471936826496, current eps 0.0996573595505618 200.0\n",
      "164399, done 830 episodes, -188.1848181834221, current eps 0.0996517415730337 200.0\n",
      "164599, done 831 episodes, -188.05381621550063, current eps 0.09964612359550562 200.0\n",
      "164799, done 832 episodes, -187.9881664076944, current eps 0.09964050561797753 200.0\n",
      "164999, done 833 episodes, -187.82906224377905, current eps 0.09963488764044943 200.0\n",
      "165199, done 834 episodes, -187.9073087678654, current eps 0.09962926966292135 200.0\n",
      "165399, done 835 episodes, -187.87532880651776, current eps 0.09962365168539326 200.0\n",
      "165599, done 836 episodes, -187.92733038533189, current eps 0.09961803370786516 200.0\n",
      "165799, done 837 episodes, -187.81629538018336, current eps 0.09961241573033708 200.0\n",
      "165999, done 838 episodes, -187.72131262656666, current eps 0.09960679775280899 200.0\n",
      "166199, done 839 episodes, -187.70048052884704, current eps 0.0996011797752809 200.0\n",
      "166399, done 840 episodes, -187.56071298878047, current eps 0.09959556179775281 200.0\n",
      "166599, done 841 episodes, -187.54184896223126, current eps 0.09958994382022472 200.0\n",
      "166799, done 842 episodes, -187.5996129545253, current eps 0.09958432584269664 200.0\n",
      "166999, done 843 episodes, -187.51202212649707, current eps 0.09957870786516854 200.0\n",
      "167199, done 844 episodes, -187.48711626773772, current eps 0.09957308988764045 200.0\n",
      "167399, done 845 episodes, -187.67413673992797, current eps 0.09956747191011237 200.0\n",
      "167599, done 846 episodes, -187.49205916671673, current eps 0.09956185393258427 200.0\n",
      "167799, done 847 episodes, -187.4311709853833, current eps 0.09955623595505618 200.0\n",
      "167999, done 848 episodes, -187.3329902631991, current eps 0.0995506179775281 200.0\n",
      "168199, done 849 episodes, -187.28905977222487, current eps 0.099545 200.0\n",
      "168399, done 850 episodes, -187.335502560179, current eps 0.09953938202247191 200.0\n",
      "168599, done 851 episodes, -187.46459368962823, current eps 0.09953376404494382 200.0\n",
      "168799, done 852 episodes, -187.50965055208243, current eps 0.09952814606741574 200.0\n",
      "168999, done 853 episodes, -187.5612718659753, current eps 0.09952252808988764 200.0\n",
      "169199, done 854 episodes, -187.60496286657144, current eps 0.09951691011235955 200.0\n",
      "169399, done 855 episodes, -187.62472895918836, current eps 0.09951129213483147 200.0\n",
      "169599, done 856 episodes, -187.59983317007763, current eps 0.09950567415730337 200.0\n",
      "169799, done 857 episodes, -187.77981404031914, current eps 0.09950005617977528 200.0\n",
      "169999, done 858 episodes, -187.80453311403306, current eps 0.0994944382022472 200.0\n",
      "170199, done 859 episodes, -187.5706533932972, current eps 0.0994888202247191 200.0\n",
      "170399, done 860 episodes, -187.52168169326237, current eps 0.09948320224719101 200.0\n",
      "170599, done 861 episodes, -187.65057152975209, current eps 0.09947758426966292 200.0\n",
      "170799, done 862 episodes, -187.64217720611407, current eps 0.09947196629213484 200.0\n",
      "Evaluation score: -183.14105365774265\n",
      "0 of 20 episodes ended close to / at the final state.\n",
      "170999, done 863 episodes, -187.5952296381366, current eps 0.09946634831460674 200.0\n",
      "171199, done 864 episodes, -187.54633504770464, current eps 0.09946073033707865 200.0\n",
      "171399, done 865 episodes, -187.52510627800908, current eps 0.09945511235955057 200.0\n",
      "171599, done 866 episodes, -187.4092957970162, current eps 0.09944949438202247 200.0\n",
      "171799, done 867 episodes, -187.3327603310228, current eps 0.09944387640449438 200.0\n",
      "171999, done 868 episodes, -187.33154450574347, current eps 0.0994382584269663 200.0\n",
      "172199, done 869 episodes, -187.34564423099113, current eps 0.0994326404494382 200.0\n",
      "172399, done 870 episodes, -187.48736751594137, current eps 0.09942702247191011 200.0\n",
      "172599, done 871 episodes, -187.43633520120275, current eps 0.09942140449438203 200.0\n",
      "172799, done 872 episodes, -187.38320720746444, current eps 0.09941578651685393 200.0\n",
      "172999, done 873 episodes, -187.24659224306362, current eps 0.09941016853932584 200.0\n",
      "173199, done 874 episodes, -187.50851814973495, current eps 0.09940455056179776 200.0\n",
      "173399, done 875 episodes, -187.51311159393893, current eps 0.09939893258426967 200.0\n",
      "173599, done 876 episodes, -187.45034264432542, current eps 0.09939331460674157 200.0\n",
      "173799, done 877 episodes, -187.25599034997592, current eps 0.09938769662921348 200.0\n",
      "173999, done 878 episodes, -187.39442228792726, current eps 0.0993820786516854 200.0\n",
      "174199, done 879 episodes, -187.32263208258857, current eps 0.0993764606741573 200.0\n",
      "174399, done 880 episodes, -187.2322193576725, current eps 0.09937084269662921 200.0\n",
      "174599, done 881 episodes, -187.17025723074806, current eps 0.09936522471910113 200.0\n",
      "174799, done 882 episodes, -187.1145286157722, current eps 0.09935960674157304 200.0\n",
      "174999, done 883 episodes, -186.92520399086473, current eps 0.09935398876404494 200.0\n",
      "175199, done 884 episodes, -186.94560032089416, current eps 0.09934837078651686 200.0\n",
      "175399, done 885 episodes, -186.82949711027976, current eps 0.09934275280898877 200.0\n",
      "175599, done 886 episodes, -186.88884966726394, current eps 0.09933713483146067 200.0\n",
      "175799, done 887 episodes, -186.69223059612588, current eps 0.09933151685393259 200.0\n",
      "175999, done 888 episodes, -186.57788604024427, current eps 0.0993258988764045 200.0\n",
      "176199, done 889 episodes, -186.33543577708141, current eps 0.0993202808988764 200.0\n",
      "176399, done 890 episodes, -186.26589348150446, current eps 0.09931466292134832 200.0\n",
      "176599, done 891 episodes, -186.2133843091941, current eps 0.09930904494382023 200.0\n",
      "176799, done 892 episodes, -186.17160958313113, current eps 0.09930342696629213 200.0\n",
      "176999, done 893 episodes, -186.0213272813724, current eps 0.09929780898876404 200.0\n",
      "177199, done 894 episodes, -186.0082422300754, current eps 0.09929219101123596 200.0\n",
      "177399, done 895 episodes, -186.11203647354145, current eps 0.09928657303370787 200.0\n",
      "177599, done 896 episodes, -186.11203647354142, current eps 0.09928095505617977 200.0\n",
      "177799, done 897 episodes, -186.19079937269606, current eps 0.09927533707865169 200.0\n",
      "177999, done 898 episodes, -186.31723658049697, current eps 0.0992697191011236 200.0\n",
      "178199, done 899 episodes, -186.30314379141618, current eps 0.0992641011235955 200.0\n",
      "178399, done 900 episodes, -186.4080217732493, current eps 0.09925848314606742 200.0\n",
      "178599, done 901 episodes, -186.3650433932067, current eps 0.09925286516853933 200.0\n",
      "178799, done 902 episodes, -186.41630662706518, current eps 0.09924724719101123 200.0\n",
      "178999, done 903 episodes, -186.3640096169186, current eps 0.09924162921348315 200.0\n",
      "179199, done 904 episodes, -186.2729298228643, current eps 0.09923601123595506 200.0\n",
      "179399, done 905 episodes, -186.29397006821895, current eps 0.09923039325842697 200.0\n",
      "179599, done 906 episodes, -186.15347859179917, current eps 0.09922477528089887 200.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179799, done 907 episodes, -186.28764730790775, current eps 0.09921915730337079 200.0\n",
      "179999, done 908 episodes, -186.3306861494355, current eps 0.0992135393258427 200.0\n",
      "180199, done 909 episodes, -186.21734137191547, current eps 0.0992079213483146 200.0\n",
      "180399, done 910 episodes, -186.17034064482925, current eps 0.09920230337078652 200.0\n",
      "180599, done 911 episodes, -186.11970622104437, current eps 0.09919668539325843 200.0\n",
      "180799, done 912 episodes, -186.24063352748072, current eps 0.09919106741573033 200.0\n",
      "Evaluation score: -180.79076167714857\n",
      "0 of 20 episodes ended close to / at the final state.\n",
      "180999, done 913 episodes, -186.3176310817413, current eps 0.09918544943820225 200.0\n",
      "181199, done 914 episodes, -186.4512968263955, current eps 0.09917983146067416 200.0\n",
      "181399, done 915 episodes, -186.44106966904084, current eps 0.09917421348314606 200.0\n",
      "181599, done 916 episodes, -186.67314185029906, current eps 0.09916859550561798 200.0\n",
      "181799, done 917 episodes, -186.55703377452056, current eps 0.09916297752808989 200.0\n",
      "181999, done 918 episodes, -186.46693749030317, current eps 0.0991573595505618 200.0\n",
      "182199, done 919 episodes, -186.57554483712613, current eps 0.0991517415730337 200.0\n",
      "182399, done 920 episodes, -186.5362529710478, current eps 0.09914612359550562 200.0\n",
      "182599, done 921 episodes, -186.66420057037263, current eps 0.09914050561797753 200.0\n",
      "182799, done 922 episodes, -186.685503768022, current eps 0.09913488764044943 200.0\n",
      "182999, done 923 episodes, -186.6587920049494, current eps 0.09912926966292135 200.0\n",
      "183199, done 924 episodes, -186.57669947351135, current eps 0.09912365168539326 200.0\n",
      "183399, done 925 episodes, -186.57435275432306, current eps 0.09911803370786516 200.0\n",
      "183599, done 926 episodes, -186.67341605459046, current eps 0.09911241573033708 200.0\n",
      "183799, done 927 episodes, -186.54944570080872, current eps 0.09910679775280899 200.0\n",
      "183999, done 928 episodes, -186.54826035392895, current eps 0.0991011797752809 200.0\n",
      "184199, done 929 episodes, -186.5539378324359, current eps 0.0990955617977528 200.0\n",
      "184399, done 930 episodes, -186.50428562731835, current eps 0.09908994382022472 200.0\n",
      "184599, done 931 episodes, -186.51335761342057, current eps 0.09908432584269664 200.0\n",
      "184799, done 932 episodes, -186.4115079573043, current eps 0.09907870786516854 200.0\n",
      "184999, done 933 episodes, -186.5890368162479, current eps 0.09907308988764045 200.0\n",
      "185199, done 934 episodes, -186.46267993758804, current eps 0.09906747191011236 200.0\n",
      "185399, done 935 episodes, -186.50698902481483, current eps 0.09906185393258427 200.0\n",
      "185599, done 936 episodes, -186.57168144654239, current eps 0.09905623595505618 200.0\n",
      "185799, done 937 episodes, -186.71623331371694, current eps 0.0990506179775281 200.0\n",
      "185999, done 938 episodes, -186.79175281070962, current eps 0.099045 200.0\n",
      "186199, done 939 episodes, -186.5449574341897, current eps 0.09903938202247191 200.0\n",
      "186399, done 940 episodes, -186.55166680155625, current eps 0.09903376404494382 200.0\n",
      "186599, done 941 episodes, -186.46611819670952, current eps 0.09902814606741574 200.0\n",
      "186799, done 942 episodes, -186.3500347606593, current eps 0.09902252808988764 200.0\n",
      "186999, done 943 episodes, -186.6277399386702, current eps 0.09901691011235955 200.0\n",
      "187199, done 944 episodes, -186.6887699743681, current eps 0.09901129213483147 200.0\n",
      "187399, done 945 episodes, -186.67708216620463, current eps 0.09900567415730337 200.0\n",
      "187599, done 946 episodes, -186.7860563053383, current eps 0.09900005617977528 200.0\n",
      "187799, done 947 episodes, -186.76174224587083, current eps 0.0989944382022472 200.0\n",
      "187999, done 948 episodes, -186.79916329490814, current eps 0.09898882022471911 200.0\n",
      "188199, done 949 episodes, -186.69422387146238, current eps 0.09898320224719101 200.0\n",
      "188399, done 950 episodes, -186.60557258709886, current eps 0.09897758426966292 200.0\n",
      "188599, done 951 episodes, -186.5781743693411, current eps 0.09897196629213484 200.0\n",
      "188799, done 952 episodes, -186.29663740683839, current eps 0.09896634831460674 200.0\n",
      "188999, done 953 episodes, -186.26006545459975, current eps 0.09896073033707865 200.0\n",
      "189199, done 954 episodes, -186.18415604810014, current eps 0.09895511235955057 200.0\n",
      "189399, done 955 episodes, -185.86263940356312, current eps 0.09894949438202247 200.0\n",
      "189599, done 956 episodes, -185.75395624959788, current eps 0.09894387640449438 200.0\n",
      "189799, done 957 episodes, -185.82461589428257, current eps 0.0989382584269663 200.0\n",
      "189999, done 958 episodes, -185.85638870651061, current eps 0.0989326404494382 200.0\n",
      "190199, done 959 episodes, -185.98251578587298, current eps 0.09892702247191011 200.0\n",
      "190399, done 960 episodes, -186.1878985953525, current eps 0.09892140449438203 200.0\n",
      "190599, done 961 episodes, -185.9615214036233, current eps 0.09891578651685394 200.0\n",
      "190799, done 962 episodes, -186.06503463349287, current eps 0.09891016853932584 200.0\n",
      "Evaluation score: -165.47546978646528\n",
      "0 of 20 episodes ended close to / at the final state.\n",
      "190999, done 963 episodes, -186.04797838700102, current eps 0.09890455056179775 200.0\n",
      "191199, done 964 episodes, -186.09442872862215, current eps 0.09889893258426967 200.0\n",
      "191399, done 965 episodes, -186.0407565809771, current eps 0.09889331460674157 200.0\n",
      "191599, done 966 episodes, -186.10472368057629, current eps 0.09888769662921348 200.0\n",
      "191799, done 967 episodes, -186.11305040424634, current eps 0.0988820786516854 200.0\n",
      "191999, done 968 episodes, -186.13891188547106, current eps 0.0988764606741573 200.0\n",
      "192199, done 969 episodes, -186.19340928194129, current eps 0.09887084269662921 200.0\n",
      "192399, done 970 episodes, -185.9982199557718, current eps 0.09886522471910113 200.0\n",
      "192599, done 971 episodes, -186.13950176118271, current eps 0.09885960674157304 200.0\n",
      "192799, done 972 episodes, -186.09766912429004, current eps 0.09885398876404494 200.0\n",
      "192999, done 973 episodes, -186.23740831464372, current eps 0.09884837078651686 200.0\n",
      "193199, done 974 episodes, -186.09597661430126, current eps 0.09884275280898877 200.0\n",
      "193399, done 975 episodes, -186.05620886604183, current eps 0.09883713483146067 200.0\n",
      "193599, done 976 episodes, -185.88345573019944, current eps 0.09883151685393259 200.0\n",
      "193799, done 977 episodes, -186.1215323165664, current eps 0.0988258988764045 200.0\n",
      "193999, done 978 episodes, -186.11579659237515, current eps 0.0988202808988764 200.0\n",
      "194199, done 979 episodes, -186.01427191658547, current eps 0.09881466292134831 200.0\n",
      "194399, done 980 episodes, -185.9284590475134, current eps 0.09880904494382023 200.0\n",
      "194599, done 981 episodes, -185.93761270381924, current eps 0.09880342696629213 200.0\n",
      "194799, done 982 episodes, -185.9168290044086, current eps 0.09879780898876404 200.0\n",
      "194999, done 983 episodes, -186.18259168463942, current eps 0.09879219101123596 200.0\n",
      "195199, done 984 episodes, -186.15744384267833, current eps 0.09878657303370787 200.0\n",
      "195399, done 985 episodes, -186.24492369741537, current eps 0.09878095505617977 200.0\n",
      "195599, done 986 episodes, -186.14854109465628, current eps 0.09877533707865169 200.0\n",
      "195799, done 987 episodes, -186.1648991475374, current eps 0.0987697191011236 200.0\n",
      "195999, done 988 episodes, -186.28010107460105, current eps 0.0987641011235955 200.0\n",
      "196199, done 989 episodes, -186.39753534078085, current eps 0.09875848314606742 200.0\n",
      "196399, done 990 episodes, -186.3828690159815, current eps 0.09875286516853933 200.0\n",
      "196599, done 991 episodes, -186.55265737008526, current eps 0.09874724719101123 200.0\n",
      "196799, done 992 episodes, -186.728312934309, current eps 0.09874162921348315 200.0\n",
      "196999, done 993 episodes, -186.9319140312187, current eps 0.09873601123595506 200.0\n",
      "197199, done 994 episodes, -187.03512404848234, current eps 0.09873039325842697 200.0\n",
      "197399, done 995 episodes, -186.92221112313342, current eps 0.09872477528089887 200.0\n",
      "197599, done 996 episodes, -186.77245066816397, current eps 0.09871915730337079 200.0\n",
      "197799, done 997 episodes, -186.63829378605925, current eps 0.0987135393258427 200.0\n",
      "197999, done 998 episodes, -186.57077820846172, current eps 0.0987079213483146 200.0\n",
      "198199, done 999 episodes, -186.55256676225807, current eps 0.09870230337078652 200.0\n",
      "198399, done 1000 episodes, -186.60091799970917, current eps 0.09869668539325843 200.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198599, done 1001 episodes, -186.46052694835976, current eps 0.09869106741573033 200.0\n",
      "198799, done 1002 episodes, -186.18855208237687, current eps 0.09868544943820225 200.0\n",
      "198999, done 1003 episodes, -186.2733096478729, current eps 0.09867983146067416 200.0\n",
      "199199, done 1004 episodes, -186.16543674199926, current eps 0.09867421348314606 200.0\n",
      "199399, done 1005 episodes, -186.1508215871134, current eps 0.09866859550561798 200.0\n",
      "199599, done 1006 episodes, -185.99182657795984, current eps 0.09866297752808989 200.0\n",
      "199799, done 1007 episodes, -185.9270425026391, current eps 0.0986573595505618 200.0\n",
      "199999, done 1008 episodes, -185.9233797603655, current eps 0.0986517415730337 200.0\n",
      "200199, done 1009 episodes, -186.00292834067267, current eps 0.09864612359550562 200.0\n",
      "200399, done 1010 episodes, -186.0150447970866, current eps 0.09864050561797753 200.0\n",
      "200599, done 1011 episodes, -185.97233169686305, current eps 0.09863488764044943 200.0\n",
      "200799, done 1012 episodes, -185.88054411129855, current eps 0.09862926966292135 200.0\n",
      "Evaluation score: -175.47398945196363\n",
      "0 of 20 episodes ended close to / at the final state.\n",
      "200999, done 1013 episodes, -185.88643148966102, current eps 0.09862365168539326 200.0\n",
      "201199, done 1014 episodes, -185.80061408441182, current eps 0.09861803370786518 200.0\n",
      "201399, done 1015 episodes, -185.80100948365177, current eps 0.09861241573033708 200.0\n",
      "201599, done 1016 episodes, -185.6624184207549, current eps 0.09860679775280899 200.0\n",
      "201799, done 1017 episodes, -185.73705252705878, current eps 0.0986011797752809 200.0\n",
      "201999, done 1018 episodes, -185.7822524310053, current eps 0.0985955617977528 200.0\n",
      "202199, done 1019 episodes, -185.73570530618136, current eps 0.09858994382022472 200.0\n",
      "202399, done 1020 episodes, -185.6270906603235, current eps 0.09858432584269664 200.0\n",
      "202599, done 1021 episodes, -185.4729926287686, current eps 0.09857870786516854 200.0\n",
      "202799, done 1022 episodes, -185.56682783109022, current eps 0.09857308988764045 200.0\n",
      "202999, done 1023 episodes, -185.54974344528057, current eps 0.09856747191011236 200.0\n",
      "203199, done 1024 episodes, -185.66855796302843, current eps 0.09856185393258426 200.0\n",
      "203399, done 1025 episodes, -185.71644927077224, current eps 0.09855623595505618 200.0\n",
      "203599, done 1026 episodes, -185.53078939194504, current eps 0.0985506179775281 200.0\n",
      "203799, done 1027 episodes, -185.46049565134038, current eps 0.09854500000000001 200.0\n",
      "203999, done 1028 episodes, -185.4891473145535, current eps 0.09853938202247191 200.0\n",
      "204199, done 1029 episodes, -185.61456031534834, current eps 0.09853376404494382 200.0\n",
      "204399, done 1030 episodes, -185.59841003365975, current eps 0.09852814606741574 200.0\n",
      "204599, done 1031 episodes, -185.67013986387275, current eps 0.09852252808988764 200.0\n",
      "204799, done 1032 episodes, -185.71167046501026, current eps 0.09851691011235955 200.0\n",
      "204999, done 1033 episodes, -185.59377062136787, current eps 0.09851129213483147 200.0\n",
      "205199, done 1034 episodes, -185.56257579905153, current eps 0.09850567415730337 200.0\n",
      "205399, done 1035 episodes, -185.43390831120706, current eps 0.09850005617977528 200.0\n",
      "205599, done 1036 episodes, -185.3368997930675, current eps 0.0984944382022472 200.0\n",
      "205799, done 1037 episodes, -185.31669797543682, current eps 0.09848882022471911 200.0\n",
      "205999, done 1038 episodes, -185.0871444129264, current eps 0.09848320224719101 200.0\n",
      "206199, done 1039 episodes, -185.20174559448208, current eps 0.09847758426966292 200.0\n",
      "206399, done 1040 episodes, -185.11423841613453, current eps 0.09847196629213484 200.0\n",
      "206599, done 1041 episodes, -185.18022969514203, current eps 0.09846634831460674 200.0\n",
      "206799, done 1042 episodes, -185.1526787269047, current eps 0.09846073033707865 200.0\n",
      "206999, done 1043 episodes, -184.87827704337448, current eps 0.09845511235955057 200.0\n",
      "207199, done 1044 episodes, -184.8942162776268, current eps 0.09844949438202247 200.0\n",
      "207399, done 1045 episodes, -184.88038519861715, current eps 0.09844387640449438 200.0\n",
      "207599, done 1046 episodes, -184.676854120082, current eps 0.0984382584269663 200.0\n",
      "207799, done 1047 episodes, -184.6758236508014, current eps 0.0984326404494382 200.0\n",
      "207999, done 1048 episodes, -184.6464121197984, current eps 0.09842702247191011 200.0\n",
      "208199, done 1049 episodes, -184.66144198187695, current eps 0.09842140449438203 200.0\n",
      "208399, done 1050 episodes, -184.68535707439088, current eps 0.09841578651685394 200.0\n",
      "208599, done 1051 episodes, -184.58816929147218, current eps 0.09841016853932584 200.0\n",
      "208799, done 1052 episodes, -184.78209907946066, current eps 0.09840455056179775 200.0\n",
      "208999, done 1053 episodes, -184.6958888825527, current eps 0.09839893258426967 200.0\n",
      "209199, done 1054 episodes, -184.6201691644646, current eps 0.09839331460674157 200.0\n",
      "209399, done 1055 episodes, -184.8925932213944, current eps 0.09838769662921348 200.0\n",
      "209599, done 1056 episodes, -184.9781625893343, current eps 0.0983820786516854 200.0\n",
      "209799, done 1057 episodes, -184.82619908602067, current eps 0.0983764606741573 200.0\n",
      "209999, done 1058 episodes, -184.75332703486703, current eps 0.09837084269662921 200.0\n",
      "210199, done 1059 episodes, -184.84869358727872, current eps 0.09836522471910113 200.0\n",
      "210399, done 1060 episodes, -184.73665703459807, current eps 0.09835960674157304 200.0\n",
      "210599, done 1061 episodes, -184.84495512744434, current eps 0.09835398876404494 200.0\n",
      "210799, done 1062 episodes, -184.59869021953546, current eps 0.09834837078651686 200.0\n",
      "Evaluation score: -168.37230222481168\n",
      "0 of 20 episodes ended close to / at the final state.\n",
      "210999, done 1063 episodes, -184.67532581958503, current eps 0.09834275280898877 200.0\n",
      "211199, done 1064 episodes, -184.61133654715542, current eps 0.09833713483146067 200.0\n",
      "211399, done 1065 episodes, -184.54022087715578, current eps 0.09833151685393259 200.0\n",
      "211599, done 1066 episodes, -184.63210791873985, current eps 0.0983258988764045 200.0\n",
      "211799, done 1067 episodes, -184.49174828503038, current eps 0.0983202808988764 200.0\n",
      "211999, done 1068 episodes, -184.5311840163877, current eps 0.09831466292134831 200.0\n",
      "212199, done 1069 episodes, -184.4171505592297, current eps 0.09830904494382023 200.0\n",
      "212399, done 1070 episodes, -184.30427800902254, current eps 0.09830342696629213 200.0\n",
      "212599, done 1071 episodes, -184.24497142352658, current eps 0.09829780898876404 200.0\n",
      "212799, done 1072 episodes, -184.36585485110479, current eps 0.09829219101123596 200.0\n",
      "212999, done 1073 episodes, -184.31114737562754, current eps 0.09828657303370787 200.0\n",
      "213199, done 1074 episodes, -184.1391060474671, current eps 0.09828095505617977 200.0\n",
      "213399, done 1075 episodes, -184.23982864084428, current eps 0.09827533707865169 200.0\n",
      "213599, done 1076 episodes, -184.46937107675097, current eps 0.0982697191011236 200.0\n",
      "213799, done 1077 episodes, -184.3743107658247, current eps 0.0982641011235955 200.0\n",
      "213999, done 1078 episodes, -184.415802643792, current eps 0.09825848314606742 200.0\n",
      "214199, done 1079 episodes, -184.61562563152057, current eps 0.09825286516853933 200.0\n",
      "214399, done 1080 episodes, -184.7686414395653, current eps 0.09824724719101124 200.0\n",
      "214599, done 1081 episodes, -184.95249993134215, current eps 0.09824162921348314 200.0\n",
      "214799, done 1082 episodes, -184.71770086805031, current eps 0.09823601123595506 200.0\n",
      "214999, done 1083 episodes, -184.70534198407321, current eps 0.09823039325842697 200.0\n",
      "215199, done 1084 episodes, -184.59538425401232, current eps 0.09822477528089887 200.0\n",
      "215399, done 1085 episodes, -184.63112285785053, current eps 0.09821915730337079 200.0\n",
      "215599, done 1086 episodes, -184.6748613957601, current eps 0.0982135393258427 200.0\n",
      "215799, done 1087 episodes, -184.90370899927518, current eps 0.0982079213483146 200.0\n",
      "215999, done 1088 episodes, -184.81000901636003, current eps 0.09820230337078652 200.0\n",
      "216199, done 1089 episodes, -184.88378046574806, current eps 0.09819668539325843 200.0\n",
      "216399, done 1090 episodes, -184.77231766173387, current eps 0.09819106741573033 200.0\n",
      "216599, done 1091 episodes, -184.67042978276524, current eps 0.09818544943820225 200.0\n",
      "216799, done 1092 episodes, -184.61790499501097, current eps 0.09817983146067416 200.0\n",
      "216999, done 1093 episodes, -184.50776005500254, current eps 0.09817421348314607 200.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217199, done 1094 episodes, -184.4671939900458, current eps 0.09816859550561798 200.0\n",
      "217399, done 1095 episodes, -184.3270178460932, current eps 0.09816297752808989 200.0\n",
      "217599, done 1096 episodes, -184.39259956068673, current eps 0.0981573595505618 200.0\n",
      "217799, done 1097 episodes, -184.5934646023112, current eps 0.0981517415730337 200.0\n",
      "217999, done 1098 episodes, -184.60386562962856, current eps 0.09814612359550562 200.0\n",
      "218199, done 1099 episodes, -184.6503127076328, current eps 0.09814050561797753 200.0\n",
      "218399, done 1100 episodes, -184.51103136393104, current eps 0.09813488764044943 200.0\n",
      "218599, done 1101 episodes, -184.58951071936085, current eps 0.09812926966292135 200.0\n",
      "218799, done 1102 episodes, -184.8883377388138, current eps 0.09812365168539326 200.0\n",
      "218999, done 1103 episodes, -184.7433042238209, current eps 0.09811803370786518 200.0\n",
      "219199, done 1104 episodes, -184.85272174179022, current eps 0.09811241573033708 200.0\n",
      "219399, done 1105 episodes, -184.80022063624082, current eps 0.09810679775280899 200.0\n",
      "219599, done 1106 episodes, -184.95483383847298, current eps 0.0981011797752809 200.0\n",
      "219799, done 1107 episodes, -185.01473772288466, current eps 0.0980955617977528 200.0\n",
      "219999, done 1108 episodes, -184.96540108719802, current eps 0.09808994382022472 200.0\n",
      "220199, done 1109 episodes, -185.0054371156244, current eps 0.09808432584269663 200.0\n",
      "220399, done 1110 episodes, -185.095310626891, current eps 0.09807870786516854 200.0\n",
      "220599, done 1111 episodes, -185.1143821641995, current eps 0.09807308988764045 200.0\n",
      "220799, done 1112 episodes, -185.11579984602176, current eps 0.09806747191011236 200.0\n",
      "Evaluation score: -148.31138242422773\n",
      "0 of 20 episodes ended close to / at the final state.\n",
      "220999, done 1113 episodes, -185.0742641315637, current eps 0.09806185393258426 200.0\n",
      "221199, done 1114 episodes, -184.9989627228202, current eps 0.09805623595505618 200.0\n",
      "221399, done 1115 episodes, -184.88139844292874, current eps 0.09805061797752809 200.0\n",
      "221599, done 1116 episodes, -184.88349385259409, current eps 0.09804500000000001 200.0\n",
      "221799, done 1117 episodes, -184.8339620620618, current eps 0.09803938202247191 200.0\n",
      "221999, done 1118 episodes, -184.69411155778232, current eps 0.09803376404494382 200.0\n",
      "222199, done 1119 episodes, -184.7148840641767, current eps 0.09802814606741574 200.0\n",
      "222399, done 1120 episodes, -184.85706893712648, current eps 0.09802252808988764 200.0\n",
      "222599, done 1121 episodes, -185.0359128637392, current eps 0.09801691011235955 200.0\n",
      "222799, done 1122 episodes, -185.02174015976794, current eps 0.09801129213483147 200.0\n",
      "222999, done 1123 episodes, -185.1376726755127, current eps 0.09800567415730337 200.0\n",
      "223199, done 1124 episodes, -184.96276905285526, current eps 0.09800005617977528 200.0\n",
      "223399, done 1125 episodes, -184.6039767917568, current eps 0.0979944382022472 200.0\n",
      "223599, done 1126 episodes, -184.6859822634358, current eps 0.09798882022471911 200.0\n",
      "223799, done 1127 episodes, -184.7318918555914, current eps 0.09798320224719101 200.0\n",
      "223999, done 1128 episodes, -184.5949969352704, current eps 0.09797758426966292 200.0\n",
      "224199, done 1129 episodes, -184.59256041616703, current eps 0.09797196629213484 200.0\n",
      "224399, done 1130 episodes, -184.61890801633785, current eps 0.09796634831460674 200.0\n",
      "224599, done 1131 episodes, -184.23861525638208, current eps 0.09796073033707865 200.0\n",
      "224799, done 1132 episodes, -184.36114407303896, current eps 0.09795511235955057 200.0\n",
      "224999, done 1133 episodes, -184.4260445873395, current eps 0.09794949438202247 200.0\n",
      "225199, done 1134 episodes, -184.47176398075854, current eps 0.09794387640449438 200.0\n",
      "225399, done 1135 episodes, -184.56148261177995, current eps 0.0979382584269663 200.0\n",
      "225599, done 1136 episodes, -184.6794342808981, current eps 0.0979326404494382 200.0\n",
      "225799, done 1137 episodes, -184.58153245680603, current eps 0.09792702247191011 200.0\n",
      "225999, done 1138 episodes, -184.51940416995873, current eps 0.09792140449438202 200.0\n",
      "226199, done 1139 episodes, -184.61454520772728, current eps 0.09791578651685394 200.0\n",
      "226399, done 1140 episodes, -184.77507080028488, current eps 0.09791016853932584 200.0\n",
      "226599, done 1141 episodes, -184.75530430975027, current eps 0.09790455056179775 200.0\n",
      "226799, done 1142 episodes, -184.97010629749354, current eps 0.09789893258426967 200.0\n",
      "226999, done 1143 episodes, -185.1243702988423, current eps 0.09789331460674157 200.0\n",
      "227199, done 1144 episodes, -185.03310682625968, current eps 0.09788769662921348 200.0\n",
      "227399, done 1145 episodes, -184.97264492912498, current eps 0.0978820786516854 200.0\n",
      "227599, done 1146 episodes, -185.15540082328735, current eps 0.09787646067415731 200.0\n",
      "227799, done 1147 episodes, -185.2139231124403, current eps 0.09787084269662921 200.0\n",
      "227999, done 1148 episodes, -185.2310968958677, current eps 0.09786522471910113 200.0\n",
      "228199, done 1149 episodes, -185.42750102745077, current eps 0.09785960674157304 200.0\n",
      "228399, done 1150 episodes, -185.47542895175576, current eps 0.09785398876404494 200.0\n",
      "228599, done 1151 episodes, -185.40586856997595, current eps 0.09784837078651686 200.0\n",
      "228799, done 1152 episodes, -185.4093762841311, current eps 0.09784275280898877 200.0\n",
      "228999, done 1153 episodes, -185.63282821535932, current eps 0.09783713483146067 200.0\n",
      "229199, done 1154 episodes, -185.6130349631677, current eps 0.09783151685393258 200.0\n",
      "229399, done 1155 episodes, -185.60304137622373, current eps 0.0978258988764045 200.0\n",
      "229599, done 1156 episodes, -185.70011104649507, current eps 0.0978202808988764 200.0\n",
      "229799, done 1157 episodes, -185.84778262509198, current eps 0.09781466292134831 200.0\n",
      "229999, done 1158 episodes, -185.81619356983057, current eps 0.09780904494382023 200.0\n",
      "230199, done 1159 episodes, -185.68179176906335, current eps 0.09780342696629214 200.0\n",
      "230399, done 1160 episodes, -185.43464634036428, current eps 0.09779780898876404 200.0\n",
      "230599, done 1161 episodes, -185.39517142668282, current eps 0.09779219101123596 200.0\n",
      "230799, done 1162 episodes, -185.47166842506064, current eps 0.09778657303370787 200.0\n",
      "Evaluation score: -170.64427365617786\n",
      "0 of 20 episodes ended close to / at the final state.\n",
      "230999, done 1163 episodes, -185.4923991097477, current eps 0.09778095505617977 200.0\n",
      "231199, done 1164 episodes, -185.36214083935567, current eps 0.09777533707865169 200.0\n",
      "231399, done 1165 episodes, -185.3611573863302, current eps 0.0977697191011236 200.0\n",
      "231599, done 1166 episodes, -184.96821716086882, current eps 0.0977641011235955 200.0\n",
      "231799, done 1167 episodes, -185.17015914669545, current eps 0.09775848314606742 200.0\n",
      "231999, done 1168 episodes, -185.06404586860023, current eps 0.09775286516853933 200.0\n",
      "232199, done 1169 episodes, -185.24362345823877, current eps 0.09774724719101124 200.0\n",
      "232399, done 1170 episodes, -185.21109006505685, current eps 0.09774162921348314 200.0\n",
      "232599, done 1171 episodes, -185.2403690164269, current eps 0.09773601123595506 200.0\n",
      "232799, done 1172 episodes, -185.17411508900193, current eps 0.09773039325842697 200.0\n",
      "232999, done 1173 episodes, -185.24683280457862, current eps 0.09772477528089887 200.0\n",
      "233199, done 1174 episodes, -185.40191052123697, current eps 0.09771915730337079 200.0\n",
      "233399, done 1175 episodes, -185.38891550264478, current eps 0.0977135393258427 200.0\n",
      "233599, done 1176 episodes, -185.37479347645967, current eps 0.0977079213483146 200.0\n",
      "233799, done 1177 episodes, -185.3135919290181, current eps 0.09770230337078652 200.0\n",
      "233999, done 1178 episodes, -185.2992612020294, current eps 0.09769668539325843 200.0\n",
      "234199, done 1179 episodes, -185.30743700992258, current eps 0.09769106741573033 200.0\n",
      "234399, done 1180 episodes, -185.2994796846876, current eps 0.09768544943820225 200.0\n",
      "234599, done 1181 episodes, -185.04780826122234, current eps 0.09767983146067416 200.0\n",
      "234799, done 1182 episodes, -185.31670422371346, current eps 0.09767421348314607 200.0\n",
      "234999, done 1183 episodes, -185.12590117933206, current eps 0.09766859550561797 200.0\n",
      "235199, done 1184 episodes, -185.21466787303575, current eps 0.09766297752808989 200.0\n",
      "235399, done 1185 episodes, -185.3041874522014, current eps 0.0976573595505618 200.0\n",
      "235599, done 1186 episodes, -185.30754015795125, current eps 0.0976517415730337 200.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235799, done 1187 episodes, -185.2961119090118, current eps 0.09764612359550562 200.0\n",
      "235999, done 1188 episodes, -185.43166498733498, current eps 0.09764050561797753 200.0\n",
      "236199, done 1189 episodes, -185.2970662892488, current eps 0.09763488764044943 200.0\n",
      "236399, done 1190 episodes, -185.40990970086415, current eps 0.09762926966292135 200.0\n",
      "236599, done 1191 episodes, -185.45837078149808, current eps 0.09762365168539326 200.0\n",
      "236799, done 1192 episodes, -185.38709641188677, current eps 0.09761803370786518 200.0\n",
      "236999, done 1193 episodes, -185.39100736558987, current eps 0.09761241573033708 200.0\n",
      "237199, done 1194 episodes, -185.2863391246102, current eps 0.09760679775280899 200.0\n",
      "237399, done 1195 episodes, -185.52749769655685, current eps 0.0976011797752809 200.0\n",
      "237599, done 1196 episodes, -185.70273954881736, current eps 0.0975955617977528 200.0\n",
      "237799, done 1197 episodes, -185.57644283302045, current eps 0.09758994382022472 200.0\n",
      "237999, done 1198 episodes, -185.50508048566212, current eps 0.09758432584269663 200.0\n",
      "238199, done 1199 episodes, -185.65559907521254, current eps 0.09757870786516853 200.0\n",
      "238399, done 1200 episodes, -185.6809912276236, current eps 0.09757308988764045 200.0\n",
      "238599, done 1201 episodes, -185.78419774381086, current eps 0.09756747191011236 200.0\n",
      "238799, done 1202 episodes, -185.76923174870961, current eps 0.09756185393258426 200.0\n",
      "238999, done 1203 episodes, -185.83748129069957, current eps 0.09755623595505618 200.0\n",
      "239199, done 1204 episodes, -185.75424460476427, current eps 0.09755061797752809 200.0\n",
      "239399, done 1205 episodes, -185.7984601037544, current eps 0.097545 200.0\n",
      "239599, done 1206 episodes, -185.72851459473648, current eps 0.09753938202247191 200.0\n",
      "239799, done 1207 episodes, -185.49257420819941, current eps 0.09753376404494382 200.0\n",
      "239999, done 1208 episodes, -185.54313681437858, current eps 0.09752814606741574 200.0\n",
      "240199, done 1209 episodes, -185.59864104912373, current eps 0.09752252808988764 200.0\n",
      "240399, done 1210 episodes, -185.1684636432844, current eps 0.09751691011235955 200.0\n",
      "240599, done 1211 episodes, -185.30116293465005, current eps 0.09751129213483146 200.0\n",
      "240799, done 1212 episodes, -185.11320070366054, current eps 0.09750567415730338 200.0\n",
      "Evaluation score: -163.36198377355737\n",
      "0 of 20 episodes ended close to / at the final state.\n",
      "240999, done 1213 episodes, -185.07418656253603, current eps 0.09750005617977528 200.0\n",
      "241199, done 1214 episodes, -185.096703604691, current eps 0.0974944382022472 200.0\n",
      "241399, done 1215 episodes, -185.34490947517943, current eps 0.09748882022471911 200.0\n",
      "241599, done 1216 episodes, -185.45471047441342, current eps 0.09748320224719101 200.0\n",
      "241799, done 1217 episodes, -185.47466191271883, current eps 0.09747758426966292 200.0\n",
      "241999, done 1218 episodes, -185.63518233623086, current eps 0.09747196629213484 200.0\n",
      "242199, done 1219 episodes, -185.50571504942985, current eps 0.09746634831460674 200.0\n",
      "242399, done 1220 episodes, -185.388636796512, current eps 0.09746073033707865 200.0\n",
      "242599, done 1221 episodes, -185.2808313823632, current eps 0.09745511235955057 200.0\n",
      "242799, done 1222 episodes, -185.20880842903804, current eps 0.09744949438202247 200.0\n",
      "242999, done 1223 episodes, -185.12725126981425, current eps 0.09744387640449438 200.0\n",
      "243199, done 1224 episodes, -185.25220798469843, current eps 0.0974382584269663 200.0\n",
      "243399, done 1225 episodes, -185.50656835326816, current eps 0.09743264044943821 200.0\n",
      "243599, done 1226 episodes, -185.45432409740224, current eps 0.09742702247191011 200.0\n",
      "243799, done 1227 episodes, -185.46892228448004, current eps 0.09742140449438202 200.0\n",
      "243999, done 1228 episodes, -185.6600612757344, current eps 0.09741578651685394 200.0\n",
      "244199, done 1229 episodes, -185.67721927062013, current eps 0.09741016853932584 200.0\n",
      "244399, done 1230 episodes, -185.61717568730785, current eps 0.09740455056179775 200.0\n",
      "244599, done 1231 episodes, -185.90234455888444, current eps 0.09739893258426967 200.0\n",
      "244799, done 1232 episodes, -185.72840342186325, current eps 0.09739331460674157 200.0\n",
      "244999, done 1233 episodes, -185.75566486647315, current eps 0.09738769662921348 200.0\n",
      "245199, done 1234 episodes, -185.82931434081186, current eps 0.0973820786516854 200.0\n",
      "245399, done 1235 episodes, -185.78311302775853, current eps 0.09737646067415731 200.0\n",
      "245599, done 1236 episodes, -185.63612997156716, current eps 0.09737084269662921 200.0\n",
      "245799, done 1237 episodes, -185.47224088627277, current eps 0.09736522471910113 200.0\n",
      "245999, done 1238 episodes, -185.76392209034955, current eps 0.09735960674157304 200.0\n",
      "246199, done 1239 episodes, -185.5539499078658, current eps 0.09735398876404494 200.0\n",
      "246399, done 1240 episodes, -185.64576317226908, current eps 0.09734837078651686 200.0\n",
      "246599, done 1241 episodes, -185.69084317888016, current eps 0.09734275280898877 200.0\n",
      "246799, done 1242 episodes, -185.52178505776592, current eps 0.09733713483146067 200.0\n",
      "246999, done 1243 episodes, -185.37567783499043, current eps 0.09733151685393258 200.0\n",
      "247199, done 1244 episodes, -185.30431174379675, current eps 0.0973258988764045 200.0\n",
      "247399, done 1245 episodes, -185.39866446574143, current eps 0.0973202808988764 200.0\n",
      "247599, done 1246 episodes, -185.4122743139619, current eps 0.09731466292134831 200.0\n",
      "247799, done 1247 episodes, -185.41733656669112, current eps 0.09730904494382023 200.0\n",
      "247999, done 1248 episodes, -185.22801388601195, current eps 0.09730342696629214 200.0\n",
      "248199, done 1249 episodes, -185.20813752233195, current eps 0.09729780898876404 200.0\n",
      "248399, done 1250 episodes, -184.93403565017684, current eps 0.09729219101123596 200.0\n",
      "248599, done 1251 episodes, -184.96993743252082, current eps 0.09728657303370787 200.0\n",
      "248799, done 1252 episodes, -184.6888144254522, current eps 0.09728095505617977 200.0\n",
      "248999, done 1253 episodes, -184.73278579963778, current eps 0.09727533707865169 200.0\n",
      "249199, done 1254 episodes, -184.63154453051354, current eps 0.0972697191011236 200.0\n",
      "249399, done 1255 episodes, -184.609071456739, current eps 0.0972641011235955 200.0\n",
      "249599, done 1256 episodes, -184.5372070683647, current eps 0.09725848314606741 200.0\n",
      "249799, done 1257 episodes, -184.20194242504135, current eps 0.09725286516853933 200.0\n",
      "249999, done 1258 episodes, -184.2192306473758, current eps 0.09724724719101124 200.0\n",
      "250199, done 1259 episodes, -184.253481446498, current eps 0.09724162921348314 200.0\n",
      "250399, done 1260 episodes, -184.5224727032533, current eps 0.09723601123595506 200.0\n",
      "250599, done 1261 episodes, -184.36305969026475, current eps 0.09723039325842697 200.0\n",
      "250799, done 1262 episodes, -184.454012991482, current eps 0.09722477528089887 200.0\n",
      "Evaluation score: -169.9754445441416\n",
      "0 of 20 episodes ended close to / at the final state.\n",
      "250999, done 1263 episodes, -184.4872762871443, current eps 0.09721915730337079 200.0\n",
      "251199, done 1264 episodes, -184.6748403851004, current eps 0.0972135393258427 200.0\n",
      "251399, done 1265 episodes, -184.66302919781728, current eps 0.0972079213483146 200.0\n",
      "251599, done 1266 episodes, -184.97853399786814, current eps 0.09720230337078652 200.0\n",
      "251799, done 1267 episodes, -184.9561330289799, current eps 0.09719668539325843 200.0\n",
      "251999, done 1268 episodes, -184.9710092768368, current eps 0.09719106741573033 200.0\n",
      "252199, done 1269 episodes, -184.9026868071617, current eps 0.09718544943820225 200.0\n",
      "252399, done 1270 episodes, -185.1347653948126, current eps 0.09717983146067416 200.0\n",
      "252599, done 1271 episodes, -184.99816134772811, current eps 0.09717421348314607 200.0\n",
      "252799, done 1272 episodes, -184.74681755605525, current eps 0.09716859550561797 200.0\n",
      "252999, done 1273 episodes, -184.73689238914295, current eps 0.09716297752808989 200.0\n",
      "253199, done 1274 episodes, -184.8725891872633, current eps 0.0971573595505618 200.0\n",
      "253399, done 1275 episodes, -184.8203841133227, current eps 0.0971517415730337 200.0\n",
      "253599, done 1276 episodes, -184.49603625757794, current eps 0.09714612359550562 200.0\n",
      "253799, done 1277 episodes, -184.5117835564092, current eps 0.09714050561797753 200.0\n",
      "253999, done 1278 episodes, -184.32967064013386, current eps 0.09713488764044945 200.0\n",
      "254199, done 1279 episodes, -184.1406390253819, current eps 0.09712926966292135 200.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254399, done 1280 episodes, -184.07306799615372, current eps 0.09712365168539326 200.0\n",
      "254599, done 1281 episodes, -184.2104465658166, current eps 0.09711803370786518 200.0\n",
      "254799, done 1282 episodes, -184.01158999095915, current eps 0.09711241573033708 200.0\n",
      "254999, done 1283 episodes, -184.1789952765486, current eps 0.09710679775280899 200.0\n",
      "255199, done 1284 episodes, -184.09206438237598, current eps 0.0971011797752809 200.0\n",
      "255399, done 1285 episodes, -184.07178024911957, current eps 0.0970955617977528 200.0\n",
      "255599, done 1286 episodes, -184.07232783956817, current eps 0.09708994382022472 200.0\n",
      "255799, done 1287 episodes, -183.89611964932993, current eps 0.09708432584269663 200.0\n",
      "255999, done 1288 episodes, -183.92993179393588, current eps 0.09707870786516853 200.0\n",
      "256199, done 1289 episodes, -183.9275047449999, current eps 0.09707308988764045 200.0\n",
      "256399, done 1290 episodes, -183.973782812704, current eps 0.09706747191011236 200.0\n",
      "256599, done 1291 episodes, -183.89001443126378, current eps 0.09706185393258428 200.0\n",
      "256799, done 1292 episodes, -183.8848575081936, current eps 0.09705623595505618 200.0\n",
      "256999, done 1293 episodes, -183.97584661107715, current eps 0.09705061797752809 200.0\n",
      "257199, done 1294 episodes, -184.12553231629005, current eps 0.097045 200.0\n",
      "257399, done 1295 episodes, -184.11618569537572, current eps 0.0970393820224719 200.0\n",
      "257599, done 1296 episodes, -183.94715670199304, current eps 0.09703376404494382 200.0\n",
      "257799, done 1297 episodes, -183.81846715096654, current eps 0.09702814606741574 200.0\n",
      "257999, done 1298 episodes, -183.9742162306262, current eps 0.09702252808988764 200.0\n",
      "258199, done 1299 episodes, -183.90774417813265, current eps 0.09701691011235955 200.0\n",
      "258399, done 1300 episodes, -183.88689022569235, current eps 0.09701129213483146 200.0\n",
      "258599, done 1301 episodes, -183.88846262416644, current eps 0.09700567415730338 200.0\n",
      "258799, done 1302 episodes, -183.8690449787401, current eps 0.09700005617977528 200.0\n",
      "258999, done 1303 episodes, -183.81699206290222, current eps 0.0969944382022472 200.0\n",
      "259199, done 1304 episodes, -183.9818981985799, current eps 0.09698882022471911 200.0\n",
      "259399, done 1305 episodes, -183.97366362991372, current eps 0.09698320224719101 200.0\n",
      "259599, done 1306 episodes, -183.78030580489772, current eps 0.09697758426966292 200.0\n",
      "259799, done 1307 episodes, -184.03606500954498, current eps 0.09697196629213484 200.0\n",
      "259999, done 1308 episodes, -184.10637110166005, current eps 0.09696634831460674 200.0\n",
      "260199, done 1309 episodes, -184.1233909239748, current eps 0.09696073033707865 200.0\n",
      "260399, done 1310 episodes, -184.2534372102977, current eps 0.09695511235955057 200.0\n",
      "260599, done 1311 episodes, -183.87741508183356, current eps 0.09694949438202247 200.0\n",
      "260799, done 1312 episodes, -184.14902802311198, current eps 0.09694387640449438 200.0\n",
      "Evaluation score: -168.8418298515681\n",
      "0 of 20 episodes ended close to / at the final state.\n",
      "260999, done 1313 episodes, -184.2354214092442, current eps 0.0969382584269663 200.0\n",
      "261199, done 1314 episodes, -184.13041513724775, current eps 0.09693264044943821 200.0\n",
      "261399, done 1315 episodes, -184.0075176562502, current eps 0.09692702247191011 200.0\n",
      "261599, done 1316 episodes, -183.76686414199511, current eps 0.09692140449438202 200.0\n",
      "261799, done 1317 episodes, -183.679812234859, current eps 0.09691578651685394 200.0\n",
      "261999, done 1318 episodes, -183.64426284602945, current eps 0.09691016853932584 200.0\n",
      "262199, done 1319 episodes, -183.5515745158053, current eps 0.09690455056179775 200.0\n",
      "262399, done 1320 episodes, -183.5180962069999, current eps 0.09689893258426967 200.0\n",
      "262599, done 1321 episodes, -183.56481806281917, current eps 0.09689331460674157 200.0\n",
      "262799, done 1322 episodes, -183.67754412192383, current eps 0.09688769662921348 200.0\n",
      "262999, done 1323 episodes, -183.64819295882404, current eps 0.0968820786516854 200.0\n",
      "263199, done 1324 episodes, -183.66405877670414, current eps 0.09687646067415731 200.0\n",
      "263399, done 1325 episodes, -183.5248840486602, current eps 0.09687084269662921 200.0\n",
      "263599, done 1326 episodes, -183.3291282547472, current eps 0.09686522471910113 200.0\n",
      "263799, done 1327 episodes, -183.08106365719934, current eps 0.09685960674157304 200.0\n",
      "263999, done 1328 episodes, -182.73363267056968, current eps 0.09685398876404494 200.0\n",
      "264180, done 1329 episodes, -182.37921634492199, current eps 0.09684890449438202 199.81\n",
      "264380, done 1330 episodes, -182.56977792675417, current eps 0.09684328651685394 199.81\n",
      "264580, done 1331 episodes, -182.37158785367723, current eps 0.09683766853932585 199.81\n",
      "264780, done 1332 episodes, -182.57334561613888, current eps 0.09683205056179775 199.81\n",
      "264980, done 1333 episodes, -182.60352929034048, current eps 0.09682643258426966 199.81\n",
      "265180, done 1334 episodes, -182.62513101826065, current eps 0.09682081460674158 199.81\n",
      "265380, done 1335 episodes, -182.69316376992865, current eps 0.09681519662921348 199.81\n",
      "265580, done 1336 episodes, -182.71289382167416, current eps 0.0968095786516854 199.81\n",
      "265780, done 1337 episodes, -182.69480843560896, current eps 0.09680396067415731 199.81\n",
      "265980, done 1338 episodes, -182.5916106505604, current eps 0.09679834269662921 199.81\n",
      "266180, done 1339 episodes, -182.7455303736768, current eps 0.09679272471910112 199.81\n",
      "266380, done 1340 episodes, -182.44055622083891, current eps 0.09678710674157304 199.81\n",
      "266580, done 1341 episodes, -182.41381234963336, current eps 0.09678148876404495 199.81\n",
      "266780, done 1342 episodes, -182.50916049665167, current eps 0.09677587078651685 199.81\n",
      "266980, done 1343 episodes, -182.70598256690636, current eps 0.09677025280898877 199.81\n",
      "267180, done 1344 episodes, -182.78178580703334, current eps 0.09676463483146068 199.81\n",
      "267380, done 1345 episodes, -182.51157319968127, current eps 0.09675901685393258 199.81\n",
      "267580, done 1346 episodes, -182.56515661193407, current eps 0.0967533988764045 199.81\n",
      "267780, done 1347 episodes, -182.52659949065028, current eps 0.09674778089887641 199.81\n",
      "267980, done 1348 episodes, -182.51166917551174, current eps 0.09674216292134831 199.81\n",
      "268180, done 1349 episodes, -182.54202953960547, current eps 0.09673654494382022 199.81\n",
      "268380, done 1350 episodes, -182.65158565459106, current eps 0.09673092696629214 199.81\n",
      "268580, done 1351 episodes, -182.62379981612503, current eps 0.09672530898876405 199.81\n",
      "268780, done 1352 episodes, -182.91082288876703, current eps 0.09671969101123595 199.81\n",
      "268980, done 1353 episodes, -182.7425166455263, current eps 0.09671407303370787 199.81\n",
      "269180, done 1354 episodes, -182.87155711422437, current eps 0.09670845505617978 199.81\n",
      "269380, done 1355 episodes, -182.98211986954777, current eps 0.09670283707865168 199.81\n",
      "269580, done 1356 episodes, -183.06172268274548, current eps 0.0966972191011236 199.81\n",
      "269780, done 1357 episodes, -183.0271675548846, current eps 0.09669160112359551 199.81\n",
      "269980, done 1358 episodes, -182.8788777216261, current eps 0.09668598314606741 199.81\n",
      "270180, done 1359 episodes, -183.0331306080938, current eps 0.09668036516853933 199.81\n",
      "270380, done 1360 episodes, -183.0104768668488, current eps 0.09667474719101124 199.81\n",
      "270580, done 1361 episodes, -183.27442339048147, current eps 0.09666912921348314 199.81\n",
      "270780, done 1362 episodes, -183.25924867429794, current eps 0.09666351123595505 199.81\n",
      "270980, done 1363 episodes, -182.96500148032607, current eps 0.09665789325842697 199.81\n",
      "Evaluation score: -167.65758997196934\n",
      "0 of 20 episodes ended close to / at the final state.\n",
      "271180, done 1364 episodes, -182.76862634150496, current eps 0.09665227528089888 199.81\n",
      "271380, done 1365 episodes, -182.83531069934594, current eps 0.09664665730337078 199.81\n",
      "271580, done 1366 episodes, -182.7527569727298, current eps 0.0966410393258427 199.81\n",
      "271780, done 1367 episodes, -182.447337799885, current eps 0.09663542134831461 199.81\n",
      "271980, done 1368 episodes, -182.52057295458093, current eps 0.09662980337078651 199.81\n",
      "272180, done 1369 episodes, -182.27930647561857, current eps 0.09662418539325843 199.81\n",
      "272380, done 1370 episodes, -182.29786249377733, current eps 0.09661856741573034 199.81\n",
      "272580, done 1371 episodes, -182.2062612013116, current eps 0.09661294943820226 199.81\n",
      "272772, done 1372 episodes, -182.33513228019413, current eps 0.09660755617977529 199.73\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272972, done 1373 episodes, -182.20158518411765, current eps 0.09660193820224719 199.73\n",
      "273172, done 1374 episodes, -181.78224103135585, current eps 0.0965963202247191 199.73\n",
      "273372, done 1375 episodes, -181.69521984719293, current eps 0.09659070224719102 199.73\n",
      "273572, done 1376 episodes, -181.9325234150182, current eps 0.09658508426966292 199.73\n",
      "273772, done 1377 episodes, -181.91474611281583, current eps 0.09657946629213483 199.73\n",
      "273972, done 1378 episodes, -182.02973171159957, current eps 0.09657384831460675 199.73\n",
      "274172, done 1379 episodes, -182.1040373196318, current eps 0.09656823033707865 199.73\n",
      "274372, done 1380 episodes, -182.16444082970008, current eps 0.09656261235955056 199.73\n",
      "274572, done 1381 episodes, -182.23131546212204, current eps 0.09655699438202248 199.73\n",
      "274772, done 1382 episodes, -182.30274017285763, current eps 0.09655137640449438 199.73\n",
      "274972, done 1383 episodes, -182.1874830291719, current eps 0.09654575842696629 199.73\n",
      "275172, done 1384 episodes, -182.43007020869612, current eps 0.0965401404494382 199.73\n",
      "275372, done 1385 episodes, -182.193333388518, current eps 0.09653452247191012 199.73\n",
      "275572, done 1386 episodes, -182.29034022245688, current eps 0.09652890449438202 199.73\n",
      "275772, done 1387 episodes, -182.46753584019112, current eps 0.09652328651685393 199.73\n",
      "275972, done 1388 episodes, -182.48894808724947, current eps 0.09651766853932585 199.73\n",
      "276172, done 1389 episodes, -182.41442180289192, current eps 0.09651205056179775 199.73\n",
      "276368, done 1390 episodes, -182.48612082882468, current eps 0.09650654494382023 199.69\n",
      "276568, done 1391 episodes, -182.47383988382094, current eps 0.09650092696629213 199.69\n",
      "276768, done 1392 episodes, -182.26878989881595, current eps 0.09649530898876404 199.69\n",
      "276968, done 1393 episodes, -182.0017477210249, current eps 0.09648969101123596 199.69\n",
      "277168, done 1394 episodes, -181.66410333038056, current eps 0.09648407303370787 199.69\n",
      "277368, done 1395 episodes, -181.64447593113883, current eps 0.09647845505617977 199.69\n",
      "277568, done 1396 episodes, -181.75677732202504, current eps 0.09647283707865169 199.69\n",
      "277768, done 1397 episodes, -181.743083010351, current eps 0.0964672191011236 199.69\n",
      "277968, done 1398 episodes, -181.4177249490453, current eps 0.0964616011235955 199.69\n",
      "278168, done 1399 episodes, -181.17587206635812, current eps 0.09645598314606742 199.69\n",
      "278368, done 1400 episodes, -181.32993595334887, current eps 0.09645036516853933 199.69\n",
      "278568, done 1401 episodes, -181.4145897971375, current eps 0.09644474719101123 199.69\n",
      "278768, done 1402 episodes, -181.3613447501632, current eps 0.09643912921348315 199.69\n",
      "278968, done 1403 episodes, -181.4167254668001, current eps 0.09643351123595506 199.69\n",
      "279168, done 1404 episodes, -181.15741721033507, current eps 0.09642789325842696 199.69\n",
      "279368, done 1405 episodes, -180.86693715222802, current eps 0.09642227528089888 199.69\n",
      "279568, done 1406 episodes, -181.13463336713684, current eps 0.09641665730337079 199.69\n",
      "279768, done 1407 episodes, -181.08073317177747, current eps 0.0964110393258427 199.69\n",
      "279968, done 1408 episodes, -180.78423221113044, current eps 0.0964054213483146 199.69\n",
      "280168, done 1409 episodes, -180.78324021667825, current eps 0.09639980337078652 199.69\n",
      "280368, done 1410 episodes, -180.94356137030067, current eps 0.09639418539325843 199.69\n",
      "280568, done 1411 episodes, -181.26000961079706, current eps 0.09638856741573033 199.69\n",
      "280768, done 1412 episodes, -181.24046135422205, current eps 0.09638294943820225 199.69\n",
      "280968, done 1413 episodes, -181.1903914885215, current eps 0.09637733146067416 199.69\n",
      "281168, done 1414 episodes, -181.38074287406292, current eps 0.09637171348314608 199.69\n",
      "Evaluation score: -143.00144647799783\n",
      "0 of 20 episodes ended close to / at the final state.\n",
      "281368, done 1415 episodes, -181.45873684955507, current eps 0.09636609550561798 199.69\n",
      "281568, done 1416 episodes, -181.7014430993721, current eps 0.09636047752808989 199.69\n",
      "281768, done 1417 episodes, -181.78420025021572, current eps 0.0963548595505618 199.69\n",
      "281968, done 1418 episodes, -181.72727719546484, current eps 0.0963492415730337 199.69\n",
      "282168, done 1419 episodes, -181.96007859520338, current eps 0.09634362359550562 199.69\n",
      "282368, done 1420 episodes, -182.1219720766079, current eps 0.09633800561797753 199.69\n",
      "282568, done 1421 episodes, -182.15306087974557, current eps 0.09633238764044944 199.69\n",
      "282768, done 1422 episodes, -182.11118927990879, current eps 0.09632676966292135 199.69\n",
      "282968, done 1423 episodes, -182.26832880143357, current eps 0.09632115168539326 199.69\n",
      "283168, done 1424 episodes, -182.1334238398258, current eps 0.09631553370786516 199.69\n",
      "283368, done 1425 episodes, -182.22217661817191, current eps 0.09630991573033708 199.69\n",
      "283568, done 1426 episodes, -182.37931627554042, current eps 0.09630429775280899 199.69\n",
      "283768, done 1427 episodes, -182.75790162473402, current eps 0.0962986797752809 199.69\n",
      "283968, done 1428 episodes, -182.83219896982268, current eps 0.09629306179775281 199.69\n",
      "284168, done 1429 episodes, -183.0476816621841, current eps 0.09628744382022472 199.88\n",
      "284368, done 1430 episodes, -182.92587671510674, current eps 0.09628182584269664 199.88\n",
      "284568, done 1431 episodes, -183.0673687623756, current eps 0.09627620786516854 199.88\n",
      "284768, done 1432 episodes, -183.04769290178567, current eps 0.09627058988764045 199.88\n",
      "284968, done 1433 episodes, -183.11049217511223, current eps 0.09626497191011237 199.88\n",
      "285168, done 1434 episodes, -182.91946845921922, current eps 0.09625935393258427 199.88\n",
      "285368, done 1435 episodes, -182.73288269104262, current eps 0.09625373595505618 199.88\n",
      "285568, done 1436 episodes, -182.68039041358904, current eps 0.0962481179775281 199.88\n",
      "285768, done 1437 episodes, -182.7864752776169, current eps 0.09624250000000001 199.88\n",
      "285968, done 1438 episodes, -182.56690172626878, current eps 0.09623688202247191 199.88\n",
      "286168, done 1439 episodes, -182.49134521871326, current eps 0.09623126404494382 199.88\n",
      "286368, done 1440 episodes, -182.74427143914536, current eps 0.09622564606741574 199.88\n",
      "286568, done 1441 episodes, -182.91179555261263, current eps 0.09622002808988764 199.88\n",
      "286768, done 1442 episodes, -182.90454430895807, current eps 0.09621441011235955 199.88\n",
      "286968, done 1443 episodes, -182.83584815640398, current eps 0.09620879213483147 199.88\n",
      "287168, done 1444 episodes, -182.83206621958382, current eps 0.09620317415730337 199.88\n",
      "287368, done 1445 episodes, -183.01795817655224, current eps 0.09619755617977528 199.88\n",
      "287568, done 1446 episodes, -182.9481091861365, current eps 0.0961919382022472 199.88\n",
      "287768, done 1447 episodes, -182.74996789969077, current eps 0.0961863202247191 199.88\n",
      "287968, done 1448 episodes, -183.00987234180243, current eps 0.09618070224719101 199.88\n",
      "288168, done 1449 episodes, -182.86315091461148, current eps 0.09617508426966292 199.88\n",
      "288368, done 1450 episodes, -182.87066312157987, current eps 0.09616946629213483 199.88\n",
      "288568, done 1451 episodes, -183.05655307878476, current eps 0.09616384831460674 199.88\n",
      "288768, done 1452 episodes, -183.04947389450615, current eps 0.09615823033707865 199.88\n",
      "288968, done 1453 episodes, -183.09982790017872, current eps 0.09615261235955057 199.88\n",
      "289168, done 1454 episodes, -183.06449454139343, current eps 0.09614699438202247 199.88\n",
      "289368, done 1455 episodes, -182.95598429062773, current eps 0.09614137640449438 199.88\n",
      "289568, done 1456 episodes, -182.95281924826887, current eps 0.0961357584269663 199.88\n",
      "289768, done 1457 episodes, -183.04371465101303, current eps 0.0961301404494382 199.88\n",
      "289968, done 1458 episodes, -183.3312606986571, current eps 0.09612452247191011 199.88\n",
      "290168, done 1459 episodes, -183.20748532868456, current eps 0.09611890449438203 199.88\n",
      "290368, done 1460 episodes, -183.249772828405, current eps 0.09611328651685394 199.88\n",
      "290568, done 1461 episodes, -182.88894091864967, current eps 0.09610766853932584 199.88\n",
      "290768, done 1462 episodes, -182.85552695875137, current eps 0.09610205056179776 199.88\n",
      "290968, done 1463 episodes, -183.00103931066135, current eps 0.09609643258426967 199.88\n",
      "291168, done 1464 episodes, -183.27176260489142, current eps 0.09609081460674157 199.88\n",
      "Evaluation score: -167.9723561446574\n",
      "0 of 20 episodes ended close to / at the final state.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291368, done 1465 episodes, -183.43834699747524, current eps 0.09608519662921348 199.88\n",
      "291568, done 1466 episodes, -183.41189328084172, current eps 0.0960795786516854 199.88\n",
      "291768, done 1467 episodes, -183.6017369727236, current eps 0.0960739606741573 199.88\n",
      "291968, done 1468 episodes, -183.599143296034, current eps 0.09606834269662921 199.88\n",
      "292168, done 1469 episodes, -183.82989749676267, current eps 0.09606272471910113 199.88\n",
      "292368, done 1470 episodes, -183.63404760173907, current eps 0.09605710674157303 199.88\n",
      "292568, done 1471 episodes, -183.58033341819953, current eps 0.09605148876404494 199.88\n",
      "292768, done 1472 episodes, -183.335336725181, current eps 0.09604587078651686 199.96\n",
      "292968, done 1473 episodes, -183.47883229140726, current eps 0.09604025280898877 199.96\n",
      "293168, done 1474 episodes, -183.49812186891955, current eps 0.09603463483146067 199.96\n",
      "293368, done 1475 episodes, -183.57550192903673, current eps 0.09602901685393259 199.96\n",
      "293568, done 1476 episodes, -183.3607381130704, current eps 0.0960233988764045 199.96\n",
      "293768, done 1477 episodes, -183.40180744933653, current eps 0.0960177808988764 199.96\n",
      "293968, done 1478 episodes, -183.37985194365282, current eps 0.09601216292134832 199.96\n",
      "294168, done 1479 episodes, -183.24997875892572, current eps 0.09600654494382023 199.96\n",
      "294368, done 1480 episodes, -183.14981296035768, current eps 0.09600092696629214 199.96\n",
      "294568, done 1481 episodes, -183.09638591003798, current eps 0.09599530898876404 199.96\n",
      "294768, done 1482 episodes, -183.0925277249997, current eps 0.09598969101123596 199.96\n",
      "294968, done 1483 episodes, -183.17598937435883, current eps 0.09598407303370787 199.96\n",
      "295168, done 1484 episodes, -182.8461421293791, current eps 0.09597845505617977 199.96\n",
      "295368, done 1485 episodes, -182.96291409843366, current eps 0.09597283707865169 199.96\n",
      "295568, done 1486 episodes, -182.81616345918633, current eps 0.0959672191011236 199.96\n",
      "295768, done 1487 episodes, -182.71986934251254, current eps 0.0959616011235955 199.96\n",
      "295968, done 1488 episodes, -182.67876279154075, current eps 0.09595598314606742 199.96\n",
      "296168, done 1489 episodes, -182.7435049282159, current eps 0.09595036516853933 199.96\n",
      "296368, done 1490 episodes, -182.5010927177057, current eps 0.09594474719101123 200.0\n",
      "296568, done 1491 episodes, -182.54972663954013, current eps 0.09593912921348315 200.0\n",
      "296768, done 1492 episodes, -182.90294901957674, current eps 0.09593351123595506 200.0\n",
      "296968, done 1493 episodes, -183.1333300472671, current eps 0.09592789325842696 200.0\n",
      "297168, done 1494 episodes, -183.22076151137696, current eps 0.09592227528089887 200.0\n",
      "297368, done 1495 episodes, -182.88256859023681, current eps 0.09591665730337079 200.0\n",
      "297568, done 1496 episodes, -182.9392961927333, current eps 0.0959110393258427 200.0\n",
      "297768, done 1497 episodes, -182.91976401590756, current eps 0.0959054213483146 200.0\n",
      "297968, done 1498 episodes, -183.15850803856728, current eps 0.09589980337078652 200.0\n",
      "298168, done 1499 episodes, -183.25510326813634, current eps 0.09589418539325843 200.0\n",
      "298368, done 1500 episodes, -183.08607427475366, current eps 0.09588856741573033 200.0\n",
      "298568, done 1501 episodes, -182.92832185960265, current eps 0.09588294943820225 200.0\n",
      "298768, done 1502 episodes, -182.87224332525992, current eps 0.09587733146067416 200.0\n",
      "298968, done 1503 episodes, -182.8044886863649, current eps 0.09587171348314608 200.0\n",
      "299168, done 1504 episodes, -182.69700007797513, current eps 0.09586609550561798 200.0\n",
      "299368, done 1505 episodes, -182.61879309193517, current eps 0.09586047752808989 200.0\n",
      "299568, done 1506 episodes, -182.68799243353288, current eps 0.0958548595505618 200.0\n",
      "299768, done 1507 episodes, -182.50135910731015, current eps 0.0958492415730337 200.0\n",
      "299968, done 1508 episodes, -182.67536859445372, current eps 0.09584362359550562 200.0\n",
      "300168, done 1509 episodes, -182.50619940870428, current eps 0.09583800561797753 200.0\n",
      "300368, done 1510 episodes, -182.56230094814313, current eps 0.09583238764044943 200.0\n",
      "300568, done 1511 episodes, -182.4098869475478, current eps 0.09582676966292135 200.0\n",
      "300768, done 1512 episodes, -182.26562964969685, current eps 0.09582115168539326 200.0\n",
      "300968, done 1513 episodes, -182.14668519672938, current eps 0.09581553370786516 200.0\n",
      "301168, done 1514 episodes, -182.04031585805157, current eps 0.09580991573033708 200.0\n",
      "Evaluation score: -165.53058674442184\n",
      "0 of 20 episodes ended close to / at the final state.\n",
      "301368, done 1515 episodes, -182.1048982409199, current eps 0.09580429775280899 200.0\n",
      "301568, done 1516 episodes, -181.9550591932983, current eps 0.09579867977528089 200.0\n",
      "301768, done 1517 episodes, -181.97554469813335, current eps 0.09579306179775281 200.0\n",
      "301968, done 1518 episodes, -182.0083976278091, current eps 0.09578744382022472 200.0\n",
      "302168, done 1519 episodes, -182.07194150673092, current eps 0.09578182584269664 200.0\n",
      "302368, done 1520 episodes, -182.19751396658208, current eps 0.09577620786516854 200.0\n",
      "302568, done 1521 episodes, -182.2296110463457, current eps 0.09577058988764045 200.0\n",
      "302768, done 1522 episodes, -182.28285293026124, current eps 0.09576497191011236 200.0\n",
      "302968, done 1523 episodes, -182.1185188026522, current eps 0.09575935393258427 200.0\n",
      "303168, done 1524 episodes, -182.044034115545, current eps 0.09575373595505618 200.0\n",
      "303368, done 1525 episodes, -182.0159629536887, current eps 0.0957481179775281 200.0\n",
      "303568, done 1526 episodes, -182.17715725516885, current eps 0.09574250000000001 200.0\n",
      "303768, done 1527 episodes, -181.92709535550966, current eps 0.09573688202247191 200.0\n",
      "303968, done 1528 episodes, -181.87536422642282, current eps 0.09573126404494382 200.0\n",
      "304168, done 1529 episodes, -181.88387254475543, current eps 0.09572564606741574 200.0\n",
      "304368, done 1530 episodes, -181.5473132718981, current eps 0.09572002808988764 200.0\n",
      "304568, done 1531 episodes, -181.61065745411662, current eps 0.09571441011235955 200.0\n",
      "304768, done 1532 episodes, -181.454511439988, current eps 0.09570879213483147 200.0\n",
      "304968, done 1533 episodes, -181.448549954918, current eps 0.09570317415730337 200.0\n",
      "305168, done 1534 episodes, -181.38151466789242, current eps 0.09569755617977528 200.0\n",
      "305368, done 1535 episodes, -181.66265455452347, current eps 0.0956919382022472 200.0\n",
      "305568, done 1536 episodes, -181.8579612723862, current eps 0.0956863202247191 200.0\n",
      "305768, done 1537 episodes, -181.994058354904, current eps 0.09568070224719101 200.0\n",
      "305968, done 1538 episodes, -182.07412705397968, current eps 0.09567508426966292 200.0\n",
      "306168, done 1539 episodes, -182.01600222872267, current eps 0.09566946629213484 200.0\n",
      "306368, done 1540 episodes, -181.67113088759467, current eps 0.09566384831460674 200.0\n",
      "306568, done 1541 episodes, -181.32663184860837, current eps 0.09565823033707865 200.0\n",
      "306768, done 1542 episodes, -181.22594052214768, current eps 0.09565261235955057 200.0\n",
      "306968, done 1543 episodes, -181.23447903987548, current eps 0.09564699438202247 200.0\n",
      "307168, done 1544 episodes, -181.31843665972627, current eps 0.09564137640449438 200.0\n",
      "307368, done 1545 episodes, -181.2310129899524, current eps 0.0956357584269663 200.0\n",
      "307568, done 1546 episodes, -181.21218957195367, current eps 0.09563014044943821 200.0\n",
      "307768, done 1547 episodes, -181.08019682762068, current eps 0.09562452247191011 200.0\n",
      "307968, done 1548 episodes, -180.81964294038195, current eps 0.09561890449438203 200.0\n",
      "308168, done 1549 episodes, -180.71343281772596, current eps 0.09561328651685394 200.0\n",
      "308368, done 1550 episodes, -180.77657665830532, current eps 0.09560766853932584 200.0\n",
      "308568, done 1551 episodes, -180.73166696301243, current eps 0.09560205056179776 200.0\n",
      "308768, done 1552 episodes, -180.58612176336993, current eps 0.09559643258426967 200.0\n",
      "308968, done 1553 episodes, -180.6588198996816, current eps 0.09559081460674157 200.0\n",
      "309168, done 1554 episodes, -180.6838916076553, current eps 0.09558519662921348 200.0\n",
      "309368, done 1555 episodes, -180.60856989732852, current eps 0.0955795786516854 200.0\n",
      "309568, done 1556 episodes, -180.47351796442538, current eps 0.0955739606741573 200.0\n",
      "309768, done 1557 episodes, -180.58208994025838, current eps 0.09556834269662921 200.0\n",
      "309968, done 1558 episodes, -180.57749700003922, current eps 0.09556272471910113 200.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310168, done 1559 episodes, -180.4536378720563, current eps 0.09555710674157303 200.0\n",
      "310368, done 1560 episodes, -180.43940278842604, current eps 0.09555148876404494 200.0\n",
      "310568, done 1561 episodes, -180.73649735347132, current eps 0.09554587078651686 200.0\n",
      "310768, done 1562 episodes, -180.89770347282138, current eps 0.09554025280898877 200.0\n",
      "310968, done 1563 episodes, -180.85346018059684, current eps 0.09553463483146067 200.0\n",
      "311168, done 1564 episodes, -180.73672908753989, current eps 0.09552901685393259 200.0\n",
      "Evaluation score: -181.61458822582077\n",
      "0 of 20 episodes ended close to / at the final state.\n",
      "311368, done 1565 episodes, -180.49026570450414, current eps 0.0955233988764045 200.0\n",
      "311568, done 1566 episodes, -180.52551484630038, current eps 0.0955177808988764 200.0\n",
      "311768, done 1567 episodes, -180.74906686443123, current eps 0.09551216292134831 200.0\n",
      "311968, done 1568 episodes, -180.69222946545307, current eps 0.09550654494382023 200.0\n",
      "312168, done 1569 episodes, -180.57080981312149, current eps 0.09550092696629214 200.0\n",
      "312368, done 1570 episodes, -180.8033774860358, current eps 0.09549530898876404 200.0\n",
      "312568, done 1571 episodes, -181.08554616272596, current eps 0.09548969101123596 200.0\n",
      "312768, done 1572 episodes, -181.3668330929989, current eps 0.09548407303370787 200.0\n",
      "312968, done 1573 episodes, -180.9991734897393, current eps 0.09547845505617977 200.0\n",
      "313168, done 1574 episodes, -181.29754956356518, current eps 0.09547283707865169 200.0\n",
      "313368, done 1575 episodes, -181.3277625711711, current eps 0.0954672191011236 200.0\n",
      "313568, done 1576 episodes, -181.68791514628344, current eps 0.0954616011235955 200.0\n",
      "313768, done 1577 episodes, -181.47722425472432, current eps 0.09545598314606742 200.0\n",
      "313968, done 1578 episodes, -181.23730352306694, current eps 0.09545036516853933 200.0\n",
      "314168, done 1579 episodes, -181.3507667237169, current eps 0.09544474719101123 200.0\n",
      "314368, done 1580 episodes, -181.48515609226249, current eps 0.09543912921348315 200.0\n",
      "314568, done 1581 episodes, -181.18604135603798, current eps 0.09543351123595506 200.0\n",
      "314768, done 1582 episodes, -181.30517001114833, current eps 0.09542789325842696 200.0\n",
      "314968, done 1583 episodes, -181.30991635542844, current eps 0.09542227528089887 200.0\n",
      "315168, done 1584 episodes, -181.21694235506192, current eps 0.09541665730337079 200.0\n",
      "315368, done 1585 episodes, -181.2337016443591, current eps 0.0954110393258427 200.0\n",
      "315568, done 1586 episodes, -181.33766814087357, current eps 0.0954054213483146 200.0\n",
      "315768, done 1587 episodes, -181.2614881570618, current eps 0.09539980337078652 200.0\n",
      "315968, done 1588 episodes, -181.28312596254477, current eps 0.09539418539325843 200.0\n",
      "316168, done 1589 episodes, -181.30916864558472, current eps 0.09538856741573033 200.0\n",
      "316368, done 1590 episodes, -181.4934711346194, current eps 0.09538294943820225 200.0\n",
      "316568, done 1591 episodes, -181.4700556282753, current eps 0.09537733146067416 200.0\n",
      "316768, done 1592 episodes, -181.47352566262788, current eps 0.09537171348314608 200.0\n",
      "316968, done 1593 episodes, -181.52355701029535, current eps 0.09536609550561798 200.0\n",
      "317168, done 1594 episodes, -181.68775988423877, current eps 0.09536047752808989 200.0\n",
      "317368, done 1595 episodes, -181.94898766870608, current eps 0.0953548595505618 200.0\n",
      "317568, done 1596 episodes, -181.79317427607307, current eps 0.0953492415730337 200.0\n",
      "317768, done 1597 episodes, -181.97674865763258, current eps 0.09534362359550562 200.0\n",
      "317968, done 1598 episodes, -181.85172128516504, current eps 0.09533800561797753 200.0\n",
      "318168, done 1599 episodes, -181.5823585352268, current eps 0.09533238764044943 200.0\n",
      "318368, done 1600 episodes, -181.62781273749192, current eps 0.09532676966292135 200.0\n",
      "318568, done 1601 episodes, -181.35913877915326, current eps 0.09532115168539326 200.0\n",
      "318768, done 1602 episodes, -181.37765953007482, current eps 0.09531553370786516 200.0\n",
      "318968, done 1603 episodes, -181.37957732436033, current eps 0.09530991573033708 200.0\n",
      "319168, done 1604 episodes, -181.78389262095087, current eps 0.09530429775280899 200.0\n",
      "319368, done 1605 episodes, -182.0616120214393, current eps 0.0952986797752809 200.0\n",
      "319568, done 1606 episodes, -181.9092724591789, current eps 0.0952930617977528 200.0\n",
      "319768, done 1607 episodes, -181.8800585941712, current eps 0.09528744382022472 200.0\n",
      "319968, done 1608 episodes, -181.9979981350447, current eps 0.09528182584269664 200.0\n",
      "320168, done 1609 episodes, -181.9727097962566, current eps 0.09527620786516854 200.0\n",
      "320368, done 1610 episodes, -181.8166483951885, current eps 0.09527058988764045 200.0\n",
      "320568, done 1611 episodes, -181.86180812110132, current eps 0.09526497191011236 200.0\n",
      "320768, done 1612 episodes, -182.06435913852783, current eps 0.09525935393258428 200.0\n",
      "320968, done 1613 episodes, -182.22727366276203, current eps 0.09525373595505618 200.0\n",
      "321168, done 1614 episodes, -182.14676906483618, current eps 0.0952481179775281 200.0\n",
      "Evaluation score: -161.59588743951977\n",
      "0 of 20 episodes ended close to / at the final state.\n",
      "321368, done 1615 episodes, -181.85274131742065, current eps 0.09524250000000001 200.0\n",
      "321568, done 1616 episodes, -181.90812739840695, current eps 0.09523688202247191 200.0\n",
      "321768, done 1617 episodes, -181.75868744486027, current eps 0.09523126404494382 200.0\n",
      "321968, done 1618 episodes, -181.66753402646017, current eps 0.09522564606741574 200.0\n",
      "322168, done 1619 episodes, -181.49342561631536, current eps 0.09522002808988764 200.0\n",
      "322368, done 1620 episodes, -181.47285261064823, current eps 0.09521441011235955 200.0\n",
      "322568, done 1621 episodes, -181.41795587185683, current eps 0.09520879213483147 200.0\n",
      "322768, done 1622 episodes, -181.32760277747403, current eps 0.09520317415730337 200.0\n",
      "322968, done 1623 episodes, -181.3600507493376, current eps 0.09519755617977528 200.0\n",
      "323168, done 1624 episodes, -181.6393531625773, current eps 0.0951919382022472 200.0\n",
      "323368, done 1625 episodes, -181.8190939419984, current eps 0.0951863202247191 200.0\n",
      "323568, done 1626 episodes, -181.68122059407247, current eps 0.09518070224719101 200.0\n",
      "323768, done 1627 episodes, -181.8394698086837, current eps 0.09517508426966292 200.0\n",
      "323968, done 1628 episodes, -182.083929659772, current eps 0.09516946629213484 200.0\n",
      "324168, done 1629 episodes, -182.01490618116782, current eps 0.09516384831460674 200.0\n",
      "324368, done 1630 episodes, -182.275416457814, current eps 0.09515823033707865 200.0\n",
      "324568, done 1631 episodes, -182.23844264584025, current eps 0.09515261235955057 200.0\n",
      "324768, done 1632 episodes, -182.0433488782067, current eps 0.09514699438202247 200.0\n",
      "324968, done 1633 episodes, -181.8544975118389, current eps 0.09514137640449438 200.0\n",
      "325168, done 1634 episodes, -181.58871181391638, current eps 0.0951357584269663 200.0\n",
      "325368, done 1635 episodes, -181.32207990349448, current eps 0.09513014044943821 200.0\n",
      "325568, done 1636 episodes, -181.17803013547783, current eps 0.09512452247191011 200.0\n",
      "325768, done 1637 episodes, -181.11775349498086, current eps 0.09511890449438203 200.0\n",
      "325968, done 1638 episodes, -181.2664112475758, current eps 0.09511328651685394 200.0\n",
      "326168, done 1639 episodes, -181.37099563812652, current eps 0.09510766853932584 200.0\n",
      "326368, done 1640 episodes, -181.6844613304876, current eps 0.09510205056179775 200.0\n",
      "326568, done 1641 episodes, -181.98675786138972, current eps 0.09509643258426967 200.0\n",
      "326768, done 1642 episodes, -182.05923725930086, current eps 0.09509081460674157 200.0\n",
      "326968, done 1643 episodes, -182.12692889909042, current eps 0.09508519662921348 200.0\n",
      "327168, done 1644 episodes, -182.11459919887267, current eps 0.0950795786516854 200.0\n",
      "327368, done 1645 episodes, -182.24231384788115, current eps 0.0950739606741573 200.0\n",
      "327568, done 1646 episodes, -182.1557011417008, current eps 0.09506834269662921 200.0\n",
      "327768, done 1647 episodes, -182.3346485605571, current eps 0.09506272471910113 200.0\n",
      "327968, done 1648 episodes, -182.51831011822213, current eps 0.09505710674157303 200.0\n",
      "328168, done 1649 episodes, -182.7408509949859, current eps 0.09505148876404494 200.0\n",
      "328368, done 1650 episodes, -182.77725861428058, current eps 0.09504587078651686 200.0\n",
      "328568, done 1651 episodes, -182.61097631937994, current eps 0.09504025280898877 200.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328768, done 1652 episodes, -182.68260683191377, current eps 0.09503463483146067 200.0\n",
      "328968, done 1653 episodes, -182.61217944500382, current eps 0.09502901685393259 200.0\n",
      "329168, done 1654 episodes, -182.643737279567, current eps 0.0950233988764045 200.0\n",
      "329368, done 1655 episodes, -182.71767636063672, current eps 0.0950177808988764 200.0\n",
      "329568, done 1656 episodes, -182.64644911971655, current eps 0.09501216292134831 200.0\n",
      "329768, done 1657 episodes, -182.75456945383135, current eps 0.09500654494382023 200.0\n",
      "329968, done 1658 episodes, -182.79656249474138, current eps 0.09500092696629214 200.0\n",
      "330168, done 1659 episodes, -182.95751794186341, current eps 0.09499530898876404 200.0\n",
      "330368, done 1660 episodes, -182.9636524100333, current eps 0.09498969101123596 200.0\n",
      "330568, done 1661 episodes, -182.84439924889068, current eps 0.09498407303370787 200.0\n",
      "330768, done 1662 episodes, -182.62761355141663, current eps 0.09497845505617977 200.0\n",
      "330968, done 1663 episodes, -182.64925847117033, current eps 0.09497283707865169 200.0\n",
      "331168, done 1664 episodes, -182.4722041792743, current eps 0.0949672191011236 200.0\n",
      "Evaluation score: -165.40919798352917\n",
      "0 of 20 episodes ended close to / at the final state.\n",
      "331368, done 1665 episodes, -182.7391119512801, current eps 0.0949616011235955 200.0\n",
      "331568, done 1666 episodes, -182.84619655463757, current eps 0.09495598314606742 200.0\n",
      "331768, done 1667 episodes, -182.8113515333241, current eps 0.09495036516853933 200.0\n",
      "331968, done 1668 episodes, -182.81787281505842, current eps 0.09494474719101123 200.0\n",
      "332168, done 1669 episodes, -183.0018531239966, current eps 0.09493912921348314 200.0\n",
      "332368, done 1670 episodes, -183.01886483251263, current eps 0.09493351123595506 200.0\n",
      "332568, done 1671 episodes, -183.02923602250377, current eps 0.09492789325842697 200.0\n",
      "332768, done 1672 episodes, -183.00831970203433, current eps 0.09492227528089887 200.0\n",
      "332968, done 1673 episodes, -183.3022064741949, current eps 0.09491665730337079 200.0\n",
      "333168, done 1674 episodes, -183.1958083364235, current eps 0.0949110393258427 200.0\n",
      "333368, done 1675 episodes, -183.25738373868285, current eps 0.0949054213483146 200.0\n",
      "333568, done 1676 episodes, -183.09106778446593, current eps 0.09489980337078652 200.0\n",
      "333768, done 1677 episodes, -183.1392500828984, current eps 0.09489418539325843 200.0\n",
      "333968, done 1678 episodes, -183.37242566493623, current eps 0.09488856741573035 200.0\n",
      "334168, done 1679 episodes, -183.40384281976787, current eps 0.09488294943820225 200.0\n",
      "334368, done 1680 episodes, -183.32160449141017, current eps 0.09487733146067416 200.0\n",
      "334568, done 1681 episodes, -183.41062503917522, current eps 0.09487171348314608 200.0\n",
      "334768, done 1682 episodes, -183.4271678659887, current eps 0.09486609550561798 200.0\n",
      "334968, done 1683 episodes, -183.22216709091796, current eps 0.09486047752808989 200.0\n",
      "335168, done 1684 episodes, -183.60113493535673, current eps 0.0948548595505618 200.0\n",
      "335368, done 1685 episodes, -183.65238274146367, current eps 0.0948492415730337 200.0\n",
      "335568, done 1686 episodes, -183.51779432695508, current eps 0.09484362359550562 200.0\n",
      "335768, done 1687 episodes, -183.58896137854194, current eps 0.09483800561797753 200.0\n",
      "335968, done 1688 episodes, -183.51690046272176, current eps 0.09483238764044943 200.0\n",
      "336168, done 1689 episodes, -183.40057095849863, current eps 0.09482676966292135 200.0\n",
      "336368, done 1690 episodes, -183.43511011192365, current eps 0.09482115168539326 200.0\n",
      "336568, done 1691 episodes, -183.44025146614433, current eps 0.09481553370786516 200.0\n",
      "336768, done 1692 episodes, -183.35915863369794, current eps 0.09480991573033708 200.0\n",
      "336968, done 1693 episodes, -183.30708901741838, current eps 0.09480429775280899 200.0\n",
      "337168, done 1694 episodes, -183.12825132116137, current eps 0.0947986797752809 200.0\n",
      "337368, done 1695 episodes, -183.2267616113672, current eps 0.0947930617977528 200.0\n",
      "337568, done 1696 episodes, -183.2966272499898, current eps 0.09478744382022472 200.0\n",
      "337768, done 1697 episodes, -183.26164077836157, current eps 0.09478182584269663 200.0\n",
      "337968, done 1698 episodes, -183.24887401151912, current eps 0.09477620786516854 200.0\n"
     ]
    }
   ],
   "source": [
    "state = env.reset().getValue()\n",
    "agent = Agent(n_actions=n_actions, inp_size=state.shape, device=device, hidden=10, gamma=0.1, agent_history_length=agent_history_length, memory_size=replay_memory_size, batch_size=batch_size, learning_rate=learning_rate)\n",
    "\n",
    "#transition = init_transition()\n",
    "#agent = Agent(n_actions=n_actions, inp_size=np.array(transition).shape, device=device, hidden=10, agent_history_length=agent_history_length, memory_size=replay_memory_size, batch_size=batch_size, learning_rate=learning_rate)\n",
    "action_scheduler = Action_Scheduler(num_actions=n_actions, max_steps=max_steps, eps_annealing_steps=eps_annealing_steps, eps_final=0.1, eps_final_step=0.02, replay_memory_start_size=start_learning, model=agent.main_dqn)\n",
    "\n",
    "step_counter = 0\n",
    "\n",
    "eps_rewards = []\n",
    "\n",
    "episode_lengths = []\n",
    "\n",
    "cos = torch.nn.CosineSimilarity(dim=0)\n",
    "\n",
    "print(\"Start training...\")\n",
    "while step_counter < max_steps:\n",
    "    epoch_step = 0\n",
    "    #agent.main_dqn.train()\n",
    "######## fill memory begins here\n",
    "    while (epoch_step < evaluate_every) or (step_counter < start_learning):\n",
    "        state = env.reset()\n",
    "        #env.stepCounter = np.random.randint(len(env.referenceStreamline_ijk)-5)\n",
    "        #env.state = TractographyState(env.referenceStreamline_ijk[env.stepCounter], env.interpolateDWIatState)\n",
    "        #transition = init_transition()\n",
    "        #referenceLine = env.referenceStreamline_ijk\n",
    "        episode_reward_sum = 0\n",
    "        terminal = False\n",
    "        #fill replay memory while interacting with env\n",
    "        #for episode_counter in range(max_episode_length):\n",
    "        episode_step_counter = 0\n",
    "        positive_run = 0\n",
    "        \n",
    "        dist = 0\n",
    "        #influential_action = None\n",
    "        while not terminal:\n",
    "            # get action with epsilon-greedy strategy\n",
    "            #if dist < 0.1:\n",
    "            #_, optimal_reward = get_best_action(state, env)\n",
    "                #print(influential_action)\n",
    "            #else:\n",
    "            #    influential_action = None\n",
    "            action = action_scheduler.get_action(step_counter, torch.FloatTensor(state.getValue()).unsqueeze(0).to(device)) #influential_action=influential_action)\n",
    "            #action = action_scheduler.get_action(step_counter, torch.FloatTensor([np.array(transition)]).to(device))\n",
    "            \n",
    "            \n",
    "            next_state, reward, terminal = env.step(action)\n",
    "            #print(reward)\n",
    "            episode_step_counter += 1\n",
    "            \n",
    "            \n",
    "            if reward < -1.:\n",
    "                reward = -1.\n",
    "            \n",
    "            #terminal = False\n",
    "            \n",
    "            #current_index = np.min([env.stepCounter,len(env.referenceStreamline_ijk)-1])\n",
    "            #path_vector = (next_state.getCoordinate() - state.getCoordinate()).squeeze(0)\n",
    "            #reference_vector = env.referenceStreamline_ijk[current_index]-env.referenceStreamline_ijk[current_index-1]\n",
    "            ##    #print(path_vector, reference_vector)\n",
    "            #cosine_sim = cos(path_vector, reference_vector)\n",
    "            #dist = torch.sum((env.referenceStreamline_ijk[current_index] - next_state.getCoordinate())**2)\n",
    "            #if dist < 0.1:\n",
    "            #    dist = 0\n",
    "            #else:\n",
    "            #    dist = dist - 0.1\n",
    "            #if dist > 3*0.81:\n",
    "            #    env.stepCounter -= 1\n",
    "            #reward = cosine_sim - dist\n",
    "            #reward = 1 - (optimal_reward - reward)\n",
    "            #reward = 1- (optimal_reward - dist)\n",
    "            #if reward == optimal_reward:\n",
    "            #    reward = 1\n",
    "            #if action == 100 and dist < 0.1:\n",
    "            #    terminal = True\n",
    "            #print(\"From function: \", influential_action, optimal_reward)\n",
    "            #print(\"From scheduler: \", action, reward,  terminal)\n",
    "            #print(\"Cosine sim: \", cosine_sim)\n",
    "            #print(\"Dist: \", dist)\n",
    "            \n",
    "            #if episode_step_counter >= 200:\n",
    "            #    terminal = True\n",
    "            \n",
    "            #print(episode_step_counter, action, reward, terminal)\n",
    "            #print(reward)\n",
    "            #if dist > 0.7: # cosine_sim < 0.4 or\n",
    "            #    terminal = True\n",
    "            #next_state = next_state[:2]\n",
    "            #next_transition = add_to_transition(next_state, transition)\n",
    "            \n",
    "            step_counter += 1\n",
    "            epoch_step += 1\n",
    "\n",
    "            # accumulate reward for current episode\n",
    "            episode_reward_sum += reward\n",
    "\n",
    "\n",
    "            agent.replay_memory.add_experience(action=action,\n",
    "                                #state=np.array(transition),\n",
    "                                state = state.getValue(),\n",
    "                                reward=reward,\n",
    "                                #new_state=np.array(next_transition),\n",
    "                                new_state = next_state.getValue(),\n",
    "                                terminal=terminal)\n",
    "\n",
    "\n",
    "            state = next_state\n",
    "            #transition = next_transition\n",
    "\n",
    "\n",
    "\n",
    "            ####### optimization is happening here\n",
    "            if step_counter > start_learning:\n",
    "                #if reward > 0.:\n",
    "                #    print(\"reward was positive: \", reward)\n",
    "                loss = agent.optimize()\n",
    "\n",
    "\n",
    "            ####### target network update\n",
    "            if step_counter > start_learning and step_counter % network_update_every == 0:\n",
    "                #print(\"Update net\")\n",
    "                #print(agent.main_dqn(torch.tensor(state).to(device).unsqueeze(0)))\n",
    "                #print(agent.target_dqn(torch.tensor(state).to(device).unsqueeze(0)))\n",
    "                agent.target_dqn.load_state_dict(agent.main_dqn.state_dict())\n",
    "\n",
    "            # if episode ended before maximum step\n",
    "            if terminal:\n",
    "                terminal = False\n",
    "                episode_lengths.append(episode_step_counter)\n",
    "                #state = env.reset()[:2]\n",
    "                #transition = init_transition()\n",
    "                break\n",
    "\n",
    "        eps_rewards.append(episode_reward_sum)\n",
    "\n",
    "        if len(eps_rewards) % 1 == 0:\n",
    "            #with open(path+'/logs/rewards.dat', 'a') as reward_file:\n",
    "                #print(\"[{}] {}, {}\".format(len(eps_rewards), step_counter, np.mean(eps_rewards[-100:])), file=reward_file)\n",
    "            print(\"{}, done {} episodes, {}, current eps {}\".format(step_counter, len(eps_rewards), np.mean(eps_rewards[-100:]), action_scheduler.eps_current), np.mean(episode_lengths[-100:]))\n",
    "    #torch.save(agent.main_dqn.state_dict(), path+'/checkpoints/fibre_agent_{}_reward_{:.2f}.pth'.format(step_counter, np.mean(eps_rewards[-100:])))\n",
    "\n",
    "########## evaluation starting here\n",
    "    eval_rewards = []\n",
    "    episode_final = 0\n",
    "    #agent.main_dqn.eval()\n",
    "    for _ in range(eval_runs):\n",
    "        eval_steps = 0\n",
    "        state = env.reset()\n",
    "        #transition = init_transition()\n",
    "        #env.state = TractographyState(env.referenceStreamline_ijk[0], env.interpolateDWIatState)\n",
    "        #env.stepCounter = 0\n",
    "        \n",
    "        eval_episode_reward = 0\n",
    "        while eval_steps < max_episode_length:\n",
    "            #_, optimal_reward = get_best_action(state, env)\n",
    "            action = action_scheduler.get_action(step_counter, torch.FloatTensor(state.getValue()).unsqueeze(0).to(device), evaluation=True)\n",
    "            #action = action_scheduler.get_action(step_counter, torch.FloatTensor([np.array(transition)]).to(device), evaluation=True)\n",
    "            next_state, reward, terminal = env.step(action)\n",
    "            \n",
    "            eval_steps += 1\n",
    "            \n",
    "            if reward < -1.:\n",
    "                reward = -1.\n",
    "            #terminal = False\n",
    "            #current_index = np.min([env.stepCounter,len(env.referenceStreamline_ijk)-1])\n",
    "            #path_vector = (next_state.getCoordinate() - state.getCoordinate()).squeeze(0)\n",
    "            #reference_vector = env.referenceStreamline_ijk[current_index]-env.referenceStreamline_ijk[current_index-1]\n",
    "            #    #print(path_vector, reference_vector)\n",
    "            #cosine_sim = cos(path_vector, reference_vector)\n",
    "            #dist = torch.sum((env.referenceStreamline_ijk[current_index] - next_state.getCoordinate())**2)\n",
    "            #if dist < 0.1:\n",
    "            #    dist = 0\n",
    "            #else:\n",
    "            #    dist = dist - 0.1\n",
    "            #if dist > 3*0.81:\n",
    "            #    env.stepCounter -= 1\n",
    "            #reward = cosine_sim - dist\n",
    "            #reward = 1- (optimal_reward - reward)\n",
    "            #if reward == optimal_reward:\n",
    "            #    reward = 1\n",
    "            #if action == 100 and env.rewardForTerminalState(next_state) < 0.1:\n",
    "            #    terminal = True\n",
    "\n",
    "            #if episode_step_counter == 200:\n",
    "            #    terminal = True\n",
    "            \n",
    "            #if cosine_sim < 0.9:\n",
    "            #    terminal = True\n",
    "            \n",
    "            eval_episode_reward += reward\n",
    "            state = next_state\n",
    "            #transition = next_transition\n",
    "            if terminal:\n",
    "                terminal = False\n",
    "                if reward == 1.:\n",
    "                    print(reward)\n",
    "                    episode_final += 1\n",
    "                break\n",
    "\n",
    "        eval_rewards.append(eval_episode_reward)\n",
    "\n",
    "    print(\"Evaluation score:\", np.mean(eval_rewards))\n",
    "    print(\"{} of {} episodes ended close to / at the final state.\".format(episode_final, eval_runs))\n",
    "    #if np.mean(eval_rewards) > 500.:\n",
    "    #    torch.save(agent.main_dqn.state_dict(), 'trained_agents/multiple/fibre_agent_{}_reward_{:.2f}.pth'.format(step_counter, np.mean(eval_rewards))+)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(path_vector.shape)\n",
    "print(reference_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-3.5291, device='cuda:0', grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "state = env.reset()\n",
    "\n",
    "q_vals = agent.main_dqn(torch.FloatTensor(state.getValue()).unsqueeze(0).to(device))\n",
    "print(q_vals[0][80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 58 [47.44071643 74.71694658 25.95875275] [47.870224 74.80299  26.640089] tensor(-3.9633, dtype=torch.float64)\n",
      "1 58 [47.01120886 74.63089938 25.27741647] [47.286892 74.28585  26.460402] tensor(-15.2968, dtype=torch.float64)\n",
      "Evaluation score: -19.260128263643985\n"
     ]
    }
   ],
   "source": [
    "eval_rewards = []\n",
    "all_distances = []\n",
    "all_states = []\n",
    "#agent.main_dqn.eval()\n",
    "for _ in range(1):\n",
    "    eval_steps = 0\n",
    "    state = env.reset()    \n",
    "    #state = env.reset()\n",
    "    #print(state.getCoordinate())\n",
    "    all_states.append(state.getCoordinate())\n",
    "    #transition = init_transition()\n",
    "    #all_states.append(torch.tensor(list(transition)[:3]))\n",
    "    eval_episode_reward = 0\n",
    "    episode_final = 0\n",
    "    #print(env.referenceStreamline_ijk[:6])\n",
    "    \n",
    "    while eval_steps < max_episode_length:\n",
    "        action = action_scheduler.get_action(step_counter, torch.FloatTensor(state.getValue()).unsqueeze(0).to(device), evaluation=True)\n",
    "        #action = action_scheduler.get_action(step_counter, torch.FloatTensor([np.array(transition)]).to(device), evaluation=True)\n",
    "        #action = torch.argmax(agent(torch.FloatTensor([np.array(transition)]).to(device)))\n",
    "        next_state, reward, terminal = env.step(action)\n",
    "\n",
    "        current_index = np.min([env.stepCounter,len(env.referenceStreamline_ijk)-1])\n",
    "        path_vector = (next_state.getCoordinate() - state.getCoordinate()).squeeze(0)\n",
    "        reference_vector = env.referenceStreamline_ijk[current_index]-env.referenceStreamline_ijk[current_index-1]\n",
    "        #    #print(path_vector, reference_vector)\n",
    "        cosine_sim = cos(path_vector, reference_vector)\n",
    "        dist = torch.sum((env.referenceStreamline_ijk[current_index] - next_state.getCoordinate())**2) * 10\n",
    "        reward = cosine_sim - dist\n",
    "        reward = 1 - (optimal_reward - reward)\n",
    "        if dist > 3*0.81:\n",
    "            env.stepCounter -= 1\n",
    "        if action == 100 and reward == 1:\n",
    "            terminal = False\n",
    "            \n",
    "        #if cosine_sim < 0.7:\n",
    "        #    terminal = True\n",
    "        #next_state = next_state\n",
    "        #next_transition = add_to_transition(next_state, transition)\n",
    "        #reward = 1 + (1+(reward/10))\n",
    "        #if reward > 1:\n",
    "        #    reward = 1\n",
    "        #elif reward > 0.:\n",
    "        #    reward = 0\n",
    "        #else:\n",
    "        #    reward = -1\n",
    "        eval_episode_reward += reward\n",
    "        print(eval_steps, action, next_state.getCoordinate().numpy(), env.referenceStreamline_ijk[np.min([eval_steps,len(env.referenceStreamline_ijk)-1])].numpy(), reward)\n",
    "        #print(eval_steps, action, next_state, env.referenceStreamline_ijk[np.min([eval_steps,len(env.referenceStreamline_ijk)-1])].numpy(), reward)\n",
    "        eval_steps += 1\n",
    "        if eval_steps == 200:\n",
    "            terminal = True\n",
    "        all_distances.append(reward)\n",
    "        all_states.append(next_state.getCoordinate())\n",
    "        #all_states.append(next_state)\n",
    "        \n",
    "        state = next_state\n",
    "        #transition = next_transition\n",
    "        if terminal:\n",
    "            terminal = False\n",
    "            #if reward > 0.9:\n",
    "            #    episode_final += 1\n",
    "            break\n",
    "\n",
    "    eval_rewards.append(eval_episode_reward)\n",
    "\n",
    "print(\"Evaluation score:\", np.min(eval_rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "states, actions, rewards, new_states, terminal_flags = agent.replay_memory.get_minibatch()\n",
    "print(np.array_equal(states[0], new_states[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sphere_dist(nextState):\n",
    "    current_index = np.min([env.stepCounter,len(env.referenceStreamline_ijk)-1])\n",
    "    x_dist = (nextState.getCoordinate()[0] - env.referenceStreamline_ijk[current_index][0]) **2\n",
    "    y_dist = (nextState.getCoordinate()[1] - env.referenceStreamline_ijk[current_index][1]) **2\n",
    "    z_dist = (nextState.getCoordinate()[2] - env.referenceStreamline_ijk[current_index][2]) **2\n",
    "    return x_dist + y_dist + z_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99\n"
     ]
    }
   ],
   "source": [
    "print(agent.gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47 11.394252873563218 tensor(0.1970, dtype=torch.float64) tensor(0.1970, dtype=torch.float64)\n",
      "67 11.394252873563218 tensor(0.2640, dtype=torch.float64) tensor(0.2640, dtype=torch.float64)\n",
      "72 11.394252873563218 tensor(0.2650, dtype=torch.float64) tensor(0.2650, dtype=torch.float64)\n",
      "75 11.394252873563218 tensor(0.1352, dtype=torch.float64) tensor(0.1352, dtype=torch.float64)\n",
      "80 11.394252873563218 tensor(0.0623, dtype=torch.float64) tensor(0.0623, dtype=torch.float64)\n",
      "88 11.394252873563218 tensor(0.0726, dtype=torch.float64) tensor(0.0726, dtype=torch.float64)\n",
      "93 11.394252873563218 tensor(0.1499, dtype=torch.float64) tensor(0.1499, dtype=torch.float64)\n",
      "96 11.394252873563218 tensor(0.1986, dtype=torch.float64) tensor(0.1986, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_actions):\n",
    "    state = env.reset()\n",
    "    next_state, reward, done = env.step(i)\n",
    "    s_dist = sphere_dist(next_state)\n",
    "    old_dist = torch.sum((env.referenceStreamline_ijk[env.stepCounter] - next_state.getCoordinate())**2)\n",
    "    if s_dist <= 0.52**2:\n",
    "        print(i, reward, s_dist, old_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 77.07567091 108.90497243  91.49815967] -100\n"
     ]
    }
   ],
   "source": [
    "next_state, reward, done = env.step(75)\n",
    "print(next_state.getCoordinate(), reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.283401924575482, 102.46417647849394, 66.32755479299973]\n"
     ]
    }
   ],
   "source": [
    "print(list(transition)[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 24.1166, 103.8659,  64.9889])\n"
     ]
    }
   ],
   "source": [
    "state = env.reset()\n",
    "#referenceLine = env.referenceStreamline_ijk\n",
    "print(state.getCoordinate())\n",
    "#print(referenceLine[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 23.13776944 102.38550419  64.06677327] [ 30.125023 102.08756   66.46997 ] -100\n"
     ]
    }
   ],
   "source": [
    "next_state, reward, done = env.step(74)\n",
    "print(next_state.getCoordinate().numpy(), env.referenceStreamline_ijk[np.min([env.stepCounter, len(referenceLine)])].numpy(), reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n"
     ]
    }
   ],
   "source": [
    "optimal_steps =  [80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71, 71, 100, 71, 71, 71, 71, 100, 92, 84, 84, 38, 100, 97, 97, 97, 38, 100, 97, 30, 43, 43, 48, 100, 94, 81, 94, 35, 97, 100, 35, 22, 35, 35, 6, 100, 19, 3, 16, 3, 21, 100, 21, 16, 34, 21, 98, 34, 100, 39, 93, 39, 72, 72, 100, 69, 100]\n",
    "transition = init_transition()\n",
    "referenceLine = env.referenceStreamline_ijk\n",
    "print(len(referenceLine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 -0.09999999999999964\n"
     ]
    }
   ],
   "source": [
    "#action = action_scheduler.get_action(step_counter, torch.FloatTensor([np.array(transition)]).to(device), evaluation=True)\n",
    "next_state, reward, terminal = env.step(88)\n",
    "next_transition = add_to_transition(next_state, transition)\n",
    "print(action, reward)\n",
    "transition = next_transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State:  [ 73.651344 107.88106   93.29415 ]\n",
      "Next State:  [ 74.56195007 107.80595503  92.88775652]\n",
      "7.450580596923828e-09\n"
     ]
    }
   ],
   "source": [
    "# Debugging the reward function\n",
    "referenceLine = env.referenceStreamline_ijk\n",
    "stepCounter = 0\n",
    "maxSteps=200\n",
    "state = env.reset()\n",
    "print(\"State: \", state.getCoordinate().numpy())\n",
    "next_state, _, terminal = env.step(80)\n",
    "print(\"Next State: \", next_state.getCoordinate().numpy())\n",
    "\n",
    "def lineseg_dist(p, a, b):\n",
    "\n",
    "    # normalized tangent vector\n",
    "    d = np.divide(b - a, np.linalg.norm(b - a))\n",
    "\n",
    "    # signed parallel distance components\n",
    "    s = np.dot(a - p, d)\n",
    "    t = np.dot(p - b, d)\n",
    "\n",
    "    # clamped parallel distance\n",
    "    h = np.maximum.reduce([s, t, 0])\n",
    "\n",
    "    # perpendicular distance component\n",
    "    c = np.cross(p - a, d)\n",
    "\n",
    "    return np.hypot(h, np.linalg.norm(c))\n",
    "\n",
    "distance = lineseg_dist(referenceLine[86].numpy(), referenceLine[85].numpy(), referenceLine[86].numpy())\n",
    "print(distance)\n",
    "\n",
    "#print(\"Diff: \", next_state.getCoordinate().numpy()-state.getCoordinate().numpy())\n",
    "#qry_pt = next_state.getCoordinate().view(-1,3)\n",
    "#print(\"Reference next state: \", referenceLine[stepCounter+1])\n",
    "#print(\"Diff to reference state: \", referenceLine[stepCounter+1]-next_state.getCoordinate().numpy())\n",
    "#distance = torch.min(torch.sum((referenceLine[np.min([stepCounter+1, maxSteps-1])] - qry_pt)**2, dim=1))\n",
    "#print(distance)\n",
    "#reward = torch.tanh(-distance+5.3)\n",
    "\n",
    "#if distance == -1:\n",
    "#    reward = 0.5\n",
    "#elif distance < 0.8:\n",
    "#    reward = 1+ (1-distance)\n",
    "#else:\n",
    "#    reward = np.max([1 - distance, -1])\n",
    "#print(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19954145509142476\n",
      "0.03981679230000309\n",
      "0.07041062249999892\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "state = np.array([ 75.6, 107.95,  92.22])\n",
    "line = np.array([ 75.78847, 107.96255,  92.28433])\n",
    "\n",
    "print(np.linalg.norm(line - state, 2))\n",
    "\n",
    "sphere_dist = ((state[0] - line[0])**2 + (state[1]-line[1])**2 + (state[2]-line[2])**2)\n",
    "print(sphere_dist)\n",
    "normal_diff = np.sum(state-line)**2\n",
    "print(normal_diff)\n",
    "if sphere_dist < 0.2**2:\n",
    "    print(True)\n",
    "else:\n",
    "    print(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action:  100 Reward:  -0.6400096416473389\n",
      "Action:  80 Reward:  -0.3780286503520091\n",
      "Action:  75 Reward:  -0.17094774926353554\n",
      "Action:  80 Reward:  -0.06020208127816557\n",
      "Action:  75 Reward:  -0.023724592605490286\n",
      "Action:  100 Reward:  -0.023724592605490286\n",
      "Action:  62 Reward:  -0.031680450691759385\n",
      "Action:  75 Reward:  -0.10966306950569177\n",
      "Action:  83 Reward:  -0.2621558822401104\n",
      "Action:  75 Reward:  -0.4853828474102172\n",
      "Action:  83 Reward:  -0.7713330234194417\n",
      "Action:  100 Reward:  -0.7713330234194417\n",
      "Action:  83 Reward:  -1.158927472394806\n",
      "Action:  62 Reward:  -1.6468544226974164\n",
      "Action:  67 Reward:  -2.2078664481054533\n",
      "Action:  51 Reward:  -2.459970885856384\n",
      "Action:  67 Reward:  -3.0430611441644246\n",
      "Action:  100 Reward:  -3.0430611441644246\n",
      "Action:  59 Reward:  -3.7319386628026487\n",
      "Action:  59 Reward:  -4.531517914723884\n",
      "Action:  59 Reward:  -5.427621034792285\n",
      "Action:  100 Reward:  -5.427621034792285\n",
      "Action:  59 Reward:  -6.420164664306009\n",
      "Action:  56 Reward:  -7.21012573500936\n",
      "Action:  51 Reward:  -8.185668593823168\n",
      "Action:  56 Reward:  -9.264514952082235\n",
      "Action:  66 Reward:  -9.504376152250732\n",
      "Action:  100 Reward:  -9.504376152250732\n",
      "Action:  66 Reward:  -10.878316642589324\n",
      "Action:  71 Reward:  -11.684246290994608\n",
      "Action:  71 Reward:  -13.482882171224585\n",
      "Action:  79 Reward:  -15.013766894750662\n",
      "Action:  58 Reward:  -16.29778288166172\n",
      "Action:  100 Reward:  -16.29778288166172\n",
      "Action:  71 Reward:  -17.927867464472456\n",
      "Action:  71 Reward:  -19.616943063578457\n",
      "Action:  84 Reward:  -20.74882253322799\n",
      "Action:  71 Reward:  -22.68542229369059\n",
      "Action:  100 Reward:  -22.68542229369059\n",
      "Action:  92 Reward:  -24.094491148196\n",
      "Action:  84 Reward:  -26.036910111309087\n",
      "Action:  92 Reward:  -27.894909786068872\n",
      "Action:  97 Reward:  -29.22946434143986\n",
      "Action:  100 Reward:  -29.22946434143986\n",
      "Action:  97 Reward:  -30.93770942329201\n",
      "Action:  38 Reward:  -33.06379059780991\n",
      "Action:  97 Reward:  -35.48076469151409\n",
      "Action:  43 Reward:  -37.24656758094286\n",
      "Action:  38 Reward:  -39.87506653295411\n",
      "Action:  100 Reward:  -39.87506653295411\n",
      "Action:  43 Reward:  -42.07728895704025\n",
      "Action:  43 Reward:  -44.59950388329224\n",
      "Action:  89 Reward:  -46.525702788416744\n",
      "Action:  48 Reward:  -46.51577793318299\n",
      "Action:  100 Reward:  -46.51577793318299\n",
      "Action:  94 Reward:  -44.74553361569235\n",
      "Action:  81 Reward:  -46.71395822922152\n",
      "Action:  48 Reward:  -50.26025222152221\n",
      "Action:  43 Reward:  -53.83576866536265\n",
      "Action:  100 Reward:  -53.83576866536265\n",
      "Action:  35 Reward:  -57.7679173101252\n",
      "Action:  43 Reward:  -61.07110670119785\n",
      "Action:  35 Reward:  -64.29611023518841\n",
      "Action:  22 Reward:  -64.69258594426614\n",
      "Action:  27 Reward:  -67.94753644296517\n",
      "Action:  100 Reward:  -67.94753644296517\n",
      "Action:  6 Reward:  -68.60859514506335\n",
      "Action:  11 Reward:  -70.03265506052335\n",
      "Action:  3 Reward:  -69.6074991211795\n",
      "Action:  16 Reward:  -66.45768588248448\n",
      "Action:  100 Reward:  -66.45768588248448\n",
      "Action:  8 Reward:  -63.980960033928525\n",
      "Action:  29 Reward:  -63.97912872209463\n",
      "Action:  21 Reward:  -65.2877329760679\n",
      "Action:  21 Reward:  -71.00622766156863\n",
      "Action:  100 Reward:  -71.00622766156863\n",
      "Action:  34 Reward:  -75.30646175774287\n",
      "Action:  26 Reward:  -79.7251625711022\n",
      "Action:  26 Reward:  -85.7736700190284\n",
      "Action:  93 Reward:  -86.29779314738443\n",
      "Action:  39 Reward:  -89.76066176762737\n",
      "Action:  100 Reward:  -89.76066176762737\n",
      "Action:  93 Reward:  -92.76729682665923\n",
      "Action:  72 Reward:  -91.66762326274807\n",
      "Action:  77 Reward:  -91.52645978577566\n",
      "Action:  77 Reward:  -94.77110103827272\n",
      "Action:  100 Reward:  -94.77110103827272\n",
      "-3134.679829616308\n"
     ]
    }
   ],
   "source": [
    "#optimal_steps = [80, 75, 80, 75, 62, 75, 83, 96, 51, 24, 62, 62, 62, 77, 65, 64, 67, 59, 56, 83, 82, 54, 56, 53, 56, 38, 56, 84, 66, 71, 71, 64, 97, 84, 71, 71, 38, 51, 30, 92, 97, 84, 43, 79, 27, 46, 89, 25, 81, 25, 48, 43, 86, 48, 57, 14, 89, 43, 43, 19, 92, 14, 27, 9, 78, 4, 16, 3, 29, 3, 47, 6, 42, 21, 39, 5, 72, 34, 98, 88, 90, 75, 77, 59, 49, 32, 82, 100]\n",
    "eps_reward = 0\n",
    "state = env.reset()\n",
    "for i in optimal_steps:\n",
    "    next_state, reward, terminal = env.step(i)\n",
    "    state = next_state\n",
    "    eps_reward += reward.item()\n",
    "    print(\"Action: \", i, \"Reward: \", reward.item())\n",
    "print(eps_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init environment..\n",
      "Loading precomputed streamlines (data/HCP307200_DTI_smallSet.vtk) for ID 100307\n",
      "..done!\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Init environment..\")\n",
    "env = RLTe.RLtractEnvironment(device = 'cpu')\n",
    "print(\"..done!\")\n",
    "n_actions = env.action_space.n\n",
    "#print(n_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([87, 3])\n"
     ]
    }
   ],
   "source": [
    "referenceLine = env.referenceStreamline_ijk\n",
    "print(referenceLine.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([47.8702, 74.8030, 26.6401])\n",
      "tensor([47.8702, 74.8030, 26.6401])\n"
     ]
    }
   ],
   "source": [
    "print(referenceLine[0])\n",
    "state = TractographyState(referenceLine[0], env.interpolateDWIatState)\n",
    "print(state.getCoordinate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  0 Action:  41 Distance:  tensor(1.3545, dtype=torch.float64)\n",
      "Step:  0 Action:  66 Distance:  tensor(1.2187, dtype=torch.float64)\n",
      "Step:  0 Action:  74 Distance:  tensor(1.5895, dtype=torch.float64)\n",
      "Step:  0 Action:  79 Distance:  tensor(1.4856, dtype=torch.float64)\n",
      "Step:  0 Action:  82 Distance:  tensor(1.2496, dtype=torch.float64)\n",
      "Step:  0 Action:  87 Distance:  tensor(1.5944, dtype=torch.float64)\n",
      "Step:  0 Action:  95 Distance:  tensor(1.5184, dtype=torch.float64)\n",
      "0 []\n",
      "Step:  1 Action:  61 Distance:  tensor(1.3162, dtype=torch.float64)\n",
      "Step:  1 Action:  66 Distance:  tensor(1.2710, dtype=torch.float64)\n",
      "Step:  1 Action:  74 Distance:  tensor(1.6272, dtype=torch.float64)\n",
      "Step:  1 Action:  79 Distance:  tensor(1.3920, dtype=torch.float64)\n",
      "Step:  1 Action:  82 Distance:  tensor(1.4070, dtype=torch.float64)\n",
      "Step:  1 Action:  87 Distance:  tensor(1.4471, dtype=torch.float64)\n",
      "Step:  1 Action:  95 Distance:  tensor(1.5094, dtype=torch.float64)\n",
      "1 []\n",
      "Step:  2 Action:  41 Distance:  tensor(1.2821, dtype=torch.float64)\n",
      "Step:  2 Action:  61 Distance:  tensor(1.2315, dtype=torch.float64)\n",
      "Step:  2 Action:  74 Distance:  tensor(1.6046, dtype=torch.float64)\n",
      "Step:  2 Action:  79 Distance:  tensor(1.3549, dtype=torch.float64)\n",
      "Step:  2 Action:  82 Distance:  tensor(1.4040, dtype=torch.float64)\n",
      "Step:  2 Action:  87 Distance:  tensor(1.4843, dtype=torch.float64)\n",
      "Step:  2 Action:  95 Distance:  tensor(1.5651, dtype=torch.float64)\n",
      "2 []\n",
      "Step:  3 Action:  41 Distance:  tensor(1.2908, dtype=torch.float64)\n",
      "Step:  3 Action:  49 Distance:  tensor(1.2627, dtype=torch.float64)\n",
      "Step:  3 Action:  61 Distance:  tensor(1.2172, dtype=torch.float64)\n",
      "Step:  3 Action:  74 Distance:  tensor(1.5797, dtype=torch.float64)\n",
      "Step:  3 Action:  79 Distance:  tensor(1.2516, dtype=torch.float64)\n",
      "Step:  3 Action:  82 Distance:  tensor(1.4621, dtype=torch.float64)\n",
      "Step:  3 Action:  87 Distance:  tensor(1.4322, dtype=torch.float64)\n",
      "Step:  3 Action:  95 Distance:  tensor(1.6009, dtype=torch.float64)\n",
      "3 []\n",
      "Step:  4 Action:  49 Distance:  tensor(1.3226, dtype=torch.float64)\n",
      "Step:  4 Action:  61 Distance:  tensor(1.3563, dtype=torch.float64)\n",
      "Step:  4 Action:  74 Distance:  tensor(1.5702, dtype=torch.float64)\n",
      "Step:  4 Action:  82 Distance:  tensor(1.5784, dtype=torch.float64)\n",
      "Step:  4 Action:  87 Distance:  tensor(1.2502, dtype=torch.float64)\n",
      "Step:  4 Action:  95 Distance:  tensor(1.5545, dtype=torch.float64)\n",
      "4 []\n",
      "Step:  5 Action:  49 Distance:  tensor(1.2380, dtype=torch.float64)\n",
      "Step:  5 Action:  61 Distance:  tensor(1.4426, dtype=torch.float64)\n",
      "Step:  5 Action:  69 Distance:  tensor(1.2523, dtype=torch.float64)\n",
      "Step:  5 Action:  74 Distance:  tensor(1.5910, dtype=torch.float64)\n",
      "Step:  5 Action:  82 Distance:  tensor(1.5806, dtype=torch.float64)\n",
      "Step:  5 Action:  87 Distance:  tensor(1.2100, dtype=torch.float64)\n",
      "Step:  5 Action:  95 Distance:  tensor(1.4956, dtype=torch.float64)\n",
      "5 []\n",
      "Step:  6 Action:  61 Distance:  tensor(1.5273, dtype=torch.float64)\n",
      "Step:  6 Action:  66 Distance:  tensor(1.3657, dtype=torch.float64)\n",
      "Step:  6 Action:  69 Distance:  tensor(1.2500, dtype=torch.float64)\n",
      "Step:  6 Action:  74 Distance:  tensor(1.6194, dtype=torch.float64)\n",
      "Step:  6 Action:  79 Distance:  tensor(1.2759, dtype=torch.float64)\n",
      "Step:  6 Action:  82 Distance:  tensor(1.5115, dtype=torch.float64)\n",
      "Step:  6 Action:  87 Distance:  tensor(1.2051, dtype=torch.float64)\n",
      "Step:  6 Action:  95 Distance:  tensor(1.3869, dtype=torch.float64)\n",
      "6 []\n",
      "Step:  7 Action:  61 Distance:  tensor(1.5700, dtype=torch.float64)\n",
      "Step:  7 Action:  66 Distance:  tensor(1.4237, dtype=torch.float64)\n",
      "Step:  7 Action:  69 Distance:  tensor(1.2798, dtype=torch.float64)\n",
      "Step:  7 Action:  74 Distance:  tensor(1.5954, dtype=torch.float64)\n",
      "Step:  7 Action:  79 Distance:  tensor(1.2693, dtype=torch.float64)\n",
      "Step:  7 Action:  82 Distance:  tensor(1.4712, dtype=torch.float64)\n",
      "Step:  7 Action:  95 Distance:  tensor(1.2862, dtype=torch.float64)\n",
      "7 []\n",
      "Step:  8 Action:  53 Distance:  tensor(1.2474, dtype=torch.float64)\n",
      "Step:  8 Action:  61 Distance:  tensor(1.6099, dtype=torch.float64)\n",
      "Step:  8 Action:  66 Distance:  tensor(1.4011, dtype=torch.float64)\n",
      "Step:  8 Action:  69 Distance:  tensor(1.3809, dtype=torch.float64)\n",
      "Step:  8 Action:  74 Distance:  tensor(1.5549, dtype=torch.float64)\n",
      "Step:  8 Action:  82 Distance:  tensor(1.4958, dtype=torch.float64)\n",
      "Step:  8 Action:  95 Distance:  tensor(1.2269, dtype=torch.float64)\n",
      "8 []\n",
      "Step:  9 Action:  53 Distance:  tensor(1.2052, dtype=torch.float64)\n",
      "Step:  9 Action:  56 Distance:  tensor(1.2501, dtype=torch.float64)\n",
      "Step:  9 Action:  61 Distance:  tensor(1.6062, dtype=torch.float64)\n",
      "Step:  9 Action:  66 Distance:  tensor(1.2593, dtype=torch.float64)\n",
      "Step:  9 Action:  69 Distance:  tensor(1.5104, dtype=torch.float64)\n",
      "Step:  9 Action:  74 Distance:  tensor(1.4608, dtype=torch.float64)\n",
      "Step:  9 Action:  82 Distance:  tensor(1.5458, dtype=torch.float64)\n",
      "9 []\n",
      "Step:  10 Action:  56 Distance:  tensor(1.2257, dtype=torch.float64)\n",
      "Step:  10 Action:  61 Distance:  tensor(1.5655, dtype=torch.float64)\n",
      "Step:  10 Action:  69 Distance:  tensor(1.5418, dtype=torch.float64)\n",
      "Step:  10 Action:  74 Distance:  tensor(1.4100, dtype=torch.float64)\n",
      "Step:  10 Action:  82 Distance:  tensor(1.5741, dtype=torch.float64)\n",
      "Step:  10 Action:  90 Distance:  tensor(1.2631, dtype=torch.float64)\n",
      "10 []\n",
      "Step:  11 Action:  56 Distance:  tensor(1.2257, dtype=torch.float64)\n",
      "Step:  11 Action:  61 Distance:  tensor(1.5655, dtype=torch.float64)\n",
      "Step:  11 Action:  69 Distance:  tensor(1.5418, dtype=torch.float64)\n",
      "Step:  11 Action:  74 Distance:  tensor(1.4100, dtype=torch.float64)\n",
      "Step:  11 Action:  82 Distance:  tensor(1.5741, dtype=torch.float64)\n",
      "Step:  11 Action:  90 Distance:  tensor(1.2631, dtype=torch.float64)\n",
      "11 []\n",
      "Step:  12 Action:  56 Distance:  tensor(1.3080, dtype=torch.float64)\n",
      "Step:  12 Action:  61 Distance:  tensor(1.5581, dtype=torch.float64)\n",
      "Step:  12 Action:  69 Distance:  tensor(1.5947, dtype=torch.float64)\n",
      "Step:  12 Action:  74 Distance:  tensor(1.3253, dtype=torch.float64)\n",
      "Step:  12 Action:  77 Distance:  tensor(1.2564, dtype=torch.float64)\n",
      "Step:  12 Action:  82 Distance:  tensor(1.5506, dtype=torch.float64)\n",
      "Step:  12 Action:  90 Distance:  tensor(1.2967, dtype=torch.float64)\n",
      "12 []\n",
      "Step:  13 Action:  56 Distance:  tensor(1.3643, dtype=torch.float64)\n",
      "Step:  13 Action:  61 Distance:  tensor(1.5247, dtype=torch.float64)\n",
      "Step:  13 Action:  64 Distance:  tensor(1.2298, dtype=torch.float64)\n",
      "Step:  13 Action:  69 Distance:  tensor(1.6218, dtype=torch.float64)\n",
      "Step:  13 Action:  74 Distance:  tensor(1.2146, dtype=torch.float64)\n",
      "Step:  13 Action:  77 Distance:  tensor(1.3332, dtype=torch.float64)\n",
      "Step:  13 Action:  82 Distance:  tensor(1.5012, dtype=torch.float64)\n",
      "Step:  13 Action:  90 Distance:  tensor(1.3043, dtype=torch.float64)\n",
      "13 []\n",
      "Step:  14 Action:  56 Distance:  tensor(1.3236, dtype=torch.float64)\n",
      "Step:  14 Action:  61 Distance:  tensor(1.4642, dtype=torch.float64)\n",
      "Step:  14 Action:  64 Distance:  tensor(1.2667, dtype=torch.float64)\n",
      "Step:  14 Action:  69 Distance:  tensor(1.6333, dtype=torch.float64)\n",
      "Step:  14 Action:  77 Distance:  tensor(1.4185, dtype=torch.float64)\n",
      "Step:  14 Action:  82 Distance:  tensor(1.5103, dtype=torch.float64)\n",
      "Step:  14 Action:  90 Distance:  tensor(1.3923, dtype=torch.float64)\n",
      "14 []\n",
      "Step:  15 Action:  56 Distance:  tensor(1.2585, dtype=torch.float64)\n",
      "Step:  15 Action:  61 Distance:  tensor(1.3793, dtype=torch.float64)\n",
      "Step:  15 Action:  64 Distance:  tensor(1.2792, dtype=torch.float64)\n",
      "Step:  15 Action:  69 Distance:  tensor(1.6204, dtype=torch.float64)\n",
      "Step:  15 Action:  77 Distance:  tensor(1.4794, dtype=torch.float64)\n",
      "Step:  15 Action:  82 Distance:  tensor(1.4951, dtype=torch.float64)\n",
      "Step:  15 Action:  90 Distance:  tensor(1.4558, dtype=torch.float64)\n",
      "15 []\n",
      "Step:  16 Action:  61 Distance:  tensor(1.2885, dtype=torch.float64)\n",
      "Step:  16 Action:  64 Distance:  tensor(1.2906, dtype=torch.float64)\n",
      "Step:  16 Action:  69 Distance:  tensor(1.6013, dtype=torch.float64)\n",
      "Step:  16 Action:  77 Distance:  tensor(1.5375, dtype=torch.float64)\n",
      "Step:  16 Action:  82 Distance:  tensor(1.4737, dtype=torch.float64)\n",
      "Step:  16 Action:  90 Distance:  tensor(1.5160, dtype=torch.float64)\n",
      "16 []\n",
      "Step:  17 Action:  64 Distance:  tensor(1.2763, dtype=torch.float64)\n",
      "Step:  17 Action:  69 Distance:  tensor(1.5565, dtype=torch.float64)\n",
      "Step:  17 Action:  77 Distance:  tensor(1.5700, dtype=torch.float64)\n",
      "Step:  17 Action:  82 Distance:  tensor(1.4267, dtype=torch.float64)\n",
      "Step:  17 Action:  90 Distance:  tensor(1.5504, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  17 Action:  98 Distance:  tensor(1.2671, dtype=torch.float64)\n",
      "17 []\n",
      "Step:  18 Action:  64 Distance:  tensor(1.2763, dtype=torch.float64)\n",
      "Step:  18 Action:  69 Distance:  tensor(1.5565, dtype=torch.float64)\n",
      "Step:  18 Action:  77 Distance:  tensor(1.5700, dtype=torch.float64)\n",
      "Step:  18 Action:  82 Distance:  tensor(1.4267, dtype=torch.float64)\n",
      "Step:  18 Action:  90 Distance:  tensor(1.5504, dtype=torch.float64)\n",
      "Step:  18 Action:  98 Distance:  tensor(1.2671, dtype=torch.float64)\n",
      "18 []\n",
      "Step:  19 Action:  64 Distance:  tensor(1.2807, dtype=torch.float64)\n",
      "Step:  19 Action:  69 Distance:  tensor(1.5051, dtype=torch.float64)\n",
      "Step:  19 Action:  77 Distance:  tensor(1.6072, dtype=torch.float64)\n",
      "Step:  19 Action:  82 Distance:  tensor(1.3555, dtype=torch.float64)\n",
      "Step:  19 Action:  85 Distance:  tensor(1.2477, dtype=torch.float64)\n",
      "Step:  19 Action:  90 Distance:  tensor(1.5722, dtype=torch.float64)\n",
      "Step:  19 Action:  98 Distance:  tensor(1.3832, dtype=torch.float64)\n",
      "19 []\n",
      "Step:  20 Action:  44 Distance:  tensor(1.3385, dtype=torch.float64)\n",
      "Step:  20 Action:  49 Distance:  tensor(1.2286, dtype=torch.float64)\n",
      "Step:  20 Action:  69 Distance:  tensor(1.3823, dtype=torch.float64)\n",
      "Step:  20 Action:  77 Distance:  tensor(1.5818, dtype=torch.float64)\n",
      "Step:  20 Action:  82 Distance:  tensor(1.2872, dtype=torch.float64)\n",
      "Step:  20 Action:  85 Distance:  tensor(1.2530, dtype=torch.float64)\n",
      "Step:  20 Action:  90 Distance:  tensor(1.6020, dtype=torch.float64)\n",
      "Step:  20 Action:  98 Distance:  tensor(1.4867, dtype=torch.float64)\n",
      "20 []\n",
      "Step:  21 Action:  44 Distance:  tensor(1.4217, dtype=torch.float64)\n",
      "Step:  21 Action:  49 Distance:  tensor(1.2387, dtype=torch.float64)\n",
      "Step:  21 Action:  69 Distance:  tensor(1.2773, dtype=torch.float64)\n",
      "Step:  21 Action:  77 Distance:  tensor(1.5501, dtype=torch.float64)\n",
      "Step:  21 Action:  82 Distance:  tensor(1.2059, dtype=torch.float64)\n",
      "Step:  21 Action:  85 Distance:  tensor(1.2581, dtype=torch.float64)\n",
      "Step:  21 Action:  90 Distance:  tensor(1.5947, dtype=torch.float64)\n",
      "Step:  21 Action:  98 Distance:  tensor(1.5446, dtype=torch.float64)\n",
      "21 []\n",
      "Step:  22 Action:  44 Distance:  tensor(1.4126, dtype=torch.float64)\n",
      "Step:  22 Action:  69 Distance:  tensor(1.2116, dtype=torch.float64)\n",
      "Step:  22 Action:  77 Distance:  tensor(1.5488, dtype=torch.float64)\n",
      "Step:  22 Action:  85 Distance:  tensor(1.3282, dtype=torch.float64)\n",
      "Step:  22 Action:  90 Distance:  tensor(1.5470, dtype=torch.float64)\n",
      "Step:  22 Action:  98 Distance:  tensor(1.5829, dtype=torch.float64)\n",
      "22 []\n",
      "Step:  23 Action:  31 Distance:  tensor(1.2443, dtype=torch.float64)\n",
      "Step:  23 Action:  39 Distance:  tensor(1.2866, dtype=torch.float64)\n",
      "Step:  23 Action:  44 Distance:  tensor(1.3997, dtype=torch.float64)\n",
      "Step:  23 Action:  77 Distance:  tensor(1.5426, dtype=torch.float64)\n",
      "Step:  23 Action:  85 Distance:  tensor(1.3959, dtype=torch.float64)\n",
      "Step:  23 Action:  90 Distance:  tensor(1.4943, dtype=torch.float64)\n",
      "Step:  23 Action:  98 Distance:  tensor(1.6163, dtype=torch.float64)\n",
      "23 []\n",
      "Step:  24 Action:  31 Distance:  tensor(1.2934, dtype=torch.float64)\n",
      "Step:  24 Action:  39 Distance:  tensor(1.3726, dtype=torch.float64)\n",
      "Step:  24 Action:  44 Distance:  tensor(1.3641, dtype=torch.float64)\n",
      "Step:  24 Action:  77 Distance:  tensor(1.5137, dtype=torch.float64)\n",
      "Step:  24 Action:  85 Distance:  tensor(1.4408, dtype=torch.float64)\n",
      "Step:  24 Action:  90 Distance:  tensor(1.4189, dtype=torch.float64)\n",
      "Step:  24 Action:  98 Distance:  tensor(1.6270, dtype=torch.float64)\n",
      "24 []\n",
      "Step:  25 Action:  31 Distance:  tensor(1.3955, dtype=torch.float64)\n",
      "Step:  25 Action:  39 Distance:  tensor(1.4232, dtype=torch.float64)\n",
      "Step:  25 Action:  44 Distance:  tensor(1.4189, dtype=torch.float64)\n",
      "Step:  25 Action:  77 Distance:  tensor(1.4476, dtype=torch.float64)\n",
      "Step:  25 Action:  85 Distance:  tensor(1.4018, dtype=torch.float64)\n",
      "Step:  25 Action:  90 Distance:  tensor(1.3865, dtype=torch.float64)\n",
      "Step:  25 Action:  98 Distance:  tensor(1.6444, dtype=torch.float64)\n",
      "25 []\n",
      "Step:  26 Action:  23 Distance:  tensor(1.2010, dtype=torch.float64)\n",
      "Step:  26 Action:  31 Distance:  tensor(1.5438, dtype=torch.float64)\n",
      "Step:  26 Action:  39 Distance:  tensor(1.4724, dtype=torch.float64)\n",
      "Step:  26 Action:  44 Distance:  tensor(1.4670, dtype=torch.float64)\n",
      "Step:  26 Action:  77 Distance:  tensor(1.2564, dtype=torch.float64)\n",
      "Step:  26 Action:  85 Distance:  tensor(1.2705, dtype=torch.float64)\n",
      "Step:  26 Action:  90 Distance:  tensor(1.2592, dtype=torch.float64)\n",
      "Step:  26 Action:  98 Distance:  tensor(1.6194, dtype=torch.float64)\n",
      "26 []\n",
      "Step:  27 Action:  23 Distance:  tensor(1.2617, dtype=torch.float64)\n",
      "Step:  27 Action:  26 Distance:  tensor(1.3512, dtype=torch.float64)\n",
      "Step:  27 Action:  31 Distance:  tensor(1.6077, dtype=torch.float64)\n",
      "Step:  27 Action:  39 Distance:  tensor(1.5253, dtype=torch.float64)\n",
      "Step:  27 Action:  44 Distance:  tensor(1.3890, dtype=torch.float64)\n",
      "Step:  27 Action:  98 Distance:  tensor(1.5487, dtype=torch.float64)\n",
      "27 []\n",
      "Step:  28 Action:  18 Distance:  tensor(1.2351, dtype=torch.float64)\n",
      "Step:  28 Action:  23 Distance:  tensor(1.2164, dtype=torch.float64)\n",
      "Step:  28 Action:  26 Distance:  tensor(1.4285, dtype=torch.float64)\n",
      "Step:  28 Action:  31 Distance:  tensor(1.6014, dtype=torch.float64)\n",
      "Step:  28 Action:  39 Distance:  tensor(1.5558, dtype=torch.float64)\n",
      "Step:  28 Action:  44 Distance:  tensor(1.2939, dtype=torch.float64)\n",
      "Step:  28 Action:  98 Distance:  tensor(1.4966, dtype=torch.float64)\n",
      "28 []\n",
      "Step:  29 Action:  18 Distance:  tensor(1.3395, dtype=torch.float64)\n",
      "Step:  29 Action:  23 Distance:  tensor(1.2725, dtype=torch.float64)\n",
      "Step:  29 Action:  26 Distance:  tensor(1.4920, dtype=torch.float64)\n",
      "Step:  29 Action:  31 Distance:  tensor(1.6207, dtype=torch.float64)\n",
      "Step:  29 Action:  39 Distance:  tensor(1.5335, dtype=torch.float64)\n",
      "Step:  29 Action:  44 Distance:  tensor(1.2629, dtype=torch.float64)\n",
      "Step:  29 Action:  98 Distance:  tensor(1.4319, dtype=torch.float64)\n",
      "29 []\n",
      "Step:  30 Action:  18 Distance:  tensor(1.4184, dtype=torch.float64)\n",
      "Step:  30 Action:  23 Distance:  tensor(1.3032, dtype=torch.float64)\n",
      "Step:  30 Action:  26 Distance:  tensor(1.5302, dtype=torch.float64)\n",
      "Step:  30 Action:  31 Distance:  tensor(1.6147, dtype=torch.float64)\n",
      "Step:  30 Action:  39 Distance:  tensor(1.4859, dtype=torch.float64)\n",
      "Step:  30 Action:  44 Distance:  tensor(1.2065, dtype=torch.float64)\n",
      "Step:  30 Action:  98 Distance:  tensor(1.3418, dtype=torch.float64)\n",
      "30 []\n",
      "Step:  31 Action:  13 Distance:  tensor(1.2379, dtype=torch.float64)\n",
      "Step:  31 Action:  18 Distance:  tensor(1.4916, dtype=torch.float64)\n",
      "Step:  31 Action:  23 Distance:  tensor(1.3284, dtype=torch.float64)\n",
      "Step:  31 Action:  26 Distance:  tensor(1.5638, dtype=torch.float64)\n",
      "Step:  31 Action:  31 Distance:  tensor(1.6021, dtype=torch.float64)\n",
      "Step:  31 Action:  39 Distance:  tensor(1.4352, dtype=torch.float64)\n",
      "Step:  31 Action:  98 Distance:  tensor(1.2489, dtype=torch.float64)\n",
      "31 []\n",
      "Step:  32 Action:  0 Distance:  tensor(1.2495, dtype=torch.float64)\n",
      "Step:  32 Action:  13 Distance:  tensor(1.4117, dtype=torch.float64)\n",
      "Step:  32 Action:  18 Distance:  tensor(1.5820, dtype=torch.float64)\n",
      "Step:  32 Action:  23 Distance:  tensor(1.3226, dtype=torch.float64)\n",
      "Step:  32 Action:  26 Distance:  tensor(1.5775, dtype=torch.float64)\n",
      "Step:  32 Action:  31 Distance:  tensor(1.5211, dtype=torch.float64)\n",
      "Step:  32 Action:  39 Distance:  tensor(1.2828, dtype=torch.float64)\n",
      "32 []\n",
      "Step:  33 Action:  0 Distance:  tensor(1.4203, dtype=torch.float64)\n",
      "Step:  33 Action:  5 Distance:  tensor(1.3761, dtype=torch.float64)\n",
      "Step:  33 Action:  10 Distance:  tensor(1.2212, dtype=torch.float64)\n",
      "Step:  33 Action:  13 Distance:  tensor(1.5318, dtype=torch.float64)\n",
      "Step:  33 Action:  18 Distance:  tensor(1.6109, dtype=torch.float64)\n",
      "Step:  33 Action:  23 Distance:  tensor(1.2563, dtype=torch.float64)\n",
      "Step:  33 Action:  26 Distance:  tensor(1.5325, dtype=torch.float64)\n",
      "Step:  33 Action:  31 Distance:  tensor(1.3783, dtype=torch.float64)\n",
      "33 []\n",
      "Step:  34 Action:  0 Distance:  tensor(1.5741, dtype=torch.float64)\n",
      "Step:  34 Action:  5 Distance:  tensor(1.4806, dtype=torch.float64)\n",
      "Step:  34 Action:  8 Distance:  tensor(1.2429, dtype=torch.float64)\n",
      "Step:  34 Action:  10 Distance:  tensor(1.2187, dtype=torch.float64)\n",
      "Step:  34 Action:  13 Distance:  tensor(1.6071, dtype=torch.float64)\n",
      "Step:  34 Action:  18 Distance:  tensor(1.5614, dtype=torch.float64)\n",
      "Step:  34 Action:  21 Distance:  tensor(1.2155, dtype=torch.float64)\n",
      "Step:  34 Action:  26 Distance:  tensor(1.4623, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  34 Action:  34 Distance:  tensor(1.2363, dtype=torch.float64)\n",
      "34 []\n",
      "Step:  35 Action:  0 Distance:  tensor(1.6504, dtype=torch.float64)\n",
      "Step:  35 Action:  5 Distance:  tensor(1.4896, dtype=torch.float64)\n",
      "Step:  35 Action:  8 Distance:  tensor(1.3297, dtype=torch.float64)\n",
      "Step:  35 Action:  13 Distance:  tensor(1.6255, dtype=torch.float64)\n",
      "Step:  35 Action:  18 Distance:  tensor(1.5023, dtype=torch.float64)\n",
      "Step:  35 Action:  21 Distance:  tensor(1.3069, dtype=torch.float64)\n",
      "Step:  35 Action:  26 Distance:  tensor(1.4191, dtype=torch.float64)\n",
      "Step:  35 Action:  34 Distance:  tensor(1.2754, dtype=torch.float64)\n",
      "35 []\n",
      "Step:  36 Action:  0 Distance:  tensor(1.6504, dtype=torch.float64)\n",
      "Step:  36 Action:  5 Distance:  tensor(1.4574, dtype=torch.float64)\n",
      "Step:  36 Action:  8 Distance:  tensor(1.3736, dtype=torch.float64)\n",
      "Step:  36 Action:  13 Distance:  tensor(1.6424, dtype=torch.float64)\n",
      "Step:  36 Action:  18 Distance:  tensor(1.4433, dtype=torch.float64)\n",
      "Step:  36 Action:  21 Distance:  tensor(1.3961, dtype=torch.float64)\n",
      "Step:  36 Action:  26 Distance:  tensor(1.4171, dtype=torch.float64)\n",
      "Step:  36 Action:  34 Distance:  tensor(1.3541, dtype=torch.float64)\n",
      "36 []\n",
      "Step:  37 Action:  0 Distance:  tensor(1.6297, dtype=torch.float64)\n",
      "Step:  37 Action:  5 Distance:  tensor(1.3586, dtype=torch.float64)\n",
      "Step:  37 Action:  8 Distance:  tensor(1.3157, dtype=torch.float64)\n",
      "Step:  37 Action:  13 Distance:  tensor(1.6391, dtype=torch.float64)\n",
      "Step:  37 Action:  18 Distance:  tensor(1.3957, dtype=torch.float64)\n",
      "Step:  37 Action:  21 Distance:  tensor(1.4311, dtype=torch.float64)\n",
      "Step:  37 Action:  26 Distance:  tensor(1.4701, dtype=torch.float64)\n",
      "Step:  37 Action:  34 Distance:  tensor(1.4513, dtype=torch.float64)\n",
      "37 []\n",
      "Step:  38 Action:  0 Distance:  tensor(1.5064, dtype=torch.float64)\n",
      "Step:  38 Action:  5 Distance:  tensor(1.2675, dtype=torch.float64)\n",
      "Step:  38 Action:  8 Distance:  tensor(1.2816, dtype=torch.float64)\n",
      "Step:  38 Action:  13 Distance:  tensor(1.6227, dtype=torch.float64)\n",
      "Step:  38 Action:  18 Distance:  tensor(1.3224, dtype=torch.float64)\n",
      "Step:  38 Action:  21 Distance:  tensor(1.4697, dtype=torch.float64)\n",
      "Step:  38 Action:  26 Distance:  tensor(1.4794, dtype=torch.float64)\n",
      "Step:  38 Action:  34 Distance:  tensor(1.5213, dtype=torch.float64)\n",
      "Step:  38 Action:  47 Distance:  tensor(1.2133, dtype=torch.float64)\n",
      "38 []\n",
      "Step:  39 Action:  0 Distance:  tensor(1.5209, dtype=torch.float64)\n",
      "Step:  39 Action:  5 Distance:  tensor(1.2129, dtype=torch.float64)\n",
      "Step:  39 Action:  8 Distance:  tensor(1.3191, dtype=torch.float64)\n",
      "Step:  39 Action:  13 Distance:  tensor(1.5965, dtype=torch.float64)\n",
      "Step:  39 Action:  18 Distance:  tensor(1.2075, dtype=torch.float64)\n",
      "Step:  39 Action:  21 Distance:  tensor(1.5323, dtype=torch.float64)\n",
      "Step:  39 Action:  26 Distance:  tensor(1.4036, dtype=torch.float64)\n",
      "Step:  39 Action:  34 Distance:  tensor(1.5428, dtype=torch.float64)\n",
      "39 []\n",
      "Step:  40 Action:  0 Distance:  tensor(1.5209, dtype=torch.float64)\n",
      "Step:  40 Action:  5 Distance:  tensor(1.2129, dtype=torch.float64)\n",
      "Step:  40 Action:  8 Distance:  tensor(1.3191, dtype=torch.float64)\n",
      "Step:  40 Action:  13 Distance:  tensor(1.5965, dtype=torch.float64)\n",
      "Step:  40 Action:  18 Distance:  tensor(1.2075, dtype=torch.float64)\n",
      "Step:  40 Action:  21 Distance:  tensor(1.5323, dtype=torch.float64)\n",
      "Step:  40 Action:  26 Distance:  tensor(1.4036, dtype=torch.float64)\n",
      "Step:  40 Action:  34 Distance:  tensor(1.5428, dtype=torch.float64)\n",
      "40 []\n",
      "Step:  41 Action:  0 Distance:  tensor(1.5209, dtype=torch.float64)\n",
      "Step:  41 Action:  5 Distance:  tensor(1.2129, dtype=torch.float64)\n",
      "Step:  41 Action:  8 Distance:  tensor(1.3191, dtype=torch.float64)\n",
      "Step:  41 Action:  13 Distance:  tensor(1.5965, dtype=torch.float64)\n",
      "Step:  41 Action:  18 Distance:  tensor(1.2075, dtype=torch.float64)\n",
      "Step:  41 Action:  21 Distance:  tensor(1.5323, dtype=torch.float64)\n",
      "Step:  41 Action:  26 Distance:  tensor(1.4036, dtype=torch.float64)\n",
      "Step:  41 Action:  34 Distance:  tensor(1.5428, dtype=torch.float64)\n",
      "41 []\n",
      "Step:  42 Action:  0 Distance:  tensor(1.5209, dtype=torch.float64)\n",
      "Step:  42 Action:  5 Distance:  tensor(1.2129, dtype=torch.float64)\n",
      "Step:  42 Action:  8 Distance:  tensor(1.3191, dtype=torch.float64)\n",
      "Step:  42 Action:  13 Distance:  tensor(1.5965, dtype=torch.float64)\n",
      "Step:  42 Action:  18 Distance:  tensor(1.2075, dtype=torch.float64)\n",
      "Step:  42 Action:  21 Distance:  tensor(1.5323, dtype=torch.float64)\n",
      "Step:  42 Action:  26 Distance:  tensor(1.4036, dtype=torch.float64)\n",
      "Step:  42 Action:  34 Distance:  tensor(1.5428, dtype=torch.float64)\n",
      "42 []\n",
      "Step:  43 Action:  0 Distance:  tensor(1.5209, dtype=torch.float64)\n",
      "Step:  43 Action:  5 Distance:  tensor(1.2129, dtype=torch.float64)\n",
      "Step:  43 Action:  8 Distance:  tensor(1.3191, dtype=torch.float64)\n",
      "Step:  43 Action:  13 Distance:  tensor(1.5965, dtype=torch.float64)\n",
      "Step:  43 Action:  18 Distance:  tensor(1.2075, dtype=torch.float64)\n",
      "Step:  43 Action:  21 Distance:  tensor(1.5323, dtype=torch.float64)\n",
      "Step:  43 Action:  26 Distance:  tensor(1.4036, dtype=torch.float64)\n",
      "Step:  43 Action:  34 Distance:  tensor(1.5428, dtype=torch.float64)\n",
      "43 []\n",
      "Step:  44 Action:  0 Distance:  tensor(1.5209, dtype=torch.float64)\n",
      "Step:  44 Action:  5 Distance:  tensor(1.2129, dtype=torch.float64)\n",
      "Step:  44 Action:  8 Distance:  tensor(1.3191, dtype=torch.float64)\n",
      "Step:  44 Action:  13 Distance:  tensor(1.5965, dtype=torch.float64)\n",
      "Step:  44 Action:  18 Distance:  tensor(1.2075, dtype=torch.float64)\n",
      "Step:  44 Action:  21 Distance:  tensor(1.5323, dtype=torch.float64)\n",
      "Step:  44 Action:  26 Distance:  tensor(1.4036, dtype=torch.float64)\n",
      "Step:  44 Action:  34 Distance:  tensor(1.5428, dtype=torch.float64)\n",
      "44 []\n",
      "Step:  45 Action:  0 Distance:  tensor(1.5209, dtype=torch.float64)\n",
      "Step:  45 Action:  5 Distance:  tensor(1.2129, dtype=torch.float64)\n",
      "Step:  45 Action:  8 Distance:  tensor(1.3191, dtype=torch.float64)\n",
      "Step:  45 Action:  13 Distance:  tensor(1.5965, dtype=torch.float64)\n",
      "Step:  45 Action:  18 Distance:  tensor(1.2075, dtype=torch.float64)\n",
      "Step:  45 Action:  21 Distance:  tensor(1.5323, dtype=torch.float64)\n",
      "Step:  45 Action:  26 Distance:  tensor(1.4036, dtype=torch.float64)\n",
      "Step:  45 Action:  34 Distance:  tensor(1.5428, dtype=torch.float64)\n",
      "45 []\n",
      "Step:  46 Action:  0 Distance:  tensor(1.5209, dtype=torch.float64)\n",
      "Step:  46 Action:  5 Distance:  tensor(1.2129, dtype=torch.float64)\n",
      "Step:  46 Action:  8 Distance:  tensor(1.3191, dtype=torch.float64)\n",
      "Step:  46 Action:  13 Distance:  tensor(1.5965, dtype=torch.float64)\n",
      "Step:  46 Action:  18 Distance:  tensor(1.2075, dtype=torch.float64)\n",
      "Step:  46 Action:  21 Distance:  tensor(1.5323, dtype=torch.float64)\n",
      "Step:  46 Action:  26 Distance:  tensor(1.4036, dtype=torch.float64)\n",
      "Step:  46 Action:  34 Distance:  tensor(1.5428, dtype=torch.float64)\n",
      "46 []\n",
      "Step:  47 Action:  0 Distance:  tensor(1.5209, dtype=torch.float64)\n",
      "Step:  47 Action:  8 Distance:  tensor(1.2639, dtype=torch.float64)\n",
      "Step:  47 Action:  13 Distance:  tensor(1.5583, dtype=torch.float64)\n",
      "Step:  47 Action:  21 Distance:  tensor(1.5480, dtype=torch.float64)\n",
      "Step:  47 Action:  26 Distance:  tensor(1.3944, dtype=torch.float64)\n",
      "Step:  47 Action:  34 Distance:  tensor(1.5913, dtype=torch.float64)\n",
      "Step:  47 Action:  42 Distance:  tensor(1.2956, dtype=torch.float64)\n",
      "Step:  47 Action:  47 Distance:  tensor(1.2660, dtype=torch.float64)\n",
      "47 []\n",
      "Step:  48 Action:  0 Distance:  tensor(1.3885, dtype=torch.float64)\n",
      "Step:  48 Action:  8 Distance:  tensor(1.2964, dtype=torch.float64)\n",
      "Step:  48 Action:  13 Distance:  tensor(1.5198, dtype=torch.float64)\n",
      "Step:  48 Action:  21 Distance:  tensor(1.5907, dtype=torch.float64)\n",
      "Step:  48 Action:  26 Distance:  tensor(1.3027, dtype=torch.float64)\n",
      "Step:  48 Action:  29 Distance:  tensor(1.2582, dtype=torch.float64)\n",
      "Step:  48 Action:  34 Distance:  tensor(1.5862, dtype=torch.float64)\n",
      "Step:  48 Action:  42 Distance:  tensor(1.3674, dtype=torch.float64)\n",
      "Step:  48 Action:  47 Distance:  tensor(1.2157, dtype=torch.float64)\n",
      "48 []\n",
      "Step:  49 Action:  0 Distance:  tensor(1.5321, dtype=torch.float64)\n",
      "Step:  49 Action:  8 Distance:  tensor(1.3821, dtype=torch.float64)\n",
      "Step:  49 Action:  13 Distance:  tensor(1.5176, dtype=torch.float64)\n",
      "Step:  49 Action:  21 Distance:  tensor(1.6158, dtype=torch.float64)\n",
      "Step:  49 Action:  26 Distance:  tensor(1.2182, dtype=torch.float64)\n",
      "Step:  49 Action:  29 Distance:  tensor(1.3106, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  49 Action:  34 Distance:  tensor(1.5309, dtype=torch.float64)\n",
      "Step:  49 Action:  42 Distance:  tensor(1.3322, dtype=torch.float64)\n",
      "49 []\n",
      "Step:  50 Action:  0 Distance:  tensor(1.5322, dtype=torch.float64)\n",
      "Step:  50 Action:  8 Distance:  tensor(1.3821, dtype=torch.float64)\n",
      "Step:  50 Action:  13 Distance:  tensor(1.5176, dtype=torch.float64)\n",
      "Step:  50 Action:  21 Distance:  tensor(1.6158, dtype=torch.float64)\n",
      "Step:  50 Action:  26 Distance:  tensor(1.2182, dtype=torch.float64)\n",
      "Step:  50 Action:  29 Distance:  tensor(1.3106, dtype=torch.float64)\n",
      "Step:  50 Action:  34 Distance:  tensor(1.5309, dtype=torch.float64)\n",
      "Step:  50 Action:  42 Distance:  tensor(1.3322, dtype=torch.float64)\n",
      "50 []\n",
      "Step:  51 Action:  0 Distance:  tensor(1.5321, dtype=torch.float64)\n",
      "Step:  51 Action:  5 Distance:  tensor(1.2367, dtype=torch.float64)\n",
      "Step:  51 Action:  8 Distance:  tensor(1.4490, dtype=torch.float64)\n",
      "Step:  51 Action:  13 Distance:  tensor(1.5675, dtype=torch.float64)\n",
      "Step:  51 Action:  21 Distance:  tensor(1.6079, dtype=torch.float64)\n",
      "Step:  51 Action:  26 Distance:  tensor(1.2407, dtype=torch.float64)\n",
      "Step:  51 Action:  29 Distance:  tensor(1.2570, dtype=torch.float64)\n",
      "Step:  51 Action:  34 Distance:  tensor(1.4905, dtype=torch.float64)\n",
      "Step:  51 Action:  42 Distance:  tensor(1.2329, dtype=torch.float64)\n",
      "51 []\n",
      "Step:  52 Action:  0 Distance:  tensor(1.6565, dtype=torch.float64)\n",
      "Step:  52 Action:  5 Distance:  tensor(1.3360, dtype=torch.float64)\n",
      "Step:  52 Action:  8 Distance:  tensor(1.4893, dtype=torch.float64)\n",
      "Step:  52 Action:  13 Distance:  tensor(1.5909, dtype=torch.float64)\n",
      "Step:  52 Action:  21 Distance:  tensor(1.5736, dtype=torch.float64)\n",
      "Step:  52 Action:  26 Distance:  tensor(1.2366, dtype=torch.float64)\n",
      "Step:  52 Action:  34 Distance:  tensor(1.4237, dtype=torch.float64)\n",
      "52 []\n",
      "Step:  53 Action:  0 Distance:  tensor(1.6565, dtype=torch.float64)\n",
      "Step:  53 Action:  5 Distance:  tensor(1.3360, dtype=torch.float64)\n",
      "Step:  53 Action:  8 Distance:  tensor(1.4893, dtype=torch.float64)\n",
      "Step:  53 Action:  13 Distance:  tensor(1.5909, dtype=torch.float64)\n",
      "Step:  53 Action:  21 Distance:  tensor(1.5736, dtype=torch.float64)\n",
      "Step:  53 Action:  26 Distance:  tensor(1.2366, dtype=torch.float64)\n",
      "Step:  53 Action:  34 Distance:  tensor(1.4237, dtype=torch.float64)\n",
      "53 []\n",
      "Step:  54 Action:  0 Distance:  tensor(1.6565, dtype=torch.float64)\n",
      "Step:  54 Action:  5 Distance:  tensor(1.4373, dtype=torch.float64)\n",
      "Step:  54 Action:  8 Distance:  tensor(1.5157, dtype=torch.float64)\n",
      "Step:  54 Action:  13 Distance:  tensor(1.6149, dtype=torch.float64)\n",
      "Step:  54 Action:  18 Distance:  tensor(1.2637, dtype=torch.float64)\n",
      "Step:  54 Action:  21 Distance:  tensor(1.5260, dtype=torch.float64)\n",
      "Step:  54 Action:  26 Distance:  tensor(1.2495, dtype=torch.float64)\n",
      "Step:  54 Action:  34 Distance:  tensor(1.3568, dtype=torch.float64)\n",
      "54 []\n",
      "Step:  55 Action:  0 Distance:  tensor(1.7441, dtype=torch.float64)\n",
      "Step:  55 Action:  5 Distance:  tensor(1.5640, dtype=torch.float64)\n",
      "Step:  55 Action:  8 Distance:  tensor(1.5016, dtype=torch.float64)\n",
      "Step:  55 Action:  13 Distance:  tensor(1.5992, dtype=torch.float64)\n",
      "Step:  55 Action:  18 Distance:  tensor(1.3915, dtype=torch.float64)\n",
      "Step:  55 Action:  21 Distance:  tensor(1.3772, dtype=torch.float64)\n",
      "Step:  55 Action:  26 Distance:  tensor(1.2197, dtype=torch.float64)\n",
      "55 []\n",
      "Step:  56 Action:  0 Distance:  tensor(1.7894, dtype=torch.float64)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 58 is out of bounds for dimension 0 with size 58",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-a7dce26ea5fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mz\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTractographyState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreferenceLine\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolateDWIatState\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstepCounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m#if reward == -1:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fibre_tracking/deepFibreTracking/dfibert/envs/RLtractEnvironment.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;31m#else:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m#    rewardNextState = rewardDistance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mrewardNextState\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewardForState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnextState\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;31m#if rewardNextState < 0.:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;31m#    rewardNextState = -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fibre_tracking/deepFibreTracking/dfibert/envs/RLtractEnvironment.py\u001b[0m in \u001b[0;36mrewardForState\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mqry_pt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetCoordinate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;31m#distance = torch.min(torch.sum( (self.referenceStreamline_ijk[np.max([self.stepCounter-1-2,0]):np.min([self.stepCounter-1+1,self.maxSteps])] - qry_pt)**2, dim =1 ))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0mdistance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreferenceStreamline_ijk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstepCounter\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m86\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mqry_pt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0;31m#reward = torch.tanh(-distance+5.3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdistance\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 58 is out of bounds for dimension 0 with size 58"
     ]
    }
   ],
   "source": [
    "possible_actions = []\n",
    "past_state = env.reset()\n",
    "all_next_states = []\n",
    "for i in range(len(referenceLine)):\n",
    "    best_actions = []\n",
    "    next_states = []\n",
    "    for z in range(n_actions):\n",
    "        env.state = TractographyState(referenceLine[i], env.interpolateDWIatState)\n",
    "        next_state, reward, _ = env.step(z)\n",
    "        env.stepCounter = i\n",
    "        #if reward == -1:\n",
    "        #    reward = 0\n",
    "        #elif reward < 0.2:\n",
    "        if reward > 1.0:\n",
    "            print(\"Step: \", i, \"Action: \", z, \"Distance: \", reward)\n",
    "        #    reward = 1\n",
    "        #elif reward < 1.:\n",
    "        #    reward = 0\n",
    "        #else:\n",
    "        #    reward = -1\n",
    "        #if reward == 1:\n",
    "        #    best_actions.append(z)\n",
    "            #print(i, z, referenceLine[i].numpy(), next_state.getCoordinate().numpy(), reward)\n",
    "    print(i, best_actions)\n",
    "    #print(i, reward)\n",
    "    #if reward > 0.9:\n",
    "    #    best_actions.append(i)\n",
    "    possible_actions.append(best_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_distance = []\n",
    "optimal_steps = []#[100, 80, 75, 80, 75, 100, 62, 75, 83, 75, 83, 100, 83, 62, 67, 51, 67, 100, 59, 59, 59, 100, 59, 56, 51, 56, 66, 100, 66, 71, 71, 79, 58, 100, 71, 71, 84, 71, 100, 92, 84, 92, 97, 100, 97, 38, 97, 43, 38, 100, 43, 43, 89, 48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n"
     ]
    }
   ],
   "source": [
    "last_state = env.reset()\n",
    "print(len(env.referenceStreamline_ijk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "[80, 88, 67, 75, 75, 62, 75, 83, 75, 83, 83, 83, 62, 67, 67, 54, 59, 59, 59, 59, 59, 59, 51, 56, 51, 56, 66, 66, 79, 71, 71, 66, 71, 71, 71, 71, 71, 84, 92, 84, 84, 92, 97, 97, 38, 97, 97, 38, 43, 43, 38, 35, 89, 48, 48, 73, 94, 35, 89, 43, 35, 22, 35, 35, 14, 14, 11, 3, 3, 16, 16, 21, 16, 21, 21, 34, 26, 47, 26, 39, 93, 39, 72, 72, 77, 77, 100]\n"
     ]
    }
   ],
   "source": [
    "steps = 0\n",
    "while len(optimal_steps) < 87:\n",
    "    step_distance = []\n",
    "    for i in range(n_actions):\n",
    "        env.reset()\n",
    "        if len(optimal_steps)>0:\n",
    "            for z in range(len(optimal_steps)):\n",
    "                _,_,_ = env.step(optimal_steps[z])\n",
    "        next_state, _, terminal = env.step(i)\n",
    "        #distance = lineseg_dist(next_state.getCoordinate().numpy(), referenceLine[np.min([len(optimal_steps), 85])].numpy(), referenceLine[np.min([len(optimal_steps)+1, len(referenceLine)-1])].numpy())\n",
    "        #distance = ((next_state.getCoordinate()[0] - env.referenceStreamline_ijk[np.min([env.stepCounter, 58])][0])**2 \\\n",
    "        #              + (next_state.getCoordinate()[1] - env.referenceStreamline_ijk[np.min([env.stepCounter, 58])][1])**2 \\\n",
    "        #              + (next_state.getCoordinate()[2] - env.referenceStreamline_ijk[np.min([env.stepCounter, 58])][2])**2)\n",
    "        current_index = np.min([env.stepCounter, len(env.referenceStreamline_ijk)-1])\n",
    "        qry_pt = next_state.getCoordinate().view(-1,3)\n",
    "        distance = torch.sum((env.referenceStreamline_ijk[current_index] - qry_pt)**2)\n",
    "        \n",
    "        step_distance.append(distance)\n",
    "    optimal_steps.append(np.argmin(step_distance))\n",
    "print(optimal_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streamline index 0, stepWidth 0.81\n",
    "optimal_steps = [80, 88, 67, 75, 75, 62, 75, 83, 75, 83, 83, 83, 62, 67, 67, 54, 59, 59, 59, 59, 59, 59, 51, 56, 51, 56, 66, 66, 79, 71, 71, 66, 71, 71, 71, 71, 71, 84, 92, 84, 84, 92, 97, 97, 38, 97, 97, 38, 43, 43, 38, 35, 89, 48, 48, 73, 94, 35, 89, 43, 35, 22, 35, 35, 14, 14, 11, 3, 3, 16, 16, 21, 16, 21, 21, 34, 26, 47, 26, 39, 93, 39, 72, 72, 77, 77, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streamline index 4, stepWidth 0.81\n",
    "optimal_steps = [17, 30, 17, 30, 17, 30, 17, 1, 6, 3, 3, 3, 11, 16, 16, 24, 16, 24, 37, 24, 91, 45, 78, 78, 86, 99, 86, 86, 86, 70, 70, 65, 70, 65, 86, 65, 86, 99, 99, 40, 45, 45, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streamline index 4, stepWidth 0.79\n",
    "#optimal_steps =[17, 30, 17, 30, 17, 30, 17, 1, 6, 3, 3, 3, 11, 16, 16, 16, 24, 24, 24, 37, 24, 91, 78, 78, 99, 86, 86, 86, 86, 86, 70, 70, 70, 65, 65, 86, 86, 86, 99, 99, 99, 45, 99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streamline index 4, stepWidth 0.78\n",
    "#optimal_steps = [17, 30, 17, 30, 17, 30, 17, 1, 6, 1, 3, 11, 3, 16, 16, 24, 16, 24, 24, 37, 37, 45, 78, 78, 99, 86, 86, 78, 86, 86, 78, 70, 65, 65, 65, 86, 86, 86, 99, 99, 99, 45, 78]\n",
    "print(optimal_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17, 30, 17, 30, 17, 30, 17, 1, 6, 3, 3, 3, 11, 16, 16, 16, 24, 24, 37, 24, 37, 78, 45, 78, 86, 86, 86, 86, 86, 78, 70, 65, 70, 65, 86, 65, 86, 86, 99, 32, 99, 45]\n"
     ]
    }
   ],
   "source": [
    "# Streamline index 4, stepWidth 0.8\n",
    "#optimal_steps = [17, 30, 17, 30, 17, 30, 17, 1, 6, 3, 3, 3, 11, 16, 16, 16, 24, 24, 37, 24, 37, 78, 45, 78, 86, 86, 86, 86, 86, 78, 70, 65, 70, 65, 86, 65, 86, 86, 99, 32, 99, 45]\n",
    "print(optimal_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streamline index 2\n",
    "optimal_steps = [3, 3, 100, 6, 3, 11, 3, 6, 100, 11, 6, 11, 3, 100, 19, 3, 11, 6, 16, 100, 3, 3, 3, 2, 11, 7, 18, 100, 15, 7, 2, 2, 100, 0, 10, 0, 2, 0, 100, 0, 0, 3, 0, 11, 100, 3, 3, 3, 3, 100, 3, 3, 1, 11, 100, 3, 3, 3, 16, 11, 100, 16, 29, 16, 42, 100, 21, 29, 21, 42, 21, 100, 34, 21, 13, 26, 100, 23, 18, 23, 31, 100, 44, 31, 31, 44, 44, 100, 44, 31, 36, 98, 15, 100, 23, 23, 44, 15, 44, 100, 15, 28, 15, 20, 36, 100, 20, 28, 20, 20, 100, 28, 28, 36, 49, 28, 100, 36, 49, 49, 90, 100, 49, 95, 95, 49, 46, 49, 38, 36, 25, 100, 28, 28, 33, 36, 41, 100, 20, 28, 12, 20, 20, 100, 7, 15, 7, 20, 10, 25, 100]\n",
    "#print(optimal_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Streamline with len 44 (index 4)\n",
    "#print(optimal_steps)\n",
    "optimal_steps = [17, 30, 100, 17, 30, 17, 17, 6, 0, 17, 37, 0, 0, 78, 24, 16, 24, 24, 100, 37, 45, 45, 70, 100, 99, 86, 86, 78, 94, 62, 100, 65, 70, 86, 65, 100, 86, 94, 99, 45, 99, 100, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with line distance\n",
    "#optimal_steps = [80, 88, 54, 96, 46, 75, 75, 75, 83, 75, 83, 83, 62, 54, 1, 59, 54, 59, 59, 67, 56, 59, 51, 59, 61, 11, 53, 61, 66, 71, 71, 79, 58, 71, 71, 71, 21, 71, 84, 92, 84, 92, 97, 84, 43, 84, 30, 97, 47, 97, 43, 30, 89, 35, 94, 73, 48, 89, 22, 72, 43, 35, 22, 35, 35, 6, 19, 3, 16, 16, 66, 16, 8, 21, 29, 21, 26, 26, 93, 26, 93, 85, 35, 85, 72, 77, 100]\n",
    "optimal_steps = [100, 80, 75, 80, 75, 100, 62, 75, 83, 75, 83, 100, 83, 62, 67, 51, 67, 100, 59, 59, 59, 100, 59, 56, 51, 56, 66, 100, 66, 71, 71, 79, 58, 100, 71, 71, 84, 71, 100, 92, 84, 92, 97, 100, 97, 38, 97, 43, 38, 100, 43, 43, 89, 48, 100, 94, 81, 48, 43, 100, 35, 43, 35, 22, 27, 100, 6, 11, 3, 16, 100, 8, 29, 21, 21, 100, 34, 26, 26, 93, 39, 100, 93, 72, 77, 77, 101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimal_steps = [80, 75, 80, 75, 62, 75, 83, 96, 51, 24, 62, 62, 62, 77, 65, 64, 67, 59, 56, 83, 82, 54, 56, 53, 56, 38, 56, 84, 66, 71, 71, 64, 97, 84, 71, 71, 38, 51, 30, 92, 97, 84, 43, 79, 27, 46, 89, 25, 81, 25, 48, 43, 86, 48, 57, 14, 89, 43, 43, 19, 92, 14, 27, 9, 78, 4, 16, 3, 29, 3, 47, 6, 42, 21, 39, 5, 72, 34, 98, 88, 90, 75, 77, 59, 49, 32, 82]\n",
    "print(optimal_steps) # <-- min of max distance reward streamline 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[80, 75, 80, 75, 62, 75, 83, 96, 51, 24, 62, 62, 62, 77, 65, 64, 67, 59, 56, 83, 82, 54, 56, 53, 56, 38, 56, 84, 66, 71, 71, 64, 97, 84, 71, 71, 38, 51, 30, 92, 97, 84, 43, 79, 27, 46, 89, 25, 81, 25, 48, 43, 86, 48, 57, 14, 89, 43, 43, 19, 92, 14, 27, 9, 78, 4, 16, 3, 29, 3, 47, 6, 42, 21, 39, 5, 72, 34, 98, 88, 90, 75, 77, 59, 49, 32, 82]\n"
     ]
    }
   ],
   "source": [
    "optimal_steps = [80, 75, 80, 75, 62, 75, 83, 96, 51, 24, 62, 62, 62, 77, 65, 64, 67, 59, 56, 83, 82, 54, 56, 53, 56, 38, 56, 84, 66, 71, 71, 64, 97, 84, 71, 71, 38, 51, 30, 92, 97, 84, 43, 79, 27, 46, 89, 25, 81, 25, 48, 43, 86, 48, 57, 14, 89, 43, 43, 19, 92, 14, 27, 9, 78, 4, 16, 3, 29, 3, 47, 6, 42, 21, 39, 5, 72, 34, 98, 88, 90, 75, 77, 59, 49, 32, 82]\n",
    "print(optimal_steps) # <-- min of max distance reward streamline 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[80, 88, 54, 96, 59, 37, 54, 37, 67, 91, 62, 78, 64, 70, 64, 62, 69, 83, 56, 59, 59, 53, 42, 53, 53, 56, 79, 58, 87, 60, 87, 58, 92, 52, 46, 58, 38, 58, 30, 58, 38, 84, 17, 55, 30, 76, 25, 76, 17, 76, 17, 81, 30, 86, 48, 65, 27, 97, 14, 84, 6, 97, 14, 89, 3, 27, 8, 19, 13, 19, 13, 29, 8, 96, 2, 88, 31, 47, 26, 59, 5, 72, 72, 85, 61, 39]\n"
     ]
    }
   ],
   "source": [
    "optimal_steps = [80, 88, 54, 96, 59, 37, 54, 37, 67, 91, 62, 78, 64, 70, 64, 62, 69, 83, 56, 59, 59, 53, 42, 53, 53, 56, 79, 58, 87, 60, 87, 58, 92, 52, 46, 58, 38, 58, 30, 58, 38, 84, 17, 55, 30, 76, 25, 76, 17, 76, 17, 81, 30, 86, 48, 65, 27, 97, 14, 84, 6, 97, 14, 89, 3, 27, 8, 19, 13, 19, 13, 29, 8, 96, 2, 88, 31, 47, 26, 59, 5, 72, 72, 85, 61, 39]\n",
    "print(optimal_steps) # <-- min reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change optimal steps\n",
    "optimal_steps = [17, 30, 100, 17, 30, 17, 17, 6, 0, 6, 0, 0, 0, 78, 24, 16, 24, 24, 100, 37, 45, 45, 70, 100, 99, 86, 86, 78, 94, 62, 100, 65, 70, 86, 65, 100, 86, 94, 99, 45, 99, 100, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 73.651344 107.88106   93.29415 ] tensor([ 73.6513, 107.8811,  93.2942])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'optimal_steps' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-fc460226c6be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mlen_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreferenceStreamline_ijk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mall_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetCoordinate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimal_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#print(step, reward)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'optimal_steps' is not defined"
     ]
    }
   ],
   "source": [
    "state = env.reset()\n",
    "print(env.state.getCoordinate().numpy(), env.referenceStreamline_ijk[0])\n",
    "step = 1\n",
    "all_distances = []\n",
    "all_states = []\n",
    "len_line = len(env.referenceStreamline_ijk)-1\n",
    "all_states.append(state.getCoordinate())\n",
    "for i in optimal_steps:\n",
    "    next_state, reward, terminal = env.step(i)\n",
    "    #print(step, reward)\n",
    "    #current_index = np.min([env.points_visited+1,len(env.referenceStreamline_ijk)-1])\n",
    "    #print(\"Reference Line at current index: \", env.referenceStreamline_ijk[current_index])\n",
    "    #distance = lineseg_dist(next_state.getCoordinate().numpy(), referenceLine[step-1].numpy(), referenceLine[np.min([step, len(referenceLine)-1])].numpy())\n",
    "    #distance = 2 + (distance/10)\n",
    "    #distance = ((next_state.getCoordinate()[0] - env.referenceStreamline_ijk[np.min([env.stepCounter, len_line])][0])**2 \\\n",
    "    #                  + (next_state.getCoordinate()[1] - env.referenceStreamline_ijk[np.min([env.stepCounter, len_line])][1])**2 \\\n",
    "    #                  + (next_state.getCoordinate()[2] - env.referenceStreamline_ijk[np.min([env.stepCounter, len_line])][2])**2)\n",
    "    current_index = np.min([env.stepCounter, len(env.referenceStreamline_ijk)-1])\n",
    "    qry_pt = next_state.getCoordinate().view(-1,3)\n",
    "    distance = torch.sum((env.referenceStreamline_ijk[current_index] - qry_pt)**2)\n",
    "    \n",
    "    print(step, i, next_state.getCoordinate().numpy(), env.referenceStreamline_ijk[np.min([env.stepCounter,len_line])].numpy(), reward, -distance.item())\n",
    "    all_distances.append(distance)\n",
    "    all_states.append(next_state.getCoordinate())\n",
    "    #if distance < 0.71:\n",
    "    #    reward = 1 - distance\n",
    "    #    #print(reward)\n",
    "    #    if reward < 0.3:\n",
    "    #        reward = 1\n",
    "    step += 1\n",
    "\n",
    "print(np.min(all_distances), np.max(all_distances), np.sum(all_distances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 76.4527, 108.1185,  91.8665])\n",
      "tensor(108.1185)\n"
     ]
    }
   ],
   "source": [
    "print(env.referenceStreamline_ijk[4])\n",
    "print(env.referenceStreamline_ijk.T[1][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reset to streamline 3/5\n"
     ]
    }
   ],
   "source": [
    "state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([74.9079, 68.6542,  6.6088]) tensor([74.9079, 68.6542,  6.6088])\n",
      "tensor([75.0515, 68.9644,  7.3432], dtype=torch.float64) tensor([75.0415, 68.9379,  7.3448])\n",
      "tensor([75.1951, 69.2746,  8.0775], dtype=torch.float64) tensor([75.1012, 69.2937,  8.0589])\n",
      "tensor([75.0732, 69.6984,  8.7569], dtype=torch.float64) tensor([75.1610, 69.6495,  8.7729])\n",
      "tensor([75.2168, 70.0086,  9.4913], dtype=torch.float64) tensor([75.2207, 70.0053,  9.4869])\n",
      "tensor([75.3605, 70.3188, 10.2256], dtype=torch.float64) tensor([75.3279, 70.4488, 10.1440])\n",
      "tensor([75.5249, 70.8786, 10.7874], dtype=torch.float64) tensor([75.4352, 70.8923, 10.8012])\n",
      "tensor([75.4030, 71.3025, 11.4668], dtype=torch.float64) tensor([75.4949, 71.2481, 11.5152])\n",
      "tensor([75.5466, 71.6127, 12.2012], dtype=torch.float64) tensor([75.6022, 71.6915, 12.1723])\n",
      "tensor([75.6902, 71.9229, 12.9355], dtype=torch.float64) tensor([75.6619, 72.0473, 12.8864])\n",
      "tensor([75.5988, 72.5737, 13.4090], dtype=torch.float64) tensor([75.6980, 72.5632, 13.4967])\n",
      "tensor([75.7633, 73.1335, 13.9709], dtype=torch.float64) tensor([75.7341, 73.0791, 14.1071])\n",
      "tensor([75.6413, 73.5573, 14.6503], dtype=torch.float64) tensor([75.7701, 73.5950, 14.7175])\n",
      "tensor([75.8058, 74.1171, 15.2121], dtype=torch.float64) tensor([75.8062, 74.1109, 15.3278])\n",
      "tensor([75.6839, 74.5409, 15.8915], dtype=torch.float64) tensor([75.8422, 74.6268, 15.9382])\n",
      "tensor([75.8483, 75.1007, 16.4534], dtype=torch.float64) tensor([75.8783, 75.1427, 16.5486])\n",
      "tensor([75.9920, 75.4109, 17.1877], dtype=torch.float64) tensor([75.9855, 75.5862, 17.2057])\n",
      "tensor([76.1564, 75.9707, 17.7496], dtype=torch.float64) tensor([76.0928, 76.0297, 17.8629])\n",
      "tensor([76.0345, 76.3946, 18.4290], dtype=torch.float64) tensor([76.2000, 76.4732, 18.5200])\n",
      "tensor([76.4324, 76.7621, 19.0312], dtype=torch.float64) tensor([76.4056, 76.9388, 19.1372])\n",
      "tensor([76.5760, 77.0723, 19.7656], dtype=torch.float64) tensor([76.5868, 77.3026, 19.8263])\n",
      "tensor([76.7196, 77.3824, 20.4999], dtype=torch.float64) tensor([76.7203, 77.5862, 20.5623])\n",
      "tensor([76.8633, 77.6926, 21.2343], dtype=torch.float64) tensor([76.8539, 77.8699, 21.2983])\n",
      "tensor([77.0069, 78.0028, 21.9686], dtype=torch.float64) tensor([76.9996, 78.0494, 22.0641])\n",
      "tensor([76.8952, 78.1343, 22.7600], dtype=torch.float64) tensor([77.0545, 78.1756, 22.8522])\n",
      "tensor([77.0638, 78.1613, 23.5518], dtype=torch.float64) tensor([77.1093, 78.3018, 23.6403])\n",
      "tensor([77.2325, 78.1883, 24.3436], dtype=torch.float64) tensor([77.1743, 78.3133, 24.4375])\n",
      "tensor([77.2174, 78.0002, 25.1313], dtype=torch.float64) tensor([77.2496, 77.9811, 25.1614])\n",
      "tensor([77.3647, 77.5814, 25.8088], dtype=torch.float64) tensor([77.3263, 77.4440, 25.7493])\n",
      "tensor([77.3177, 76.9954, 26.3661], dtype=torch.float64) tensor([77.4029, 76.9069, 26.3372])\n",
      "tensor([77.4650, 76.5766, 27.0435], dtype=torch.float64) tensor([77.2996, 76.5694, 27.0552])\n",
      "tensor([77.1535, 76.4929, 27.7865], dtype=torch.float64) tensor([77.1912, 76.3470, 27.8160])\n",
      "tensor([77.1384, 76.3048, 28.5742], dtype=torch.float64) tensor([77.1715, 76.1842, 28.5990])\n",
      "tensor([77.2857, 75.8860, 29.2517], dtype=torch.float64) tensor([77.2455, 75.9670, 29.3653])\n",
      "tensor([77.4544, 75.9130, 30.0435], dtype=torch.float64) tensor([77.4148, 75.8119, 30.1317])\n",
      "tensor([77.4393, 75.7248, 30.8312], dtype=torch.float64) tensor([77.5840, 75.6568, 30.8980])\n",
      "tensor([77.7739, 75.5189, 31.5395], dtype=torch.float64) tensor([77.6571, 75.5543, 31.6881])\n",
      "tensor([77.9426, 75.5459, 32.3313], dtype=torch.float64) tensor([77.8233, 75.5124, 32.4695])\n",
      "tensor([77.9275, 75.3577, 33.1190], dtype=torch.float64) tensor([77.9895, 75.4705, 33.2509])\n",
      "tensor([78.0961, 75.3848, 33.9108], dtype=torch.float64) tensor([78.1556, 75.4286, 34.0324])\n",
      "tensor([78.2648, 75.4118, 34.7026], dtype=torch.float64) tensor([78.3218, 75.3867, 34.8138])\n",
      "tensor([78.4335, 75.4388, 35.4944], dtype=torch.float64) tensor([78.4792, 75.4569, 35.5950])\n",
      "tensor([78.5771, 75.7490, 36.2287], dtype=torch.float64) tensor([78.6250, 75.6365, 36.3608])\n",
      "tensor([78.7458, 75.7760, 37.0205], dtype=torch.float64) tensor([78.7585, 75.9202, 37.0968])\n",
      "tensor([78.8894, 76.0862, 37.7548], dtype=torch.float64) tensor([78.8921, 76.2038, 37.8328])\n",
      "tensor([79.0330, 76.3964, 38.4892], dtype=torch.float64) tensor([79.0733, 76.5676, 38.5219])\n",
      "tensor([79.1975, 76.9562, 39.0510], dtype=torch.float64) tensor([79.2544, 76.9314, 39.2110])\n",
      "tensor([79.3411, 77.2664, 39.7853], dtype=torch.float64) tensor([79.4356, 77.2952, 39.9001])\n",
      "tensor([79.4847, 77.5766, 40.5197], dtype=torch.float64) tensor([79.4953, 77.6510, 40.6141])\n",
      "tensor([79.6283, 77.8868, 41.2540], dtype=torch.float64) tensor([79.6289, 77.9347, 41.3501])\n",
      "tensor([79.7720, 78.1970, 41.9883], dtype=torch.float64) tensor([79.7625, 78.2183, 42.0861])\n",
      "tensor([79.9156, 78.5072, 42.7227], dtype=torch.float64) tensor([79.8960, 78.5020, 42.8221])\n",
      "tensor([79.8039, 78.6387, 43.5141], dtype=torch.float64) tensor([79.9359, 78.7429, 43.5840])\n",
      "tensor([79.9475, 78.9489, 44.2484], dtype=torch.float64) tensor([79.9758, 78.9837, 44.3458])\n",
      "tensor([80.0911, 79.2591, 44.9828], dtype=torch.float64) tensor([80.0356, 79.3395, 45.0598])\n",
      "tensor([80.2348, 79.5693, 45.7171], dtype=torch.float64) tensor([80.2167, 79.7033, 45.7489])\n",
      "tensor([80.3992, 80.1291, 46.2789], dtype=torch.float64) tensor([80.3979, 80.0671, 46.4380])\n",
      "tensor([80.5428, 80.4393, 47.0133], dtype=torch.float64) tensor([80.5791, 80.4309, 47.1270])\n",
      "tensor([80.6865, 80.7495, 47.7476], dtype=torch.float64) tensor([80.7602, 80.7947, 47.8161])\n",
      "tensor([80.8509, 81.3093, 48.3095], dtype=torch.float64) tensor([80.9658, 81.2604, 48.4333])\n",
      "tensor([81.2488, 81.6767, 48.9117], dtype=torch.float64) tensor([81.2837, 81.7186, 49.0069])\n",
      "tensor([81.6467, 82.0442, 49.5140], dtype=torch.float64) tensor([81.6016, 82.1768, 49.5804])\n",
      "tensor([82.0446, 82.4117, 50.1163], dtype=torch.float64) tensor([82.0211, 82.6052, 50.1101])\n",
      "tensor([82.4410, 83.0113, 50.4898], dtype=torch.float64) tensor([82.4406, 83.0337, 50.6397])\n",
      "tensor([82.8389, 83.3787, 51.0920], dtype=torch.float64) tensor([82.9928, 83.3187, 51.1434])\n",
      "tensor([83.4771, 83.4912, 51.5781], dtype=torch.float64) tensor([83.6211, 83.5545, 51.5789])\n",
      "tensor([84.0760, 83.8648, 51.9754], dtype=torch.float64) tensor([84.2494, 83.7903, 52.0145])\n",
      "tensor([84.8286, 83.8004, 52.2678], dtype=torch.float64) tensor([84.9416, 83.9694, 52.3732])\n",
      "tensor([85.4275, 84.1740, 52.6651], dtype=torch.float64) tensor([85.6339, 84.1485, 52.7320])\n",
      "tensor([86.0656, 84.2864, 53.1511], dtype=torch.float64) tensor([86.3261, 84.3276, 53.0908])\n",
      "tensor([86.8253, 84.4987, 53.3351], dtype=torch.float64) tensor([87.0183, 84.5068, 53.4496])\n",
      "tensor([87.4635, 84.6111, 53.8212], dtype=torch.float64) tensor([87.6663, 84.6348, 53.9010])\n",
      "tensor([88.2161, 84.5467, 54.1136], dtype=torch.float64) tensor([88.3712, 84.7040, 54.2728])\n",
      "tensor([88.9758, 84.7590, 54.2976], dtype=torch.float64) tensor([89.1131, 84.8213, 54.5483])\n",
      "tensor([89.6139, 84.8715, 54.7837], dtype=torch.float64) tensor([89.8181, 84.8904, 54.9201])\n",
      "tensor([90.1933, 84.6947, 55.3214], dtype=torch.float64) tensor([90.3453, 84.6596, 55.4757])\n",
      "tensor([90.7727, 84.5180, 55.8592], dtype=torch.float64) tensor([90.8480, 84.3259, 56.0010])\n",
      "tensor([91.1989, 84.0752, 56.3869], dtype=torch.float64) tensor([91.2836, 83.8824, 56.5045])\n",
      "tensor([91.6251, 83.6325, 56.9146], dtype=torch.float64) tensor([91.6366, 83.3615, 56.9986])\n",
      "tensor([91.8480, 82.9906, 57.3554], dtype=torch.float64) tensor([91.9971, 82.7743, 57.4050])\n",
      "tensor([92.0709, 82.3487, 57.7963], dtype=torch.float64) tensor([92.2664, 82.1258, 57.7883])\n",
      "tensor([92.5305, 81.7367, 58.0616], dtype=torch.float64) tensor([92.6291, 81.4843, 58.0996])\n",
      "tensor([92.9901, 81.1248, 58.3270], dtype=torch.float64) tensor([92.9918, 80.8427, 58.4109])\n",
      "tensor([93.1874, 80.3549, 58.4830], dtype=torch.float64) tensor([93.3526, 80.1598, 58.6193])\n",
      "tensor([93.6470, 79.7429, 58.7484], dtype=torch.float64) tensor([93.7133, 79.4768, 58.8277])\n",
      "tensor([93.8444, 78.9730, 58.9045], dtype=torch.float64) tensor([94.0740, 78.7938, 59.0361])\n",
      "tensor([94.3039, 78.3610, 59.1698], dtype=torch.float64) tensor([94.3412, 78.0615, 59.2157])\n",
      "tensor([94.5013, 77.5911, 59.3259], dtype=torch.float64) tensor([94.6084, 77.3291, 59.3953])\n",
      "tensor([94.6987, 76.8212, 59.4820], dtype=torch.float64) tensor([94.8756, 76.5968, 59.5749])\n",
      "tensor([94.8960, 76.0513, 59.6380], dtype=torch.float64) tensor([95.1428, 75.8644, 59.7545])\n",
      "tensor([95.3556, 75.4393, 59.9034], dtype=torch.float64) tensor([95.4100, 75.1321, 59.9341])\n",
      "tensor([95.5530, 74.6694, 60.0595], dtype=torch.float64) tensor([95.5819, 74.3928, 60.1869])\n",
      "tensor([95.7759, 74.0275, 60.5003], dtype=torch.float64) tensor([95.8519, 73.6955, 60.4714])\n",
      "tensor([95.9732, 73.2575, 60.6564], dtype=torch.float64) tensor([96.0245, 72.9989, 60.8249])\n",
      "tensor([96.1962, 72.6156, 61.0972], dtype=torch.float64) tensor([96.2938, 72.3504, 61.2082])\n",
      "tensor([96.4191, 71.9737, 61.5381], dtype=torch.float64) tensor([96.4664, 71.6538, 61.5617])\n",
      "tensor([96.3701, 71.2289, 61.8528], dtype=torch.float64) tensor([96.5391, 70.9719, 61.9737])\n",
      "tensor([96.5931, 70.5870, 62.2936], dtype=torch.float64) tensor([96.7118, 70.2753, 62.3272])\n",
      "tensor([96.8160, 69.9451, 62.7344], dtype=torch.float64) tensor([96.7844, 69.5935, 62.7392])\n",
      "tensor([96.7671, 69.2003, 63.0491], dtype=torch.float64) tensor([96.8571, 68.9116, 63.1513])\n",
      "tensor([96.7181, 68.4555, 63.3638], dtype=torch.float64) tensor([96.8297, 68.2003, 63.5164])\n",
      "tensor([96.6692, 67.7108, 63.6785], dtype=torch.float64) tensor([96.7041, 67.5243, 63.9253])\n",
      "tensor([96.6223, 67.1249, 64.2358], dtype=torch.float64) tensor([96.5785, 66.8482, 64.3342])\n",
      "tensor([96.5734, 66.3801, 64.5505], dtype=torch.float64) tensor([96.4529, 66.1722, 64.7431])\n",
      "tensor([96.2485, 65.8134, 65.0295], dtype=torch.float64) tensor([96.2314, 65.5445, 65.1868])\n",
      "tensor([95.9237, 65.2467, 65.5085], dtype=torch.float64) tensor([96.0099, 64.9168, 65.6306])\n",
      "tensor([95.8748, 64.5019, 65.8231], dtype=torch.float64) tensor([95.7884, 64.2891, 66.0744])\n",
      "tensor([95.5499, 63.9352, 66.3021], dtype=torch.float64) tensor([95.4713, 63.6600, 66.4535])\n",
      "tensor([95.2251, 63.3685, 66.7811], dtype=torch.float64) tensor([95.1541, 63.0310, 66.8325])\n",
      "tensor([94.9016, 62.6597, 67.0027], dtype=torch.float64) tensor([94.8370, 62.4019, 67.2116])\n",
      "tensor([94.5768, 62.0930, 67.4816], dtype=torch.float64) tensor([94.5198, 61.7728, 67.5907])\n",
      "tensor([94.2532, 61.3842, 67.7032], dtype=torch.float64) tensor([94.2052, 61.0929, 67.8713])\n",
      "tensor([93.9297, 60.6755, 67.9248], dtype=torch.float64) tensor([93.8905, 60.4131, 68.1519])\n",
      "tensor([93.8808, 59.9307, 68.2394], dtype=torch.float64) tensor([93.6701, 59.6838, 68.3959])\n",
      "tensor([93.5573, 59.2219, 68.4610], dtype=torch.float64) tensor([93.4497, 58.9545, 68.6400])\n",
      "tensor([93.5084, 58.4772, 68.7757], dtype=torch.float64) tensor([93.3240, 58.1902, 68.8402])\n",
      "tensor([93.1849, 57.7684, 68.9973], dtype=torch.float64) tensor([93.1983, 57.4259, 69.0405])\n",
      "tensor([93.1360, 57.0236, 69.3119], dtype=torch.float64) tensor([93.0726, 56.6617, 69.2408])\n",
      "tensor([93.0243, 56.2217, 69.3346], dtype=torch.float64) tensor([92.9469, 55.8974, 69.4410])\n",
      "tensor([92.9126, 55.4197, 69.3572], dtype=torch.float64) tensor([92.8257, 55.1111, 69.5248])\n",
      "tensor([92.8009, 54.6178, 69.3799], dtype=torch.float64) tensor([92.8001, 54.3123, 69.5607])\n",
      "tensor([92.6892, 53.8158, 69.4025], dtype=torch.float64) tensor([92.6942, 53.5203, 69.5218])\n",
      "tensor([92.5775, 53.0139, 69.4252], dtype=torch.float64) tensor([92.5883, 52.7283, 69.4829])\n",
      "tensor([92.4658, 52.2120, 69.4479], dtype=torch.float64) tensor([92.4042, 51.9580, 69.3699])\n",
      "tensor([92.3312, 51.4698, 69.1525], dtype=torch.float64) tensor([92.2202, 51.1877, 69.2568])\n",
      "tensor([91.9594, 50.7573, 69.0518], dtype=torch.float64) tensor([91.9415, 50.4407, 69.1914])\n",
      "tensor([91.6359, 50.0485, 69.2734], dtype=torch.float64) tensor([91.5722, 49.7312, 69.1735])\n",
      "tensor([91.2641, 49.3360, 69.1726], dtype=torch.float64) tensor([91.1155, 49.0750, 69.1997])\n",
      "tensor([90.7106, 48.7541, 69.2781], dtype=torch.float64) tensor([90.5707, 48.4919, 69.2567])\n",
      "tensor([90.1571, 48.1722, 69.3836], dtype=torch.float64) tensor([90.0131, 47.9396, 69.4118])\n",
      "tensor([89.6036, 47.5903, 69.4891], dtype=torch.float64) tensor([89.4481, 47.4342, 69.6674])\n",
      "tensor([89.0415, 47.1288, 69.8457], dtype=torch.float64) tensor([88.9573, 46.8970, 69.9998])\n",
      "tensor([88.7166, 46.5621, 70.3247], dtype=torch.float64) tensor([88.4665, 46.3597, 70.3321])\n",
      "tensor([88.1631, 45.9802, 70.4302], dtype=torch.float64) tensor([88.0605, 45.7443, 70.6426])\n",
      "tensor([87.8396, 45.2714, 70.6518], dtype=torch.float64) tensor([87.6618, 45.0829, 70.8515])\n",
      "tensor([87.5161, 44.5627, 70.8733], dtype=torch.float64) tensor([87.3471, 44.4030, 71.1321])\n",
      "tensor([87.1913, 43.9960, 71.3523], dtype=torch.float64) tensor([87.0324, 43.7231, 71.4127])\n",
      "tensor([86.8678, 43.2872, 71.5739], dtype=torch.float64) tensor([86.7178, 43.0432, 71.6933])\n",
      "tensor([86.5443, 42.5784, 71.7954], dtype=torch.float64) tensor([86.3117, 42.4278, 72.0037])\n",
      "tensor([85.9822, 42.1170, 72.1521], dtype=torch.float64) tensor([85.8209, 41.8906, 72.3361])\n",
      "tensor([85.6573, 41.5502, 72.6311], dtype=torch.float64) tensor([85.4140, 41.3331, 72.7405])\n",
      "tensor([85.0952, 41.0888, 72.9877], dtype=torch.float64) tensor([85.0108, 40.8447, 73.2294])\n",
      "tensor([84.7704, 40.5221, 73.4667], dtype=torch.float64) tensor([84.7028, 40.3502, 73.7777])\n",
      "tensor([84.5618, 40.1495, 74.1550], dtype=torch.float64) tensor([84.3949, 39.8558, 74.3260])\n",
      "tensor([84.2369, 39.5828, 74.6339], dtype=torch.float64) tensor([84.2807, 39.3211, 74.9101])\n",
      "tensor([84.1900, 38.9969, 75.1913], dtype=torch.float64) tensor([84.0753, 38.8421, 75.5170])\n",
      "tensor([83.9814, 38.6243, 75.8796], dtype=torch.float64) tensor([83.8699, 38.3631, 76.1239])\n",
      "tensor([83.6566, 38.0576, 76.3585], dtype=torch.float64) tensor([83.6645, 37.8840, 76.7308])\n",
      "tensor([83.4479, 37.6850, 77.0468], dtype=torch.float64) tensor([83.4590, 37.4050, 77.3377])\n",
      "tensor([83.4010, 37.0990, 77.6042], dtype=torch.float64) tensor([83.2536, 36.9260, 77.9446])\n",
      "tensor([82.9231, 36.8100, 78.1908], dtype=torch.float64) tensor([82.8617, 36.5164, 78.5091])\n",
      "tensor([82.7144, 36.4375, 78.8791], dtype=torch.float64) tensor([82.5670, 36.1024, 79.1270])\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64) tensor([82.3763, 35.7140, 79.7998])\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for i, x in enumerate(all_states):\n",
    "    try:\n",
    "        print(x, env.referenceStreamline_ijk[i])\n",
    "    except IndexError:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAoAAAAHgCAYAAAA10dzkAAAgAElEQVR4nOy9eZhsZXXv349GUDRRURMMj+eEq0aNJJIrcsEYjHEg8ZoQBzSoV+NwFYkh/jR6UKKAAQURnEFAESNoQAw1z0PXPM9dXfM8T91V1UMVwznf3x/n1rbnrmHv2qe61ud51mPsrtp7d3Wb93PW+661FkAQBEEQBEHMFQt8PwBBEARBEAQxXUgACYIgCIIg5gwSQIIgCIIgiDmDBJAgCIIgCGLOIAEkCIIgCIKYM0gACYIgCIIg5gwSQIIgCIIgiDmDBJAgCIIgCGLOIAEkCIIgCIKYM0gACYIgCIIg5gwSQIIgCIIgiDmDBJAgCIIgCGLOIAEkCIIgCIKYM0gACYIgCIIg5gwSQIIgCIIgiDmDBJAgCIIgCGLOIAEkCIIgCIKYM0gACYIgCIIg5gwSQIIgCIIgiDmDBJAgCIIgCGLOIAEkCIIgCIKYM0gACYIgCIIg5gwSQIIgCIIgiDmDBJAgCIIgCGLOIAEkCIIgCIKYM0gACYIgCIIg5gwSQIIgCIIgiDmDBJAgCIIgCGLOIAEkCIIgCIKYM0gACYIgCIIg5gwSQIIgCIIgiDmDBJAgCIIgCGLOIAEkCIIgCIKYM0gACYIgCIIg5gwSQIIgCIIgiDmDBJAgCIIgCGLOIAEkCIIgCIKYM0gACYIgCIIg5gwSQIIgCIIgiDmDBJAgCIIgCGLOIAEkCIIgCIKYM0gACYIgCIIg5gwSQIIgCIIgiDmDBJAgCIIgCGLOIAEkCIIgCIKYM0gACYIgCIIg5gwSQIIgCIIgiDmDBJAgCIIgCGLOIAEkCIIgCIKYM0gACYIgCIIg5gwSQIIgCIIgiDmDBJAgCIIgCGLOIAEkCIIgCIKYM0gACYIgCIIg5gwSQIIgCIIgiDmDBJAgCIIgCGLOIAEkCIIgCIKYM0gACYIgCIIg5gwSQIIgCIIgiDmDBJAgCIIgCGLOIAEkCIIgCIKYM0gACYIgCIIg5gwSQIIgCIIgiDmDBJAgCIIgCGLOIAEkCIIgCIKYM0gACYIgCIIg5gwSQIIgCIIgiDmDBJAgCIIgCGLOIAEkCIIgCIKYM0gACYIgCIIg5gwSQIIgCIIgiDmDBJAgCIIgCGLOIAEkCIIgCIKYM0gACYIgCIIg5gwSQIIgCIIgiDmDBJAgCIIgCGLOIAEkCIIgCIKYM0gACYIgCIIg5gwSQIIgCIIgiDmDBJAgCIIgCGLOIAEkCIIgCIKYM0gACYIgCIIg5gwSQIIgCIIgiDmDBJAgCIIgCGLOIAEkCIIgCIKYM0gACYIgCIIg5gwSQIIgCIIgiDmDBJAgCIIgCGLOIAEkCIIgCIKYM0gACYIgCIIg5gwSQIIgCIIgiDmDBJAgCIIgCGLOIAEkCIIgCIKYM0gACYIgCIIg5gwSQIIgiCPMqVOn8PTTT+Opp57CE088gX6/j42NDXS7XfR6PZw8eRKnTp3i+zEJgpgyJIAEQRAzzKlTp3Dy5Ek89dRTePLJJ9Hv97G5uYn19XV0u12srq5idXUVKysraLVaTDQaDbTbbWxubqLf7+Opp57CyZMn+f5xCIKYEiSABEEQZzB7CV6v12MEr91uM4I3kLzB/z2Qv3a7jU6ng06ng263i263i0ajgU6ng16vh83NTWxsbGBzcxNPPPEEnn76acoKEsQRhwSQIAiCRwaC9/TTT28TvME27VbBG2TvBoI3kLy9BO+wGAhgv99n7jm47+bmJnq9HskgQRxhSAAJgiA4ZKfgPfHEE4xoVatVNJvNbYK3VxZvHMEbVQC3xs6sYK/Xw5NPPknnBQniCEECSBAEMQGnTp1iCi12Ct7a2tquDN7WTJ5SqUQqlUK73WYkjy3Bm0QAD5LBwXlBEkGCmG1IAAmCIA5hZyXtVsHrdDp7nsEb/Ocgg7eX4KlUKmSz2alJ3zgCuHOLeHNzk7aICeIIQAJIEMTcs7XQYtAqZXNzc5vg7bdNe1ChxWExSwJIW8QEcbQgASQI4sgzSquUncUWkwjeYaFUKmdSAPeTwWQyiXa7TVvEBDEDkAASBDHzTNIqhctCizNdALvd7sQCuFUElUolisUis01MW8QEceZCAkgQxBnPMK1SwuEwarXatmbHfAveMAKYy+WOhAD2+30oFApUKhXaIiaIGYAEkCAI3jmoVcpBlbRbBU8sFqNcLp9RgndYKBSKIyWAcrkclUplzy3iQdDUEYI4MyABJAhiKozSKmVnFu+gStpBDASQb6mbZwGUyWSoVquHVhHT1BGC4B8SQIIgWGFnq5R+v89Kq5RhQyKRkADyLIBSqRS1Wm2o84J7TR2hLWKCmB4kgARBDAVfrVJGEcBSqcS71M2zAEokEtTr9ZGLR7ZuEdN5QYKYDiSABEEAOHNbpRx1Aczn80dGAMViMRqNxtjvpy1igpgeJIAEMScM2yrF4/GgVCqdMa1Shg2pVDpzAiiXy4+UAIpEIjSbzYmvs98WMckgQbAHCSBBHBGGaZVyWCVtu93mdVtyUgEsFou8P8c8C6BQKESr1WL1mjuzgmtra+j1erRFTBATQgJIEDPCqVOnRqqk3U/wDsvg8dmbbh4FsFAoHCkBXFlZYfWaO2XQ4XAgFAptaylDIkgQo0MCSBBnEMMK3s52KWxV0na7/M6nnSRkMhkJ4AjBxSQQgUCA1dVVzgSw3+/D4XAgHA7vKh6hLWKCGA0SQIKYIny3Shkm1Go1MpkM73I0ashkMt5kataeud1ucyaA7XabUwG02WyIRCJ7bhFvbGxQFTFBDAkJIEGwyJneKmWYUKvVSKfTvMvRrMjULD5zu91GvV5Ht8ueAG5ubkIgEKDT6XAqgFarFdFodF8J3XpesN+nLWKC2A8SQIIYgWFbpSwtLSGZTJ5xrVKGCY1Gg1QqxftzjBp8bqeOG0dJADc2NiAQCFi95l5hsVgQj8cPzUZSSxmCOBgSQILYwrCtUnZu0+4stLDZbAgGg7wLxjih1WqRTCZ5f45Rg8+K2nGDr3OLAwFcW1tjTczW19chEAhYveZeYTabkUgkhn79ThGkLWKCOA0JIDFX7GyVwlUlrd1uRyAQ4F0wxgmdTodEIsH7c4waJIDDBxcCuLa2BoFAgPX1dU4F0Gg0IplMjvXenYUj/f7pLeKTJ0/y/f+aCGLqkAASR4pxW6XsLLSYdIvW6XTC7/fzLhjjhF6vRzwe5/05Rg0+p2qMG3y1ruFCALvdLgQCATY2NjgVQIPBgHQ6PdE1aIuYIEgAiRlkZyUtH61SDguXywWv18u7YIwTi4uLiMVivD/HqDGLDayPkgB2Oh0IBAIms8ZVLC4uIpPJsHY9mjpCzCskgMQZB5utUvgqtPB4PPB4PLwLxjhhMBgQjUZ5f45RY1YFkI/xdQMBZHO7tt1uQyAQoNfrcSqAOp0O2WyWk2tvzQrm83lUq1U6L0gcWUgAiakzTKuUYrGIYDB4xrZKOSy8Xi9cLhfvzzFOGI3GmRTAWZxgMk0BXFlZQalUQiqVQigUgsPhQDabZU3YVldXpyKAWq0W+Xye03v0+33Y7XaEw2FqKUMcWUgACdY5rFXKQZW0A8FLpVJQq9VnrOAdFn6/H06nk/fnGCdMJhMikQjvzzFqKJXKmZtgwqYAdjod1Ot15HI5RKNR+Hw+WK1W6HQ6SKVSCAQCiMViaDQamM1m2Gw2yOVyyOVyBIPBiUe4raysQCgUci5mGo0GhUKB8/vYbDZEo9Ft5wVpi5g4SpAAEmNTLpdRrVbR74/XKuWgDF42m4VSqeR9gR43AoEA7HY7788xTpjNZiwvL/P+HKPGLAqgRCIZSQAHWbxkMomlpSW4XC4YjUYolUoIhUIIBAIoFAoYDAY4HA4Eg0EkEgkUi0W0Wi3mf2+DSSBra2soFAqw2WwQCoUwGo1Ip9NjFXK0Wq2pCKBKpUKxWOT8Pnv1G6SpI8RRggSQGJurrroKN99889itUg6KQqEAuVzO+wI9boRCIdhsNt6fY5ywWCwIh8O8P8eoMYszjHcKYLvdRq1WQzab3ZbF02q1TBZPIpFAq9XCYrHA6/UiEokgm82iWq2i3W4Pdd+BAG49A9jpdBCJRKBWqyGRSOD1elGv14cWpmazCbFYzLmYKZVKlEolzu9jMpkO7DdIU0eIWYcEkBibj3zkI7jhhhs4WRhLpRKkUinvC/S4sbS0BIvFwvtzjBMWiwVLS0u8P8eooVKpZmKG8dYsnkgkgsVigcFgYLJ4QqGQyeI5nU6EQiEkk0kmi8fGM+wlgFvFplKpwOVyQSwWQ6fTIR6PH1ox3Gg0piKACoUClUqF8/sYjUakUqlDX7dzi5hayhCzAgkgMTaf/vSn8YUvfIGTRbJSqUAsFvO+WI8by8vLMJvNvD/HOGG1WhEKhXh/jlHjTBHArVm8SCSyLYsnkUi2ZfGEQiEcDgeTxavVakNn8SZ9xv0EcGusr68jkUhAr9dDJBLB4XCgVCrtWehRr9chkUg4FzO5XM4cPeEyxmk3Q1NHiFmCBJAYm89//vP4zGc+w8kCVavVIBQKeV/Mx41IJAKj0cj7c4wTszrGTq1WT00AW60WisUikskkQqEQnE4nDAYDFAoFk8VTKpW7snilUmlbFk8sFqNcLk/9sxpWALdGo9GAz+eDVCqFUqlEOBxGu91mvl+r1SCVSjkXM6lUilqtxvl99Hr9RO1maOoIcaZDAkiMzQ033ICPfexjnCxQjUYDAoFgKtkQLiIWi8FgMPD+HOPErI6xU6vVSKfTrFxrZxbP6/Xum8WzWq3w+XyIRqMjZ/FmSQAHsbm5iWw2C7PZDKFQCIvFglwuh3K5DJlMxrmYSSQSNBoNzu/DVrsZmjpCnKmQABJjc8stt+Dqq6/mZIFqtVoQCARYXV3lXSzGiXg8Dr1ez/tzjBMOh2Mmx9iNIoCdTofJ4iUSCQSDwX2zeEajES6Xa98s3iQhFotRqVSm/llNIoBbY3V1FUtLS1AoFJBIJBCLxWg2m5yK2TTu0e/3oVarWa82pqkjxJkECSAxNnfeeSeuvPJKThaoQVNZthbaaUcymYROp+P9OcYJp9MJn8/H+3OMGhqNZpsAttttVKtVZDIZJotnsVig0WiYLJ5UKoVOp9uWxcvlcqjValPpQcm3ALI1t7fX6yESiUAkEkEkEmFxcRHJZJLVSSODEAqFaLVanAugSqXitNp4a1YwEolgZWWFzgsSU4UEkBibe+65B1dccQUnC9Rgrmij0eBdLMaJVCoFjUbD+3OME7Myx3hnFk8mk8FgMDBZPIFAAKFQCJVKxWTxlpaWkEqlUCqVsLKywvvPcFQEsN/vo1QqMb07o9EotFotxGIx3G43qtUqaxNCBALBxE2rh4lpVRv3+6cLW8rlMm0RE1OFBJAYmwcffBCXX345Z4uUUChEtVrlfZEeJzKZDNRqNe/PMU643e4zRgC3ZvGWl5e3ZfHEYvG2LJ5EIoHFYmGyePV6/YyfJCMSiY6UAKpUqm0ZrlqtBo/HA4lEAo1Gw4wYnCRrNjgbzLWUyWSyqRSb9Pu/LWyhqSPENCEBJMbmkUcewSWXXMLZIsXXAXk2YpYnmXg8Hng8nqncq9PpoNlsolAoIB6PIxgMwuFwYHFxEXK5fFsWz2QybcvilcvlbVk8rVaLVCrF++c3SvAlgKurq6wLYKFQgFqt3vN7GxsbSKVSMBgMEAqFsNvtKBQKI2cFNzc3IRAI0Ol0piJlozTCniTEYvGuwhZqKUNwDQkgMTYikQgXXnghZ4uUVCpFsVjkfZEeJ/L5PBQKBe/PMU54vV643W7Wrrczi+fxePbN4tlsNvj9fsRisZGzeFqtFslkkvfPb5QQiUS8ZLm5EkCNRnPo61qtFgKBAORyORQKBUKh0NBbuuvr6xAIBOh2x88ijiJl0yg26fdPn2s86DOgqSMEF5AAEmOj0Wjwile8grNFSi6XI5/P875IjxOFQgEymYz35xgnvF4vXC7X0K/fmcULBAK7sngikYjJ4rnd7n2zeJMECeDwwYUA5vN5aLXaoV+/ubmJfD4Pq9UKoVAIk8mETCbDCM5esba2BoFAwElxyahSxlaMsq1NU0cINiEBJMbGYrHg/PPP52yRmsXZroOY5VF2Pp8PTqdzlzBUKhWk02kmi2c2m6FWq5ksnkwmg16v35bFy+fzaDQaUzmLp9PpZk4A+TrnyoUA5nI56HS6sd7bbrexvLwMlUoFqVQKn8+3Z6+/brcLgUDA6nMfJGWrq6ucC+DGxsZYWc2tWcGNjQ3aIiZGhgSQGBuv14sXvehFnC1SO9t6zFKUy+WZGmW3NYtnNpuh0Whgt9sPzOKFw2Gk02mUy+Uzol+jTqdDIpHg/TlGiaMkgNlsFnq9fmLxKpfLcDqdEIlE0Ov12+YQt9ttCASCA7OEbMQ0zxqykdWkLWJiHEgAibGJRCJ4znOew+mCPmsZnUFUq1WIRCLen2Pnoj/I4oXD4W1ZPJFIxGTxBmez+MjiTfr3QgI4/N8C2wKYyWSwuLjIqhgNGqqLRCI4nU5kMhkIBALWWsrsF4OzhgPx5DIGLa/YkFqaOkKMAgkgMTa5XA4LCwucicHi4iLi8Tjvi/Q4UavVmG2daUWn00Gj0dh2Fs9ut0Ov10MmkzFZPLVaDbPZvC2LV6lUmCxeMBiEzWbj/TMcNQbZIr6fY5QQCoWo1WpTvy8XAphOp2EwGDiRpMEc4kED7+XlZU6zc9M8azhoes+21FIVMXEYJIDE2NTrdSwsLKBer3OySBmNRqZv2KzFYJYx23K8M4vndrv3zOLp9Xpmpm88HkehUBg6ixcKhWC1Wnn/DEcNEsDR/o7YFsBUKgWj0cipLNXrdaZgRCgUwmq1Ip/Ps74lzGZW7rBotVoQiUSc3mNr4cigKv+pp57CyZMn+V5GCB4hASTGZm1tDQsLC8jlcpwsUmazGcvLy7wv0uNEs9kca5bxIIuXz+cRi8Xg9/sPzOJ5PJ49s3iTxNLSEiwWC++f4agxiwIoEAiOjAAmk0mYTCZORabRaEAsFqPf72NlZQWhUAgKhQJyuRyBQIC1EXFcZeX2+5kkEgnn9xmIYC6Xg0ajoS1iggSQGJ+nn34aCwsLnGXprFYrQqEQ74v0OLGyssKMrNpr8S2Xy9uyeCaTCSqVisniyeVyLC4u7sriNZtNzs/ihcNhmM1m3j/DUWNxcRGxWIz35xgljpIAJhIJmM1mTgWmXq9DKpXukppCoQCbzQahUAiDwYBUKjXRz7aysgKhUDgVKavVapDJZFO5V7//22KdwXnBrVvEJIPzBQkgMRFnnXUWfD4fJ4vUQH74XqRHjU6ng2q1CoFAgHA4DL/fD5vNti2LJxaLt2XxlpeXkclkWMviTRLLy8skgFMKgUDA2RGKg2IggGxuccbjcVgsFl5lqds9PYdYo9FAIpHA4/EwI9ZGuU+z2WQyjVxHpVKBQqGYmgAOJrJs/RqdF5xPSACJiXj+85/PWcGA0+nkTC7ZWEDL5TJSqRSWlpb2zOIJBALodDo4HI6pZ/EmiUgkApPJxPtzjBokgMMHFwIYi8U4F8BKpQK5XH7o63q9HqrVKtxuN8RiMbRaLfO3Mcx9Go3GrkwjV7FzhjLXcVimllrKzA8kgMREnHfeedDpdJwsUm63e2ozaXdGp9NBvV5HLpdjzuLZbDbodLptWTyNRgOLxbIti1etVpl+ZXxs700a0WgURqOR9+cYNQwGw8wVDfEpgPV6nVUBjEajsNlsnMpLuVweOVu2vr6OZDKJxcVFiEQi2O12FIvFA7OC09yWHXaEHpu/J6vVeujrdk4doS3iowcJIDERF1xwAWcTL3w+30gjyUaNlZWVbVk8l8vFZPGEQuG2s3gOhwPBYHCkLB5fY74mjWg0CoPBwPtzjBqzJoCDSlOuBLDT6aDVaqFYLO7ZFmjQW69arbJS7BCJRDgXwEmzZc1mE36/HzKZDEqlEktLS3tO+5jmtuwkE1TGieXlZdjt9pHeQ1NHjiYkgMREvPa1r8Vjjz3GyQI2mCk7yQI4yOJFo1H4fD4miyeVSndl8bxe764s3iTPLxaLUS6XeReNUSMWi2FxcZH35xg1ZlUAG43GRNfY+TdutVqh1WqZnnlSqRQ6nQ42m405ipDNZpFOp+HxeJgt0ng8PlHfu3HEYtQoFApQq9UTX2dzcxO5XA4WiwVCoRBmsxnZbJbJiJZKJSiVyqkIGdsNtA+LUCgEl8s19vtpi/joQAJITMTFF1+Mhx56iJMFMhQKHXq+cGVlBaVSaVsWz2g0bsviKRQKGAwGJouXSCRQLBbRarU4PYsnlUpRKpV4F41RYzB9ge/nGDWMRiMikQjvzzFsDCuAg75tmUxm1xzmrVXjBoMBTqcToVAIyWQSpVJpzyr0bvf0/24GZwAHW6R6vR5isRhutxu1Wm1kMQiHw3A4HJzKSz6fZ327tN1uIxwOQ6lUMnOIE4kEK6I5TEyjf+LWCAQC8Hg8E19n5xbx5uYmnnzySb6XJGIESACJiXjTm96E+++/n5MFctCOpFar7cpwHJTFi0QirGXxJgmZTIZCocC7aIwaiUSCs3OdXMasCeDgnGij0dhVVORyuWAwGKBQKCAUCiEUCvecw1ypVMb6G98qgFsX9VqtxmQFdTrdSFnBpaUlOJ1OTuWFy+3SXq+HUqkEh8MBoVAIkUiERCLB+TSQabTP2Ro+nw9+v5/1z27QU5CYHUgAiYl4+9vfju9///sTLYSDLF4ymdyWxRsInlAoZLJ4Tqdzqlm8SUKhUCCfz/P+HKNGMpmEVqvl/TlGDZPJdMYK4F7n8Ww2G7NFu98/ZLLZLOr1Out/4/sJ4CDW19eZfwgMmxWcdGtxmBj0sONakpLJJBQKBfPzu1wuVCoVThpDx2KxoYoy2Aq3241gMMjJtZ966im+lyRiBEgAiYm48sorcfvttx+42LTbbdRqNWSz2V3nlAaLn0QigVarhdVqZRY/r9cLrVbLaxZvklAqlchms7w/x6iRSqWg0Wh4f45Rw2Qy8To5ZtTzeD6fDwKBAOl0euqtgQ4TwK1Rq9WYdio6nW7frFgwGITb7eZUXtLp9FTOy209l1ev1+H1eiGRSKBWqxGJRFidQxyJRDg/O7k1nE4nwuEwCSBBAkhMxj/+4z/i5ptvRiaTwdLSEpLJJEKhEJxOJwwGA5RKJbOFtTWLNzinNMji7bVIzepW5CDUajUymQzvzzFqpNNpqNVq3p9j1JiGALJ5Hm+wBdxsNqf+WY0igINYX19HPB6HVquFWCyGx+NBvV5nvs/W2bKDYlrn5fa6z8bGBtLpNIxGI4RCIWw2GwqFwsRZwXA4zPnW+daw2+2IRCIkgAQJ4Cxz/PhxLCws7Iprr70WANDr9XDttdfi3HPPxXOf+1y85z3vQbVaneiePp8P9913H66//nq8//3vx4tf/GI873nPw8LCAq6++momi+fz+ZgtrFqtNlYWb1YzUYPQaDRIpVK8P8eokclkZlIA2ZodPa3zeLMmgIMYNFl2uVwQi8XQ6/VIJpPw+Xzwer2cyss05g0Pc5+VlRUEg0HI5XLI5XIEg0GsrKyMda9QKMR55nRrWCwWxGIxTq799NNPs7G0EVOCBHCGqdfrqFQqTKjVaiwsLECv1wMArrnmGrzsZS+DVquF2+3GpZdeije+8Y0T3fPmm2/G2972Nnz605/G7bffjiuuuAIf//jHORGdTCYDlUrFu1iMGzqdDslkkvfnGDWy2exMfu7DCuBh/fEOOo9Xq9VY26pdXV2dSQHcGmtra4jFYtBoNBAKhdBqtWg0GpzJSzwen0rBxLBj7TY3N5HP55k5xEajEel0eqQ5xIFAgHNx3homkwnJZJIEkCABPEr867/+K17+8pfj1KlTaLfbeNaznoVf//rXzPcjkQgWFhZgs9lYu+cXv/hFfOpTn+JkkcrlclAoFLyLxbih1+sRj8d5f45xPnelUsn7c4waZrMZ4XAY3e7o5/H8fv/UR/UdBQEcRK/Xg91uZ7bCFxcXkUqlRhKhYWIa4+b6/fGmmnQ6HUQiEajVakgkEni93m1b5PsFF1W5B8Xi4iLS6TQJIEECeFR44okn8KIXvQi33norAECr1WJhYQGrq6vbXnfs2DHcddddrN33a1/7Gj7ykY9wskgVi0XIZDLexWLcMBgMMzebttvtIp/Pz4R47zyPp1QqoVard53HW1xcHLo/3jRjIID7nYHlMlZWVtBsNlld/L1eLwKBANbW1hCNRqHRaCCRSODz+Vi71zTGzfX7kxVm9Ho9VCoVZot80E5nbW1tz9d7PB7OqnL3Cp1Oh1wuRwJIkAAeFR555BE885nPRKlUAgA8/PDDOOuss3a97g1veAO+9KUvsXbfb37zm3j/+9/PySJVLpchkUh4X6jHjVnrSzeIQqEAuVzO+3N0u6Odx1MqlbBYLBP1x5v2z8aXALZaLdYFcKfIDETI6XRCJBLBYDDs2h5d39hEudVFpNhCpNg6tKBiWhWzbBVmDNrp6PV6iEQiOBwOlEqlbT+ny+XC0tLS1ARQo9GgUChwcu2TJ0+ytrYQ3EMCeER4xzvegXe9613Mf5+WAH73u9/Fu971Lk4WqWq1CpFIxPtCPW6wVZQw7Zhm5pXN83gWiwVLS0u8f37DxsrKypESQLfbjVAotOf3ut0uwssRfOe/lPjAXRJc8nU5/uSrchw/IdkWf3WHDvnG/i1WpjFtpN/npjCj0WjA5/NBKpVCpVIhHA6j3W7D4XBgeXl5agKoVCpRKpVIAAkSwKNANpvFM57xDAgEAuZr09oCvu+++/C2t72Nk0WqXq9DIBCcsY2eD4tZE5JBFItFSKVS1q7X6XTQaDRGOo8Xi8VGPo83a5/3URPAwzJZH3vAvkv49oofaKL7XmOQBeZakoLBIGctbTY3N5HNZmE2myEUCiGTyeByuVg7j3lYyOVyVKtVEkCCBPAocOONN+K8887b1vKF56QAACAASURBVINpUATy2GOPMV+LRqOsF4H84he/wF/8xV9wskg1m00IBIIzfitvv7DZbAiFQrw/x6hRKpVG3noftj8el+fxrFYrCeCQwYUADhoMN9vr8GcbeMSRwddFIXziZw68/j9Uh4rfq2+Q4mu/8aLZ2X/02rRapvj9fvh8Ps7vs7q6CpVKBalUCplMhkAgwPrvZWdIJJKhilNIAI8+JIAzzsmTJ3Hs2DGcOHFi1/euueYaHDt2DDqdDm63G5dddhkuu+wyVu//2GOP4fWvfz2nC+SZcGB/nLDb7QgEArw/x6hRLpchFot3fX3a82pHDavVOlPCzeff96QC2Gyvw5dp4DFXFrfLwvjUz524/BtyvParsqGyfMdPSPC6m5UQeHII5RqIpfOw2+1MK5VMJrNnRmwazab7/d8WtHB9n37/dFuWwWhLu93OVFEnk0lO5hCLRCLOJPPUqVOsri8Et5AAzjhKpRILCwuIxWK7vjdoBP3CF74Q55xzDt797nejUqmwen+pVIrXvOY1nCxSfDbKZSOcTif8fj/vzzGqGCQSCQiFQt76440b8ySAzZU2ctUWUqUG4sUGIvk6wrkagpkqfKkK3MkKnPEybNESzJEijMsF6Jby0ATzUAZyELmSEDiTkPoLEHnzeNyTw29cWTziyOBX9jQesqbwc3MSP9REcbMwhM/9yoP/8xMb3nHXIi68UXG43N2kxHt+ZMZXfuPHTw0JKIJF+LMNPGxL483f0jGv+9gDdngzv81GdbtdRCIRqFQqJiPWarWY708rMzfNytxBcczWzyAajTITV9xuN6rVKitziHu9HgQCAVZXV0kACRJAYjL0ej0uuOACThbITqcDgUCAWq3G+2I9TrhcLni9Xt6fY+dneth5vMF/TnIej4+w2WwIBoO8P8ewv4dUsYofPCSA1JPGrx0pPGiM4QfqZXxTHMQNj/lw3cMufPwBG95/jxl/+51FXH67Fn/+dSVe+RXp0Fk2LuOim09L3r894sU9uhh+9LgBClsArQO2cPv9PtY2NnHfYhyv2PJzfPSn9m3v6/V6KJVKTFbQZDIhm83C6/VOpWfeNCtz9Xo9stnsnrJWq9Xg8XggkUig0WgQjUbR7XbHvtfGxgYEAsFE1yABPDqQABITYbfbcd5553G2UIpEIlQqFd4X7HHC4/HA4/FM/b6jnMdzOBy7zuPVajUIhULeP79R40wSwE6ng0SxAeNyAf9lS+IuxRK++IgHH7rPgr++Q4dX//vwW6UHxR+dkODlX5bij2+Q4dX/LsOFX5Pjz25S4M9vVuLi/1DhkltUeOM31HjTbRq8+XYt/voOHd52px7vuFOHv/2OHn//AyPe/SMT3ne3Ge//sQUfvM+KD99vw0d/asfHHrDjul+6cZMgiO+ro3jImoIyWEQo39xT8qxWK6LR6NCy4M3U8c8PufDyL58Wwffebd7zup1Oh+nzKBKJoNfrxx67Nmw4HA6Ew+GpCKBWq0U+nz9U3FKpFAwGA4RCIex2+1hziNfW1iAQCDjZWiYBnD1IAImJCAQCeMELXsDZQiqRSFAqlXhf0McJr9cLt9vNybUnOY+3urp64LVntfqaLwHMV1vQhvK4RxvBF/7Ljb//vnHPFid7xYX/Lsbbv63Du39oxEfut+Iz/+nAlx7x4OvCAO5SLOE+XRS/tCYg9mSgXyrAlSgjkq+jUGthpT3+76fVam3bWmUjxp0x60zWmG3l995txvrG3tWwvV6P+YfM1qwgF9WzdrsdkUhkKgKoUqlQLBaHfn2r1UIgEIBcLodCoUAoFBpaiAfHariqOCYBnC1IAImJSCQSOOusszhbXGUyGQqFAu9yMU74/X44nc6JFmk+5tU2Go2ZFMBpFN1Um6uQerO46XE/rr7XgosPqG79H9dLcOmtarznRyZ89iEnbhUF8TNDDAp/DsFMFeVagzmPNe3PigsBNJvNiMfjY73XlarjT752Wpr1y+X9X/f/tmbb7TbC4TAUCgXkcjmCwSCrWUGr1TqWzI4TCoUC5fL+P/N+MZhDbLVaGSHer3hmECsrKxAKhZz9LMRsQQJITESxWGT6DXKxUCkUCuRyOd7lYpwYSNt+359Wf7xRY1bb73AhgCvtDozLRXxLGsJ7fmRitit3xhu/qcFHf2LFLcIAHrEl4U1V0Fo9+PMbfM5HRQAH1azjvv/aX7hw/IQEdyn3b4o8aDUz+O+9Xg+FQoGRILPZjFwuN3GGy2KxjC2zowYbffna7TaWl5eZljI+nw+NRmPX65rNJsRiMSc/xxNPPMH3ckSMCAkgMRGtVgsLCwucndNTq9XIZDK8y8U4EQqFYLVaRzqPFwwGeZ9X22q1eBOTSYINAex0OvCnq7hHG8FHf2LDa7+2eyv3jd9Q4/O/cuMBQwymSBGVxni/p6MmgEajEclkcuz337cYx/ETEnzkJ/vP+rXb7ftOzWi321haWmKygqFQaOxqV5PJNNHPMkpIpVLW+vL1ej2Uy2Vm/J5er0c8HmfO/NVqNUilUhJAAgAJIDEhm5ubWFhY4EzStFotUqkU73JxUOx3Hm+QxZvkPB4fMav9Fx0Ox1htd5orbch9WZx41ItLb1XvEr4/u0mB//ugHT9djCGcY68ifVIBXG13xj4HyIUAGgwGpFKpscXlsw+7cfyEBNf+Yv9JHzab7dBCk16vh3w+D4vFAqFQCIvFgnw+P1LBxM7WLFyGWCzmpC/f2toa4vE4dDodRCIRnE4nYrEY5HI5CSABgASQmJBTp05hYWEB4XCYk0Vdr9cjkUjwLhfjnMdzu90wGAwzd5aOzwkVk8QoAlhurOBhSwKf/Jkdr9lRsPHKr0jxgR+b8V1lGPZYCe0zcKs9UWzgfXebcItouIxnu91GpVJBOp3G0tISHA4HnE7nntuE48bi4uJY0tTqrOO6X7qZz9+eqO372lHP5q2uriIUCjEFE4Pzg4e9b7/WLFyEUCjkvKp5MIdYLBZDKBRieXkZnc7+M5dJAOcDEkBiYp7znOdw1u7EYDAgFotxLg9cnMeLRCIwmUxTF6FJY3V1dSYbcB8mgNXmKh61p/DxB2y7euld/B8qfP5XbojcGdRa08nKTiKAjzlSTBuYhy0JrLY7uyRva2W4QCCASCSCWq2GxWKB2+2G1WqFSCSC0WhkpZpWr9cjk8kM/fpmex3fU0XwupuVp4tmvizFA8aDt13HLTQZFEwMsoJWq/XANio6nQ65XI5z+dvc3GT+Bri+V7/fRzabhUKhgMlkYj6HfD7PSlXwk08+yfdSRIwICSAxMeeeey7MZjMni6TJZEIkEmHlWqP2x5v0PF4sFoPBYOBdjMb5nAQCARqNBu/PMko4nU74fL5tXyvVV/CoPYlrfu7Y1Xvvzd/S4lZRENYod1m+g2JQbT2KAG6VvE/dv/hbgb1Jgn+8U4R/u1eE/xQot2Wic7kc6vX6tn+ktFot5m86EolAqVQy5+bGlRGdTndo1qyztgGJL49rf+Ha9vu4/HbtgdW/g2DjbN4wWUGNRoNCocC5kK2vr3PamHkvAdTr9ej3T1cEh0Ih5szkzqkrJIBHHxJAYmLOP/98qNVqThZJi8Uy0vYyl/3xRo14PA69Xs+7GI0agwks9Xqd92cZJQYCGC3UcY82gg/82LyraveN39Tg68IAXIky71vz+wngsJk8vdGMf/v54q75uxdcL8FvnAefmx0I4GDxHlTTDjJkNpsNpVJppHNze2XNNjd78GcbuFcfx8d/5thVVPOWO3R4xJHZt/ffzjAajWOfM9wZm5ubyOVyMJvNu7KCo/bmGze63S6njZl3xqCZ9NavDX73NpsNQqGQOcu5sbFBAnjEIQEkJuaVr3wlRCIRJ4vkXs19+eqPN2okk0nodDrexWicmKURfM2VNtTBHP71AR3e/E3lriKOv/qWFjcJ/DBHirxL3yDa7TZyuRwEAgFCodCB27UHZfK63dNb2//tTOMWUQD/8AMjjp+Q4I9vkMG4vH//zJ0CuDVWVlYQCAQglUqh0WgQi8UOFZSV7gZ+IVTjUdMSfqyL4YuP+vDuH5n2nBv8v25V4yZBEM5UbeRJFuOeMzwsVlZWEAwGIZfLoVQqIZFIpnIGkOvGzDsjkUjAbDbv+/1u9/QcYo1GA4lEAo/Hg1ptuN8TCeDsQQJITMyf/umf4pFHHmFtcdx6Hk+v10Ov158R/fFGjVQqBa1Wy/tzjBNCoRDVapX359jv78ObquCH6mV88F4LXnXD7gzYe35kwg9Uywhm+PsZhsnkCQQCmM3mQyVv2Fhtd/DRn1hx/IQEr7tJgVB2b4k/SAAHMRg/ptfrIRaLYXO6ofGn8YAxiX//7wA+/jMH/va7Brzupt3SvTVe81U5Pny/Dd9XR+FM1rC5OZr0bQ2uizM2NzeRzWaZ3QKbzYZisTiyqI4ingKBYCry1+/3EY1GYbVaD31dr9dDtVqF2+2GWCyGVqtlzmLv956nnnqK76WIGBESQGJiLrnkEvz85z8feXEc5jyeTCaDWq0+I/rjjRqZTIazrXGu40ybwTxo1fKlRz245Jbd0zde/3UVPnK3Bnf9txn56vSql0cpvNgpeVyN3Ks2V/HO754+H/im2zTIVnYX8wwjgP1+H+sbm1AvlXDNgzb88VcOHmv36q9I8JZvafCpnztxmzSMx1xZ+DINrA25vTtMTKs4QyaTIZfLIRAIQCaTQalUclI522w2IRKJpiaAy8vLcDgcI71nfX0dyWQSi4uLEIlEsNvte0oxCeDsQQJITMyb3/xm/PjHP961yLBxHs/j8XA2T5fryGazUKlUvD/HOCEWi3kXwHy1tW+rlj++QYYP3mvBD9TLcCcr6HQ6cLvd8Hq9rD/HJJJ3kNxxOXM5XW4y5+2uunt3JXqr1dq3SXKv14Mv08BNguCuUXev/7oK7/uBDp/6kQzX/0SKB+QOuOIlNNrrUKlUKJVKnAqMRqNBPp/nXJQkEgnTImeQFRxUztrt9pHPR+4X9Xqds8bMe8XguMG47282m/D7/YwULy0tMX9HJICzBwkgMRGtVgt/+Zd/iU9+8pP453/+Z9x///2snsfz+XwTzdPlVWDyeSgUCt6fY5yQSCQol8tTv29rtY3HXWn8009tuwo4Lv4PFb7wX25IPBnU92jV4na7x25HxJXkHRQDAeTqs/zXh13MZ/d33zfgDlkIQncGxuUiHNE8zMt5GCJl/NqZxfdUEZz4tQ9X3WPBn92k2Pa5v+5mJb7yGz/sid+eBduraEQmk3EugGq1eirVuSKRaM+K2FarxZyPVKlUTIeCce9TrVY5a8y8VwQCAXi93omvMyigGfz+zWYzqtUq38sRMSIkgEeAYrGID33oQzj33HPx7Gc/GxdeeCFcLhfz/VOnTuGrX/0qzjvvPDz72c/GW9/6VsTj8bHv981vfhMXX3wxXvCCF2BhYQFnn302XvGKV+CKK67A/fffz+p5vMPm6Z7JUSgUIJPJeH+OcUIqlaJUKk3tfq5EGTc85sNFN28/T/bWb+twiygwVKuWwwSQD8k7KLgWQGe8jL+5a/HAbdv94pU3yPDp/3RC6i+gu37wFu6gaEQgEEChUAxVNDJuTCPL2O8f3px5c3MTmUwGRqOR2RYdJytYLpehUCimJoA+nw9+v5/Va7bbbYTDYRQKBTaWM2KKkADOOCsrKzh+/Dj+6Z/+CQ6HA+l0GkqlEslkknnNbbfdhuc///kQCAQIBAL4+7//e1xwwQXo9Xpj3VOpVOLRRx+F1+tFp9PBhz/8YXzta1/jZBFbWlqC1WqdmoiwGaVSCVKplPfnGCekUimKxSKn9/Cnq/iWNIS3flu3a5vxxsf98CRH24IeHBc4kyTvoKjVapwK4CDixQZ+uhjDJx6w439/14A3flODP7tJgUtuUeGv7tDhqnvMuO6XbtwmDeOXtjS8mfqh0rdXyGQyhEIhpmjE4/GwOmmk3+9DqVSiXD68X+Ak0ev1RmrO3Gq14Pf7IZVKoVarR8oKFotFqFSqqQmg2+1GMBjk5NpPP/00W8saMSVIAGecEydO4E1vetO+3z916hTOO+883HHHHczX2u02zj77bPzqV79i5Rk++clP4otf/CIni9fy8jJnTaa5jnK5DIlEwvtzjBMymQyFwv5tRMaNYKaKO2QhvO1O/Tbpe8VXpPi/D9oh8WYPnW+7XyZPLBafcZJ3UExLAPeKZrPJ+vgxmUyGWu30GLdarQaXywWRSASDwYBMJsNKqxO5XI5KpcKpJG1sbIzVnHljYwPpdBoGgwEikQgOhwPlcvnArGA+n4dGo5maADqdToTDYRJAAgAJ4Mzzmte8Bp/73Ofwvve9Dy95yUtw0UUX4b777mO+n0qlsLCwAJ/Pt+19l19+Oa677jpWnuG6667DZz/7WU4Wqmg0CqPRyPtiPU5Uq1XO+iNyHXK5HPl8npVrhbI13Clfwjt2SN/LvyzFh++z4hfmOIr17ZXd42zXWiwW2O32M0ryDoparQahUMjLvbkQQKlUinq9vu1r3e7pSSMqlWriSSP9/nbJ5CoG0znW1tbGvkaz2YTP52OygtFoFN3ubqHcOpljGmG32xGJREgACQAkgDPP2WefjbPPPhtf/vKX4fV6ce+99+LZz342HnzwQQCAxWLBwsICyuXytvddddVVeP/738/KM1x//fX4xCc+wclCFY/Hsbi4yPtiPWsL/KShUCiQy+XGfn84V8NdiqVdZ9Be/mUpPnSfBT83xZGvNFndrvV6vTNVMX7UBHBr5ezOYGPSSL+/t2SyHd3u6Uboo07C2CsGvRQHLVScTicqlQrzcw8yhtMSQIvFglgsRgJIACABnHme9axn4bLLLtv2tX/5l3/BpZdeCmA6AnjzzTfjQx/6ECcLVTKZnNlmyoNRX7OSkdoaSqUS2Wx2pPeEczV8RxHG33xnu/T9j+sleN8P9LhLYIPO4uDsTJ7X64XL5eL9sxs2jpoAisViNJvNQ1+3ddKIWq1GLBYbOtsmFotZP1e4MwbTOdhu/txoNODz+SCRSJgJK7FYDCaTaWoCyMYs5f3i5MmTrKwnxPQgAZxxjh07hk984hPbvnb33XfjD//wDwFMZwv4W9/6Ft773vdyslCl0+mZbabcbDYhEAhYnzE8jVCpVMhkMoe+LpKv47uKJfzNXdsLOS64XoK/uU2KE/cK8cvfnJY8Nide7BWzJoDVapU3AWw0GqwLoEgkGkoAB7Fz0sgwRSOj3mOcWF1d5XQ6x9asoFAohFwuR7Va5WzayNbgapQeCeBsQgI441x99dW7ikA+97nPMVnBQRHIt7/9beb7nU6H1SKQH/7wh3jnO9/JyUKVzWahVCp5X6zHicGYp1mZXLI11Go10uk089+3nsnT2f346sOLeMs3to9g+6MTErzzDgVu+7UJNt/S1AsvfD4fCeCQwYUACoXCPXvnDRPDFo0c1p6FjWi1WlObzuH3+5nZw4Nxa5OcPTwsuJykQgI4e5AAzjhOpxO/8zu/g1tvvRWJRAIPP/wwzjnnHDz00EPMa2677Ta84AUvgFAoRDAYxJVXXjlRG5id/PSnP8Vb3vIWThaqfD4PuVzO+2I9TgwyCa3W9EaTTRJbJU8mk8FkMjHbtT97RIDP3SPCW26V7sr0vfeHBtyvjyKzx8ixacasNQ3ns0io0WjsOwlk3Bj8Y2eSa3S7+xeNDNqzsP3cO6PRaEAsFk9FAAej2Qbj1gbZUJfLxUlWUKPRcNZImwRw9iABPAKIxWJceOGFOPvss/HqV796WxUw8NtG0H/wB3+As88+G29961sRi8VYu/8vf/lLXHbZZZwsVMVicWZ76XU6HQgEAjQaDd6fZRDDVtdKJBIYTSY8oHTjqh8u7sr0ve9uE+7TRZEu8yt9W4MEcPhgWwDZlrO9ikYKhcJI/fnGjWmOZxv8b3Dn/T0eD8RiMbRaLeLxOGuNtZVKJWeNtE+dOsXamkJMBxJAYmIef/xxXHTRRZwsVJVKBWKxmPfFetwQCASo1WpTveewkrffmbx0uYnP/0SJN/yHYpv0vedHJtyriyJVOnOEdmv4/f6ZEsBKpXJkBHBzc5MzOdtaNCIQCBAOhzndJp3meLZgMAiPx7Pn99bX15FIJKDT6SAWi+F2uydugTM4b0gCSAAkgAQLKJVKvOpVr+JkoZrlVirdbhcikQjVapX1604qeTuv1+l0sBgu4Jr/dGybwfu6mxS4SeBHODddiR0n/H4/HA4H788xbBxFAex0OpzJ0iCjPhAiLiaN9PvTHc/m9/vh8/kOfV2tVoPb7YZYLIZOp0MikRgrKyiRSDhro0MCOHuQABITYzQacezYMc4WqlltpdLtdiEWi1GpjDbSbBBsS96eEtJYwU/00V2TOf76GzL8SOpGY6XN+2c4bJAADh9sC+CgeXK3O9r0jFGi2z2dUV9fX2eEaFA0kk6nWZk00u/3USqVpjaezev1IhAIjPQ5x+PxbRI8itCJRKKxC3VIAI8eJIDExLhcLvz+7/8+JwtVq9Wa2VYq3e7pmbqlUmnf709D8vaKdLmJG37jw598Vc5I36tukOHzv3LDHithcXERsViM989vlAgEAjMngHwdb2g0Gqxu17IxPeOwGGQAt4re2toaotEoVCoVM4t4UrEtFApTG8/mdrsRCoVGfl+v19uWFdTr9UgmkwdmBbkuoiFmDxJAYmKWlpbwu7/7u5wsVLNWSbszZDIZ8vk8L5K3V+SrLdwk8ONVN/y2hcubb9fibk1k2zg2g8HAjK+alQgEArDb7bw/x7BxlARwbW2Nyc5xJUsHNWgeFI1YrdaJJo30+6fn8+p0uqkIIBuzedfW1hCPx6HVaiGRSOD1evfcGh93xjEJ4NGFBJCYmHQ6jWc+85mcLFRnYiXtXrFfJk8gEExd8vZc8FfauF0S2pbx+7vvGSD3Zfe8v9FoRCQS4f1zHSVmTQDL5fJUBXBlZQXFYhHxeBxerxfRaJS1bdNul73xafvFoK/mYa9bXV1FMBiETCZj5vCOkpmc5nxeNmfz9no9VKtVpp/iICs4+J1wKelPPPEE38sQMQYkgMTEVCoVLCwscJalEwqFnBRSjBrjbNfKZDLE43FezzDGiw2887u/beXyjjv1EHsyBz6TyWTC8vIy75/5KBEMBudeAFdXV1Eul5FKpRAKheBwOKDX6yGTySAQCCCRSKDT6WCxWKBUKplt00mzgXttz7IdrVYLQqFw6Ndvbm4inU5jcXGRqaId5rzcNOfzWq1WTmbzrq2tIRaLQaPRMFnBYrHI2e+IBHA2IQEkJqbdbmNhYQHFYpGThVIsFqNcLk9lUWb7TJ5arR5qpBpXYVwu4H9+XYnjJyT4s5sUeNSeRHsIGTWbzQiHw7w99zgRDAZhs9l4f45ho1wuQyKRjPy+TqeDWq2GTCaDcDgMt9sNo9G47W9Uo9HAarXC5/MhFouhUChs+wdas9nE6uoqCoUCzGYzhEIhHA7H2C1CuJqfuzWazebYDZrr9TpTNDIYh7afCCWTSRiNxqkIoNlsRiKR4Oz6vV4PlUoFTqcTIpEIAoEAqVSK9UwtCeBsQgJITMwTTzyBhYUFJJNJThZKqVTKqlxOs/BCo9FsG6k2zfiZIca0dHn7nXos54dv5WKxWLC0tMTLc48bR0kAO50OGo0GcrkcIpEIvF4vzGYzVCoVhEIhhEIhVCoVTCYTPB7PyH+jzWZzW8uWVqsFr9fLFBSMWlXL9fzcfv/0hA6JRDLRNXYWjQSDwV1FEYlEAmazeSoCaDQakUqlpnKvcrkMoVAItVoNqVQKn8/H2lxlEsDZhASQmJhTp07hmc98JoLBICcLpVwuRz6fH+k9fFXX7gydTseZGO8XrdU2TjzqZbZ8P/kzO6rN0aqorVbrzAlgKBSaKQEslUoQi8XMuTy/3w+r1QqtVguxWAyBQAC5XA6DwQCXy4VwOIx0Oo1qtYp2e7L2PDsFcC9BksvlWFpaGqq338rKykjbs+NErVZjbUJHr9dDsVhkikasViuKxSJ6vR5isRisVutUpGxxcRGZTGYq96rVapDJZOj1eiiXy3A4HNva6EySFXzyySf5XoaIMSABJFjhec97HmdTGFQqFbLZ7K6vnymSd1Do9XrE4/GpSUW1uYqr7jYx8neHLDTWz2qz2TgTeq4iFArBarXy/hw7Y3AuL5lMMucU9Xo9JBIJBAIBpFIp9Ho9HA4HgsEgkskkyuUyp62P9hPArYKUz+dhMpkgEongdDoPnELRarUgEok4FRiuJnRsLRpRqVSwWq2wWCxTkTKdTodcLjeVe1UqlV0NrrvdLqLRKJMV9Pv9Y2UFSQBnExJAghVe8pKXwGAwsL5QtdttqFQq+P3+M1byDopp9tPrdDr41IMOHD8hwZ98VQ6he/yzh3a7nQRwhGi326hWq0in0wiHw8zfqVwuh0AgYOa6Wq1W+P1+xONxxGIxXtvADDu1o9lsMrNpBxmrndvDk5zPm0Rg2IxB0YhCoYBQKBy6aGSS0Gg0KBQKUxHAYrG4b4PrnVlBo9E40jEAEsDZhASQYIVjx45BqVSOvXgelMkbbIWdqZJ3UBiNxqn10/uuMozjJyR4+ZelWAwXJrqWw+FAIBDg/fMbJZaWljgVwE6ng3q9jmw2i0gkAo/HA5PJtOtc3uDvNBqNIpfLMbK183qlUglSqZSXz2oUARzE2toaIpEIlEolFAoFUyTU77NzPu+wKJVKUCqVnIvS0tISLBbL0EUjk4RKpUKpVJqKAObzeWi12kNf1+12EYlEoFKpmKzgYdNDSABnExJAghVe/epX4/HHH993wZlku3ba26hshtlsnko7FYU/iwuuP73te79+cuF0OBzw+/28f36jxGDhnvQ6rVYLhUIBsVgMPp8PFosFGo2GqaJUKBQwGo1wu90Ih8PIZDKo1Woj/2Nk1gRwEL1eD7lcDkajESKRCC6XEq8ahgAAIABJREFUC5lMhrXzefvFQRksNiMUCsHtdqPfH65oZJJQKBSoVCpTEcBR+xv2ej2USiXY7XYIhUIYjcY9s7/9fh9PPfUU30sQMQYkgAQrXHTRRfjFL34Bo9EIn8/H6nbtNLNobIfFYuG8nUo4V8Of3qjA8RMS/H+/dLOSFXW5XPD5fLx/fqPEKAK4srKCUqmERCLBNJDW6XTMuTyZTIbFxUU4HA6EQiGkUilUKhVWz+UVi8WZFMCt0Wg0mEyZUChENpvlrBfgtEa0BQIBeL3eXTK0X9HIJPeSyWQHnq1kM1Kp1Nj9DTudDpaXlxkRDgQCWFlZIQGccUgAjwA33ngjFhYWtsWrXvUq5vu9Xg/XXnstzj33XDz3uc/Fe97zHlSr1Ynuubi4iLvuuguf+cxn8Pa3vx3nnHMOnvGMZ+Css87C17/+dVa3a6eVReMirFYrQqEQZ9fvdDr4m+8sMpM9miuTVYcOwuVywev18v75jRLhcHibAO7MOjudTiwuLm5riqzVamGz2RAIBBCPx1EsFrGysjKV5z0KArhVzsRiMRQKBRQKBTNFhk2BGXYLc9Lw+Xzw+Xz7fn9n0ciok0a2hkQi2XNsGxfBRnubgQjbbDYIhUKYTCZks1lqAzOjkAAeAW688Ua89rWvRaVSYaLRaDDfv+aaa/Cyl70MWq0Wbrcbl156Kd74xjdOdM/rrrsO//AP/4AvfvGLuPfee/H6178e3/jGNzipXJzFliSDsNvtnJ6lMy4XcfyEBK/5qhyJInvj8txuNzweD++f32ExaIqczWZhsVigUChgMpmgVCq3ZZ0tFgt8Ph+i0Sjy+TxTBcvnsx8lARwUaGxubiKbzcJgMEAkEsHtdrMmONlsdiozer1eLwKBwKGvG3fSyNYQiUSHnq9jK6LRKKvtbTqdDsLhMJRKJZaWliZdxggeIAE8Atx444143etet+f32u02nvWsZ+HXv/4187VIJIKFhQXYbDbWnuFd73oXvv3tb3OyWHEtUVwG12fprv/16X5/n32I3RY8Ho8Hbreb98+v2z0tec1mE/l8HtFoFF6vFxaLBWq1mtl6VCqVUKlUUCgUWF5eRjabPeOLhIrFImQyGS/3ZlsAy+Xyrgrder3OzKU1mUzI5/MTbZlmMpmpzOh1u90IhUIjvWcwaWRQKT1M0Uiv14NAIGD1TOFBsby8DIfDwfp1B79TYvYgATwC3HjjjTjnnHPw0pe+FBdccAE++MEPIpfLAQC0Wi0WFhawurq67T3Hjh3DXXfdxdozXHXVVbjllls4WaycTufMnUcbBJdn6VbaHfz5/xvzJvXu7pM4SXi9Xrhcrql+VisrK0xT5EAgAJvNBq1Wy5zLk8vlWFxchNPpxNLSEtLpNCqVCtMUeXl5GWazmfff+bBRKBSOjAAeVKHb7Z7enpfL5VAqlYhEImNtmU5rRq/T6UQ4HB7rvaMUjWxubkIgELD6ezgoQqEQXC4XJ9d++umnWVtLiOlBAngEkMlkePTRRxEIBKBQKHDZZZfh2LFj6Ha7ePjhh3HWWWftes8b3vAGfOlLX2LtGT760Y/ihhtu4GSxmpXtyL3C4/Fw9uwKfxbHT0hw0c1KtFbZOfs3CJ/Px4kADs7lpVIphEIhOBwO6PX6befydDod04cwkUigVCoNdS5veXkZJpOJ99/5sHGUBHCYCt3NzU1kMhlmy9Tr9Y7UdHhaM3odDgeWl5cnusYwRSPr6+sQCARjnx8cNfYqbiEBnG9IAI8gq6ur+L3f+z385Cc/mZoAfvrTn8YXvvAFThYrPrJRbD47V1up//KwC8dPSPClR9gXTL/fD4fDMdZ7B+fyMpkMwuEw3G43jEbjtmpwjUYDq9UKn8+HWCyGQqGAVqs10TOTAA4fXBSBqNXqoV9fq9XgdDqZ7eFCoXDo9nAikYDJZOJclGw2G6LRKGvX269opNvtQiAQTDSCbZTw+Xzw+/0kgAQDCeAR5eKLL8b1118/tS3gz3/+8/jMZz7DyWI1iYzwHT6fj5MRefXWKv7kq3IcPyGZuOnzXjFojbLf9zudDhqNBnK5HCKRCLxeL8xm866myCaTCR6Ph6kG368pMhsRiURmTgDlcjkv9240ThcMsSUA+Xx+rBYtnU4HS0tLkMvljBytr6/v+dp4PD6VEW0WiwXxeJz16w6KRgYFMna7HQKBYOJWMsOG2+1GMBjk5NonT55kbS0hpgcJ4BFkbW0NL3zhC/G9732PKQJ57LHHmO9Ho1HWi0BuuOEGfOxjH+NksQoGg7DZbLwv2ONEIBDgRF5/40zh+AkJLr1VjTYHQjWYWdtqtZhzeX6/H1arFVqtFmKxmDmXZzAY4HK5EA6HkU6nUa1WmXN504xIJAKj0cj773zYOGoCOEmLloEc6fV6iMVi+Hy+XdWxbFex7hdmsxmJRILTe9TrdUYA9Xo9Z5NGtsYkZxtJAI8mJIBHgC984QvMjE6LxYK3ve1tePGLX4x6vQ7gdBuYY8eOQafTwe1247LLLsNll13G6jPccsstuPrqqzlZrHb2d5ul4EpeP/GAHcdPSHCTYPIK49XVVZTLZSSTSUb8BvNQBQIBpFIp9Ho9HA4HgsEgkskkyuUyJy1/JolZE8B8Pn9kBJDNFi3VahUOhwNCoRAWi4U5OxeJRGCz2TgXQKPRiFQqxfl9ms0mRCIRotEo1Go1pFIpAoEAZ1XBNpsNkUiEBJBgIAE8AnzgAx/AS1/6Upx11lk4//zz8YEPfADJZJL5/qAR9Atf+EKcc845ePe7341KpcLqM9x555248sorOVvYZ2lrb2twMZ+2VF/BK78ixfETErgS5aHe0263Ua1WkU6nEQ6HmSktcrkcAoEAYrEYWq0WVqsVfr8fNpsNBoNh4nN504xoNAqDwcD7cwwbR00A2W7R0m63EQqFIJPJoFarYbVapyKAgzYuXN+nVqsx4/MGY9cGDZYtFstQ5yJHCa62tkkAZxcSQIIV7rnnHlxxxRWcLFaxWGymFvatEQ6HWW9N8p+mOI6fkOCv79BtO0/X6XRQr9eRzWYRiUTg8XhgMpm2ncvbOoovGo3uey5vFrOuJIDDB9sCOKju5UIuNjc3kUqlIJfLIRQK4fP5to0hYzv0ej2y2SznAlipVCCXy3d9fXV1lRFflUo1dtucnWEymZBMJjn5WU6dOsX3EkSMAQkgwQoPPvggLr/8ck4Wq0QiAb1ez/uCPU5wkb38wD0mHD8hwdcescHn88FqtUKj0UAkEkEgEEChUMBoNMLtdiMcDiOTyaBWq41UfMGFuHIdsyiACoWCl3uzLYDT6NEXDAZhNptht9uZ1iqlUon1IgqtVot8Ps+5AB7UO7Hf/23bnEHRiMvlmmhuMJeZTRLA2YQEkGCFRx55BJdccgkni1UqlYJWq+V9wR4nxpWS1dVVlEolJBIJpiJXp9Ph0ccl+KMTYhw/IcEjUh0cDgdCoRBSqRQqlQpr5/JmraVKt3s6U7y4uMj7cwwbuVzuyAhgKpXivEdfMBiE2+1Gv396ezgYDEIqlUKj0SCRSLDWTkWj0aBQKHAugKO0zmk0GvB4PBCLxdDr9UilUiP/vDqdDrlcjgSQYCABJFhBJBLhwgsv5GSxymQyUKvVvC/Y40Q8Ht9XSgZNkdPpNJaWluB0OrG4uMicy5NIJNBqtbDZbAgEAkgkEvDHMjh+QoI/OiHBSpu7MWezVlDR7ZIAjhJsC2AymeS8R99ejYw3NjaQTCah1WpZK6JQqVQolUqcC+A4ldNra2uIxWLbikaG3Q7nUmxJAGcTEkCCFTQaDV7xilccuYVy0kgkEtBoNMhms1heXobb7YbJZIJSqYRQKIRIJIJarYbFYoHP50M0GkU+n0ez2dxzy3a13cHLv3y6ACRebHD23LO2ndrtkgAeFDsrva1WK+LxOGutRxKJBMxmM6fC5PP54PP59vxer9dDuVxmiihsNhvK5fJY28MKhQKVSoVzAZykcGacohGlUolyuUwCSDCQABKsYLFYcP7553OyePE5MWGY6HQ6aDabyOfziEaj8Pl8sFgsUKvVTCsVpVIJk8kEt9uN5eVlZLNZ1Ov1sZoi/69b1Th+QgJzpMjZzzRrMtXtHpxtPRMjl8tBqVSydr2dzbkHRUCDCSxisZiZwOJyuaBUKiGXyxEOh9HtTpYNnEaTZq/XO9Qki9XVVQQCAUilUmi1WiSTyZG2S+VyOarVKucCmEqlWDk3ubVaelA0stfvk8ufi5hNSAAJVvB6vXjRi17EyUJZKpUgkUh4X7BXVlaYpsiBQAA2mw1arRYSiYRpiry4uAin04mlpSWk02ksLy9DpVKx+hx/930Djp+Q/P/svXmUbHV97t3KApVBhIUG9XpajVw1AcNNwHA01wmNN4aEBS6naFATl0FMNMv7ap9XjIoxAkogMb7OUaMSLsINNc/zPHXN8zzPXXN1NXA4z/vHcW93VVd117B3Dc3+rvWspd3VVbsGzu9Tv9/3+zz4L1uSsecajUY3bvBm0645nU7PBYCj/aHE55Aw56YOAU36skFMfmezWeh0OjKbd9R8eVpFIhHGTZp3d3dnSrLo9/vkDrxQKITX653qeFgoFKJarTIOgHRH2x03NCIQCFCr1VgAZIssFgDZoqVCoRBe8IIXMLJQlkol8Hi8pSzKRF9eIpGAz+eD1WqFRqOBSCQi+/JUKhUsFgtpilwoFNBoNCYu8nQD4Cd+et4E+nvKEGOvwyZOXp8kABzNUx71bRz3OZzWnLvVaqFaraLT+c0uEZHNS0zXznp8Gg6HGffoczgc8Pl8M/8dcVxqMpnA5XJhsVhQKpUmPj8+n496vc44AEYiEcZ2TccNjXC53LkB/yg9+eSTq15+2JqzWABki5bKZDLY2tpiJOe1UqmAw+HQdt+ji6vD4YBOpyOPyng8HnlU5nK5EIlEkMvl5jJFZqLP64uPO7G9I8A9HA9jcBKPx6FSqRiHIDq1adCaTqchkUgORe0Rlj5cLpdsHaDmKU/qD51W4wCQEHW6VqVSTR1RFgqFYLFYGAUmYmd9kftoNBpwu90kQI+bpmUKlMa9ZkxDM3VohMPhYHd3l3YPRRYAN7dYAGSLlqpWq9ja2iIXFjpVr9fB4XBmypel9kOFw2E4nU4YDIYhU2SZTAaDwTC0uI4zRV5ETOS93i/0YXtHgM8+bGcMTjbReicWi60ltLbbbTKFhTrtTbQOUKP2qJY+TOUpHwWAhHq9HqLRKGQyGcRiMYLB4JG3DwaDsFqtjMKM1WpFMBik5b6I5yeXyyESieDz+dBqtTAYDMDhcBiLY6MqEAgw/ppRny+Hw4HRaKQ9aYQFwM0tFgDZoqW63S62traQyWRoX7AajQY4HM7YY9a9vb1DOyjUfiixWAytVgu73Y5AIIBkMolyuczY4jqqQqEAoVBI630SOcAPSQKMXXcymYRCoVjKa0SXVr1rube3h1wuh0gkcmgQiPqFg0hhCQQCtA6BTCsCAKdJlxgMBshms9BqtUf2CQYCAdhsNkYhxmKx0J5lOxgMkM/nSTCyWCzkaQPTUObz+WC325cCgN1uFxwOB71ejxwaEYvFkEqlE4dGptVTTz216uWHrTmLBUC2aKmzZ89ia2sL4XCYkYWVw+EgHA7D6/XCarVCrVZDKBQe2kGZtR+KaRWLRVoHWNrtNq6/R4rtHQF0QeamgJPJ5MZ5Ly4DAMf1iFI/iyKR6NAg0KQvHKlUivb+0Gmfw7QASNVRfYLEziaTEGMymRAOhxm7/729PTidTnA4nJmOv+fVOF9DptRqtcDhcIaeD11JIywAbm6xAMgWbXXRRRfB5XLNvSgRx2Tjmt45HA4ZCO92uxGNRpHP5+fqy1um6B5gcSfL2N4R4LV3i7DXZG4Xc1VwsogIQ+BF72fU1me0fWDUuzESiSCfz08cBFq313heAKTChMfjIfvoksnkUEoHUzIajYhGo4w+BrFTFgqFyONvv9/PyI7gUb6GdKvRaIDL5U78/SJJIywAbm6xAMgWbXX55ZfDbDYfubCO8ymj9uXJ5fKhYzKiL4/L5aJUKq0cMmZVpVIBl8ul7f5+rAlje0eA932X2Zi2eS1KVqlZ+xZHzZGJuD2qrQ+1fWCeTOWjtKqEm0UBkFCv10MkEoFMJgOfz4dKpVr4Po+SwWBALBZjFJTa7Ta5UzYYDJDL5WAwGMDj8WCz2RbK4h3V7u4uPB7PUgCwVquBz+dP/Z7OkjTCAuDmFguAbNFWV199NVQqFWKxGOLxONkLRZ1sHPUpm3ZhFQgEKBQKK4eMWVWr1WidYP7Uz63Y3hHgPoGX0evexPSVcQA47ksHdeKbao7sdrsRi8WOtPWhU6sGwF6vRwtcDAYDmEwmiMXihf0Ej5JOp0M8HmcUlIij0tHhiHq9DqfTCT6fD41Gg1QqtfDxsN1un8vWZh5VKhWIRKKZ3tNpk0ZYANzcYgHwhNa9996Lra0tfPaznyV/NhgMcNddd+HKK6/EJZdcgttvvx3lcnnux/D5fHj00Ufxj//4j7jjjjtw+eWX47LLLsPW1hYeeOABaDSaQ5ON8/bliUQi5HK5lUPGrJpngnmS2u02bvy6DNs7Asi99A/bUJXNZmmfXmZSzWYTfr8fYrF4bnPkZWtVfZZ0A+DBwQHcbjecTicqlQqsVuvcfoJHSavVIpFIMApKxx2VdrtdhMNhWlJUrFYrAoHAUgCwVCpBIpHM9bfHDY08/fTTdCxZbK2gWAA8gWWz2fDKV74Sb3jDG4YA8M4778QrXvEKKJVKOBwO3HTTTXjTm9409+P88R//MW688UZ8+MMfxj333INXv/rVuP/++5FOp2lftCQSCSMTxkyLGGChY0cpUahhe0eAV+4IUNljdsBlHeP3jjNH5vF44PF4c5kjr0KrBMBarUYrAI72s43rE1x0x4zYeWMSlOr1+lRHpcR0tF6vJwcoZk0PMZvNjA61UJXP5yGTyRa6j0lDIywAbm6xAHjCqtvt4pprroFcLsdb3/pWEgBbrRYuvPBCPPbYY+RtQ6EQtra2YDabaXnsG264Ab/85S8ZWbRkMhlSqdTKF+1Z1Ww2weFwaBlWKdUa2N4RYHtHgGKN2SPKfD5Pu33NtKJG7s1ijpxIJDbKuuYkAeCknF5qnyDhJzhvn6BarUY6nWYUlGq1GgQCwcx/QwxQaLVapNPpqWB3GUMthLLZLJRKJa2vE/GcA4EALesHW8svFgBPWN1xxx34+7//ewAYAkClUomtrS00m82h2586dQoPPvggLY/9R3/0R/jRj37EyKKlUCiQSCRWvmjPs9hyOBzUajVa7u8NX5Vge0cAR5zZgRgm/AupmmSOTETuzWOOvGnWNavyWmQKAI8aaBgMBshkMsf6CR4lpVKJTCbDKCjN2itHVbfbRSgUgkQigUQiOdY8W6/XM97TSCidTkOtVtN+v71eD91ul5b1g63lFwuAJ6geeeQRXHvttRgMBgCGAfDhhx/GRRdddOhvbrzxRnzhC1+g5fHf9a534dvf/jYji5ZarUYsFlv5oj2riKlCOhJSovkaXvnrHcB4gR6gnCS6/AtnNUeeN3Kv02EBcFoxAYAOhwNer3dqyJqnT1ChUCCXyzEKSov0yhEiYFen04HH48HhcKBWqx26nVarRTKZXAoAJhIJ6HQ6Ru777NmztKwfbC2/WAA8IZXNZvGSl7wEHo+H/NmyAfDWW2/F/fffz8iipdVqEYlEVr5ozyMej4dyubzw/fybLIjtHQFu+46O8WsulUrg8/lTAwVd5siLaFVTtfNqVUfWTAHgrBOtzWZzpj5BuVyOfD7PKCgVi0VIpVLa7q9Wq8HhcIDH40Gn0yGTyZCwu4wjbULRaBQGg4EFQLaGigXAE1JPPPEEtra2cMEFF5Da2trCc57zHFxwwQVQKBSMHwF/8IMfxD333MPIoqXX68nps00Tn8+nxcPwfz2kwfaOAD9S05+2MqpyuTxkYL0sc+RFtGnm1ScJAO12O/x+/1x/S+0TJI5Ox/UJSqVSFAoFRkEpn89DLpfTfr+dTgfBYBASiYScpFUoFMhms0sBwHA4DLPZzAIgW0PFAuAJqU6nA5/PN6QbbrgBH/nIR8ig8wsvvBCPP/44+TfhcJjWIZCPf/zjOHPmDCOLltFoJC0XNk10eBh6U+cTQF59RoB0qc7YtRLmyIFAABwOZ+nmyIuIBcDpxAQA2my2hS1NxvUJUk2IJRIJSqUSo6CUzWahUCgYu//9/X2k02lotVpwOBwYjUbU63XGATAYDMJqtbIAyNZQsQB4got6BAyct4E5deoUVCoVHA4HTp8+jdOnT9P2eHfddRc++9nPMrJomc1meL3elS/a80gkEiGfXyy3936BD9s7AvzFD4wLXw9hjpxOpxEMBuFwOA6ZI8vlcnA4HHg8nqWaIy+idDq9cQBIR3TdrGICAK1WK4LBIG33R+0TNJvNKJVKEIlEKJfLjIJSJpOBSqViHMgODg4gFovJlBG9Xo9sNkubZ+KofD4f7HY7I/f9zDPP0LaGsLXcYgHwBNcoABJG0FdccQUuvvhi3HbbbSiVSrQ93uc//3l88pOfZGTRslqtcLvdK1+055FYLEY2m53779vtNt76TSW2dwT4pWH6QZhms4lCoYBYLDazOXK1WqU1wWQZ2rT4Orqyi2cVAYDTZr1OI4vFglAoRDtcUPsEuVwuAoHAwn6CRymVSkGj0SwNAMvlMtrtNgKBAMRiMWQyGcLhMO2Reh6PB06nkwVAtoaKBUC2aKsvf/nLuOOOOxhZtOx2O5xO58oX7XkklUoXMrG2RovY3hHgv98tOuT/d5w5MtFgP6s5MhFhR/egBpNiAXA6MQGATJsa93o98Hg8iMViSCQShEIhRnKHE4kEtFrtUgBQKBQOmUcTRssajYY8AqfreNjlco31aWQB8NldLACyRVvde++9eP/738/IorW7uwuHw7HyRXseLWpi/aDYj+0dAT7yfd3M5sjz7uAREXbrmqIxTpuWX3ySANBkMiESiTAKTHw+n8x1JvoEXS7XUJ/goorH49Dr9UsBQD6fPxHwKpUKbDYbeDweDAbDxBzeaTXPlDYLgCe/WABki7b6l3/5F9xyyy2MLFoulws2m23li/Y8UigUSCaTx95ukjnyn9x33vvv//mhYGZz5HlFZ4TdsrSJAKhSqZb+uM1mk3YAXEaqBY/HGzKPHtcnuGgPXTQahdFoXAoAcrncY+G13W7D7/dDJBJBJpMhEonM1btJx5DOJJ07d27VSw9bcxYLgGzRVj/84Q/xzne+k5FFy+PxwGKxrHzRnkdKpRLxeJz8/7OYIweCIbz+SyJs7whgixaXds2NRoMFQIa1DAAk+kCJnWPisyYQCLC7u0vb7pnBYEAsFmMUmIjP4+jPqX2CarUaqVRq7j5BJu1SqBoMBmSLxTS339/fRzKZhFqtJnc+Z0lSMZvNjPRosgC42cUCIFu01S9+8Qu8+c1vZmQh8/v9MJlMK1+0pxXVHFkikUCj0cxljmyOFLC9I8C1Xxaj2VreQAadGcbLUjabhVgsXvl1TKtYLEYLABJT3ZlMBqFQiJzqHu0DJXaOY7EY4vE4zGYzuFwuLBYLKpXKQhDAdKzZNMDU6/UQDochlUrn7hMMhUKwWCyMA2C/3weHw0GnMzkqbtLrUC6XyZ1Po9GIfD5/7M4nkzu0LABubrEAyBZt9fjjj+MP/uAPGFksg8EgDAbDyhft0YV3GnNkoVAIvV4/lznyt2UBbO8I8Jc/Wi78EhnG9TpznoN066QDYKvVQrlcJhNXRj0aqVPdR/WBUo+AG40GnE4n+Hw+dDrd3L1mOp0OiUSCMWDa398np9KngaR5+wQDgQBsNhvjANjtdsHhcBay4mm1WvD5fBCJRJDL5YhGoxPvj0lAZwFwc4sFQLZoK5FIhNe//vWMLJbhcBg6HfMRaONEmCPH43F4vd6ZzZF1Oh3C4dnTO9rtNm5+QIXtHQF+qGI+/WP0sTkcDmo1ZjOH6VQulzsRANhoNJDP54daBEa/VJhMJrjdbkSjURQKhZmGdcb1AHY653fZhUIhlEolEonETMeoTOfa9nq9uXbMyuUyLBbL1H2CTPrlUUX890WHpU2/30cikSD/TXK73YeAV6PRMPb+sLW5xQIgW7SVWq3Gq171KkYWy2g0Co1Gw9hiPI05slKphNlsntkcWa/XIxgMznxNumAe2zsCvPZuEfLV5fbiEQtUtVpd6uMuolwuB5FItPLrmPb1DQaDkMvl5Odt1L6HGPihtgjQ4ct41BBIv99HNBolY9lCodBUu1RMAsbBweI7Zs1mE263+9g+Qa/Xi93dXcYBkGixoNP4eTAYoFQqkcBrMplQKBQwGAygUqmQyWRYAGRrqFgAZIu2slgsuPrqqxlZMOlqmF/EHHnex5wnxq7dbuP93zNge0eAzzxsXwmkcLlcVCqVlTz2PFpHAKT2ghK7x9TPG5fLHbLvyWazjB+7TzMFPBgMkE6noVarIRAI4PF4juy/U6vVSKfTjAFTp9MBh8NZeHL5uD5Bt9sNl8vFOADu7e2Bx+Mxdv/NZhNerxdCoRAKhQIikYgRAHzyySdXveywtUCxAMgWbeXxePCiF72IkUUrmUxOnZvKlDnyvDKZTPD5fDP9DdeRwvaOANd8UYhQdjW7cDweD+VyeSWPPY/y+fzKAJA62T2uF1ShUMBkMpG7x8ViEeFwGGq1eunXOosNzGAwQLFYhNFoBI/Hg8PhGOtdp1KpGAVAoieVrhQQAnAJ02WiT9DpdDJmmExVrVaDQCBg/HH6/T7i8Ti4XC74fD48Hg+azSYLgGwBYAGQLRorFovhoosuYmTRGpfzSvRKLcsceV4RoDnt7VOlOm74Rxm2dwT4GtezEqDpdM4DYKlUWtnjz6p8Pg+hUMjY/RMRedQvFhqNBiKRCBwOB0KhkJzsHtcLOqoWlNqjAAAgAElEQVRoNLr2ADgKLXa7HTweDyaTCaVSifydUqlk7Ijx4ICZI1NC1D5BqVQKm83GWCYvoUqlApFIxDgAEhKJRIhGo+Tkt9lsRrFYXPh5sgC42cUCIFu0VT6fx9bWFq07aYQ5ss/nA5/PJ82RqYvussyR59UsOcbNVhsf/P75o9+3fVOJcn11SRx8Ph/F4vK8BxcVXQDYarXIoZ9xbQJSqZT0aQyHw8jlcnPZ5TDd1zrxM7agEXSr1SJ99zQaDTKZDORyObLZLGMA02g0wOVyGYWkZrNJfoFc1E/wOJVKJUgkkqUBoEAgQK1WI19L4v0jPErn/SywALjZxQIgW7TV3t4etra25to1Os4cWSKRgMvlLrzorkJ2ux0ul2uq235L5CMHP3bjq919EwgEKBQKK3/9plWhUJgJAInPHGHho9frIZVKxw79EG0CdH6xiEQiKwXAReGm1+shFApBLBaT/23SmS5CFdM9c4RsNht8Pt/CfoLHqVAoQCaTLQ0AR1NUiPcvFotBoVBAKBTC6/VObUxN6Kmnnlr1ssPWAsUCIFu01f7+Pra2tibm3lIb4n0+H6xW69TmyMViEXw+f+WQMY8cDgd2d3ePvZ3Cm8WrzpyPffu5Prry6xYKhcjn8yu/jmlVKBQgEAiGfkbtB6XG641+5ggLHzqGfqbVpgMgof39fYhEIkgkEohEInLgiU6AqdVq4PP5jIOSxWIhEzMm9QnS8Ti5XA4KhWIp8EeYaE/q/RsMBigUCjCZTKQx+LSxeiwAbnaxAMgWbXXu3DlsbW1BpVLhscceg8/nG9pZofqYGY1GuFyuqc2Ry+UyuFzuyiFjHjmdTjgcjiNvkyzW8Qdfk6106ndUIpFoYwCw2WwiFouBx+PB4/Ec6gcl4vWIz9w67CCfFAA8ODiATCZDPp9HLpeDTqcjgYmugYNqtQqhUMg4LJlMJoTD4UM/H+cnuMjjZDIZqFSqpQDgLKkjjUYDLpeLHJQ7zg+SBcDNLhYAT1B997vfxXXXXYfLLrsMl112GW666SaIRCLy94PBAHfddReuvPJKXHLJJbj99ttRLpcXekwOh4N/+qd/wh133IE//MM/xIUXXoitrS1cddVVeOyxxyaaI8+qWq1GJgGsGjZmlcvlgs1mm7wgt35j+XLzAypU9lbX90eVWCxGLpdb+XVQRSSvhEIh7O7uQq/Xk16NPB4PHA6HHLpZx35QqlYFgI1Gg3YAlEgkKBaL5P+vVCokMFmtVlSr1YXuf1lDE8dFpk3rJ3icUqkUNBrNUgBwHg/FXq+HaDQKuVwOkUgEn8839niYBcDNLhYAT1DxeDwIhUJEo1FEIhF88YtfxIUXXgi/3w8AuPPOO/GKV7wCSqUSDocDN910E970pjct9Ji33XYbPvjBD+KrX/0qHnnkEVx11VWQSqW0L1p7e3vkMcaqF+5Z5fF4YLVaJ/7+PoEX2zsCvO5LIriT62O7IpFIkM1ml/64xOBPMpmE3+8/1CpAJK9QvRprtRoKhcJGtQlEIhFotdqlPy5TADhuV4ywVuHxeNDr9VPl1o5TqVSCWCxmHJamjUxbNHc4kUhAp9MtBQAXsdAZDAbI5XKkDZDVakW5XCZ///TTT9OxdLG1omIB8ITXFVdcgR//+MdotVq48MIL8dhjj5G/C4VC2Nragtlspu3xXv7yl0Mul9O+aBE2EKs+tptHXq8XZrN57O+kngxeuXO+7+9hY2zl1zp0bVIpMpkMY/dPmHJTbXzkcjl5bEttFYhGo8e2Cmxan2g4HD4xACgWi4fAYFSdTgc+n4+MmksmkzM9frFYXMrU7KyRdvv7+3P1CUajURgMhqUAIF0T1Ht7e3C5XODz+VCr1Ugmk+wU8IYXC4AntM6ePYtHHnkEF110EQKBAJRKJWnRQq1Tp07hwQcfpO1xr7nmGvB4PNoXLeJb7CZl0xLy+/0wmUyHfp6r7OF/fE2K7R0BPvfI0T2Cq5BMJkM6nV7oPoiIvUwmg1AoREbsjZpyU218iMGfWR+rVCqxADiFmABAkUiESqVy7O36/T4ikQi5cxYOh6c6mlzW1KxGo0EqlZrrb2fpEwyHwzCZTEsBQLoHaIjdT5lMBo/HQ9vawdbyiwXAE1ZerxeXXHIJLrjgAlx++eUQCoUAgIcffhgXXXTRodvfeOON+MIXvkDb41933XV49NFHGVm4Ni2ajFAgEIDBYDj08wfFftLvr7omfX9UyeXyiRPdo2q1WiiXy+SEt8ViIcPpiWNbImKPKVNuFgCnExMAKBQKZ+rz29/fRyqVgkqlIi1I2u32xNvncjnI5XLGYYmOzNxGowG3203ulKXT6UOvdSgUgsViWQoAMtU/ORgMMBgMaFs72Fp+sQB4wurJJ59ELBaDw+HAmTNncNVVVyEQCCwNAN/4xjfiP/7jPxhZuPh8/kYlUxAKhULQ6/VDP0sUavj9X+/+/dKwXke/hBQKBZLJ5CF4yOfzY/0aiQlvk8kEt9uNaDSKQqGwtL7NUqnEyO4zUzpJAEg1Gp4VIgqFAgwGw5FRc9lsdim2KQqFgjZDa2KnTCKRHNrtDAQCsNlsSwFAJk2nz549S9vawdbyiwXAE14333wzPvnJTy7tCPitb30rvv/97zOycAmFwo0yJp600KdLdbzjWyps7wjwR/cpsNdcrylV4thWIpHAZrPB4XAcylIm0leofo2rntAul8sbBYChUAg6nW7pj8sEAPL5/LHgNotqtRpsNtvYqLll2abI5XLk83la73NcnyBhDbUMAMzn84wdn7MAuNnFAuAJr7e//e346Ec/Sg6BPP744+TvwuEw7UMgf/Inf4KHHnqIkYVLLBavZCp1UVEjv3KVPbz7QTW2dwS48R9lCGRWd6RNNeb2er2wWCxDkWdcLhcKhYLMUs5ms6jX6yt/PSeJBcDpxAQAjkuamFeE1Qqfz4dGo0E2m0UqlYJarWYclqRS6ZCdDd0qlUqwWCzgcDiQyWRHDs7QpWw2C6VSyQIgW4eKBcATVGfOnIFWq0UqlYLX68WZM2fwnOc8BzKZDMB5G5hTp05BpVLB4XDg9OnTOH36NK3XcPvtt+Mb3/gGIwuXVCpdeChhFYrFYlCpVCjVGvizf9Vie0eA//E16dIsXxqNBhmz53Q6YTAYIJPJyGNbhUIBk8kEj8eDWCyGYrGIZrMJlUqFWGw9j6fHadPMwk8SAHK5XNpSMgh1u10Eg0GIxWKIxWJIpVLGsnkJicXihU2ep5HNZoNKpSIhd1yfIF1iEp5ZANzsYgHwBNVf/dVfYXt7GxdddBFe/OIX4+abbybhD/iNEfQVV1yBiy++GLfddhtKpRKt1/CRj3wEX/7ylxlZuORy+aGetE1QIpGAQqHAh35gxPaOAG/4qgQOmnN+2+02qtUq0uk0AoEA7HY7NBoNRCIROBwOhEIhGbM3rTG3Wq1GNLr6SLppValUNg4AR3tDlyEmAPCoqLFFtb+/D7vdDh6PB7FYjEAgQHs2L6Fpp5kXlcPhgNfrPbJPkC4x6Tn4zDPP0Lp+sLXcYgGQLVrrE5/4BD7/+c8zsnAplUrE4/GVL9yzKplM4ks/lWB7R4DX3i2COTJ/HyORixyPx+HxeGA2m4eObaVSKfR6PZxOJ8Lh8EKRZxqNBpFIZOWv37RiAXA6NRqNhfv1qCKyZsclRdCleDwOnU6HbDYLrVZLe9QcoXmHWWYVkXdO/H+iT1CtVoPP58PtdtP23Jj0HGQBcLOLBUC2aK3PfOYz+Nu//VtGFq5N25EilEim8Dt3nzd7/o48ONXf7O3tIZfLIRwOD+UpE5FnSqUSZrMZHo8H8XgcxWKR9sgzrVaLcDi88tdvWlUqFTLzdBMUDAaXCoDEZyoQCMDn89G2i7a/v0/GNDIFTKMQUy6XYTabweVyYbPZaIM2OoZZppHFYkEwGBz7u1KpRD43i8WycJ9gOByG2WxmAZCtQ8UCIFu01pkzZ/DXf/3XjCxgmwYkhDzhBLZ/nfZBnfhtt9uoVCpIpVLw+/2w2WzQaDRk5JlIJIJGoyHzlNPpNKrV6tKmbXU63Ua93tVq9VkPgMQEdzqdRjAYPNQKIBKJoFaroVQqIRAIjvXfm0b9fp983ZkCpkgkAqPReOjne3t72N3dBY/Hg8FgQKFQmCtqjhATvYzjZDabEQ6Hj7xNo9EgkzcW6RMMBoOwWq0sALJ1qFgAZIvWuueee/DhD3+YkQXTYDAgGJxuB22dZPXHsL0jwKvOCGB2uGAymaBQKMjIM5lMBoPBAJfLhUgkstCxLZ3S6/UIhUIrv45pRQDgqu1optUiADj65YHISyaMtyUSCfR6PXZ3dw+1Auzt7aFer6NYLJL+e06nc+4jx16vxzgAHreL1W63yag5lUqFVCo1Mywt4yibkMFgQDQaneq23W4XoVAIEokEUql05j5Bn88Hu93OyPM4d+7cqpccthYoFgDZorW++c1v4r3vfS8jC6bJZILf71/5wj1J9Xod2WwWoVAIu7u70Ov1kEgkeOIJDm78Ch/bOwLc+6gGXq8XiUQCpVKJ9mNbOrVpwL2JADguIYYqasIKkSmtVCrHfnmY1nibAEBiEa9Wq7BYLODxeLDZbDMfgXa7XXA4HNqHF6iaNjmj1+uRUXNSqRSRSGTq61rGUTYhnU6HeDw+098Q6SkE6E/bJ+jxeOB0OlkAZOtQsQDIFq31ne98B+95z3sYWTAtFgu8Xu9KF+12u41yuYxkMjm080Ic24rFYmi1WjgcDgSDQaTTacQTKVz/5fMA+NmH7SsHj2llNBoRCARWfh3TqlarbRQAUiMCieGeWCwGt9sNk8k0lLBCtepZtOdzFAAJ7e3tweFwkEbM0/aedTodxgEwEAjMdIw5GjXn8/mOBTtiJ5OpCWOqNBoNksnk3H8/S5+gy+WC2+1mAZCtQ8UCIFu01r//+7/j7W9/OyMLps1mg8vlWsri3Gw2USgUEI1GhxZkYudFLpfDaDSSOy/5fB6NRmN4oW228O+aCG76JxnZA/i//49j5eAxrdZ9x3VUBACu864qNUpPq9VCJBKRwz18Ph9KpRIWiwU+n4+xhJW9vb0jTZtbrRZpxKzT6ZDP54/sq2u32+BwOOj3+4wBE9EjO+vfjUbN7e7uTnzunU6H8edBSKVSIZ1OL3w/4/oER98rh8MBn8/HAiBbh4oFQLZorf/8z//E6dOnGVk8HQ4Hdnd3abu/druNer2OTCaDUCgEh8MBnU43FHmmUqnIBTmRSKBcLk8FGJFcFf/zPgUJftd+iY9/kwdR3VtOLi4dMplM8Pl8K7+OabVOALi3tzfUDjD6uVKr1VCpVJDL5UilUksd7pm0AzgOiPx+P9lXNw4uCGDkcDiMmjT7fL6Fo9Oq1SpsNhu4XC7MZvOhXbNlPA9CdGYOHxwc3SdIeH+yAMjWaLEAyBat9cQTT+D6669nZOFyOp2w22c/QqX2Ufl8PlitVqhUKrJhXiwWQ6fTweFwIBQKIZPJoF6vz70gp0t1vPV+JbZ3BPiDr8nwrxIvfvV/N+dokpDZbF75kfssqtfrSwXASRO31CluajvA6OcqEAjAaDQu/XWaFgAJUc2K5XI54vH4ECQ1m01wOJyFpm+Pk8fjwe7uLi331Ww2yV0zrVaLbDaLwWCwlOdBSCaT0Z45fHAwvk/QYDAgFAox8jzY2uxiAZAtWksqleK1r30tIwuX2+2G1Wqd+HvieC0ajcLlcsFoNA71UcnlcphMJrjd7qkb5ufRl/6vC9s7Apz+hhzRfG3pYEKXLBYLPB7Pyq9jWhGvM93vKTFxS+37pH6BICZuZzXfXiUAzpPbu7+/j3g8DplMNpRa0Wg0wOFwGAUmt9tN+yBDt9tFIBCASCSCQqFAIBAAl8tlHP4ODg4gkUgYjZwbDAZknyCHw4FKpWIkd5itzS4WANmitXQ6HU6dOsXIwuX1emEymYZ2XRwOB7Ra7aHjNavVCr/fz1gf1VG6+QEVtncEeMyaIBdcDodzqEdw3WW1WuF2u1d+HdNqUQBstVoolUpHTtxS+z4X/QLh9/s3CgCpcJFOp8kBC5fLxTgAMjnI0O/3EYvFyF7MYDDI+CDIsiLnDg7OD5zo9foj+wTn0ZNPPrnq5YatBYsFQLZoLbvdjpe85CULL1Kji7HFYoFYLAaXyz3kcxYKhZDNZlGv11cOIflqg+z7y5TP7wIRR0vr4O03i5Y5dEOHCNA+DsqazebQxO3oTrFCoRhKWWHKrmdTAZAKgvl8Hmq1GhwOB263mzEPPafTCY/HwygoVSoVEpKIODamns+yIucIAEylUgv7CbIAePKKBUC2aC2/34/LLrts6sWo0Wggl8shEonA5XLBYDBAJpONtb8gLFeYOLalS65ECds7Alz3FQn5M6K5fB0AdRbZ7faNBEBip5U6cet0OmEwGIYmbqkDPqvYKV4VANbrdVrjzur1Omkdw+Px4HA4aE/TcDgc8Hq9jIJSuVyGWCzGwcF5mxXi+dAZNUeIx+MtJXLu4OD8xHEmkyH//7x+giwAnrxiAZAtWiuZTOKCCy4YWnDa7Taq1SrS6TQCgcCheCqhUAiNRkMGpKdSKVQqlUOLMWGdsWrQOEpKXxbbOwK89ZvKoefP4XBQrVZXfn2zyOFwwOl0rvw6jhMxcev3+8HhcIZaAoRCIdRqNTkJuew4vaPk9/thMpkYu/9Wq4VWq4Vms4lGo0EOfxDqdru0TLzWajUIBALyf9tsNvB4PFgsFlSrVVogxm63M2ZlQqhUKkEikQz9rF6vk96IdETNHRz8JnFkGZFzBwcHkMvlyOVyY69jkdxhFgA3v1gAPGH1jW98AzfccAMuvfRSvPjFL8att96KcDg8dJvBYIC77roLV155JS655BLcfvvtKJfLCz/2wcEB1Go1rr76atx111245ZZboFAowOfzweFwIJVK52qWJxSLxaBWq1e+cB+lx6znc39v+45u6OdcLhflcnnl1zeLdnd3abXdWUTUiVvqlwiqAbdGowGHw4Hf7ycnbld93UeJLgA8DvTq9Tr29vbQaDTQbDaH1Gq1FgbBarUKoVA49LNGowGn0wkejwej0bjwwAOTViaECoUCZDLZ2N+12214vV7SGmqRPjoicWQZkXMHBweQSqUoFotH3mYaP8FRPfXUUwuvGWyttlgAPGH17ne/Gz/96U/h9/vhdrvxnve8B6dOnUKv1yNvc+edd+IVr3gFlEolHA4HbrrpJrzpTW+a6/HOnj2LP/uzP8NrXvMaPPe5z8Ull1yCyy67DO9617vw6U9/GqFQaKHUAqoSiQSUSuXC98OkvqcMYXtHgL/+iWXo53w+H6VSaeXXN4ucTiccjuUaV0+auCW+RFAnboncZOqR7yb1Wvp8vpkAcFbQI/6b63a76Ha76Pf7Q+p2u2i32wuDYKVSgUgkmghOHo8HAoEAWq0WuVxuLnCyWCwIBoOMglIul4NCoTjyNlRLHKlUimg0OrNx9DITRw4ODiAWi6fe2ZulT5AFwM0vFgBPeFWrVWxtbUGr1QIAWq0WLrzwQjz22GPkbUKhELa2tmA2m+d6jB//+MeQyWSkn9bW1hbi8TjtC2YqlYJcLl/5wn2UPvh9A7Z3BLhP4B36uUAgQKFQWPn1zSKXyzWX7+K0MFMqlRCPx8mJW4VCcWjidhbLnpMCgMdB3qygd5xGQbDT6cwEgtTeuaPAgrBcUSqVSKVSM4Gg2WxmzMuOUDabhVKpnOq2+/v7SCaTUCqVEAqFZGLONH/b6SwvceTgYL6BE2qUnkAggMfjOdQnyALg5hcLgCe8YrEYtra24PP5AABKpRJbW1toNptDtzt16hQefPDBhR/v3LlzuOCCCxgxEM5kMpBIJLTfL10KZCrY3hHglTsChLLD/X4ikQj5fH7l1ziLXC4XbDbbQvcxGqnH5MTtpk1be71eGI3GuUBvVsibFwSngZRxvXOT1O/3EYlEIJFIIJPJEIvFpoJNk8mESCTCKCil02mo1eqZ/oaYhNbr9eDxeHA6ncf29hFDYcswnD44OD9wMu/U92ifoNVqJe1rWADc/GIB8ATXM888gz/90z/Fm9/8ZvJnDz/8MC666KJDt73xxhvxhS98gZbHvfTSSxcGh3HK5XIQiUQrX7gn6d/kQWzvCPD+7xkO/U4sFiOXy638GmfRccbbVFGnuZ1OJ/R6/aGJW6vVSk7cjhvyWVQEAK5b79+kHT2fzweRSIRQKIR6vb400JsFBJvNJtrt9pEgWCwWIZVKZ95hSiQSUCgUEIvFCIVCR1qSGI1GRKNRRkEpmUxCq9XO/ffVahVWq5UcqJjk89doNJZmOE0MnMwz5TvuuqkJKsVikZb1gq3VFQuAJ7juvPNObG9vI5fLkT9bBgC++MUvZmRat1AoQCAQrHxBn6SP/tiM7R0B/lUaOPQ7qVSKTCaz8mucRR6PBxbLcC/jaHby6MStRqOB3W4nJ25rtdrSJm5XDYCzHt02Gg2y34rYDVsV9E0Dgq1WC/1+/9CO3VHDE9MASiaTgVqthlAoJLOnR2+n1+sRi8UYhaVEIgGdTkcrKOl0ukN9j/V6HXw+fykA2O/3weFwxr6m84roE0wkErSsF2ytrlgAPKH16U9/Gv/tv/03JJPJoZ8zfQRM3JdUKqV9gS2VSuDxeCsHo7GLf7uN674iwfaOAMbQ4aNemUyGVCq18uucRsTErcVigVKphM1mOzRxS81OXhcT7mX5LU4ziDHL0W2320U0GoVUKiUHCzYJBPP5PORy+UJQMRgMUCgUyMQKl8s1tGul0+mQSCQYhaVYLAaDwUDb/XU6naGouUQigf39/bFT00yp2+2Cw+EsZPg8SU8//TQt6wVbqysWAE9YnTt3Dp/+9Kfxspe9DNFo9NDviSGQxx9/nPxZOBxeaAhktF73utfhiSeeoH3hrVQq4HA4a+HhNipH/LwB9Ou+JMJe83APm0KhQDKZXPl1UkWduPX5fLBYLEMTtwKBACKRiJy4zefzax1nRwBgrVaj7f6mmbil6+i22+0iFouRWbuRSGTtQLDT6QwdDfd6PWSz2WOnZ2dRpVKB2WwGj8eD3W5HvV6HVqtFMplkFJYikQiMRiPt99vv9xGNRiGTySAWi+F0OidOTdMtJvsNWQDc/GIB8ITVpz71KVx++eXQaDQolUqk9vf3ydvceeedOHXqFFQqFRwOB06fPo3Tp0/Tdg3XX389HnnkEdoXeCLrlYlYrkX1/V/bv3zw+4f7/zqdDpRKJRKJxMrAiJi49Xg8hyZu5XI5OXEbi8XIidtVJVUs8jxnBcBprVWWOYzR6/UQj8chl8shkUgQDofR6XRWDoCjMNhsNrG3t4dgMAiFQkGLqTRV9XoddrsdPB4PAoGAcR/AcDgMs9nM2P0Tx91yuRwcDgcej4dxL0Am+w3Pnj1L25rB1mqKBcATVltbW2P105/+lLwNYQR9xRVX4OKLL8Ztt92GUqlE2zWcPn0aP/nJT2hf4Ambj3XchXrfd/XY3hHgIcnh/r9OpwO1Wo1YLMboNYybuKXG6imVSpjNZni9XiQSiWMnbgOBwEYBIJG4Mg4AZwE96g5Xp7O6YYxer4dkMgmFQkEOi3Q6qwHBbreLcrmMRCIBj8cDk8lEfrb4fD6sVistptLj1Gw2IRKJwOPxoNfraUnjGKdgMAir1cookB0cnPcblEgkMBqNQ7ucTDxWrVZjrN+QBcDNLxYA2aK93vGOd+C73/0u7Qv8umbqxvI1vHJHgO0dAcK58XFvGo0GkUiElscjJm7D4TA5cSuRSMhjW2Li1u/3LzRxGwwGYTCM39FcRxEAWC6XZ9rRa7fbc3voLQsEU6kUlEolRCIRAoHzXzKYAr1KpTIEeoRtDzHNTaRyEGkrvV4P3W6XBGwmQFCpVJKtCgKBAGq1GplMhlYQ9Pv9sNlsjAMg1W+QGjVnNBpRLBZpfU5HmXSzAMgWC4Bs0V633HILHnjgAcYW+HXL1CXsX0bj36jS6XTkUd60GjdxO5qfbLfbEQwGGZm4DYVC0Ov1K399x2nSjh6Xy4Xb7Ua1Wh3a0Wu1WmsPetOAYDqdhkqlIs2HCYuWRUDP6/UeCXrpdJoEvWnulwkQpObZ9no9hEIhiMXioeGKRR/D5/PB4XAwDoDj/AZbrRaZmKJWqxeKmqNqFo9GFgCffcUCIFu01/ve9z58/etfZ2Th5/F4a5ep+ycPabC9I8CP1JMBT6/XIxgMHvp5u91GtVpFKpVCIBCAzWYjLTGoE7e7u7vkxO2yjI7D4TB0uslQu0rQm2StEo/HySGKcDi8sbB3HAgS1ikCgQA+n4+czJ0F9Hg8HrlbPCvoLRsEZTIZ8vn80M/29/cPDc30+/Ona3g8HjidTsYB8Ci/QQJuCWugeaLmqKJjQnuSnnnmmVUvNWwtWCwAskV7ffSjH8Xdd9/NCBAIBAIUi8WVQx+hYPZ8+sdv/79CZMqTwcxgMMDlck2cuJVKpTAYDGs1cRuJRBjxc6QD9I6KPyOGKGQyGaRS6dr569EJgrlcDlqtFnw+Hw6HA9FodKmgNw0I0pE3LJVKUSwWx/6OiC2jHpHPk7PrcrngcrkYB8B4PA69Xn/kbahG2SKRaKaoOapmibdjAfDZVywAskV7/c3f/A0+97nPMQIK6xapZgzlsb0jwOlvyEmQoU7cmkwmKBQKcDgccDgcyOVymEwmcuK2WCwem3G7SgDUaDS0g96ycm4JWxWpVAqZTIZ4PL4U6GEaqAjrHiJDmZgqpX7GPB7PUkFvVhDsdGbLG5ZIJCiVSkfeZjAYkEBM5Ne22+2pH8PpdMLj8TAOgNFodGq7GeI56XQ68Pn8qaLmqEqlUjPH27EA+OwpFgDZor0+97nP4VOf+hQjUCKRSNYiUYOYuBWYvNjeEeD3vyo8cuLWYDDA4/Gs/LpnUTQahVqtXjroMQEf0WgUEokEcrkciURiLTiZxngAACAASURBVKBoHtCjfr6IQR8q6I2aKTcajZU/l0kgOE3MHCGRSIRyuTw1nJRKJXLKdlpocjgc8Pl8jAPgvHYzlUoFFovl2Kg5quhKN2EB8GQWC4Bs0V533303Pv7xjzMCJctO1Dhu4vZnXMWvAVCMVCo1ceLWarXC7XavHOpmUSwWg0ql2hjQmwY+IpEIJBIJacy9ahCcFfRqtdpU11wsFmEwGEgA2tvbWzn8LQKCQqEQ1Wp1ZkipVquwWCzg8Xiw2Wyo1WoTb2uz2eD3+xkHwEXtZhqNBpxOJ/h8PvR6/aGoOaqi0Sit6SZUnTt3btVLDVsLFguAbNFeX//61/GhD32IESghpv7ovM92u01O3AaDwUMTtyKRaOLErT1WPA+AXzs6+s5ut8Plcq0c6mZRPB6HUqncONCbBj7C4TBEIhGUSiXS6TTjIMgU6B2nUqkEk8kEHo+H3d3dtQVB6sBIv384b1ggEBwJb8dpb2+PtFsxmUxjdxOtViuCwSDjAOj3+2G32xe+n06nA7/fD6FQSNrkjL5uTJpbswC4+cUCIFu01z//8z/j1ltvZQRKVCrV3IbKkyZuBQIBOBwOJBIJOXEbDoeRy+WOnbh1Js5HwF1/z9EA6HA44HQ6Vw51x4kKesSxaaVSWVkqBpPqdM5b3YhEIqhUKmQymYWhq9vtolqtDoGeQqFgHPSOU7lcPhSvturXf/R163R+EzM3CoI8Ho8Ws+RWqwW32w0+nw+dTod8Pk/unpnNZoTDYcYB0Ov1Ynd3l7b76/d/EzVHTL8T2b9MmluzALj5xQIgW7TX9773Pbz73e9mBFCmMVRut9tkagExcatUKsmJW5lMRk7lLjpx606Wsb0jwHVfkRwNik4nHA7HygFvHOhNmrgtlUpQKpWk5xwxxblqWGACBAOBAIRCIdRqNbLZ7LFQRgU9n893JOilUqmlgd5xIvrIqEeiq76mo0CQyBvmcrkzDT8cp263S+6eqVQqpNNpGAwGRCIRxgHQ7XYzMm08GAxIj0GBQACv1wuXy8WYtyELgJtfLACyRXv97Gc/w1ve8hZGwEWv15ORWK1WC8Vi8dDELTXj1mQywePxkBO3dOcI+9LnbWBe9yURWkeYMLtcLtjt9qVD3qI5t0QKBZFLG4vF1gJkmFC73SahQKPRIJfLTQV6Fotl7UDvOFWrVVitVvB4PFitVlSr1ZVfE1W9Xg/VapX8b5swgKc7Zq7X6yEcDkMikYDP58Nms9H+GKNietp4MBigWCzCaDSS/w4yETXH1uYXC4Bs0V6PPvoo3vjGN9IGMs1mE/l8njzmkMvlQzmkxCJMTNyWy2XaQW+Sao0Wrv2yGNs7Akjck6eTPR4PrFbrykFv3pzbXq+HWCxGTtKmUqmNAJ1pRYBeKpWCx+MZsu7hcrkbC3rHqVarwW63g8fjkZOly3z8Xq+Hvb09sv/WZrOR/pijX+IajQZjecP7+/uQy+UQiUSHjlHp1rKmjQ8ODmCxWMgvxSaT6VgrHRYAn13FAiBbtBePx8O11147M8js7e2RE7e7u7uHJm7VajWkUin0ej1SqRSq1Sqt0Wfz6gu/2sX2jgB/8x+TAY/oB1sW6DGVc0sdoFCpVMhmsyuHmFmBgwA9oj2AWCB5PB4UCgUJevF4HLu7u+DxeNDr9SgUCiu/fqZEzaQlhiTofoxms4lcLodQKAS73Q6NRkP238pkMhL0EokEKpXKoc8s03nDWq0WiUTiUNxepzO7AfNRIiL2lgGABGxSo+Y0Gs3COcpPPvnkqpcZtmgoFgDZor0UCgVe85rXjIWY0Ylbu91+aOJWq9XC4XAgGAySgfME6Fmt1rXz07NGz08Cv+aLk9NA/H4/TCYTIzt6q8i5JZ6TQCCATqdDsVhcOcRQNS3o+Xw+8svEpB09YvHk8/kwGAxr91zp1N7eHgm9RqMRpVJp5vtotVrI5/OIRCLY3d2FVqslow0lEgkMBgPcbjfi8ThKpRI6nc5M908FwWazSRsIEhm8Bwfnj1Hz+TxpwOx2u9FqtWjblQuFQksBwFHY7Ha7ZI6yTCZDLBZDvz971BwLgCejWABki/YyGo142cteht3dXTzxxBPw+/2wWq2HJm71ev1ME7edzvraqfyvX+cB/3+Kw3m/nc75IQOj0TgX6FH785YNetMs9m63m9w5WsURIgF6fr9/CPS4XO5Y0Jv3tWs2m3C5XCQcMbFLti4ivOZ4PN5E6G232ygWi4hGo6RHplgsJjOs9Xo9nE4notEoisUi6fVHl+jeEVQqlchms4d+Xi6XSSsdh8OBvb29haDMZDItZdjk4OD8ZPM42Nzf30c8Hiej5maNz2MB8GQUC4AntLRaLW655Ra89KUvxdbWFp544omh3587dw7/8A//gKuvvhrPf/7zcfPNNyMajc71WIPBABwOB/feey/+8i//Eq9//etx4YUX4rnPfS6uvfZacuI2Go2iUCgsFH22u7uL3d3dlQPfqH6oCmN7R4CbH1AdOpZutVoIBALQ6XQL59yuqxqNBnmEaLVaabcZ6fV6qNVqQ6CnVCqHQM9sNtMCerPA0Sqgd5lqNpvkcyVg2mAwkK0ZQqEQWq0Wu7u75EQ9YeGyLC0aM0dIoVAgl8tN/H2tVoPNZiP7Jecxpj44OIDBYEAsFlsKABqNRkSj0Ym/HwwGyGazZJ60y+VCs9lkAfBZUiwAntASiUS4++678V//9V9jAfC+++7D5ZdfDg6HA4/Hgz//8z/Hq171KgwGg5kfq9vt4g1veAM+8IEP4J577sFDDz2EK664ApVKhXbQcrlcsNlsKwe+UeWrDfz3u0XY3hFA688cgrxoNAoejwe3241arbaxoHecarUaOV26u7s7cxTZLKCXTCYZBb3jRD0uNZvNGw+ChFl1IpEgp+plMhnZgysWi8HlciGTyRAMBtFsNld+zaPXvwgIymQyFAqFY283bnd0Figjeg2XAYB6vR7xeHyq2xJekVwul5wMn3Tbp556iq6liq0VFguAz4IaBcBz587h6quvxre+9S3yZ61WC8973vPwyCOPLPx4mUwGW1tbjAxoeDweWCyWlcLepGPbu/7Dgu0dAT77sG3sjl4mk4FSqYRYLD7Rdir9/nnjYaPRCD6fD4/Hc2hXaJNA7zhRUyaInaFVX9NRIo7NqdY2RCoJn8+HSqWCzWYje3D39vbIz2qr1YLX6yWHCabxTFy25s0blkgkM03JttvtQ6/FNIMVarUaqVRqKQCo0WhmfizqFxu9Xj9kls0C4MkqFgCfBTUKgIlEAltbW3C5XEO3e8tb3oLPfOYzCz9etVrF1tYWqtUq7fDl8/mmHqZgCvQmHd0qvBls7wjw+n8Qo9oc3+/U6/WQSCQglUqhUChoSZ9YZ+XzeahUKnIxMZvNGwt6x6ler5OWKutgstzr9VCv15FOp8k+XOK1H5dKUq/Xp/4stlot+Hw+0jx7HT/Hk0Bw0q6gWCweGxF3nLrdLoLBIBktOC6SjSoidWYZALjIYxH/3o6LmmMB8GQUC4DPghoFQKPRiK2tLRSLxaHbve9978P73//+hR+v2+1ia2sLmcxkX7x5FQgEYDAYVgp6k+LPer0e/uf9SmzvCPBzQ/zYxSkYDJJTtPNMW66TiB29cbDB5XIhkUggEAhIs91yubyxoHecqMfgy4hdm8ZLb7Q/ki5Yo5pnE4ka6wqCx+UNC4XCufv6Dg5+E8kmlUohlUoRjUbR7x/eeTyu15BOyeXyhR+r3+8jEolAKpWSHon7+/sLrxNsrb5YAHwW1LIB8OzZs9ja2kI4HKYdAEOhEHQ6HSOgR0fO7b/KgtjeEeDWf9NNdXvqFC0TwxNMwMZRoEfAhtfrRTKZHPJz6/V6SCaTkMlkkEqliMfjawcLdKparZKxa8T06KL3uaiXHlPqdDpDu2DraBQ+Lm+41+uRIMjn81Gr1RaGrv39fSSTSSgUCojFYoRCoSFT6Wl7DemQVCqduUfxqOeVSqXIFgG2Nr9YAHwW1LKPgAHgoosuYsSuJRKJQKPRrBz0JildaeDVZ4TY3hHAk56+F6xer5O7Ri6Xa+mTlKM66vjwONCbZiGORqMQi8VQKBRruWtEpyqVCsxm80yDMYSXHmGKTreXHlMivqQR720ikVi793ZS3jCPx1vY4oUqYsKWgHSfz4dOpwOxWExrIsdRmvdY+7jnNc+wIFvrVywAPgtq0hDIAw88QP6s3W7TNgQCAJdffvnCyRfjFI/HoVKpaMm5ZUof/8n5YZAvP+GZ+W9LpRJ0Oh0EAgGCwSDj10oFvUAgQCvoTQMLwWCQzN7N5/MrhwMmRfWTczqdaDQaK/fSY0qdTofM2JXL5YjH42t35E8Mw8RiMbjdbsbyholsXoPBAD6fDx6PN9ZvkAkJBAJadjVH9fTTT9OyTrC12mIB8IRWt9uFy+WCy+XC1tYWHnzwQbhcLmQyGQDnbWBe9KIXgcvlwuv14tZbb53bBmZcXX311VCpVLT051FBj9g5KpfLtOXc0i2h6/wwyPX3SNHqzHcN2WwWCoUCEomElqPScaA3LnOVCdA7TsQ0JZ/Ph16v3/h+yHHqdDoolUqIxWKwWq3kbt44L71CobDyHWC61O12yf4xInliFf9dNhoNZLNZskdSrVaTn31iEMnr9TKaN3xwcIBKpQIulwsul0v2hzIJgHTvarIAeLKKBcATWmq1GltbW4f00Y9+FMBvjKB/67d+C8973vNw8803IxKJ0Pb4r3rVqyAUCucGvUk7euVyGWq1GkKhEKFQaKWgN0ntbhev+5IY2zsCBLLzT4L2ej3EYjGIxWIolUrkcrmp/mZa0Ft2n9hxopoOm83mtbdTGafjvPQ0Gg3sdjtCoRDC4TBpwDvOKuckqdvtIhaLDQ1IMPG5a7fbKBQKY2PopFIpjEYjPB4P4vH4SvKGDw4OwOVykcvlSOsgwkOSbkgjDPrpirCj6uzZs7StFWytrlgAZIuR+t3f/V08/vjjc4PeUTm3vV4PqVSKtFKZBoyWrXc8oML2jgBy7+LX1un8JnfXYDCgUqlsNOgdp729PdJOxW630zI8Qbdm8dLLZrNDXnqjKhQK5LG/1+s98SAYj8chl8vJidJ5PpfdbhflchnxeBxut3sonUQkEkGn0y10dM4UCBJQRqRttFotuFwucve7UChM5SU4jfr9PjgcDjqdDguAbI0tFgDZYqR+//d/Hz//+c8ZzbntdrsIBAIQCAQwGo1rtWP0oR8Ysb0jwH+aEgvdDxX0vF4v5HI5OBwOuFwuOBzORoPecapWq+TwBBFRtexrGB2GoRpWL+qlN6p8Pg+tVksODGxKv9+8r2sikYBcLicnZccNslANw8eBtlqtJndUc7kc7Z+R0XSRRUFwf38fHA4H7XZ76OedTueQr+KiINjpdMDhcIYmkFkAZItaLACyxUhdccUVeNvb3oZYLMZ4zm2z2SR3jNZhgrbf7+OOH5un8gOkLnT1eh2ZTAaBQGCslxth8REMBqHX68HlcuHxeE40KPT75wdj9Ho9+Hw+vF4vI8+X6qU36fVnyktvVLlcDhqNBkKhEH6//0S/v4Q1kFwuh1AohN1uh9/vJ19/qmG4xWKhBbTnEV15w91uFxwOB91ud+zve73eoSnqeYGz1WqBw+HQtqPIAuDJKxYA2WKkOBwO3va2t+HKK6/Egw8+uJRFrFwuQ6fTQSgUzn20RJeISeCf6KKHFryjQG/Uy+0ow+RisUiCQigUOjE7f5OUz+fJ/s9gMDi39cm6eumNfk6y2Sz5fAOBwNpYvSyqVqs1sU+PGJDQ6XSIxWJrt6M9DgT7/eNj5gi1221wOJxjoW5/fx+xWAwymQwSiQSRSGSmxzk4OJ9ZzOVyaYe/g4MDPPPMM6teYtiioVgAZIuxOnfuHAQCAa655hpcd911EIvFS1k4qf2B2Wx2JQvF//4/u9jeEeArj9lI0KNOHs4Cesc933Q6DblcDplMhmQyuXa+a3S/v+l0mpyQPmqYYBYvvXK5vJaARTxfpVIJkUg08ah0HdXpdFAul0mbFb1ef2SfXqfTQa/XQyaTIcF3XXdA580bbjabM+3KDQYDpFIp8v0PBAITdw9HVavVwOfzWQBka2KxAMgW4/Xkk0/i/vvvx2WXXYbbbrsNwWBwKf9AE1FrBoOBsf7AcTFcarUan/4uH9s7AnzoX0Qk6BGgwcSOBmG3IRKJoFarUSgUVr5IMqler4d4PE7ai/j9fkQiETidTuh0uhPhpTf6fFOpFJkuseod7tFrIwZivF7vxMnncDg8dZ8esQNK7M6u63DMKAhOipkjtLe3N9eu3GAwQC6XG5oaH+0jHFWlUoFIJGIBkK2JxQIgW0urUqmEj33sY7j44otx5syZpQxtNJtN0m7B6XTOvYhMAj3q0SHVYuK7Mh+2dwT4+E8sS12QOp0O6alnMpnWajCGjudGeOmNTn5yOBzw+XwYjUaEw+ET5aVHFbVnjjgaXBYIjvZJUk3DqQMxgUAAmUzmyMnnWR6TAB+BQACPx7OSYaDjNC0I0rErVyqVYDQah5JlJt1OIpGwAMjWxGIBkK2ll81mw0033YSXv/zl+NnPfraUI8tKpTJVfyCxyI2axk4CvUlHhz83xLC9I8BHf2xeyYLUaDRI8HU4HFPFj62LRr30jEbjRC89Ykep0+mQE+FarfZZsQNKTNEy4atHPT53OBxj+yQJ0/BqtboUCM3n8+QwkNvtXlsQHBczR4BgpVKBUCikBcJqtRoZH2m1Wg8lfuTzecjlchYA2ZpYLACytZJ65pln8Itf/AIvfelL8aY3vQkGg2Epi2Y6nYZMJiNTCQjQs9vtc4HeJP3SGMf2jgAf+ZFppQtStVqF0WgkJ2jXqX+s2+0OHR0u4qVHqNVqwePxkLuBlUpl5c+TSVGPwqVS6cypMdRdVZfLNTaKzuVyIRaLrU3mcKFQgMFgGIrUW/U1jVO32x3aEez1eigWixCLxbTCWKPRwO7uLng8HoxGI5kznM1moVQqGQHAc+fOrXoJYYuGYgGQrZVWt9vFmTNn8IIXvAAf+9jHkEqlaF8gqTt6BOjxeDxwOBzweDxotdq5QW+SHjEnsL0jwF/8wLjyhajf/80ErUgkWuqxIfEejHrpKRQKRrz0CFEXRavVinq9vvL3gElRkzZkMhkSicTQazgK2+P69BwOB8LhMPL5/EYcn48eha6jYTjx2jebTdTrdYTDYUilUkZi5qhffoh/01QqFQuAbE0sFgDZWouKx+O49dZbcfnll+O+++6beQGaBHrEjh4RA0Wd+qzX6yQk7O7u0nqk9CtrEts7Arz/e8zvbM7yGiWTSUilUsjlcqTTaVqP39fJS49QvV4nj8mIfqlVvw9MikiNEQqFEAqF0Gg0Y2Gbzj69VatcLsNkMpHtDquGfeoXnnHm1VarldG8YcIgn8/ng8/nI5VK0e4FyALgySgWANlaq5LJZPid3/kdvPa1rwWHwxn7jysBeoSP21GgN82xVaVSgV6vh0AgoM1PT+7LYXtHgLd/S7XyBXJU3W4XoVAIQqEQWq0WxWJx5vsY9dIbPT5fBy+90feY2C1yu90bscO16HugVCrB5/MXilzbJFUqFTI5xm63LwUEqb2SxHsw+oVndGd7GXnDBwcHCIfD5LCQTCZDPB6n7XFYADwZxQIgW2tXTz31FB566CG88IUvxE033YS/+7u/w2233Yavfe1rQ6BH9XGjoz8pk8mQfnqL7o4FczVs7wjwui+J1naHpd1uw+PxkIH0tVrtyAVuU730qCoWi2Turt/vX/vr7ffP7+oVi0VEo1HS5kYkEk31HnQ6HYRCIYhEIiiVStp3fddR1WqV3PW12Wy0TMKPZg+P65WkvgfTwDbTIBgOh2E2m7G/vz8UuxcOhxeOh2PrZBQLgGytVT3yyCN485vfjCuuuALPec5z8MIXvhDXXHMN3vnOd+KXv/wl443o3W4X4XAYQqEQer1+7iGCZruL7R0BtncEyFXXb1qRqr29PVgsFjKBwW63n0gvPaqy2SxUKhVEItHa7I6Nm36WSqXgcDjkbu3u7i4ikcjMNjedTgfBYJDMms1msyceBGu1Gmw2G3g8HiwWy1T/LU/qV52UPUzHTjLdecOEgsEgrFYr+f8Hg8GQybbP50On02EB8FlcLACytVZlsVjw85//HA6HA/1+HwDgcrnwlre8BVdffTW+//3vL2WxbrVacDqdZF/RLP2B+zkfnvn2DXjwnr8DvvLCiXr6sU+g31yuT99RXnpE3xiXy4XRaEQ2mz0RR6WTRPXUm2eCdpHHnQQZPB7v0PRzo9Gg7boIuxyiPzCXy514EKzX62RWuNlsJkGQiKQbZ3Uz2q+6jOxhuvKGCfl8PjgcjkM/HwwGKBQKQ5Y6rVZr6vt98sknV7xKsEVXsQDI1kbUuXPn8Ktf/QqnTp3CDTfcAI1Gs5TFo1qtwmAwQCAQIBgMTobPXu9I2DtK/dbho1c6FpNJu0mTvPSIv83lclAqlRCLxYjFYiceEHq9HmKxGCQSCRQKBVKpFG3PeVyf3qShmFqttrTXut1uw+fzkb6J+Xx+5e8DUyL+WwiFQlAqleT0PxFJt25WN6MgOG3M3Kg8Hg+cTueRtymXy2TfpMPhwN7eHguAz6JiAZCtjap+v4+vfOUruPjii/EXf/EXiMfjS/lHOZvNju8P7HbmBj9yJ/CX719osaDbS6/f/42/HAFFq8pUXvbCSwzHqNVq5HK5qf+23W6jUCgMxdEd1ae3DkfO/f75XTCv1wuBQACdTrfRBtqjU+iTdlYJGxxip3ueIahlfR7nyRsm5HQ64Xa7p7ptvV4fOi6vVqssAD4LigVAtjayMpkMPvCBD+DSSy/FPffcsxR7D2p/oE6nQ7lYWBj+8JUXYhDTT7W4LdtLr9//Te8YAQjlcnnlCyPTou6O6fV6lEqloc8AdRhg9Ahdp9MN9eltSq8k1UNOr9evLRRR3yMCuHd3dycmlRy1s9poNOByucDj8aDX69cWfgkQpA6M9PuT84YJORwO+Hy+mXYNm80m2fpiMBhQLBYPWciwAHhyigVAtja6tFotrr/+erz61a/Go48+upQjtFarBZfLBc+/f3Zh+Dv7g3cM3fc6eulRn/OzxViZSG0wGo3gcrkQi8WQSqVjhwGy2exaxpLNo2azCbfbDT6fD4PBMAS/q9C4VgYCuEUiEXQ6HTmcNO/xLfU563S6tT0OH42ZOw4EbTYbAoHAXP2D7Xab3BnWaDTIZrMkCD711FOr/mefLZqKBUC2Nr7Onj2LH/zgB7jqqqtw8803kwMkTGsvqFsI/joB2UZ56fX75xvqLRbLifHT6/V6aDQaQ9nPKpUKPB4PXC4XCoUCRqMRKpUKXC4XJpNprF3OSVOz2SSB32QyMb7zS7wPxBcfq9UKpVJJ7nCPtjIwAdzNZhMej4fsi1zXAZnj8oYJmc1mhMPhuYdIDg4O0Ov1EAwGIRKJoFAokEwmcXDATgGflGIBkK0TU41GA5/5zGfw/Oc/H3fddddSvskfmH44E/S5zRpoNWrSS2/Uz3ATvPT6/fMxXDqdDkKh8OjhmDUSMfVJHBtSPQ0JA/GjgLtWq5Hw63Q6T8yu31GiRupRJ2gXUbvdRrFYnPg+EMe3yWRyaTvco5+T0d2vdQTBfv9w3jDVQsZoNCIajS4EgIT6/T6i0SikUinMZvOq/6lni6ZiAZCtE1eBQADvete7cNVVV+Hb3/72UoCq16whZlPA+J/fRPzHn4BTzYVa+Bh+8fOfnVgvvV6vh0wmA4VCAalUeih/dpWL4qQ+vdFjw3neh3K5DIPBAD6fD6/Xu/Hv4zTa29uDw+EYGhKY5vNBDCiN8zUcfR/W7YtPu90mY/XUavVam2iPM5XW6XSIx+O0ACCh/f19tNvtVf8TzxZNxQIgWyeyzp07By6Xi9/+7d/G7/3e70EqldL2j+1xXnrE/9ZoNEilUht/THqcer0eotEoxGIxVCrVTNOziz5utVpFKpUaOwE9atpL945dPp+HRqOBUChEIBBYO4BhQlRPPavVSh6Hjx6jU49vqfnDdPsaLkPtdhuBQIBMU6HTJohutVotZLNZBAIB0saJ7pi5p59+etX/vLNFU7EAyNaJroODA9x777249NJL8d73vhfhcHjqf0wX8dKr1WowmUzg8/kbEzm2qDqdDvx+PwQCAQwGAy3Hhf3+4cEYan8Y0adnsVhon4Ce9toymQzpmxiJRDbiOHyR97hYLMLv90Mulw956lGP0Ynj25P0WhAT8dR+uFWBYK/XQ61WI7/8mEymQ6kxDocDlUoFzWaT1pg5FgBPTrEAyNazogqFAu644w5cfPHFuPvuu4ca+f//9u49LOoy7x/4IEdRQxAJV4XMdDUtrdUEM9y0sjXT9Clb043NytRKrUzNDpaFa6tbeVWWj9ljrj48pikDOEcGUATkfD6fz0c5zaB54v37w9/3u8NBRYGZYeb9uq77j50Zrr1hknlzHz6fvqql19r6n6LKSqXSqB8YhhyNjY3iubG4uDicP3++21+r33u4Y3cG4XyYEDBM5WKM8IFcUFAAlUoFlUplMtvhPfl+9P9NREVFQaVSdWpLl5aWhoiICEil0tt+r/vrEPory+VyqNXqPn+vhZI3wr8J/WLiISEh4upqSUlJp9XVvug3zABoPhgAyWJcu3YNv/32G8aNGwdnZ2fMmjULY8eOha+vb5/W0hO2SGUyGcLDw41eWsNQo66uTuwykJKS0u6snP42elJSEiIiIjr1Hjal7gzdHVqtFjk5OZDL5dBoNCgpKTH5ICh0K+nqFrT+9m1JSckN//ipqakR3+uEhASLCILCe61QKKBSqZCfn9+jP0hudmZSv2PJnRQT7802cwyA5oMBkCzCrl274OjoCBsbG0yePBmPPPIIpk6dijlz5uC3334zyId0c3MzkpOTtdWhtAAAIABJREFUERgYiNjYWIMUrzb20Gq1yM/Ph0qlQmBgIEJCQsSVJGEbPT4+HtnZ2SgvLzebm7Ude+6aQpFh/dB9o24lPS07VFNTg6ioKPGmtKX8Ny7ckFUqlcjNzb3lz66pqaldCaiuQndflLzpjSB49epVY/86p17CAEgWoaCgABkZGe2KmLa0tOD999+Hg4MDXn31VZSUlBjkA6O+vh7R0dFmdT7wZuf0hNVVodyHJZyVE4Z+h42zZ88apJOK/vmwtLS0dtu3Quju624l1dXViIyMRGBgIJKSkswm2N9saLVa5OXlQaVSQaFQICcnB83NzeI54o4XxuRyuVgCytC1PnvSZo4B0HwwAJLFy83NxbPPPouhQ4di165dBru1W15eDo1GA4VC0a/OjAmrF9nZ2YiLi7thG66u6rgJ22YymQxhYWEmsTJmiKHfYuvcuXO9Vkxa2L7VLyaufz5M/3LM7Zxd7a1RVVUllsxJTk426yCov5UeHh4uXo4RVvViY2PFC2OmUhngRkHwZquCDIDmgwGQ6P9TKBSYMGECJk6ciMDAQIP8AtbpdMjLyxPPB5pSD1bhxmdubi4SExMREREhbhn29Jye0GoqKCgIUVFR3aorZw6jvr4esbGxCAwMRHx8fLfPygm1DfXPTHbcvhWKiZvS5RhhVFZWIiIiAkFBQUhJSTGZAHQno2OdyY7vhX5B8czMTKjVasjlcmRlZZnsav/t9BtmADQfDIDUI1evXsVHH32Ee+65Bw4ODrj33nuxfft2tLW1ia9pa2vDxx9/DHd3dzg4OGDu3LnIzc014qxv7PLly/jqq6/g5OSEBQsWIC0tzSC/gJubm5GSkiLWVzPkIfrulLvRP6fXmx/eDQ0NYl25hIQEs14h0h/6Z+X0W+rpdDrU19eL27f6N9L7+r0wxCgvL8eZM2cQHByMtLQ0ky+iLdQ3FI41hISEdKozeav3QqfToaioCBqNBjKZzKRrRnbVb7hjm7lr164Z+9c09RIGQOoRPz8/DBs2DMHBwSgqKsKxY8cwePBg7NmzR3zNzp074eTkhICAAKSkpGDhwoUYM2YMLl68aMSZ31xNTQ1ee+01DBw4EBs3buy1mna3GkKv3aCgIKSlpfXqB4UQLoqLi5Geno5z586JH2j6/VaFgr2G3DKsqalBZGRkn3zfpjqampqQnZ0NlUoFqVQKuVwubt+q1WpER0cbpbahIUZZWZlYRDs9Pd3oQVB/hbXjBRn99nRFRUWoq6u7o/dCp9OhuLgYoaGhJvN93+zncaN+wwyA5oMBkHrkmWeewcqVK9s9tmTJEixfvhzA9dU/d3d37Nq1S3y+qakJ9vb28Pf3N+hc70RiYiJmzZqFESNGYP/+/QbbWquoqEBoaCgUCgXy8/Nv+wPnZmfDhHCRlpbWow+0vhjl5eUIDQ2FXC5Hbm6uycyrpx+mHbcMO5a8iY6OhlKpRHBwMDIyMkxuC7cvhk6nQ2lpKcLCwgzWTUX/spLwR1BXK6x9eUFGKB4ufN9paWkmvZIr9BsuLi6GTCaDXC439q9l6iUMgNQjfn5+8PT0RE5ODgAgOTkZbm5uOHz4MIDrt28lEgmSkpLafZ2Pjw/WrVtn8Pneiba2Nvj7+2PUqFF45JFHcObMGYN9QObn50Mul9/wwkRzc3O7c3pdlfYQzobdbu0wYw2dTofCwkIolUqo1WqT7sHacd4dV1hv1Jquqy1DYatQrVZDoVAgLy+vX3zfvfFzKykpQWhoKGQyGTIzM3slCHY8wyrcQhcuK+n/EWSMFVadToeysjKcPn0awcHBSE1NNYkg2NLSgpSUFBw+fBibN2/GM888A09PT0gkEowYMQJvvfWWsX8lUy9hAKQeuXbtGjZv3gwrKyvY2NjAysoKO3bsEJ+PjIyERCJBZWVlu6974YUXsHTpUkNPt0d0Oh0+/vhjODo6YsWKFSgoKDDoL2SpVIqwsDAkJCS0O6en35mhL1cuDD20Wi2ysrLE78+ULsjcqGNJVyustxsuhItBCoUCarXapHvP9uYQtkiFs3JZWVnd+oNFP3jrn5sUzrAK/zZyc3NRWVlpkscLysrKcObMGYPeltbpdKipqYFGo8E333yDV199FTNmzMDgwYNha2uLBx54AMuXL8eXX34JpVKJqqqqdme7qf9jAKQeEVbG/P39kZqaikOHDsHFxQUHDx4EYF4BUFBUVIQXXngBQ4YMwRdffNGrxW71a7ilp6cjOjq63Tk9YQUjIiICxcXFnVo/meNoamoSC2ifO3cO9fX1Bvv/Fi7ICNu3+nXc9Lsz9EXHEq1Wi+zsbMhkMoSGhqK0tNTo74UhhrASGhIS0qlmpLCql5OTg4SEhC6DtzHL3vR0VFRUiLelk5KSeu13i1arRWZmJo4ePYqPPvoIixYtwtixY2FlZQVXV1c8/vjjWL9+PX7++WckJCTg4sWLDHsWgAGQemTUqFH47rvv2j32+eef449//CMA89gCvpGwsDA8+OCDGDt2LI4fP37bqzzCDUP9FlzdOadXWVmJsLAwyOVyi9kmbG1txfnz58USKomJib26StLV2TD94K2/fVtWVmbQ28otLS1IT09HcHAwzpw5Y1IroX01hLZoSUlJOHXqFAIDA8WjDadOncKZM2eQmJjY71oFdndUVlbi7Nmz4n/r3a0KIKyGnjlzBt9//z1Wr16NWbNmwcnJCdbW1pgwYQKWLl0KPz8/BAUFoaysjJc6LBgDIPWIi4sL9u7d2+6xHTt2YNy4cQD+cwlk9+7d4vPNzc395hLIrVy5cgV79+6Fi4sLnnzySSQmJnb6pSw0cxdWLfTPIimVSrEF1+2c0xPOByoUCoSGhlpMQeXW1utdJiIiIsQLE7f74d/x/bhRIWtTuyCjvxIaFRVlsJvpfT2E90PYTu+qmHV0dDTkcjkUCkW3Wq2Zy6iqqhLLBZ07dw6pqanic0ILut9++w2ffvop/uu//gsTJkyAtbU1hg4disceewxr167Fvn37cO7cObS2tnJVj9phAKQe8fX1xciRI8UyMCdOnICrqys2bdokvmbnzp0YOnQopFIpUlNTsWjRIpMvA3O7zp8/jzVr1sDOzg4LFizAyy+/jJkzZ+Lnn38WtwuFVYucnBxUVlb2yjm9lpYWpKWlISgoCNHR0QbdHjX2KC0tFTupdLUS2rG+Ycft2/66itTQ0ID4+Hixp3R/ec+FVb3CwsJO9Sb1t9Nv9IeQ0GpNqVRCpVLd0e34/jiE29J+fn6wtbXFjBkzMGPGDAwbNgxWVla47777sHjxYnz66ac4ceIECgsLuapH3cIASD3S0tKC9evXw8PDQywE/eGHH+LSpUvia4RC0HfffTfs7e0xd+5c8dawOXjllVdw//33w9raGo6OjnB1dRUPUMfFxRlku/D8+fOIiYlBYGAgUlJSzOISSHc/HPPy8iCXy6FUKhEXF9epD7FQ3zAzMxOlpaVmU2y6rq4O586dE4to9+ZZ1J4O4ZKMUIYoNDQUgYGBYlu0mJiYO34/hJUv4ZJMf2qjeKsh3IAPDAyEn58f/vrXv2Ly5MmwtbXF4MGD4ePjgwkTJsDGxgbPPPMMkpOTuapHd4wBkKiHDhw4gKCgIBQXF6OtrQ1tbW04efIkxowZg4ceeghqtdpgHyCVlZUIDw+HTCYzy/OBQtmbrrbTT506BalUCqVSiczMzE59iM11VFdXi0W0Dd1m7WarrHK5vE9b1Al9peVyOUJCQvrVbWmdToempibExcXhwIED2LBhA5544gm4u7tDIpHA09MTCxYswNatW3H06FHk5OS0a8GWnZ2Nl19+udP5a6LbwQBI1EcuXryIL774AoMGDcLSpUuRm5trsA+XgoICKBQKaDQalJeXG/0D704+3G+0Xah/CaBjaY/GxkYkJiYapaWesUdFRYUYiPuiqLJQXFy4tNTVKqsxLskI5YJkMhk0Go3J1Y3U6XQoLy+HXC7Hl19+iRUrVmDq1KlwcHDAwIEDMW3aNLzyyiv4+uuvERYWhoaGBq7qkUEwABL1sfLycixfvhyDBg3CJ598YrAzW8LtUVM+H9jxNnTH7VuNRtNu+7a7ZW+Elnode+2a+xCKKms0mk4lVLo7Opa+0e9cIhQXT0lJQWFhoUmtsra0tCAzM1Msm1NSUmLQuel0OrS0tCApKQmHDh3C+++/j7/85S8YPXo0JBIJRo4ciaeffhqbNm3CkSNHkJGRgcuXLzPskdEwAJJJEirPdxxr164FcH11be3atXBxccGgQYOwZMkSVFdXG3nWNxcZGYlp06bB09MTR44cMdiHU0NDg1g+JTk52WjnAzt2Zjhz5ky729CRkZG9HiwqKyvFVbHuFhY2hyGcJVOpVFAqlTe8MCGE74yMDMTExIilb/Q7l2RnZ3fZucRUR0tLCzIyMnDq1CmEhYWhtLS01/+t6XQ6VFVVQa1W46uvvsIrr7yC6dOnY9CgQbCzs8OUKVPwt7/9Dbt27YJarUZNTQ2DHpkcBkAySbW1taiqqhKHWq2GRCJBWFgYAGD16tUYPXo0NBoN4uPj4eXlhZkzZxp30t1w7do1HDhwAG5ubpg9ezZiYmIM9sFYVVUlng/syz67+rc9U1NTERUVdcOuJb11G/pW8ykuLoZarYZSqTSrSwO3GsKFCZlMBqVSicTExE4tA5VKpVj6prCw0KRK3/RkNDc3i/UTw8PDUVZWdsc/w/T0dPj7+2Pr1q149tlnMWbMGEgkEri5uWHu3Ll45513cPDgQSQlJeH3339n2KN+gQGQ+oX169dj7NixaGtrQ1NTE2xtbXHs2DHx+aysLEgkEkRHRxtxlt3X1NSE9957Dw4ODli1apXBujzo99nVaDR3/KEojMbGxk7FrDve9szIyEBJSYnROzPodDrk5uZCLpcjNDS0X56N7M73eLOC1lKpFDKZDElJSWbTMvBWo7m5GWlpaWIh7RvVzBS68ISHh+Pbb7/FqlWrMHPmTDg5OcHGxgb3338//vrXv2LHjh2QyWSoqKhg0KN+jQGQTN6lS5cwbNgw+Pn5AQA0Gg0kEgkaGxvbvc7DwwNfffWVMaZ4x3JycjB//nw4OzvjX//6l8E+kPXPB0ZFRaGuru6Wr6+qqkJeXl6nFSSFQiFu3xYUFPT6bc+++N6F2olnz57ttwWVhfdE2FLXvxEtFLTu2I+4ubkZqampCAoKQkREBKqrq43+fRhqNDU1ISUlBQcOHICXlxd++eUXHDt2DJ988gmWLFmCcePGYcCAAXB2doaPjw/eeust/PTTT4iNjcWFCxcY9sjsMACSyTt69Cisra1RUVEBADhy5Ajs7Ow6vW769OntClD3JzKZDOPHj8ekSZNw6tQpg30oNjQ0IC4urt1lCaEXsbB9q1KpEBAQIG6lCdu3/X0FqbGxEQkJCQgMDERcXJxJ1dHTH0J7r+LiYrE/tFqtFt+Tjlvq3bn9q39bOjo6GrW1tUb/PvvqZ3f+/HmcPXsWP/zwA9auXYvHH38cU6ZMgY2NDRwdHTFnzhxs374dAQEBKC4uZhFlshgMgGTynnrqKSxYsED83+YYAIHrK527du3CXXfdhUWLFiEjI6PPA1BZWRmysrIQFRWFoKAgBAQEICAgQGzBlZ6ebhLbt305amtrxe8/NTXVqKFWuCjTsU2dfn/o9PR0FBcX98p7cv78efEPgLi4uH5dNkcofxQQEIDPP/8cS5cuxf333w8bGxvcddddmDlzJt544w3s3bsXkZGRKCwsxHvvvQdHR0dxd4HIkjAAkkkrLi7GgAEDEBAQID5mTlvAXamursbKlSsxcOBAbNq0qcerM/rbt0lJSYiIiGi3fatfrDczMxMKhQIhISE9Ph/Y30ZFRQXCwsIgk8mQnZ3dp9vYwqpeVyut+nUODdWmrra2FtHR0QgMDERSUpJJd0vR6XRobGxETEwM9u/fj3Xr1mHOnDlwc3ODRCLBmDFjsHDhQnz00Uc4duwY8vLybrqqV1VVhYKCAgP+CycyDQyAZNK2bdsGd3d3XLlyRXxMuARy/Phx8bHs7Ox+dQmkO+Lj4zFz5kyMHDkSP//88y1Xe/RDRVpamrhVKJVKxe3b+Pj4W5b10Gq1yMjIQHBwMCIjI812e/BGP8OioiKoVCqoVKpe6S7R3NyMiooKZGdnIz4+HmFhYQgKCoJUKhVXWoWLMt2tc9hXo6qqChEREQgODjb6aqjwfpSWluLUqVP4xz/+geXLl+PBBx+EnZ0dHB0d8cgjj+C1117Dnj17EB4ejsbGRp7VI+omBkAyWdeuXYOHhwc2b97c6bnVq1fDw8MDoaGhiI+Ph7e3N7y9vY0wy77V1taGI0eOYOTIkfDy8sLZs2fR2tqK4uJixMfHi71WuwoVwlahcAHgdj98GxsbER8fL64K9Zc6cL0xtFotsrOzIZPJEB4efsObox3Din75G/3uJTKZDBEREUhKSkJeXh6qq6tN+qJMeXk5wsLCcOrUKWRmZvb5CqRwQSUhIQEHDx7Exo0bMW/ePIwcORISiQSjR4/G/PnzsWXLFvj7+yMrKwtXrlxh2CPqAQZAMllKpRISiQQ5OTmdnhMKQTs7O8PR0RGLFy9GVVWVEWbZty5duoSUlBTs378fXl5esLa2houLCyQSCRYtWoSIiAhx+7avQkV1dbVYtLmvt0ZNbTQ3NyMlJQWBgYGIiooSV0ObmppQXl7eLoB3LH8jdC8x5e3UW4Wy4uJihISEQKFQIDc3t1fee51Oh8rKSiiVSuzevRu+vr7405/+BEdHR9jb2+Ohhx6Cr68v/vWvf0Gj0aCuro5Bj6gPMAASmbC3334bgwcPhre3N1atWoVPP/0UCxYsgJubG3bs2GGwcCGEAZVKBbVabbC6hcYeQk/i7OxshISEICAgQLwsI5fL2wVwUy9/05P3Pj8/H0qlEmq1GoWFhd1eUW5paUFqaiqOHDmCLVu2YMGCBbjnnnsgkUjg7u6OJ598Eu+99x4OHTqE1NRUXLp0iWGPyEAYAIlMWGtra5cH2ENCQjB58mSMHz8eJ06cMGggyszMRHBwMM6ePWtW5wP1b0XHxsa260kcGhqK2NhYJCcni8Wu09PT+3xr1JSG/ra4RqPB6dOnxcCr0+lQU1OD0NBQ7NmzB6+99hq8vLwwZMgQ2NraYvLkyXjppZewc+dOKBQKVFVVMegRGRkDIFE/deXKFXz77bdwdnbGvHnzkJycbNCwJNTQS0xM7FfnA7VaLWpqapCfn4/k5GRERERALpe3uxUtFLW+UU/isrIyhIaGQi6X92lbPVMcTU1N0Gg0cHZ2xsSJE/HYY49h7NixsLKywrBhw/DnP/8Z69atw4EDBxAfH4+LFy8y7BGZIAZAon6uvr4ea9asgYODA9avX4+qqiqDhYGamhpERETg1KlTyMrKMrktUKFVXUZGBmJiYqDRaCCVShEUFISwsDDExcXd8lb0jYZQd06pVCIkJAQlJSVmFQSFW+VnzpzB999/j9WrV2PWrFkYOnQoBgwYgMmTJ2P69Omws7PDjBkzoFarWUSZqB9hACSLU15ejuXLl8PFxQUODg6YPHky4uLixOfb2trw8ccfw93dHQ4ODpg7dy5yc3ONOOPuSUlJwZ///Ge4ublh7969BgtjHc8HlpSUGDysaLVaVFdXi7UO9VvVKZVKREZGIjU1FYWFhairq+vVoCZsiwv1+wwZwHvze8jLy8OJEyfw2Wef4fnnn8eECRNgbW0NJycnzJo1C2vWrMGPP/6I6Oho6HQ6cVWvuroab7/9Nl566SUj/wsgotvBAEgWpaGhAZ6envj73/+OmJgYFBYWQqlUIj8/X3zNzp074eTkhICAAKSkpGDhwoUYM2YMLl68aMSZd09bWxuOHz8OT09PPPzwwwgNDTVoiMjKykJwcDAiIiL6pMeu0NqrpKQEGRkZOHfuHEJCQsRVPaHWoTFa1TU1NSE5ORmBgYE4d+4c6uvrjR7suvr5NTQ0IDo6Gvv27cNbb72Fxx9/HK6urrCyssLYsWPx3HPP4ZNPPsFvv/2GgoKCbq/qcZuXqH9hACSLsnnzZsyaNeuGz7e1tcHd3R27du0SH2tqaoK9vT38/f0NMcVeceHCBXz22WcYNGgQli1bhry8PIMGIeF8YEJCwh3fVBY6mOTm5iIxMRGnT5/GqVOnEBAQAJVKhaioKKSlpaGoqOiOax32xaivr0dMTIzR6ycKK7NBQUHYsWMHli1bhgceeAC2trYYPHgwvLy8sGrVKnz33Xc4c+YMmpubGeL6oZaWFqxfvx4eHh5wcHCAt7c3YmNjxed9fX0hkUjajXnz5hlxxmQqGADJokycOBEbNmzA888/j+HDh2Pq1Kn47//+b/H5goICSCQSJCUltfs6Hx8frFu3ztDT7bHS0lIsW7YMgwcPxqeffmrQXq81NTU4e/YsgoODb3o+UFjVKy4uRnp6utjBJCAgAMHBwTh9+jQSEhKQk5ODysrKfnPztrq6WuyqkZGR0Wfz1ul0aGpqQlxcHH7++We88847ePLJJzFixAhIJBJ4enpiwYIF2Lp1K44ePYqcnBxcvXqVYc9MCD2PT58+jby8PGzbtg133XUXysvLAVwPgE8//TSqqqrE0dDQYORZkylgACSLYm9vD3t7e3zwwQdITEzEvn374ODggIMHDwIAIiMjIZFIUFlZ2e7rXnjhBSxdutQYU+4VEREReOihhzBmzBj83//9n0FXy0pKSqBWq6FSqVBQUICKigrk5OQgISEB4eHhCA4ORkBAANRqNaKjo8UOJufPnzeZVb2ejNLSUrGYcn5+fo++J51Oh/Lycsjlcvzzn//E3/72Nzz00ENwcHCAg4MD/vSnP+GVV17B119/jbCwMDQ0NDDombELFy7A2toawcHB7R5/+OGH8eGHHwK4HgAXLVpkjOmRiWMAJItia2vbqWXc22+/DS8vLwDmGwAB4OrVq9i/fz+GDx+Oxx9/HHFxcX0Wejr2JY6MjBS3b6VSKUJDQ5GYmIi8vDxUVVX1m1W9nvw88vLyoFAooNFobllIW6fToaWlBcnJyfj3v/+NTZs2Yf78+fDw8IBEIsEf/vAHzJs3D++//z4OHz6M9PR0XL58mWHPwrS0tEAikSAkJKTd448++ihmz54N4HoAdHJywvDhwzF+/HisXr0a9fX1RpgtmRoGQLIoHh4eePXVV9s9tnfvXvzhD38AYH5bwF1pbGzEO++8AwcHB6xZswbl5eU9CjfNzc2oqKhAdnY24uPjER4e3qkvcUZGBkpKSlBTUyOeD4yPj++3bdLudLS0tCAjIwPBwcHiKp1Op0N1dTXUajW+/vprrFy5Eo888ggGDx4MOzs7PPjgg1ixYgX++c9/QqVSobq6mkGPRN7e3pg9ezYqKipw9epV/Pvf/8aAAQMwfvx4AIC/vz+kUilSU1Nx8uRJTJw4EdOnT8fVq1eNPHMyNgZAsijLli3rdAlkw4YN4qqgcAlk9+7d4vPNzc397hJId2RlZWHevHkYNmwYvvnmm1uuwul0OtTW1qKwsBCpqamIjIyEUqlEQEAAZDIZIiIikJSUhLy8vFv2Ja6trRXPB2ZmZppc/cC+GlqtFunp6fD398dzzz0HOzs7uLq6QiKRYPjw4ZgzZw42bNiA//mf/0FiYiJ+//13hj26qfz8fPj4+EAikcDa2hrTp0/H8uXLMWHChC5fL/yR23HVkCwPAyBZlNjYWNjY2MDPzw95eXk4cuQIHB0dcfjwYfE1O3fuxNChQ8W/mhctWtRvysDcrra2NgQFBeG+++7DAw88ALlcjtbWVhQXFyMqKgpZWVmIi4tDWFgYAgMDIZVKodFoEBMTg8zMTJSWlqKhoeGOA5FwPk6lUqGoqMgszvwJYbmurg7h4eH49ttvsWrVKsycORNOTk6wtrbGxIkT8eKLL2LTpk3w8fHBwIED8cEHH+D333839n8S1E/pdDrx6MrSpUsxf/78G77W1dUVP/74o6GmRiaKAZAsTlBQECZPngx7e3tMmDCh3S1g4D+FoO+++27Y29tj7ty5yMnJMdJs+9bVq1eRlZWFw4cPY86cObC2tsawYcMgkUjw6KOPIiIiAsnJycjPz0dNTU2frNRptVrk5OSIhZSrq6uNHuDuZP7Hjx/Htm3bsGTJEowfPx4DBgyAs7MzfHx88Oabb2L//v2IiYlBa2trp1W92NhYrFmzhp00qMcaGhrg5OSEffv2dfl8WVkZrKysIJVKDTwzMjUMgEQWbOvWrXBwcMC0adOwcuVKbN++HUuWLIGrqys++OAD1NXVGSxINTU1ISkpCYGBgYiLizO584FCEeXIyEj88MMPePPNNzF79my4uLjAysoK48aNw5IlS/DZZ5/h5MmTKCoqYqCjPqdQKCCXy1FYWAiVSoUpU6ZgxowZuHz5MrRaLTZu3Ijo6GgUFRUhJCQEDz/8MMaNG8fVZmIAJLJkWq0WV65c6fR4bGwsvLy8MHLkSBw8eNCgW7N1dXWIjIwU6+cZ43ygTqdDYWEhpFIpvvjiC7z44ouYNGkSbGxsMGTIEHh7e+ONN97A999/j7Nnz6KlpYVn9fq5WxVUNtUWkUePHsW9994LOzs7uLu7480330RTUxOA62VinnrqKQwfPhy2trbw9PTE66+/jurqaiPPmkwBAyARdenatWs4dOgQRowYgUcffRSRkZEGDWFlZWUICQmBUqnss/OBQhHl2NhY/PTTT1i/fj3mzp2Lu+++GxKJBGPGjMGzzz6LDz/8EL/++ityc3N5e9JM3aqgcn9uEUnUFQZAIroprVaLLVu2YODAgVi5ciWKi4sNuhKXk5MDmUyG06dP9+h8oE6nQ1lZGWQyGXbu3IkVK1ZgypQpsLe3h6OjI6ZPn45XX30Ve/bsQXh4OBobG7mqZyFuVVDZXFpEEuljACTqRdu2bevUd/OPf/yj+PwkJqtmAAAK00lEQVTFixexdu1auLi4YNCgQViyZEm/2Y7Jz8/HokWL4OTkhC+//NKgPW6bm5uRnJwsng+82c1jnU6H5uZmJCYm4pdffsHGjRvx9NNPY9SoUZBIJBg1ahT+8pe/YPPmzfjf//1fZGZmsoiyhbtVQWVLqA9KlocBkKgXbdu2DZMmTWrXd7Ourk58fvXq1Rg9ejQ0Gg3i4+Ph5eWFmTNnGnHGt0+lUmHixImYMGECpFKpQbeF6+rqEBUVhcOHD+Pdd99FTU0NKisroVQqsXv3bvz973/HtGnT4OjoCHt7e0ydOhUvv/wydu/ejZCQENTW1jLoUZduVlDZnDsEkeViACTqRdu2bcOUKVO6fK6pqQm2trY4duyY+FhWVhYkEgmio6MNNcVecfnyZXzzzTcYOnQo5s+fj9TU1D4Pf1qtFqmpqThy5Ih4WH/IkCGQSCRwc3PDE088gXfffRe//PILUlJScOnSJYY96rabFVRmACRzxABI1Iu2bdsGR0dHjBgxAmPGjMFLL72EkpISAIBGo4FEIkFjY2O7r/Hw8MBXX31ljOn2WG1tLd544w0MHDgQ77zzTq/U8BM6joSGhmLPnj147bXX4OXlhSFDhsDGxgaTJk3CsmXL4Ofnhw0bNsDNzQ2PPfYYsrKyjP3jIDPQVUFlbgGTOWIAJOpFMpkMv/76K1JSUqBQKODt7Q0PDw+0tLTgyJEjsLOz6/Q106dPx6ZNm4ww296TlJQEHx8fuLu7Y9++fd0u3aLVapGVlYVff/0VH3/8MZ577jncd999sLKygouLC2bPno23334bP/30E+Li4nDhwoVOq3otLS3YunUrCgoKjPTdkznSL6hsSS0iyXIwABL1ocbGRtx111346aefzDoAAtfrpB09ehSjR4/GtGnTEB4e3m5Vr76+HhEREdi7dy/WrFmDxx57DM7OzuI5q+effx6ff/45pFIpSkpKWES5n7l69So++ugj3HPPPXBwcMC9996L7du3twvsvr6+nS5JzZs3z4iz/o+bFVQGLKtFJFkGBkCiPjZt2jRs2bLFLLeAu9La2ipuhU+dOhULFy7ExIkTYW1tDScnJzz66KNYvXo1fvjhB0RFRUGr1fKsnhnw8/PDsGHDEBwcjKKiIhw7dgyDBw/Gnj17xNf4+vri6aefbndJqqGhwYiz/o+bFVQGLKtFJFkGBkCiPqTVauHs7Iw9e/aIl0COHz8uPp+dnd0vL4F0R0lJCcaNG4d3330Xx48fR35+Plf1zNgzzzyDlStXtntsyZIlWL58ufi/fX19sWjRIkNPjYi6wABI1Ivee+89hIeHo6ioCJGRkXjiiSfg6uqK2tpaANfLwHh4eCA0NBTx8fHw9vaGt7e3kWdN1HN+fn7w9PQUV8WSk5Ph5uaGw4cPi6/x9fWFk5MThg8fjvHjx2P16tWor6831pSJLBoDIFEvevHFFzFixAjY2dlh5MiRePHFF5Gfny8+LxSCdnZ2hqOjIxYvXoyqqiojzpiod1y7dg2bN2+GlZUVbGxsYGVlhR07drR7jb+/v3iG7uTJk5g4cSKmT5/O9npERsAASEREPebv749Ro0bB398fqampOHToEFxcXHDw4MEbfo1QXqVjBw4i6nsMgERE1GOjRo3Cd9991+6xzz//vF0rxK64urrixx9/7MupEVEXGACJiKjHXFxcsHfv3naP7dixA+PGjbvh15SVlcHKygpSqbSvp0dEHTAAEhFRj/n6+mLkyJFiGZgTJ07A1dVVrHGp1WqxceNGREdHo6ioCCEhIXj44Ycxbtw4/P7770aePZHlYQAk6qf+8Y9/QCKRYP369eJjwiUTFxcXDBo0CEuWLEF1dbURZ0m3ozvFlIV6dO7u7nBwcMDcuXORm5trxFlf19LSIvZoFub+4Ycf4tKlSwCACxcu4KmnnsLw4cNha2sLT09PvP766/zvk8hIGACJ+qHY2Fjcc889ePDBB9sFwNWrV2P06NHQaDSIj4+Hl5cXZs6cacSZ0u3oTjHlnTt3wsnJCQEBAUhJScHChQvZkYKIbhsDIFE/o9VqMW7cOKjVasyePVsMgEKh6WPHjomvzcrKMttC0+boVsWUhZ60u3btEp9vampiT1oium0MgET9zMsvv4wNGzYAQLsAaCmt5szZrYopC2VTkpKS2n2dj48P1q1bZ/D5ElH/xQBI1I/4+/tj8uTJ4naffgA8cuQI7OzsOn3N9OnTxYP4ZNpuVUw5MjISEokElZWV7b7uhRdewNKlSw09XSLqxxgAifqJ0tJSuLm5ISUlRXyMAdC83KqYMgMgEfUWBkCifuLkyZOQSCSwtrYWh0QigZWVFaytrRESEsIt4H7uVsWUuQVMRL2FAZCon2hpaUFaWlq7MW3aNKxYsQJpaWniJZDjx4+LX5Odnc1LIP3IrYopC5dAdu/eLT7f3NzMSyBEdNsYAIn6Mf0tYOB6GRgPDw+EhoYiPj4e3t7e8Pb2NuIM6XbcqpgycL0MzNChQyGVSpGamopFixaxDAwR3TYGQKJ+rGMAFApBOzs7w9HREYsXL0ZVVZURZ2g4np6ekEgkncbatWsBXP9ZdXzujTfeMPKs27tVMWXgP4Wg7777btjb22Pu3LnirWEiou5iACQis1BbW4uqqipxqNVqSCQShIWFAbgeAF9//fV2r2lubjbupImIjIQBkIjM0vr16zF27FixjVrH1VIiIkvGAEhEZufSpUsYNmwY/Pz8xMdmz54NV1dXDBs2DJMmTcKWLVvQ2tpqxFkSERkPAyARmZ2jR4/C2toaFRUV4mP79u2DQqFAamoqDh8+jJEjR2Lx4sVGnCURkfEwABKR2XnqqaewYMGCm75GaJ2Xn59voFkREZkOBkAiMivFxcUYMGAAAgICbvo6nU4HiUQChUJhoJkREZkOBkAiMivbtm2Du7s7rly5ctPXnT17FhKJpF1rPSIiS8EASERm49q1a/Dw8MDmzZvbPZ6fn4/t27cjPj4eRUVFkEqluPfee+Hj42OkmRIRGRcDIBGZDaVSCYlE0qkwcmlpKXx8fODi4gJ7e3vcd999eP/991kHkIgsFgMgERERkYVhACQiIiKyMAyARERERBaGAZCIiIjIwjAAEhEREVkYBkAiIiIiC8MASERERGRhGACJiIiILAwDIBEREZGFYQAkIiIisjAMgEREREQWhgGQiIiIyMIwABIRERFZGAZAIiIiIgvDAEhERERkYRgAiYiIiCwMAyARERGRhWEAJCIiIrIwDIBEREREFoYBkIiIiMjCMAASERERWRgGQCIiIiILwwBIREREZGEYAImIiIgsDAMgERERkYVhACQiIiKyMAyARERERBaGAZCIiIjIwjAAEhEREVkYBkAiIiIiC8MASERERGRhGACJiIiILAwDIBEREZGFYQAkIiIisjAMgEREREQWhgGQiIiIyMIwABIRERFZGAZAIiIiIgvDAEhERERkYRgAiYiIiCwMAyARERGRhWEAJCIiIrIwDIBEREREFoYBkIiIiMjCMAASERERWRgGQCIiIiILwwBIREREZGEYAImIiIgsDAMgERERkYVhACQiIiKyMAyARERERBaGAZCIiIjIwjAAEhEREVkYBkAiIiIiC8MASERERGRhGACJiIiILAwDIBEREZGFYQAkIiIisjAMgEREREQWhgGQiIiIyMIwABIRERFZmP8HEG6falNPk6oAAAAASUVORK5CYII=\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<mpl_toolkits.mplot3d.art3d.Line3D at 0x2aacad997880>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#for i in range(len(states)):\n",
    "#    print(states[i], env.referenceStreamline_ijk[i])\n",
    "#    distance = ((states.T[0][i] - env.referenceStreamline_ijk.T[0][i])**2 \\\n",
    "#                      + (states.T[1][i] - env.referenceStreamline_ijk.T[1][i] )**2 \\\n",
    "#                      + (states.T[2][i] - env.referenceStreamline_ijk.T[2][i])**2)\n",
    "#    print(distance)\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot3D(env.referenceStreamline_ijk.T[0][:], env.referenceStreamline_ijk.T[1][:], env.referenceStreamline_ijk.T[2][:])\n",
    "ax.plot3D(states.T[0][:], states.T[1][:], states.T[2][:])\n",
    "#print(optimal_steps[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([75.0415, 75.2101, 75.0415], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "states = torch.stack(all_states)\n",
    "print(states.T[0][:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 71.7731, 113.9662,  79.6186])\n"
     ]
    }
   ],
   "source": [
    "print(referenceLine[86])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 73.651344 107.88106   93.29415 ] tensor([ 73.6513, 107.8811,  93.2942])\n",
      "tensor(66.2049, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "print(env.state.getCoordinate().numpy(), referenceLine[0])\n",
    "step = 0\n",
    "#all_rewards = []\n",
    "eps_reward = 0\n",
    "for i in optimal_steps:\n",
    "    next_state, distance, terminal = env.step(i)\n",
    "    if distance < 0.71:\n",
    "        reward = 1 - distance\n",
    "        #print(reward)\n",
    "        if reward < 0.3:\n",
    "            reward = 1\n",
    "    eps_reward += reward\n",
    "    #all_rewards.append(reward)\n",
    "    step += 1\n",
    "print(eps_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_actions):\n",
    "    \n",
    "    next_state, distance, terminal = env.step(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action:  100 Step:  1 Coordinates:  [ 73.651344 107.88106   93.29415 ] [ 74.42344 107.87124  93.08491]\n",
      "Action:  67 Step:  2 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 75.16057  107.88882   92.774536]\n",
      "Action:  100 Step:  3 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 75.78847 107.96255  92.28433]\n",
      "Action:  100 Step:  4 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 76.45265  108.118454  91.86654 ]\n",
      "Action:  100 Step:  5 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 77.116844 108.27435   91.448746]\n",
      "Action:  100 Step:  6 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 77.739716 108.54131   91.02359 ]\n",
      "Action:  100 Step:  7 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 78.36259  108.80828   90.598434]\n",
      "Action:  100 Step:  8 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 78.996666 109.15176   90.25207 ]\n",
      "Action:  100 Step:  9 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 79.630745 109.495224  89.9057  ]\n",
      "Action:  100 Step:  10 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 80.264824 109.8387    89.55933 ]\n",
      "Action:  100 Step:  11 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 80.833374 110.28288   89.21371 ]\n",
      "Action:  100 Step:  12 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 81.32385 110.75597  88.79464]\n",
      "Action:  100 Step:  13 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 81.78852 111.07612  88.22755]\n",
      "Action:  100 Step:  14 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 82.26274  111.20639   87.596565]\n",
      "Action:  100 Step:  15 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 82.764885 111.12094   86.97968 ]\n",
      "Action:  100 Step:  16 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 83.17989 111.072    86.2975 ]\n",
      "Action:  100 Step:  17 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 83.60093  110.91725   85.635086]\n",
      "Action:  100 Step:  18 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 84.02196  110.762505  84.97268 ]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-9b9d7b386c25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mterminal\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreward\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fibre_tracking/deepFibreTracking/dfibert/envs/RLtractEnvironment.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mpositionNextState\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetCoordinate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstepWidth\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0maction_vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mnextState\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTractographyState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositionNextState\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolateDWIatState\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mnextState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fibre_tracking/deepFibreTracking/dfibert/envs/_state.py\u001b[0m in \u001b[0;36mgetValue\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolatedDWI\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# interpolate DWI value at self.coordinate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolatedDWI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolFuncHandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoordinate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolatedDWI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fibre_tracking/deepFibreTracking/dfibert/envs/RLtractEnvironment.py\u001b[0m in \u001b[0;36minterpolateDWIatState\u001b[0;34m(self, stateCoordinates)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0minterpolated_dwi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_interpolated_dwi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mras_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdwi_postprocessor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fibre_tracking/deepFibreTracking/dfibert/data/__init__.py\u001b[0m in \u001b[0;36mget_interpolated_dwi\u001b[0;34m(self, points, postprocessing, ignore_outside_points)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpostprocessing\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             result = postprocessing(result, self.data.b0, \n\u001b[0m\u001b[1;32m    289\u001b[0m                                  \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbvecs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m                                  self.data.bvals)\n",
      "\u001b[0;32m~/fibre_tracking/deepFibreTracking/dfibert/data/postprocessing.py\u001b[0m in \u001b[0;36m_wrapper\u001b[0;34m(dwi, b0, bvecs, bvals)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdwi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbvecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mdata_sh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspherical_harmonics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msh_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msh_order\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmooth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msmooth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdwi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbvecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mdata_resampled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_sh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_sh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fibre_tracking/deepFibreTracking/dfibert/data/postprocessing.py\u001b[0m in \u001b[0;36m_wrapper\u001b[0;34m(dwi, _b0, bvecs, _bvals)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mreal_sh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreal_sym_sh_mrtrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msh_order\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_sphere\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_sphere\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0minv_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmooth_pinv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_sh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmooth\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mdata_sh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdwi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minv_b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/atari/lib/python3.8/site-packages/dipy/reconst/shm.py\u001b[0m in \u001b[0;36msmooth_pinv\u001b[0;34m(B, L)\u001b[0m\n\u001b[1;32m    661\u001b[0m     \"\"\"\n\u001b[1;32m    662\u001b[0m     \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m     \u001b[0minv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpinv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    664\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mpinv\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/atari/lib/python3.8/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36mpinv\u001b[0;34m(a, rcond, hermitian)\u001b[0m\n\u001b[1;32m   1959\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconjugate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1961\u001b[0;31m     \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_matrices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhermitian\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhermitian\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1962\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m     \u001b[0;31m# discard small singular values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msvd\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/atari/lib/python3.8/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv, hermitian)\u001b[0m\n\u001b[1;32m   1624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1625\u001b[0m         \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->DdD'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->ddd'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1626\u001b[0;31m         \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1627\u001b[0m         \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_realType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "terminal = False\n",
    "step = 0\n",
    "actions = []\n",
    "past_state = env.state\n",
    "step = 1\n",
    "while terminal != True:\n",
    "    for i in range(n_actions)\n",
    "    action = np.random.randint(n_actions)\n",
    "    next_state, reward, terminal = env.step(action)\n",
    "    if reward < 1:\n",
    "        actions.append(action)\n",
    "        past_state = next_state\n",
    "        print(\"Action: \", action, \"Step: \",step, \"Coordinates: \", next_state.getCoordinate().numpy(), referenceLine[step].numpy())\n",
    "        step += 1\n",
    "    else:\n",
    "        env.state = past_state\n",
    "        env.stepCounter = step\n",
    "    #action = np.random.choice(possible_actions[step])\n",
    "    #next_state, reward, terminal = env.step(action)\n",
    "    #step += 1\n",
    "\n",
    "print(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 77.7397, 108.5413,  91.0236])\n",
      "tensor([ 78.3626, 108.8083,  90.5984])\n"
     ]
    }
   ],
   "source": [
    "print(referenceLine[6])\n",
    "print(referenceLine[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 78.1077, 108.7354,  91.6977], dtype=torch.float64)\n",
      "tensor([ 77.7615, 108.8643,  91.6973], dtype=torch.float64)\n",
      "tensor([ 77.8808, 108.4698,  91.6927], dtype=torch.float64)\n",
      "tensor([ 78.0768, 109.0850,  91.6268], dtype=torch.float64)\n",
      "tensor([ 77.5148, 108.5987,  91.6375], dtype=torch.float64)\n",
      "tensor([ 78.3125, 108.4477,  91.5947], dtype=torch.float64)\n",
      "tensor([ 77.7489, 109.2253,  91.5590], dtype=torch.float64)\n",
      "tensor([ 77.6419, 108.2420,  91.5700], dtype=torch.float64)\n",
      "tensor([ 78.4297, 108.8083,  91.5614], dtype=torch.float64)\n",
      "tensor([ 77.4379, 108.9717,  91.5654], dtype=torch.float64)\n",
      "tensor([ 78.0813, 108.1849,  91.5566], dtype=torch.float64)\n",
      "tensor([ 78.1025, 109.3932,  91.4139], dtype=torch.float64)\n",
      "tensor([ 77.3094, 108.3452,  91.4445], dtype=torch.float64)\n",
      "tensor([ 78.6147, 108.4838,  91.3841], dtype=torch.float64)\n",
      "tensor([ 77.4417, 109.2998,  91.3783], dtype=torch.float64)\n",
      "tensor([ 77.8415, 107.9787,  91.4083], dtype=torch.float64)\n",
      "tensor([ 78.3907, 109.1557,  91.4638], dtype=torch.float64)\n",
      "tensor([ 77.2027, 108.6996,  91.4375], dtype=torch.float64)\n",
      "tensor([ 78.4256, 108.1555,  91.3717], dtype=torch.float64)\n",
      "tensor([ 77.7865, 109.5055,  91.3048], dtype=torch.float64)\n",
      "tensor([ 77.4984, 108.0024,  91.3116], dtype=torch.float64)\n",
      "tensor([ 78.6872, 108.8408,  91.3203], dtype=torch.float64)\n",
      "tensor([ 77.1729, 109.0570,  91.3086], dtype=torch.float64)\n",
      "tensor([ 78.1746, 107.9095,  91.2645], dtype=torch.float64)\n",
      "tensor([ 78.3889, 109.4422,  91.1813], dtype=torch.float64)\n",
      "tensor([ 77.0434, 108.4461,  91.1692], dtype=torch.float64)\n",
      "tensor([ 78.6965, 108.2442,  91.1141], dtype=torch.float64)\n",
      "tensor([ 77.5030, 109.5370,  91.1019], dtype=torch.float64)\n",
      "tensor([ 77.5000, 107.8270,  90.9938], dtype=torch.float64)\n",
      "tensor([ 78.6388, 109.1633,  91.2107], dtype=torch.float64)\n",
      "tensor([ 76.9888, 108.7771,  91.1266], dtype=torch.float64)\n",
      "tensor([ 78.4668, 107.9465,  91.0478], dtype=torch.float64)\n",
      "tensor([ 78.0655, 109.6183,  91.0848], dtype=torch.float64)\n",
      "tensor([ 77.2055, 108.1323,  91.1605], dtype=torch.float64)\n",
      "tensor([ 78.8286, 108.6225,  91.0812], dtype=torch.float64)\n",
      "tensor([ 77.2105, 109.3476,  91.0498], dtype=torch.float64)\n",
      "tensor([ 77.8390, 107.7826,  91.1087], dtype=torch.float64)\n",
      "tensor([ 78.6632, 109.3198,  90.9072], dtype=torch.float64)\n",
      "tensor([ 76.9030, 108.6561,  90.7911], dtype=torch.float64)\n",
      "tensor([ 78.6834, 108.0832,  90.7689], dtype=torch.float64)\n",
      "tensor([ 77.7496, 109.6751,  90.8953], dtype=torch.float64)\n",
      "tensor([ 77.2161, 107.9836,  90.8505], dtype=torch.float64)\n",
      "tensor([ 78.8374, 108.9642,  90.9474], dtype=torch.float64)\n",
      "tensor([ 77.0033, 109.0777,  90.9567], dtype=torch.float64)\n",
      "tensor([ 78.1431, 107.7515,  90.9129], dtype=torch.float64)\n",
      "tensor([ 78.3585, 109.5817,  90.8446], dtype=torch.float64)\n",
      "tensor([ 76.9926, 108.2972,  90.8376], dtype=torch.float64)\n",
      "tensor([ 78.8549, 108.4211,  90.8108], dtype=torch.float64)\n",
      "tensor([ 77.3852, 109.5591,  90.7525], dtype=torch.float64)\n",
      "tensor([ 77.7615, 107.7120,  90.7482], dtype=torch.float64)\n",
      "tensor([ 77.6912, 108.6687,  89.7427], dtype=torch.float64)\n",
      "tensor([ 78.0374, 108.5397,  89.7432], dtype=torch.float64)\n",
      "tensor([ 77.9181, 108.9343,  89.7477], dtype=torch.float64)\n",
      "tensor([ 77.7221, 108.3191,  89.8136], dtype=torch.float64)\n",
      "tensor([ 78.2841, 108.8053,  89.8029], dtype=torch.float64)\n",
      "tensor([ 77.4863, 108.9563,  89.8458], dtype=torch.float64)\n",
      "tensor([ 78.0500, 108.1788,  89.8814], dtype=torch.float64)\n",
      "tensor([ 78.1570, 109.1620,  89.8705], dtype=torch.float64)\n",
      "tensor([ 77.3692, 108.5958,  89.8791], dtype=torch.float64)\n",
      "tensor([ 78.3610, 108.4323,  89.8751], dtype=torch.float64)\n",
      "tensor([ 77.7176, 109.2191,  89.8838], dtype=torch.float64)\n",
      "tensor([ 77.6964, 108.0109,  90.0266], dtype=torch.float64)\n",
      "tensor([ 78.4895, 109.0588,  89.9960], dtype=torch.float64)\n",
      "tensor([ 77.1842, 108.9202,  90.0563], dtype=torch.float64)\n",
      "tensor([ 78.3572, 108.1042,  90.0621], dtype=torch.float64)\n",
      "tensor([ 77.9574, 109.4254,  90.0322], dtype=torch.float64)\n",
      "tensor([ 77.4082, 108.2484,  89.9767], dtype=torch.float64)\n",
      "tensor([ 78.5962, 108.7045,  90.0029], dtype=torch.float64)\n",
      "tensor([ 77.3733, 109.2486,  90.0688], dtype=torch.float64)\n",
      "tensor([ 78.0123, 107.8986,  90.1357], dtype=torch.float64)\n",
      "tensor([ 78.3005, 109.4017,  90.1289], dtype=torch.float64)\n",
      "tensor([ 77.1116, 108.5632,  90.1201], dtype=torch.float64)\n",
      "tensor([ 78.6259, 108.3471,  90.1318], dtype=torch.float64)\n",
      "tensor([ 77.6242, 109.4945,  90.1760], dtype=torch.float64)\n",
      "tensor([ 77.4100, 107.9618,  90.2592], dtype=torch.float64)\n",
      "tensor([ 78.7555, 108.9580,  90.2712], dtype=torch.float64)\n",
      "75 [ 78.7555186  108.95801267  90.27122457] [ 78.36259  108.80828   90.598434] 0.2838811622505798\n",
      "tensor([ 77.1024, 109.1599,  90.3263], dtype=torch.float64)\n",
      "tensor([ 78.2959, 107.8671,  90.3386], dtype=torch.float64)\n",
      "tensor([ 78.2988, 109.5771,  90.4467], dtype=torch.float64)\n",
      "tensor([ 77.1600, 108.2408,  90.2298], dtype=torch.float64)\n",
      "tensor([ 78.8100, 108.6269,  90.3138], dtype=torch.float64)\n",
      "tensor([ 77.3321, 109.4575,  90.3926], dtype=torch.float64)\n",
      "tensor([ 77.7333, 107.7858,  90.3557], dtype=torch.float64)\n",
      "tensor([ 78.5934, 109.2718,  90.2799], dtype=torch.float64)\n",
      "tensor([ 76.9703, 108.7816,  90.3592], dtype=torch.float64)\n",
      "tensor([ 78.5884, 108.0565,  90.3906], dtype=torch.float64)\n",
      "tensor([ 77.9598, 109.6215,  90.3317], dtype=torch.float64)\n",
      "tensor([ 77.1356, 108.0842,  90.5333], dtype=torch.float64)\n",
      "tensor([ 78.8959, 108.7480,  90.6493], dtype=torch.float64)\n",
      "88 [ 78.89586077 108.74800996  90.64932975] [ 78.36259  108.80828   90.598434] 0.2906038664155419\n",
      "tensor([ 77.1154, 109.3209,  90.6715], dtype=torch.float64)\n",
      "tensor([ 78.0493, 107.7290,  90.5451], dtype=torch.float64)\n",
      "tensor([ 78.5828, 109.4204,  90.5900], dtype=torch.float64)\n",
      "tensor([ 76.9615, 108.4399,  90.4931], dtype=torch.float64)\n",
      "tensor([ 78.7955, 108.3264,  90.4838], dtype=torch.float64)\n",
      "tensor([ 77.6558, 109.6526,  90.5275], dtype=torch.float64)\n",
      "tensor([ 77.4404, 107.8224,  90.5959], dtype=torch.float64)\n",
      "tensor([ 78.8063, 109.1069,  90.6029], dtype=torch.float64)\n",
      "96 [ 78.80625982 109.10688665  90.60289128] [ 78.36259  108.80828   90.598434] 0.28603082585170475\n",
      "tensor([ 76.9440, 108.9829,  90.6297], dtype=torch.float64)\n",
      "tensor([ 78.4137, 107.8450,  90.6879], dtype=torch.float64)\n",
      "tensor([ 78.0373, 109.6921,  90.6923], dtype=torch.float64)\n",
      "100 [ 77.89944  108.702034  90.72022 ] [ 78.36259  108.80828   90.598434] 0.24062869\n"
     ]
    }
   ],
   "source": [
    "state = TractographyState(torch.Tensor([ 77.8994346, 108.7020324, 90.72022516]), env.interpolateDWIatState)\n",
    "for i in range(n_actions):\n",
    "    env.state = state\n",
    "    env.stepCounter -= 1\n",
    "    next_state, _, terminal = env.step(i)\n",
    "    qry_pt = next_state.getCoordinate().view(-1,3)\n",
    "    distance = torch.min(torch.sum((referenceLine[7] - qry_pt)**2, dim=1))\n",
    "    if distance < 0.3:\n",
    "        print(i, next_state.getCoordinate().numpy(), referenceLine[7].numpy(), distance.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(187.0214)\n",
      "[ 73.651344 107.88106   93.29415 ]\n",
      "-1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "next_state, reward, terminal = env.step(100)\n",
    "print(next_state.getCoordinate().numpy())\n",
    "print(reward)\n",
    "print(terminal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47, 75, 80, 88, 93, 96], [67, 75, 80, 88, 93], [62, 67, 75, 80], [62, 67, 75, 80, 83], [62, 67, 75, 80, 83], [62, 67, 75, 83, 96], [62, 67, 75, 83, 96], [62, 75, 83, 91, 96], [62, 75, 83, 91, 96], [62, 75, 83, 91, 96], [62, 70, 75, 83, 91, 96], [62, 70, 75, 78, 83, 91], [54, 57, 62, 67, 70, 75, 83], [54, 62, 67, 75], [54, 59, 67, 72], [51, 54, 59, 62, 67, 72], [51, 54, 59, 64, 67, 72], [51, 54, 59, 64, 67, 72], [51, 54, 59, 64, 67, 72], [51, 54, 56, 59, 64, 67, 72], [51, 54, 56, 59, 64, 67, 72], [51, 56, 59, 64], [51, 56, 59, 64], [51, 56, 59, 64], [50, 51, 53, 56, 59], [50, 51, 53, 56, 61, 66], [53, 58, 61, 66, 74, 79], [58, 66, 71, 74, 79], [58, 66, 71, 79], [58, 63, 66, 71, 79], [58, 63, 66, 71, 79], [58, 63, 66, 71, 79], [58, 63, 66, 71, 79], [58, 63, 66, 71, 79, 84], [58, 63, 71, 79, 84, 92], [58, 63, 71, 79, 84, 92], [63, 71, 79, 84, 92], [63, 71, 79, 84, 92], [38, 71, 79, 84, 92], [38, 63, 71, 84, 92, 97], [38, 71, 84, 92, 97], [38, 84, 92, 97], [38, 76, 84, 92, 97], [38, 76, 84, 92, 97], [38, 43, 84, 89, 97], [38, 43, 84, 89, 97], [30, 38, 43, 97], [30, 38, 43, 97], [30, 38, 43, 97], [22, 30, 38, 43, 97], [22, 30, 38, 43, 97], [22, 35, 43, 89, 97], [35, 43, 48, 89], [40, 48, 81, 89, 94], [40, 48, 73, 81, 86, 94], [73, 81, 86, 94], [40, 48, 81, 89, 94], [35, 43, 48, 89], [22, 35, 43, 89, 97], [22, 35, 43, 89, 97], [22, 30, 35, 43, 89], [22, 30, 35, 43, 89], [14, 22, 27, 35, 43], [14, 22, 27, 35], [6, 14, 19, 22, 27, 35], [6, 11, 14, 19, 27], [3, 6, 11, 19], [3, 6, 11, 16], [3, 8, 11, 16], [3, 8, 11, 16, 24, 29], [3, 8, 16, 21, 29], [8, 16, 21, 29], [8, 13, 16, 21, 29], [8, 13, 16, 21, 29], [21, 29, 34, 42], [13, 21, 26, 34, 47], [13, 18, 26, 31, 34, 39, 47], [26, 34, 39, 47, 93], [26, 34, 39, 47, 93], [26, 39, 47, 85, 93], [26, 39, 47, 85, 93], [39, 47, 72, 85, 93], [64, 72, 80, 85, 93], [64, 72, 77, 85, 93], [56, 64, 69, 72, 77, 85], [64, 69, 77, 85, 90, 98], [100]]\n"
     ]
    }
   ],
   "source": [
    "print(possible_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 71.5173, 114.6476,  79.9506])\n",
      "tensor([ 71.7731, 113.9662,  79.6186])\n",
      "[64, 69, 77, 85, 90, 98]\n",
      "tensor([ 71.5173, 114.6476,  79.9506]) tensor(0.4643)\n",
      "tensor([ 71.5173, 114.6476,  79.9506]) tensor(0.4643)\n",
      "tensor([ 71.5173, 114.6476,  79.9506]) tensor(0.4643)\n",
      "tensor([ 71.5173, 114.6476,  79.9506]) tensor(0.4643)\n",
      "tensor([ 71.5173, 114.6476,  79.9506]) tensor(0.4643)\n",
      "tensor([ 71.5173, 114.6476,  79.9506]) tensor(0.4643)\n"
     ]
    }
   ],
   "source": [
    "env.state = TractographyState(referenceLine[85], env.interpolateDWIatState)\n",
    "print(env.state.getCoordinate())\n",
    "print(referenceLine[86])\n",
    "print(possible_actions[85])\n",
    "for i in possible_actions[85]:\n",
    "    env.state = TractographyState(referenceLine[85], env.interpolateDWIatState)\n",
    "    env.stepCounter = 84\n",
    "    next_state, reward, _ = env.step(z)\n",
    "    print(next_state.getCoordinate(), reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 71.773056 113.966225  79.618576] [ 72.30127204 114.02878755  79.99932066] 0.27901215525974304\n",
      "[ 71.773056 113.966225  79.618576] [ 71.7609279  113.6971063   80.14330044] 0.2753356828217112\n",
      "[ 71.773056 113.966225  79.618576] [ 71.37937604 113.65758474  79.97858924] 0.15498393104601757\n",
      "[ 71.773056 113.966225  79.618576] [ 71.66780472 114.12438903  79.11184227] 0.2567791198339029\n",
      "[ 71.773056 113.966225  79.618576] [ 71.97880832 114.37794723  79.10548775] 0.26325960220840583\n",
      "[ 71.773056 113.966225  79.618576] [ 71.31423388 113.95652005  79.25698482] 0.2105177635246191\n",
      "[ 71.773056 113.966225  79.618576] [ 71.97504289 114.04982978  79.29253904] 0.10630013104166292\n",
      "[ 71.773056 113.966225  79.618576] [ 71.63016002 113.84417747  79.3660627 ] 0.06376299386222199\n",
      "[ 71.773056 113.966225  79.618576] [ 72.24376411 114.29266559  79.36222956] 0.2215660937612901\n",
      "[ 71.773056 113.966225  79.618576] [ 71.91375289 113.81268975  79.56895814] 0.023572970787664616\n",
      "[ 71.773056 113.966225  79.618576] [ 71.35118583 113.73139254  79.58605126] 0.1779744651043897\n",
      "[ 71.773056 113.966225  79.618576] [ 72.20619251 114.00206886  79.62102829] 0.18760720625139998\n",
      "[ 71.773056 113.966225  79.618576] [ 71.66712842 113.67455586  79.7755295 ] 0.08507069391326497\n",
      "[ 71.773056 113.966225  79.618576] [ 72.03154546 113.7906186   79.91830767] 0.0898390464981324\n"
     ]
    }
   ],
   "source": [
    "#env.state = TractographyState(referenceLine[85], env.interpolateDWIatState)\n",
    "for i in range(n_actions):\n",
    "    env.reset()\n",
    "    env.state = TractographyState(referenceLine[85], env.interpolateDWIatState)\n",
    "    next_state, reward, _ = env.step(i)\n",
    "    distance = env.rewardForTerminalState(next_state)\n",
    "    if distance < 0.3:\n",
    "        print(referenceLine[86].numpy(), next_state.getCoordinate().numpy(), distance.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 71.7731, 113.9662,  79.6186])\n",
      "tensor(122.0777, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "distance = env.rewardForTerminalState(next_state)\n",
    "print(referenceLine[86])\n",
    "print(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_actions):\n",
    "    env.state = TractographyState(torch.FloatTensor([ 74.64776812, 107.9270337, 93.22325858]), env.interpolateDWIatState)\n",
    "    next_state, reward, _ = env.step(i)\n",
    "    env.stepCounter = 2\n",
    "    if reward < 0.1:\n",
    "        reward = 1\n",
    "    elif reward < 0.5:\n",
    "        reward = 0\n",
    "    else:\n",
    "        reward = -1\n",
    "    if reward == 1:\n",
    "        #best_actions.append(i)\n",
    "        print(\"[{}]\".format(i), referenceLine[2].numpy(), next_state.getCoordinate().numpy(), reward)\n",
    "#print(best_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = TractographyState(torch.FloatTensor(referenceLine[0]), env.interpolateDWIatState)\n",
    "coordinates = state.getCoordinate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(referenceLine[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(referenceLine[0])\n",
    "print(referenceLine[70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = TractographyState(referenceLine[69], env.interpolateDWIatState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = env.reset().getValue().reshape(-1).shape[0]\n",
    "print(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = torch.FloatTensor(state.getValue()).unsqueeze(0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_vals = agent.main_dqn(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(state.getValue().shape)\n",
    "shape = state.getValue().shape\n",
    "shape = np.prod(np.array(shape))\n",
    "print(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = TractographyState(referenceLine[70], env.interpolateDWIatState)\n",
    "qry_pt = torch.FloatTensor(state.getCoordinate()).view(-1,3)\n",
    "distance = torch.min(torch.sum( (referenceLine - qry_pt)**2, dim =1 ))\n",
    "qry_pt = torch.FloatTensor(state.getCoordinate()).view(3)\n",
    "distance_terminal = torch.sum( (referenceLine[-1,:] - qry_pt)**2 )\n",
    "\n",
    "#print(distance)\n",
    "#print(distance_terminal)\n",
    "reward = (torch.tanh(-distance+5.3) + 2*torch.tanh(-distance_terminal+5.3))/2\n",
    "print(reward)\n",
    "\n",
    "print(torch.tanh(-distance+5.3))\n",
    "print(torch.tanh(-distance_terminal+5.3))\n",
    "\n",
    "reward += 200/20 * reward.sign()\n",
    "print(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.tanh(-distance_terminal+5.3)+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = TractographyState([32., 84., 94.], env.interpolateDWIatState)\n",
    "qry_pt = torch.FloatTensor(state.getCoordinate()).view(-1,3)\n",
    "distance = torch.min(torch.sum( (referenceLine - qry_pt)**2, dim =1 ))\n",
    "print(torch.tanh(-distance+5.3))\n",
    "qry_pt = torch.FloatTensor(state.getCoordinate()).view(3)\n",
    "distance = torch.sum( (referenceLine[-1,:] - qry_pt)**2 )\n",
    "print(-distance)\n",
    "print(torch.tanh(-distance)+2)\n",
    "#print(torch.where(distance < env.maxL2dist_to_terminalState, 1, 0 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(-1.5 + 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qry_pt = torch.FloatTensor(state.getCoordinate()).view(3)\n",
    "distance = torch.sum( (referenceLine[-1,:] - qry_pt)**2 )\n",
    "print(round(-distance.item(),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Init agent\")\n",
    "#memory = ReplayMemory(size=replay_memory_size)\n",
    "state = env.reset()\n",
    "agent = Agent(n_actions=n_actions, inp_size=state.getValue().shape, device=device, hidden=256, agent_history_length=agent_history_length, memory_size=replay_memory_size, learning_rate=learning_rate)\n",
    "\n",
    "print(\"Init epsilon-greedy action scheduler\")\n",
    "action_scheduler = Action_Scheduler(num_actions=n_actions, max_steps=max_steps, eps_annealing_steps=100000, replay_memory_start_size=replay_memory_size, model=agent.main_dqn)\n",
    "\n",
    "step_counter = 0\n",
    "    \n",
    "eps_rewards = []\n",
    "\n",
    "print(\"Start training...\")\n",
    "while step_counter < max_steps:\n",
    "    epoch_step = 0\n",
    "\n",
    "######## fill memory begins here\n",
    "    while epoch_step < evaluate_every:  # To Do implement evaluation\n",
    "        state = env.reset()\n",
    "        episode_reward_sum = 0\n",
    "        \n",
    "        #fill replay memory while interacting with env\n",
    "        for episode_counter in range(max_episode_length):\n",
    "            # get action with epsilon-greedy strategy       \n",
    "            action = action_scheduler.get_action(step_counter, torch.FloatTensor(state.getValue()).to(device).unsqueeze(0))\n",
    "                    \n",
    "            next_state, reward, terminal = env.step(action)\n",
    "\n",
    "            if reward >= 1:\n",
    "                reward = 10\n",
    "            elif reward > -0.05:\n",
    "                reward = 1\n",
    "            \n",
    "            if episode_counter == max_episode_length-1:\n",
    "                reward = -100\n",
    "                terminal = True\n",
    "            # increase counter\n",
    "            step_counter += 1\n",
    "            epoch_step += 1\n",
    "\n",
    "            # accumulate reward for current episode\n",
    "            episode_reward_sum += reward\n",
    "\n",
    "\n",
    "            agent.replay_memory.add_experience(action=action,\n",
    "                                state=state.getValue(),\n",
    "                                reward=reward,\n",
    "                                new_state=next_state.getValue(),\n",
    "                                terminal=terminal)\n",
    "\n",
    "\n",
    "            state = next_state\n",
    "\n",
    "        \n",
    "\n",
    "            ####### optimization is happening here\n",
    "            if step_counter > replay_memory_size:\n",
    "                loss = agent.optimize()\n",
    "\n",
    "\n",
    "            ####### target network update\n",
    "            if step_counter > replay_memory_size and step_counter % network_update_every == 0:\n",
    "                agent.target_dqn.load_state_dict(agent.main_dqn.state_dict())\n",
    "            \n",
    "            # if episode ended before maximum step\n",
    "            if terminal:\n",
    "                terminal = False\n",
    "                state = env.reset()\n",
    "                break\n",
    "                \n",
    "        eps_rewards.append(episode_reward_sum)\n",
    "        \n",
    "        if len(eps_rewards) % 10 == 0:\n",
    "            with open(path+'/logs/rewards.dat', 'a') as reward_file:\n",
    "                print(\"[{}] {}, {}\".format(len(eps_rewards), step_counter, np.mean(eps_rewards[-100:])), file=reward_file)\n",
    "            print(\"[{}] {}, {}\".format(len(eps_rewards), step_counter, np.mean(eps_rewards[-100:])) )\n",
    "    torch.save(agent.main_dqn.state_dict(), path+'/checkpoints/fibre_agent_{}_reward_{:.2f}.pth'.format(step_counter, np.mean(eps_rewards[-100:])))\n",
    "########## evaluation starting here\n",
    "    eval_rewards = []\n",
    "    for _ in range(eval_runs):\n",
    "        eval_steps = 0\n",
    "        state = env.reset()\n",
    "        eval_episode_reward = 0\n",
    "        while eval_steps < max_episode_length:\n",
    "            action = action_scheduler.get_action(step_counter, torch.FloatTensor(state.getValue()).to(device).unsqueeze(0), evaluation=True)\n",
    "\n",
    "            next_state, reward, terminal = env.step(action)\n",
    "\n",
    "            eval_steps += 1\n",
    "            eval_episode_reward += reward\n",
    "            state = next_state\n",
    "\n",
    "            if terminal:\n",
    "                terminal = False\n",
    "                break\n",
    "\n",
    "        eval_rewards.append(eval_episode_reward)\n",
    "    \n",
    "    print(\"Evaluation score:\", np.mean(eval_rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!mkdir -p 'checkpoints/'\n",
    "#torch.save(agent.main_dqn.state_dict(), 'checkpoints/fiber_agent_{}_reward_{:.2f}.pth'.format(step_counter, np.mean(rewards[-100:])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CONDA (atari)",
   "language": "python",
   "name": "atari"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
