{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import os, sys\n",
    "sys.path.insert(0,'..')\n",
    "\n",
    "from collections import deque \n",
    "\n",
    "from dfibert.tracker.nn.rl import Agent, Action_Scheduler, DQN\n",
    "import dfibert.envs.RLtractEnvironment as RLTe\n",
    "from dfibert.envs._state import TractographyState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on Lunar Lander to check functionality of agent\n",
    "#env = gym.make('LunarLander-v2')\n",
    "#n_actions= env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_steps = 3000000\n",
    "replay_memory_size = 300000\n",
    "agent_history_length = 1\n",
    "evaluate_every = 10000\n",
    "eval_runs = 20\n",
    "network_update_every = 100\n",
    "start_learning = 2000\n",
    "eps_annealing_steps = 150000\n",
    "\n",
    "max_episode_length = 550\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#batch_size = 64\n",
    "#learning_rate = 0.0000000625\n",
    "batch_size = 32\n",
    "learning_rate = 0.00000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading precomputed streamlines (data/HCP307200_DTI_smallSet.vtk) for ID 100307\n"
     ]
    }
   ],
   "source": [
    "env = RLTe.RLtractEnvironment(stepWidth=0.3, action_space=20, device = 'cpu')\n",
    "n_actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 12])\n",
      "tensor([[ 61.8814,  53.5273,  65.1122,  59.5295,  63.2473,  63.3582,  49.6618,\n",
      "          57.5226,  56.9831,  61.0424,  49.2360,  45.0796,  60.3465,  55.7477,\n",
      "          60.6391,  54.9909,  55.8694,  60.2220,  35.0820,  47.0737,  53.0218,\n",
      "          56.9755,  60.0529,  32.3047,  20.4098,  58.4533,  59.7584,  63.0841,\n",
      "          54.4836,  43.6310,  57.3373,  22.6192,  32.9992,  61.3936,  32.4899,\n",
      "          60.6012,   8.0376,  39.1546,  58.7364,  28.7151,  25.3395,  59.5876,\n",
      "          13.1139,  54.3735,  25.8479,  10.7677,  54.2027,  11.2558,  38.6437,\n",
      "          60.1825,  22.2333,  24.1235,   8.7726,  27.5614,   2.9120,  12.3545,\n",
      "          26.7937,  17.6043,  34.9672, -12.4343,  23.0219,  27.1385, -15.7887,\n",
      "          61.7124,  42.1585,  20.3453,  24.3167,  -4.8190,  43.8532,  45.2633,\n",
      "          13.3825,  64.5126,   0.7540,  17.9066,  45.4248,  -8.3953,  60.9557,\n",
      "          51.1121,  22.9783,  49.9606,   8.7290,   3.0979,  55.1753,  -3.8223,\n",
      "          64.8611,  28.4904,  43.0782,  48.9762,  12.0101,  67.0276,  12.0111,\n",
      "          23.9232,  59.5696,  21.2108,  39.0073,  46.0813,  14.7475,  61.6706,\n",
      "          39.2160,  29.3636,  35.8707]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor([[ 63.6283,  55.3608,  66.8185,  61.1888,  66.2913,  66.0564,  51.9236,\n",
      "          59.3875,  59.3944,  63.5277,  53.6934,  48.2030,  63.8540,  58.4446,\n",
      "          63.3026,  58.4384,  57.4725,  62.1727,  37.2078,  49.2459,  56.9622,\n",
      "          60.5168,  62.6494,  35.4438,  22.5426,  62.1371,  62.0415,  65.8335,\n",
      "          57.5910,  46.8625,  60.4251,  26.2690,  36.7441,  63.1429,  35.5379,\n",
      "          64.3739,  12.9968,  41.9775,  61.7111,  33.1583,  29.6506,  61.3467,\n",
      "          15.9077,  56.4057,  30.3011,  13.3768,  56.7660,  14.4481,  40.0194,\n",
      "          63.0712,  27.3223,  26.0509,  11.5913,  33.8582,  10.7094,  15.7474,\n",
      "          31.1777,  20.3366,  38.5003,  -7.2658,  26.0212,  29.5287, -11.0445,\n",
      "          66.1286,  46.5212,  23.9947,  28.5018,   0.2056,  49.2398,  46.6589,\n",
      "          17.8200,  68.1692,   5.3408,  20.7294,  46.7196,  -2.4405,  65.7757,\n",
      "          53.7897,  25.3095,  52.4488,  13.9321,   5.8551,  57.1451,   0.3461,\n",
      "          71.6645,  32.7234,  46.6471,  51.2306,  16.3589,  71.9192,  16.1005,\n",
      "          27.7186,  63.3874,  24.3338,  41.3170,  49.6902,  19.2401,  71.4144,\n",
      "          42.2975,  31.2736,  38.9589]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "<dfibert.envs._state.TractographyState object at 0x2aaab54c11c0> 0.9 False\n",
      "tensor([[ 61.8814,  53.5273,  65.1122,  59.5295,  63.2473,  63.3582,  49.6618,\n",
      "          57.5226,  56.9831,  61.0424,  49.2360,  45.0796,  60.3465,  55.7477,\n",
      "          60.6391,  54.9909,  55.8694,  60.2220,  35.0820,  47.0737,  53.0218,\n",
      "          56.9755,  60.0529,  32.3047,  20.4098,  58.4533,  59.7584,  63.0841,\n",
      "          54.4836,  43.6310,  57.3373,  22.6192,  32.9992,  61.3936,  32.4899,\n",
      "          60.6012,   8.0376,  39.1546,  58.7364,  28.7151,  25.3395,  59.5876,\n",
      "          13.1139,  54.3735,  25.8479,  10.7677,  54.2027,  11.2558,  38.6437,\n",
      "          60.1825,  22.2333,  24.1235,   8.7726,  27.5614,   2.9120,  12.3545,\n",
      "          26.7937,  17.6043,  34.9672, -12.4343,  23.0219,  27.1385, -15.7887,\n",
      "          61.7124,  42.1585,  20.3453,  24.3167,  -4.8190,  43.8532,  45.2633,\n",
      "          13.3825,  64.5126,   0.7540,  17.9066,  45.4248,  -8.3953,  60.9557,\n",
      "          51.1121,  22.9783,  49.9606,   8.7290,   3.0979,  55.1753,  -3.8223,\n",
      "          64.8611,  28.4904,  43.0782,  48.9762,  12.0101,  67.0276,  12.0111,\n",
      "          23.9232,  59.5696,  21.2108,  39.0073,  46.0813,  14.7475,  61.6706,\n",
      "          39.2160,  29.3636,  35.8707]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor([53.5273], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "Argmax actions:  tensor([2], device='cuda:0')\n",
      "tensor([54.0936], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([54.0936], device='cuda:0', grad_fn=<IndexPutBackward>)\n",
      "tensor([54.4527], device='cuda:0')\n",
      "tensor(0.4282, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor([[69.8217, 62.7116, 72.9487, 67.3711, 70.8939, 71.1167, 57.6730, 65.5343,\n",
      "         64.8148, 68.7852, 56.6590, 52.5855, 67.8952, 63.3010, 68.3314, 62.3348,\n",
      "         63.6183, 67.6165, 42.4274, 54.9824, 60.3265, 64.3770, 67.3753, 39.9209,\n",
      "         28.0862, 65.7306, 67.4345, 70.9891, 61.7090, 51.1367, 64.6862, 29.8620,\n",
      "         40.6824, 68.7255, 39.7542, 67.9210, 15.2490, 46.6965, 66.0314, 35.6698,\n",
      "         32.9140, 66.8376, 20.4195, 61.6589, 32.8767, 18.2042, 61.3629, 18.4511,\n",
      "         46.3521, 67.3684, 28.9866, 31.0500, 15.8538, 34.3417,  9.6600, 19.4795,\n",
      "         33.3326, 25.0639, 42.1582, -5.5555, 30.0898, 34.0673, -8.8221, 68.8530,\n",
      "         49.1213, 27.6719, 31.1747,  2.1985, 50.7622, 52.4861, 20.5302, 71.4381,\n",
      "          7.7528, 25.3170, 52.6153, -1.3586, 68.0895, 58.1571, 30.3286, 57.2420,\n",
      "         15.6469, 10.5821, 62.2527,  3.3277, 71.8068, 35.5090, 50.3183, 56.1360,\n",
      "         19.3133, 73.9992, 18.8239, 31.1360, 66.8728, 28.4109, 46.6219, 53.2537,\n",
      "         22.0076, 67.9159, 46.1737, 36.9736, 43.1922]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor([[ 63.6283,  55.3608,  66.8185,  61.1888,  66.2913,  66.0564,  51.9236,\n",
      "          59.3875,  59.3944,  63.5277,  53.6934,  48.2030,  63.8540,  58.4446,\n",
      "          63.3026,  58.4384,  57.4725,  62.1727,  37.2078,  49.2459,  56.9622,\n",
      "          60.5168,  62.6494,  35.4438,  22.5426,  62.1371,  62.0415,  65.8335,\n",
      "          57.5910,  46.8625,  60.4251,  26.2690,  36.7441,  63.1429,  35.5379,\n",
      "          64.3739,  12.9968,  41.9775,  61.7111,  33.1583,  29.6506,  61.3467,\n",
      "          15.9077,  56.4057,  30.3011,  13.3768,  56.7660,  14.4481,  40.0194,\n",
      "          63.0712,  27.3223,  26.0509,  11.5913,  33.8582,  10.7094,  15.7474,\n",
      "          31.1777,  20.3366,  38.5003,  -7.2658,  26.0212,  29.5287, -11.0445,\n",
      "          66.1286,  46.5212,  23.9947,  28.5018,   0.2056,  49.2398,  46.6589,\n",
      "          17.8200,  68.1692,   5.3408,  20.7294,  46.7196,  -2.4405,  65.7757,\n",
      "          53.7897,  25.3095,  52.4488,  13.9321,   5.8551,  57.1451,   0.3461,\n",
      "          71.6645,  32.7234,  46.6471,  51.2306,  16.3589,  71.9192,  16.1005,\n",
      "          27.7186,  63.3874,  24.3338,  41.3170,  49.6902,  19.2401,  71.4144,\n",
      "          42.2975,  31.2736,  38.9589]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Debugging the optimization of the agent\n",
    "\n",
    "#state = env.reset()\n",
    "#state = torch.tensor([state]).to(device).float()\n",
    "transition = init_transition()\n",
    "state = torch.FloatTensor([np.array(transition)]).to(device)\n",
    "print(state.shape)\n",
    "print(agent.main_dqn(state))\n",
    "print(agent.target_dqn(state))\n",
    "\n",
    "action = 1\n",
    "\n",
    "next_state, reward, done = env.step(action)\n",
    "print(next_state, reward, done)\n",
    "\n",
    "action = torch.tensor([action]).to(device)\n",
    "#next_state = torch.tensor([next_state]).float().to(device)\n",
    "next_state = add_to_transition(next_state, transition)\n",
    "next_state = torch.FloatTensor([np.array(next_state)]).to(device)\n",
    "reward = torch.tensor([reward]).float().to(device)\n",
    "done = torch.BoolTensor([done]).to(device)\n",
    "state_action_values = agent.main_dqn(state)\n",
    "print(state_action_values)\n",
    "state_action_values = state_action_values[0][action]\n",
    "print(state_action_values)\n",
    "\n",
    "next_state_actions = agent.main_dqn(next_state).max(1)[1]\n",
    "print(\"Argmax actions: \", next_state_actions)\n",
    "next_state_values = agent.target_dqn(next_state)[0][next_state_actions]\n",
    "print(next_state_values)\n",
    "next_state_values[done] = 0.0\n",
    "print(next_state_values)\n",
    "expected_state_action_values = next_state_values.detach() * 0.99 + reward\n",
    "print(expected_state_action_values)\n",
    "\n",
    "agent.optimizer.zero_grad()\n",
    "loss = torch.nn.SmoothL1Loss()(state_action_values, expected_state_action_values)\n",
    "print(loss)\n",
    "loss.backward()\n",
    "agent.optimizer.step()\n",
    "\n",
    "print(agent.main_dqn(state))\n",
    "print(agent.target_dqn(state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(8) 0.946156463865072\n"
     ]
    }
   ],
   "source": [
    "state = env.reset(streamline_index=0)\n",
    "#env.stepCounter += 1\n",
    "#state = env.state = TractographyState(env.referenceStreamline_ijk[1], env.interpolateDWIatState)\n",
    "best_actions = []\n",
    "    #path_vectors = []\n",
    "    #reference_vectors = []\n",
    "    #cosine_sims = []\n",
    "    #distances = []\n",
    "rewards = []\n",
    "all_states = []\n",
    "all_states.append(state.getCoordinate())\n",
    "for i in range(n_actions):\n",
    "    #print(state.getCoordinate(), env.state.getCoordinate())\n",
    "    #print(env.stepCounter)\n",
    "    next_state, reward,_ = env.step(i)\n",
    "    all_states.append(next_state.getCoordinate())\n",
    "    all_states.append(state.getCoordinate())\n",
    "    rewards.append(reward)\n",
    "    #print(reward)\n",
    "    best_actions.append(reward)\n",
    "    env.state = state\n",
    "    env.stepCounter -= 1\n",
    "best_action= torch.argmax(torch.tensor(best_actions))\n",
    "#return best_action, rewards[best_action]\n",
    "print(best_action, float(rewards[best_action]))\n",
    "#print(np.argmin(rewards))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[1.0, 0.0, 0.0]\n",
    "[0.0, 1.0, 0.0]\n",
    "[0.0, 0.0, 1.0]\n",
    "[1.0, 1.0, 1.0]\n",
    "[1.0, 1.0, 0.0]\n",
    "[1.0, 0.0, 1.0]\n",
    "[0.0, 1.0, 1.0]\n",
    "[0.0, 0.0, 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[(1.0, 1.0, 1.0), (1.0, 1.0, -0.1), (1.0, 1.0, 0.0), (1.0, -1.0, 1.0), (1.0, -1.0, -0.1), (1.0, -1.0, 0.0), (1.0, 0.0, 1.0), (1.0, 0.0, -0.1), (1.0, 0.0, 0.0), (-1.0, 1.0, 1.0), (-1.0, 1.0, -0.1), (-1.0, 1.0, 0.0), (-1.0, -1.0, 1.0), (-1.0, -1.0, -0.1), (-1.0, -1.0, 0.0), (-1.0, 0.0, 1.0), (-1.0, 0.0, -0.1), (-1.0, 0.0, 0.0), (0.0, 1.0, 1.0), (0.0, 1.0, -0.1), (0.0, 1.0, 0.0), (0.0, -1.0, 1.0), (0.0, -1.0, -0.1), (0.0, -1.0, 0.0), (0.0, 0.0, 1.0), (0.0, 0.0, -0.1), (0.0, 0.0, 0.0)]\n27\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "all_list = [[1.0, -1.0, 0.0], [1.0, -1.0, 0.0], [1.0, -0.1,  0.0]]\n",
    "res = list(itertools.product(*all_list))\n",
    "print(res)\n",
    "print(len(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ 0.56850094  0.7964525   0.20608273]\n [-0.2448079   0.32232834  0.91442525]\n [ 0.06630033  0.21294856  0.97481136]\n [ 0.2976444  -0.14866509  0.94303049]\n [-0.88066305 -0.02273461  0.47319735]\n [-0.3269133   0.60570818  0.72542767]\n [ 0.29302278 -0.82590186  0.48168845]\n [ 0.53896642 -0.55128484  0.63686751]\n [-0.39729605  0.91656922  0.04535095]\n [ 0.30028895 -0.34105966  0.89078889]\n [-0.18785252  0.02074667  0.98197811]\n [ 0.7497542  -0.36016226  0.55511421]\n [-0.02219545 -0.0315316   0.99925628]\n [-0.78862495 -0.33063452  0.51841248]\n [-0.17470144 -0.2668175   0.94778047]\n [ 0.24744799 -0.6622021   0.7072891 ]\n [-0.75737196 -0.15971698  0.63314943]\n [ 0.64424259  0.56096435  0.51987544]\n [-0.15121196 -0.92621937  0.34532972]\n [ 0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "import dipy\n",
    "n_pts = 19\n",
    "theta = np.pi * np.random.rand(n_pts)\n",
    "phi = 2 * np.pi * np.random.rand(n_pts)\n",
    "hsph_initial = dipy.data.HemiSphere(theta=theta, phi=phi)\n",
    "directions = hsph_initial.vertices\n",
    "directions = np.concatenate((directions, np.array([[0.0, 0.0, 0.0]])))\n",
    "print(directions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cos = torch.nn.CosineSimilarity(dim=0)\n",
    "\n",
    "def get_best_action(state, env):\n",
    "    best_actions = []\n",
    "    #path_vectors = []\n",
    "    #reference_vectors = []\n",
    "    #cosine_sims = []\n",
    "    #distances = []\n",
    "    rewards = []\n",
    "    for i in range(n_actions):\n",
    "        #print(state.getCoordinate(), env.state.getCoordinate())\n",
    "        #print(env.stepCounter)\n",
    "        next_state, reward,_ = env.step(i)\n",
    "        #print(env.stepCounter)\n",
    "        #current_index = np.min([env.stepCounter,len(env.referenceStreamline_ijk)-1])\n",
    "        #print(current_index)\n",
    "        #path_vector = next_state.getCoordinate() - state.getCoordinate().squeeze(0)\n",
    "        #print(path_vector)\n",
    "        #path_vectors.append(path_vector.numpy())\n",
    "        #reference_vector = env.referenceStreamline_ijk[current_index]-env.referenceStreamline_ijk[current_index-1]\n",
    "        #print(reference_vector)\n",
    "        #reference_vectors.append(reference_vector.numpy())\n",
    "        #cosine_sim = cos(path_vector, reference_vector)\n",
    "        #cosine_sims.append(cosine_sim.item())\n",
    "        #print(cosine_sim)\n",
    "        #dist = torch.sum((env.referenceStreamline_ijk[current_index] - next_state.getCoordinate())**2)\n",
    "        #dist = torch.dist(env.referenceStreamline_ijk[current_index], next_state.getCoordinate(), p=2)\n",
    "        #reward = -dist\n",
    "        #if dist < 0.1:\n",
    "        #    dist = 0\n",
    "        #else:\n",
    "        #    dist = dist - 0.1\n",
    "        #print(dist)\n",
    "        #distances.append(dist.item())\n",
    "\n",
    "        #reward = cosine_sim - dist\n",
    "        rewards.append(float(reward))\n",
    "        #print(reward)\n",
    "        best_actions.append(reward)\n",
    "        env.state = state\n",
    "        env.stepCounter -= 1\n",
    "\n",
    "    #best_actions = torch.topk(torch.tensor(best_actions), k=1)[1].numpy()\n",
    "    #rewards = np.array(rewards)\n",
    "    #print(rewards)\n",
    "    #random_action = np.random.choice(best_actions, size=1)\n",
    "    best_action= torch.argmax(torch.tensor(best_actions))\n",
    "    return best_action, rewards[best_action]#random_action\n",
    "    #return best_actions, rewards[best_actions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(6) -0.5125007211924459\ntensor(6) -2.020862962499808\ntensor(6) -4.3705958785439964\ntensor(6) -7.7640695223235765\ntensor(6) -12.16412045377145\ntensor(6) -17.446953982786077\ntensor(6) -23.75236255351808\ntensor(6) -30.996760569903753\ntensor(6) -39.287136993203646\ntensor(6) -48.62353966419279\ntensor(6) -58.66251862194845\ntensor(6) -69.40653808666264\ntensor(6) -80.99969003881719\ntensor(6) -92.99033447039456\ntensor(6) -104.7407125036759\ntensor(6) -117.0118435322357\ntensor(6) -129.41584155732937\ntensor(6) -142.8073516908918\ntensor(6) -157.1866628548108\ntensor(6) -171.02448864148596\ntensor(6) -185.86234020070896\ntensor(6) -199.88377338860352\ntensor(6) -214.92266265907364\ntensor(6) -230.979019255646\ntensor(6) -244.1700554337158\ntensor(6) -255.77049762166237\ntensor(6) -259.39129398594895\ntensor(6) -261.3067983865766\ntensor(6) -261.45687607784794\ntensor(6) -263.0694143536292\ntensor(5) -265.9198844149538\ntensor(5) -269.94449208756663\ntensor(5) -275.1434536138946\ntensor(5) -281.6701139047571\ntensor(11) -286.0951512778804\ntensor(11) -291.66101610192425\ntensor(11) -295.18945320353004\ntensor(11) -299.89238264080143\ntensor(11) -302.36641144341615\ntensor(11) -306.26099773711815\ntensor(11) -307.9130265186057\ntensor(11) -307.5822256386527\ntensor(11) -308.8847257477674\ntensor(1) -311.458078195771\ntensor(1) -312.0392588592115\ntensor(1) -313.86179403872666\ntensor(1) -313.17329545511234\ntensor(1) -313.7716421018671\ntensor(1) -315.6574423761428\ntensor(1) -315.69018743595177\ntensor(1) -317.0400698457919\ntensor(7) -318.1342588444777\ntensor(7) -321.84885947046376\ntensor(7) -329.9724497461891\ntensor(1) -340.50222679630735\ntensor(1) -352.9017764481463\ntensor(1) -364.55824035312634\ntensor(16) -373.48978507751457\ntensor(16) -381.66168957750756\ntensor(16) -391.0146706553965\ntensor(16) -397.6413797811406\ntensor(16) -405.48442936104783\ntensor(16) -412.6130165475623\ntensor(16) -418.8897285318824\ntensor(16) -419.4198887352405\ntensor(16) -414.3425681365582\ntensor(16) -403.83316119738583\ntensor(16) -386.35315246853355\ntensor(16) -366.1939880714654\ntensor(16) -348.6616955564323\ntensor(0) -329.2556302317287\ntensor(0) -309.34295486151575\ntensor(0) -289.2886151174049\ntensor(0) -270.7225293456711\ntensor(0) -253.6640711811554\ntensor(0) -230.46089353044687\ntensor(0) -206.446261551258\ntensor(0) -185.01921735031308\ntensor(0) -165.02047084486966\ntensor(0) -146.96387387688705\ntensor(0) -130.30304689886032\ntensor(0) -117.21019489626107\ntensor(0) -108.84101286463743\ntensor(0) -101.62825743096158\ntensor(0) -95.96491022176178\ntensor(0) -88.30822543326687\ntensor(0) -86.57334287005204\ntensor(0) -84.85846030683723\ntensor(0) -83.1635777436224\ntensor(0) -81.48869518040757\ntensor(0) -79.83381261719273\ntensor(0) -78.1989300539779\ntensor(0) -76.58404749076307\ntensor(0) -74.98916492754822\ntensor(0) -73.41428236433339\ntensor(0) -71.85939980111856\ntensor(0) -70.3245172379037\ntensor(0) -68.80963467468888\ntensor(0) -67.31475211147404\ntensor(0) -65.83986954825919\ntensor(0) -64.38498698504434\ntensor(0) -62.950104421829494\ntensor(0) -61.53522185861465\ntensor(0) -60.14033929539979\ntensor(0) -58.765456732184944\ntensor(0) -57.410574168970086\ntensor(0) -56.075691605755225\ntensor(0) -54.76080904254037\ntensor(0) -53.46592647932552\ntensor(0) -52.19104391611066\ntensor(0) -50.936161352895795\ntensor(0) -49.701278789680934\ntensor(0) -48.48639622646607\ntensor(0) -47.2915136632512\ntensor(0) -46.11663110003634\ntensor(0) -44.96174853682147\ntensor(0) -43.826865973606594\ntensor(0) -42.711983410391724\ntensor(0) -41.61710084717685\ntensor(0) -40.54221828396197\ntensor(0) -39.4873357207471\ntensor(0) -38.45245315753222\ntensor(0) -37.437570594317336\ntensor(0) -36.44268803110246\ntensor(0) -35.46780546788757\ntensor(0) -34.51292290467269\ntensor(0) -33.5780403414578\ntensor(0) -32.66315777824292\ntensor(0) -31.768275215028027\ntensor(0) -30.893392651813137\ntensor(0) -30.038510088598247\ntensor(0) -29.20362752538335\ntensor(0) -28.38874496216846\ntensor(0) -27.59386239895356\ntensor(0) -26.818979835738666\ntensor(0) -26.064097272523764\ntensor(0) -25.329214709308864\ntensor(0) -24.614332146093957\ntensor(0) -23.919449582879057\ntensor(0) -23.24456701966415\ntensor(0) -22.58968445644924\ntensor(0) -21.954801893234333\ntensor(0) -21.339919330019423\ntensor(0) -20.74503676680451\ntensor(0) -20.1701542035896\ntensor(0) -19.615271640374683\ntensor(0) -19.080389077159765\ntensor(0) -18.56550651394485\ntensor(0) -18.070623950729928\ntensor(0) -17.595741387515005\ntensor(0) -17.140858824300086\ntensor(14) -16.683422597816104\ntensor(0) -16.24287275335742\ntensor(14) -15.79976924562968\ntensor(0) -15.373552119927236\ntensor(14) -14.944781330955733\ntensor(0) -14.532896924009535\ntensor(14) -14.118458853794268\ntensor(0) -13.720907165604308\ntensor(14) -13.320801814145282\ntensor(0) -12.93758284471156\ntensor(14) -12.551810212008773\ntensor(0) -12.182923961331294\ntensor(14) -11.811484047384745\ntensor(0) -11.456930515463506\ntensor(14) -11.099823320273197\ntensor(0) -10.759602507108198\ntensor(14) -10.416828030674127\ntensor(0) -10.090939936265366\ntensor(14) -9.762498178587537\ntensor(0) -9.450942802935018\ntensor(14) -9.136833764013426\ntensor(0) -8.839611107117149\ntensor(14) -8.539834786951793\ntensor(0) -8.256944848811756\ntensor(12) -7.969763322584499\ntensor(0) -7.698450346630229\ntensor(12) -7.4228457825887375\ntensor(0) -7.163109768820233\ntensor(12) -6.899082166964506\ntensor(0) -6.650923115381769\ntensor(12) -6.3984724757118085\ntensor(0) -6.1618903863148375\ntensor(12) -5.921016708830641\ntensor(0) -5.696011581619439\ntensor(12) -5.4667148663210074\ntensor(0) -5.253286701295571\ntensor(12) -5.035566948182905\ntensor(0) -4.833715745343237\ntensor(12) -4.627572954416335\ntensor(0) -4.437298713762433\ntensor(12) -4.242732885021297\ntensor(0) -4.064035606553163\ntensor(12) -3.8810467399977906\ntensor(0) -3.713926423715424\ntensor(12) -3.5425145193458163\ntensor(0) -3.386971165249217\ntensor(12) -3.2271362230653744\ntensor(13) -3.08084595219175\ntensor(0) -3.08084595219175\n200\n"
     ]
    }
   ],
   "source": [
    "state = env.reset(streamline_index=0)\n",
    "all_top_actions = []\n",
    "all_top_rewards = []\n",
    "terminal = False\n",
    "while terminal != True:\n",
    "    best_actions, best_rewards = get_best_action(state, env)\n",
    "    all_top_actions.append(best_actions)\n",
    "    all_top_rewards.append(best_rewards)\n",
    "    next_state, reward, terminal = env.step(best_actions)\n",
    "    state = next_state\n",
    "\n",
    "for i in range(len(all_top_actions)):\n",
    "    print(all_top_actions[i], all_top_rewards[i])\n",
    "print(len(all_top_actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "35\n"
     ]
    }
   ],
   "source": [
    "streamline_0 = set().union(*all_top_actions)\n",
    "print(len(streamline_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "streamline_1 = set().union(*all_top_actions)\n",
    "print(len(streamline_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "streamline_2 = set().union(*all_top_actions)\n",
    "print(len(streamline_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New run\n",
      "0 [43.4998  94.53768 24.26608]\n",
      "1 [43.29119233 94.16509197 24.95438249] tensor(0.7652, dtype=torch.float64) tensor(0.7786, dtype=torch.float64) False\n",
      "2 [42.72683425 94.16310479 25.53541262] tensor(0.9863, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "3 [42.16247616 94.1611176  26.11644274] tensor(0.9863, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "4 [42.58868676 93.71840502 26.64412645] tensor(-1.6293, dtype=torch.float64) tensor(-1.6252, dtype=torch.float64) False\n",
      "5 [43.34130514 93.65398249 26.93655646] tensor(-8.6558, dtype=torch.float64) tensor(-8.0003, dtype=torch.float64) False\n",
      "6 [43.24986661 94.30478423 27.41004995] tensor(-10.4995, dtype=torch.float64) tensor(-3.3497, dtype=torch.float64) False\n",
      "7 [43.70944068 93.69284061 27.67541137] tensor(-19.9590, dtype=torch.float64) tensor(-10.7563, dtype=torch.float64) False\n",
      "8 [44.18737204 93.98184884 27.08876339] tensor(-29.1352, dtype=torch.float64) tensor(-13.1668, dtype=torch.float64) False\n",
      "9 [43.44978137 94.04268204 27.41794316] tensor(-22.7587, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "10 [42.86132353 94.3302084  27.89454148] tensor(-18.0710, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "11 [43.44070405 94.15345569 28.43229301] tensor(-23.6602, dtype=torch.float64) tensor(-8.8847, dtype=torch.float64) False\n",
      "12 [44.2146272  93.92593524 28.50562373] tensor(-35.1334, dtype=torch.float64) tensor(-15.2290, dtype=torch.float64) False\n",
      "13 [43.62616936 94.2134616  28.98222206] tensor(-28.5671, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "14 [43.25537571 94.69768497 29.51526971] tensor(-22.7096, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "15 [42.88458206 95.18190834 30.04831736] tensor(-17.8020, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "16 [43.62217273 95.12107515 29.71913758] tensor(-28.9087, dtype=torch.float64) tensor(-13.4464, dtype=torch.float64) False\n",
      "17 [43.25137908 95.60529852 30.25218523] tensor(-24.1313, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "18 [43.23629104 95.41716542 31.03988967] tensor(-24.2855, dtype=torch.float64) tensor(-3.1631, dtype=torch.float64) False\n",
      "19 [42.80678347 95.33111822 30.35855339] tensor(-35.1505, dtype=torch.float64) tensor(-13.9221, dtype=torch.float64) False\n",
      "20 [42.03286031 95.55863867 30.28522267] tensor(-40.5407, dtype=torch.float64) tensor(-8.7935, dtype=torch.float64) False\n",
      "21 [41.39782105 96.05990625 30.24577721] tensor(-45.2930, dtype=torch.float64) tensor(-7.7059, dtype=torch.float64) False\n",
      "22 [41.7686147  95.57568288 29.71272956] tensor(-62.4398, dtype=torch.float64) tensor(-20.4682, dtype=torch.float64) False\n",
      "23 [42.22818876 94.96373926 29.97809098] tensor(-75.6296, dtype=torch.float64) tensor(-17.5101, dtype=torch.float64) False\n",
      "24 [42.36271933 95.7058968  30.27339373] tensor(-69.6617, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "25 [42.4972499  96.44805434 30.56869647] tensor(-66.0625, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "26 [42.92675747 96.53410154 31.25003275] tensor(-70.1506, dtype=torch.float64) tensor(-6.9151, dtype=torch.float64) False\n",
      "27 [43.06128803 97.27625908 31.5453355 ] tensor(-66.5113, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "28 [43.17298452 98.07820093 31.52268249] tensor(-64.0323, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "29 [43.28468102 98.88014278 31.50002949] tensor(-61.9091, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "30 [42.95006499 99.08612054 30.79171792] tensor(-72.1356, dtype=torch.float64) tensor(-12.1561, dtype=torch.float64) False\n",
      "31 [43.06176148 99.88806239 30.76906491] tensor(-67.3303, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "32 [43.65021932 99.60053602 30.29246658] tensor(-80.7993, dtype=torch.float64) tensor(-17.1149, dtype=torch.float64) False\n",
      "33 [ 43.76191581 100.40247788  30.26981358] tensor(-75.2850, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "34 [ 43.87361231 101.20441973  30.24716057] tensor(-71.4038, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "35 [ 43.9853088  102.00636158  30.22450756] tensor(-68.4673, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "36 [ 44.00039685 102.19449468  29.43680312] tensor(-76.9320, dtype=torch.float64) tensor(-9.7807, dtype=torch.float64) False\n",
      "37 [ 43.68885694 102.11083132  30.1797993 ] tensor(-95.0001, dtype=torch.float64) tensor(-18.4581, dtype=torch.float64) False\n",
      "38 [ 43.21092557 101.82182309  30.76644728] tensor(-120.6000, dtype=torch.float64) tensor(-26.4038, dtype=torch.float64) False\n",
      "39 [ 43.32262206 102.62376494  30.74379427] tensor(-118.6818, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "40 [ 43.64613361 103.33253191  30.5222324 ] tensor(-118.7082, dtype=torch.float64) tensor(0.2850, dtype=torch.float64) False\n",
      "41 [ 44.2842523  103.44495641  31.00830367] tensor(-132.9434, dtype=torch.float64) tensor(-13.9450, dtype=torch.float64) False\n",
      "42 [ 44.39594879 104.24689826  30.98565066] tensor(-131.1848, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "43 [ 43.80749095 104.53442462  31.46224899] tensor(-129.9358, dtype=torch.float64) tensor(-15.7979, dtype=torch.float64) False\n",
      "44 [ 43.68610802 105.32261987  31.60407436] tensor(-113.5127, dtype=torch.float64) tensor(-1.2640, dtype=torch.float64) False\n",
      "45 [ 44.00961957 106.03138684  31.38251249] tensor(-96.8166, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "46 [ 44.12131606 106.83332869  31.35985948] tensor(-81.5407, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "47 [ 43.36160083 106.62100796  31.17586851] tensor(-90.2927, dtype=torch.float64) tensor(-21.7735, dtype=torch.float64) False\n",
      "48 [ 42.60898245 106.6854305   30.8834385 ] tensor(-93.0858, dtype=torch.float64) tensor(-18.1371, dtype=torch.float64) False\n",
      "49 [ 42.93249399 107.39419747  30.66187663] tensor(-76.7798, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "50 [ 43.36200156 107.48024467  31.34321291] tensor(-75.1463, dtype=torch.float64) tensor(-11.0396, dtype=torch.float64) False\n",
      "51 [ 43.68551311 108.18901164  31.12165105] tensor(-60.9746, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "52 [ 43.53822543 108.60786303  30.44417791] tensor(-54.7237, dtype=torch.float64) tensor(-5.0120, dtype=torch.float64) False\n",
      "53 [ 43.86173697 109.31663     30.22261604] tensor(-42.6610, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "54 [ 44.18524852 110.02539697  30.00105417] tensor(-32.5089, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "55 [ 44.04162302 109.71520033  29.2667179 ] tensor(-38.0184, dtype=torch.float64) tensor(-13.3691, dtype=torch.float64) False\n",
      "56 [ 44.41343856 110.42773414  29.36745901] tensor(-27.0661, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "57 [ 44.7852541  111.14026795  29.46820012] tensor(-18.8626, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "58 [ 45.43084035 110.76942195  29.78724815] tensor(-21.7265, dtype=torch.float64) tensor(-8.7553, dtype=torch.float64) False\n",
      "59 [ 45.05699669 110.98787019  30.47180735] tensor(-21.1952, dtype=torch.float64) tensor(-6.7392, dtype=torch.float64) False\n",
      "60 [ 45.38050824 111.69663716  30.25024548] tensor(-13.1659, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "61 [ 45.49220473 112.49857901  30.22759247] tensor(-7.3340, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "62 [ 44.79877859 112.29123629  30.59128078] tensor(-12.5222, dtype=torch.float64) tensor(-8.7903, dtype=torch.float64) False\n",
      "63 [ 45.12229014 113.00000326  30.36971891] tensor(-5.4633, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "64 [ 45.55179771 113.08605046  31.05105519] tensor(-6.2774, dtype=torch.float64) tensor(-3.9945, dtype=torch.float64) False\n",
      "65 [ 45.87530925 113.79481743  30.82949332] tensor(-1.5985, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "66 [ 46.43966734 113.79680461  30.2484632 ] tensor(-0.8750, dtype=torch.float64) tensor(-0.8292, dtype=torch.float64) False\n",
      "67 [ 46.01015977 113.71075741  29.56712692] tensor(-1.5315, dtype=torch.float64) tensor(-1.5262, dtype=torch.float64) False\n",
      "68 [ 46.38197531 114.42329122  29.66786803] tensor(0.9948, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defi stopped at/close to the terminal state!\n",
      "69 [ 46.94407554 114.88476913  29.31124292] tensor(0.8157, dtype=torch.float64) tensor(0.8157, dtype=torch.float64) False\n",
      "Defi stopped at/close to the terminal state!\n",
      "Defi stopped at/close to the terminal state!\n",
      "70 [ 46.94407554 114.88476913  29.31124292] 1.0 1.0 True\n",
      "1 -3320.8259851139405\n",
      "New run\n",
      "0 [47.870224 74.80299  26.640089]\n",
      "1 [47.13263333 74.86382697 26.96926881] tensor(0.5242, dtype=torch.float64) tensor(0.5259, dtype=torch.float64) False\n",
      "2 [46.73619767 74.26427052 26.59581088] tensor(0.9960, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "3 [46.90065931 74.82407477 27.15765745] tensor(-3.4145, dtype=torch.float64) tensor(-3.4105, dtype=torch.float64) False\n",
      "4 [47.66037454 75.0363955  27.34164843] tensor(-10.6591, dtype=torch.float64) tensor(-8.3526, dtype=torch.float64) False\n",
      "5 [47.80400003 75.34659214 28.0759847 ] tensor(-22.8400, dtype=torch.float64) tensor(-13.0927, dtype=torch.float64) False\n",
      "6 [47.40756437 74.74703568 27.70252678] tensor(-20.9048, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "7 [47.08273208 74.18032566 28.18150875] tensor(-26.9755, dtype=torch.float64) tensor(-5.1718, dtype=torch.float64) False\n",
      "8 [47.49929281 73.48614123 28.15533369] tensor(-32.5478, dtype=torch.float64) tensor(-5.0766, dtype=torch.float64) False\n",
      "9 [46.88062532 72.98572663 28.00388811] tensor(-33.6384, dtype=torch.float64) tensor(-0.6035, dtype=torch.float64) False\n",
      "10 [46.71616368 72.42592237 27.44204155] tensor(-33.3168, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "11 [46.55170203 71.86611811 26.88019498] tensor(-32.8435, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "12 [46.21708601 72.07209587 26.17188342] tensor(-38.0253, dtype=torch.float64) tensor(-4.6123, dtype=torch.float64) False\n",
      "13 [46.0197255  72.84202526 26.01581433] tensor(-56.5926, dtype=torch.float64) tensor(-18.3794, dtype=torch.float64) False\n",
      "14 [45.88519493 72.09986772 25.72051159] tensor(-54.7027, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "15 [45.72073329 71.54006347 25.15866502] tensor(-54.4498, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "16 [45.58620272 70.79790593 24.86336227] tensor(-53.9758, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "17 [45.45167215 70.05574839 24.56805952] tensor(-53.6101, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "18 [45.31714159 69.31359085 24.27275678] tensor(-52.8860, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "19 [45.40858012 68.6627891  23.79926329] tensor(-52.2366, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "20 [45.50001864 68.01198736 23.3257698 ] tensor(-51.6957, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "21 [45.59145717 67.36118561 22.85227631] tensor(-50.5629, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "22 [45.98789283 67.96074207 23.22573424] tensor(-75.5754, dtype=torch.float64) tensor(-25.1300, dtype=torch.float64) False\n",
      "23 [45.85336227 67.21858453 22.93043149] tensor(-71.9535, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "24 [45.26490443 67.50611089 23.40702981] tensor(-95.4622, dtype=torch.float64) tensor(-24.1952, dtype=torch.float64) False\n",
      "25 [45.35634296 66.85530914 22.93353632] tensor(-91.6316, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "26 [44.76788512 67.14283551 23.41013465] tensor(-118.9730, dtype=torch.float64) tensor(-28.1871, dtype=torch.float64) False\n",
      "27 [45.13867877 66.65861214 22.877087  ] tensor(-116.4966, dtype=torch.float64) tensor(-0.7718, dtype=torch.float64) False\n",
      "28 [45.2600617  65.87041689 22.73526162] tensor(-112.8097, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "29 [45.58121045 65.1941101  22.42611344] tensor(-108.4399, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "30 [45.70259338 64.40591485 22.28428807] tensor(-104.5799, dtype=torch.float64) tensor(0.9706, dtype=torch.float64) False\n",
      "31 [46.39601952 64.61325757 21.92059976] tensor(-115.1892, dtype=torch.float64) tensor(-14.3127, dtype=torch.float64) False\n",
      "32 [46.51740245 63.82506233 21.77877439] tensor(-110.0580, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "33 [46.63878538 63.03686708 21.63694901] tensor(-104.8013, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "34 [47.05534612 62.34268265 21.61077396] tensor(-98.6257, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "35 [47.47190685 61.64849822 21.5845989 ] tensor(-91.6455, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "36 [47.63636849 62.20830248 22.14644546] tensor(-109.5331, dtype=torch.float64) tensor(-24.5794, dtype=torch.float64) False\n",
      "37 [48.05292923 61.51411805 22.12027041] tensor(-100.9384, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "38 [48.46948996 60.81993362 22.09409535] tensor(-92.5974, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "39 [48.8860507  60.12574919 22.06792029] tensor(-86.6859, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "40 [49.34562476 59.51380557 22.33328171] tensor(-80.3552, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "41 [48.78126668 59.51181839 22.91431184] tensor(-95.2302, dtype=torch.float64) tensor(-19.3926, dtype=torch.float64) False\n",
      "42 [49.24084075 58.89987477 23.17967326] tensor(-89.1375, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "43 [49.70041481 58.28793115 23.44503468] tensor(-84.6163, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "44 [50.33545408 57.78666357 23.48448014] tensor(-80.7189, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "45 [50.79502814 57.17471995 23.74984156] tensor(-77.4668, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "46 [51.48845428 57.38206267 23.38615325] tensor(-84.8360, dtype=torch.float64) tensor(-9.1372, dtype=torch.float64) False\n",
      "47 [52.13404052 57.01121667 23.70520128] tensor(-81.7999, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "48 [52.77962677 56.64037067 24.02424931] tensor(-79.4756, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "49 [52.40781123 55.92783685 23.9235082 ] tensor(-91.8528, dtype=torch.float64) tensor(-13.8343, dtype=torch.float64) False\n",
      "50 [53.05339747 55.55699085 24.24255623] tensor(-87.9952, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "51 [53.69898371 55.18614485 24.56160426] tensor(-85.7608, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "52 [54.39240985 55.39348757 24.19791595] tensor(-94.2557, dtype=torch.float64) tensor(-9.3875, dtype=torch.float64) False\n",
      "53 [54.95451008 55.85496548 23.84129084] tensor(-108.7464, dtype=torch.float64) tensor(-15.4793, dtype=torch.float64) False\n",
      "54 [55.71422531 56.06728621 24.02528182] tensor(-112.1659, dtype=torch.float64) tensor(-4.6094, dtype=torch.float64) False\n",
      "55 [55.57059982 55.75708958 23.29094554] tensor(-138.9835, dtype=torch.float64) tensor(-27.3563, dtype=torch.float64) False\n",
      "56 [55.45888555 55.88855496 24.08235996] tensor(-147.8681, dtype=torch.float64) tensor(-10.3504, dtype=torch.float64) False\n",
      "57 [55.78239709 56.59732193 23.86079809] tensor(-173.4678, dtype=torch.float64) tensor(-25.8435, dtype=torch.float64) False\n",
      "58 [56.20860769 56.15460935 24.3884818 ] tensor(-151.8601, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "59 [55.65509906 55.5727167  24.49397656] tensor(-154.8327, dtype=torch.float64) tensor(-21.1460, dtype=torch.float64) False\n",
      "60 [56.23447957 55.395964   25.03172809] tensor(-134.4820, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "61 [56.81386008 55.21921129 25.56947961] tensor(-116.5393, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "62 [56.50232017 55.13554792 26.31247579] tensor(-112.5423, dtype=torch.float64) tensor(-11.6444, dtype=torch.float64) False\n",
      "63 [56.87311382 54.65132455 25.77942814] tensor(-109.2651, dtype=torch.float64) tensor(-12.6619, dtype=torch.float64) False\n",
      "64 [57.59894609 54.34704732 25.58790038] tensor(-97.9838, dtype=torch.float64) tensor(-4.9761, dtype=torch.float64) False\n",
      "65 [58.17832661 54.17029461 26.1256519 ] tensor(-82.0025, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "66 [58.57622104 54.53777613 26.72792871] tensor(-73.6296, dtype=torch.float64) tensor(-4.7076, dtype=torch.float64) False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67 [58.37886052 55.30770552 26.57185963] tensor(-85.5689, dtype=torch.float64) tensor(-24.3566, dtype=torch.float64) False\n",
      "68 [58.80507112 54.86499295 27.09954334] tensor(-69.8693, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "69 [59.23128171 54.42228037 27.62722706] tensor(-56.9122, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "70 [59.62771737 55.02183682 28.00068498] tensor(-55.2908, dtype=torch.float64) tensor(-9.0382, dtype=torch.float64) False\n",
      "71 [59.1982098  54.93578963 27.3193487 ] tensor(-65.9700, dtype=torch.float64) tensor(-21.5757, dtype=torch.float64) False\n",
      "72 [58.56317054 55.43705721 27.27990324] tensor(-77.8497, dtype=torch.float64) tensor(-25.2129, dtype=torch.float64) False\n",
      "73 [59.20875678 55.0662112  27.59895127] tensor(-62.8109, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "74 [58.43483362 55.29373166 27.52562054] tensor(-75.9736, dtype=torch.float64) tensor(-24.5027, dtype=torch.float64) False\n",
      "75 [59.08041987 54.92288565 27.84466858] tensor(-60.9769, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "76 [58.6509123  54.83683845 27.16333229] tensor(-72.7328, dtype=torch.float64) tensor(-22.9187, dtype=torch.float64) False\n",
      "77 [59.29649854 54.46599245 27.48238032] tensor(-57.8398, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "78 [58.55890787 54.52682565 27.8115601 ] tensor(-65.0423, dtype=torch.float64) tensor(-18.0593, dtype=torch.float64) False\n",
      "79 [58.23775912 55.20313244 28.12070828] tensor(-72.3742, dtype=torch.float64) tensor(-19.9483, dtype=torch.float64) False\n",
      "80 [58.88334536 54.83228644 28.43975631] tensor(-58.1389, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "81 [59.5289316  54.46144044 28.75880434] tensor(-46.1685, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "82 [60.17451784 54.09059443 29.07785237] tensor(-35.5104, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "83 [60.82010408 53.71974843 29.3969004 ] tensor(-26.1644, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "84 [61.46569033 53.34890243 29.71594843] tensor(-18.1307, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "85 [61.58762106 52.92507205 29.0365364 ] tensor(-19.7630, dtype=torch.float64) tensor(-7.3539, dtype=torch.float64) False\n",
      "86 [61.21682741 53.40929542 29.56958405] tensor(-21.4139, dtype=torch.float64) tensor(-8.8846, dtype=torch.float64) False\n",
      "87 [61.26574725 54.15406523 29.25490201] tensor(-27.9210, dtype=torch.float64) tensor(-13.4013, dtype=torch.float64) False\n",
      "88 [61.69195784 53.71135265 29.78258573] tensor(-18.5534, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "89 [61.49459733 54.48128204 29.62651664] tensor(-27.1995, dtype=torch.float64) tensor(-14.3231, dtype=torch.float64) False\n",
      "90 [61.17108578 53.77251507 29.84807851] tensor(-22.7322, dtype=torch.float64) tensor(-3.8465, dtype=torch.float64) False\n",
      "91 [60.84757424 53.0637481  30.06964038] tensor(-20.2617, dtype=torch.float64) tensor(-4.5310, dtype=torch.float64) False\n",
      "92 [61.27378483 52.62103552 30.59732409] tensor(-13.0295, dtype=torch.float64) tensor(0.4801, dtype=torch.float64) False\n",
      "93 [62.03350006 52.83335625 30.78131507] tensor(-9.3651, dtype=torch.float64) tensor(-1.1268, dtype=torch.float64) False\n",
      "94 [62.6790863  52.46251025 31.1003631 ] tensor(-4.2267, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "95 [62.79080057 52.33104486 30.30894869] tensor(-6.4966, dtype=torch.float64) tensor(-4.8877, dtype=torch.float64) False\n",
      "96 [63.21701116 51.88833228 30.8366324 ] tensor(-0.9609, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "97 [63.55162719 51.68235453 31.54494397] tensor(0.9867, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "Defi stopped at/close to the terminal state!\n",
      "Defi stopped at/close to the terminal state!\n",
      "98 [63.55162719 51.68235453 31.54494397] 1.0 1.0 True\n",
      "2 -4971.155473458521\n",
      "New run\n",
      "0 [ 73.651344 107.88106   93.29415 ]\n",
      "1 [ 74.38893497 107.82022454  92.96497153] tensor(0.9861, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "2 [ 75.12652564 107.75939134  92.63579176] tensor(0.9951, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "3 [ 75.03508711 108.41019309  93.10928525] tensor(-0.3727, dtype=torch.float64) tensor(-0.3594, dtype=torch.float64) False\n",
      "4 [ 74.47706227 108.93310281  93.37625661] tensor(-4.9641, dtype=torch.float64) tensor(-4.9593, dtype=torch.float64) False\n",
      "5 [ 75.21465294 108.87226961  93.04707683] tensor(-3.0769, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "6 [ 75.77901103 108.87425679  92.46604671] tensor(-2.6114, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "7 [ 76.34336911 108.87624398  91.88501659] tensor(-2.3126, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "8 [ 77.03679525 109.0835867   91.52132828] tensor(-1.9739, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "9 [ 77.73022139 109.29092943  91.15763997] tensor(-1.7382, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "10 [ 78.42364753 109.49827216  90.79395167] tensor(-1.5473, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "11 [ 78.58810917 110.05807641  91.35579823] tensor(-6.9520, dtype=torch.float64) tensor(-4.6375, dtype=torch.float64) False\n",
      "12 [ 79.06604054 110.34708464  90.76915025] tensor(-5.7114, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "13 [ 79.54397191 110.63609286  90.18250227] tensor(-5.5546, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "14 [ 80.10833    110.63808005  89.60147215] tensor(-5.5049, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "15 [ 80.19976852 109.9872783   89.12797866] tensor(-9.3728, dtype=torch.float64) tensor(-3.0897, dtype=torch.float64) False\n",
      "16 [ 80.67769989 110.27628652  88.54133068] tensor(-8.5270, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "17 [ 79.91798466 110.0639658   88.3573397 ] tensor(-19.4577, dtype=torch.float64) tensor(-10.5386, dtype=torch.float64) False\n",
      "18 [ 80.48234275 110.06595298  87.77630958] tensor(-17.4142, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "19 [ 79.89388491 110.35347934  88.2529079 ] tensor(-34.7416, dtype=torch.float64) tensor(-17.0523, dtype=torch.float64) False\n",
      "20 [ 80.45824299 110.35546653  87.67187778] tensor(-31.6843, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "21 [ 81.02260108 110.35745371  87.09084766] tensor(-30.7053, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "22 [ 81.58695916 110.3594409   86.50981753] tensor(-29.5150, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "23 [ 82.15131725 110.36142808  85.92878741] tensor(-28.6557, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "24 [ 82.5251609  110.14297984  85.24422822] tensor(-27.9509, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "25 [ 82.89900455 109.9245316   84.55966902] tensor(-26.5390, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "26 [ 83.2728482  109.70608336  83.87510983] tensor(-24.7480, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "27 [ 83.64669186 109.48763512  83.19055063] tensor(-21.4259, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "28 [ 83.75840612 109.35616974  82.39913622] tensor(-18.0547, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "29 [ 83.87012039 109.22470435  81.60772181] tensor(-15.0750, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "30 [ 84.46903112 109.5983139   82.00498978] tensor(-26.8269, dtype=torch.float64) tensor(-13.2529, dtype=torch.float64) False\n",
      "31 [ 84.32540563 109.28811727  81.27065351] tensor(-23.2780, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "32 [ 84.21370913 108.48617542  81.29330651] tensor(-28.3916, dtype=torch.float64) tensor(-5.3973, dtype=torch.float64) False\n",
      "33 [ 83.78420156 108.40012822  80.61197023] tensor(-26.8494, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "34 [ 84.40286905 108.90054282  80.76341581] tensor(-43.4293, dtype=torch.float64) tensor(-16.5066, dtype=torch.float64) False\n",
      "35 [ 83.97336148 108.81449562  80.08207953] tensor(-40.6578, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "36 [ 83.54385391 108.72844842  79.40074325] tensor(-39.7561, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 [ 83.37939227 108.16864417  78.83889669] tensor(-40.2734, dtype=torch.float64) tensor(-0.7922, dtype=torch.float64) False\n",
      "38 [ 82.9498847  108.08259697  78.15756041] tensor(-39.0704, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "39 [ 82.31176601 107.97017248  77.67148914] tensor(-37.8985, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "40 [ 83.04629254 108.29810313  77.57645087] tensor(-57.3958, dtype=torch.float64) tensor(-19.6488, dtype=torch.float64) False\n",
      "41 [ 83.69187878 107.92725713  77.8954989 ] tensor(-79.7409, dtype=torch.float64) tensor(-24.4366, dtype=torch.float64) False\n",
      "42 [ 83.05376009 107.81483263  77.40942764] tensor(-76.0080, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "43 [ 82.41564141 107.70240814  76.92335637] tensor(-74.0522, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "44 [ 81.77752272 107.58998365  76.43728511] tensor(-72.5038, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "45 [ 81.02490434 107.65440618  76.1448551 ] tensor(-70.4472, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "46 [ 80.6530888  106.94187237  76.04411399] tensor(-76.2125, dtype=torch.float64) tensor(-6.5527, dtype=torch.float64) False\n",
      "47 [ 80.06463096 107.22939874  76.52071232] tensor(-81.9418, dtype=torch.float64) tensor(-7.5811, dtype=torch.float64) False\n",
      "48 [ 79.42959169 107.73066632  76.48126685] tensor(-83.5457, dtype=torch.float64) tensor(-3.1749, dtype=torch.float64) False\n",
      "49 [ 78.67697331 107.79508885  76.18883685] tensor(-81.0573, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "50 [ 79.42959169 107.73066632  76.48126685] tensor(-111.0844, dtype=torch.float64) tensor(-32.2845, dtype=torch.float64) False\n",
      "51 [ 78.67697331 107.79508885  76.18883685] tensor(-106.0909, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "52 [ 77.92435493 107.85951138  75.89640684] tensor(-101.6839, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "53 [ 77.36633009 108.3824211   76.1633782 ] tensor(-103.3423, dtype=torch.float64) tensor(-5.0537, dtype=torch.float64) False\n",
      "54 [ 77.95478793 108.09489474  75.68677988] tensor(-123.9718, dtype=torch.float64) tensor(-27.1248, dtype=torch.float64) False\n",
      "55 [ 78.28940395 107.88891698  76.39509145] tensor(-146.3529, dtype=torch.float64) tensor(-31.0086, dtype=torch.float64) False\n",
      "56 [ 77.53678557 107.95333952  76.10266144] tensor(-135.7934, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "57 [ 76.89119933 108.32418552  75.78361341] tensor(-129.7773, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "58 [ 76.51938379 107.61165171  75.6828723 ] tensor(-144.1094, dtype=torch.float64) tensor(-16.1338, dtype=torch.float64) False\n",
      "59 [ 75.74546063 107.83917216  75.60954157] tensor(-140.7928, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "60 [ 74.97153748 108.06669261  75.53621085] tensor(-138.8294, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "61 [ 74.83700691 107.32453507  75.2409081 ] tensor(-160.8257, dtype=torch.float64) tensor(-23.8752, dtype=torch.float64) False\n",
      "62 [ 74.20196765 107.82580265  75.20146264] tensor(-157.0469, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "63 [ 73.56692838 108.32707023  75.16201718] tensor(-154.0511, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "64 [ 72.93188912 108.82833781  75.12257172] tensor(-150.2733, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "65 [ 72.29684985 109.32960539  75.08312626] tensor(-143.8722, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "66 [ 72.6706935  109.11115716  74.39856706] tensor(-167.1626, dtype=torch.float64) tensor(-31.6070, dtype=torch.float64) False\n",
      "67 [ 72.27279907 108.74367563  73.79629026] tensor(-173.9174, dtype=torch.float64) tensor(-19.6495, dtype=torch.float64) False\n",
      "68 [ 71.71477423 109.26658535  74.06326161] tensor(-156.9389, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "69 [ 70.98024771 108.9386547   74.15829988] tensor(-151.0700, dtype=torch.float64) tensor(-10.4843, dtype=torch.float64) False\n",
      "70 [ 71.17760822 108.1687253   74.31436896] tensor(-170.2211, dtype=torch.float64) tensor(-34.8096, dtype=torch.float64) False\n",
      "71 [ 70.61325014 108.16673812  74.89539909] tensor(-159.1534, dtype=torch.float64) tensor(-6.0918, dtype=torch.float64) False\n",
      "72 [ 70.29210138 108.84304491  75.20454727] tensor(-140.7991, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "73 [ 70.29210138 108.84304491  75.20454727] tensor(-140.9885, dtype=torch.float64) tensor(-17.6797, dtype=torch.float64) False\n",
      "74 [ 69.97095263 109.51935171  75.51369545] tensor(-123.3183, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "75 [ 69.64980388 110.1956585   75.82284363] tensor(-105.5387, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "76 [ 69.45244337 110.9655879   75.66677455] tensor(-89.9427, dtype=torch.float64) tensor(-3.2815, dtype=torch.float64) False\n",
      "77 [ 69.36100484 111.61638964  76.14026804] tensor(-69.6602, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "78 [ 69.26956631 112.26719139  76.61376153] tensor(-51.0394, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "79 [ 69.59071506 111.59088459  76.30461334] tensor(-56.3189, dtype=torch.float64) tensor(-19.5043, dtype=torch.float64) False\n",
      "80 [ 68.85312439 111.65171779  76.63379312] tensor(-47.3221, dtype=torch.float64) tensor(-5.7567, dtype=torch.float64) False\n",
      "81 [ 69.59071506 111.59088459  76.30461334] tensor(-45.8113, dtype=torch.float64) tensor(-11.8174, dtype=torch.float64) False\n",
      "82 [ 69.4561845  110.84872705  76.0093106 ] tensor(-51.0841, dtype=torch.float64) tensor(-18.4151, dtype=torch.float64) False\n",
      "83 [ 69.62064614 111.40853131  76.57115716] tensor(-35.1351, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "84 [ 69.78510778 111.96833557  77.13300373] tensor(-21.3116, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "85 [ 69.77001974 111.78020246  77.92070817] tensor(-13.3289, dtype=torch.float64) tensor(-2.2492, dtype=torch.float64) False\n",
      "86 [ 70.36893046 112.15381201  78.31797614] tensor(-4.8080, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "87 [ 70.16032116 111.78122241  79.00627778] tensor(-5.2933, dtype=torch.float64) tensor(-2.8987, dtype=torch.float64) False\n",
      "88 [ 70.77898865 112.28163701  79.15772336] tensor(-1.8980, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "89 [ 71.51351517 112.60956766  79.06268509] tensor(-0.0062, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "Defi stopped at/close to the terminal state!\n",
      "90 [ 71.83466393 111.93326086  78.75353691] tensor(-1.3887, dtype=torch.float64) tensor(-1.3887, dtype=torch.float64) False\n",
      "91 [ 71.6117467  112.57518394  78.31269376] tensor(-1.7035, dtype=torch.float64) tensor(-0.0338, dtype=torch.float64) False\n",
      "92 [ 71.94636272 112.36920618  79.02100533] tensor(-0.4519, dtype=torch.float64) tensor(0.6978, dtype=torch.float64) False\n",
      "93 [ 72.27119501 112.9359162   78.54202336] tensor(-0.2223, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "Defi stopped at/close to the terminal state!\n",
      "Defi stopped at/close to the terminal state!\n",
      "94 [ 72.27119501 112.9359162   78.54202336] 1.0 1.0 True\n",
      "3 -5186.195168626943\n",
      "New run\n",
      "0 [ 73.651344 107.88106   93.29415 ]\n",
      "1 [ 74.38893497 107.82022454  92.96497153] tensor(0.9861, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "2 [ 75.12652564 107.75939134  92.63579176] tensor(0.9951, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "3 [ 74.90360841 108.40131441  92.19494861] tensor(0.1905, dtype=torch.float64) tensor(0.2039, dtype=torch.float64) False\n",
      "4 [ 75.59703455 108.60865714  91.83126031] tensor(0.9951, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "5 [ 76.05660862 107.99671352  92.09662173] tensor(0.1527, dtype=torch.float64) tensor(0.1576, dtype=torch.float64) False\n",
      "6 [ 75.72199259 108.20269128  91.38831016] tensor(-1.5909, dtype=torch.float64) tensor(-1.5815, dtype=torch.float64) False\n",
      "7 [ 76.09583625 107.98424304  90.70375096] tensor(-2.6098, dtype=torch.float64) tensor(-0.9687, dtype=torch.float64) False\n",
      "8 [ 76.83036277 108.31217369  90.6087127 ] tensor(-2.0816, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 [ 76.50685123 107.60340672  90.83027456] tensor(-12.5032, dtype=torch.float64) tensor(-9.5779, dtype=torch.float64) False\n",
      "10 [ 77.06895146 108.06488462  90.47364945] tensor(-10.7107, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "11 [ 77.63105169 108.52636253  90.11702434] tensor(-10.6565, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "12 [ 78.19315192 108.98784044  89.76039922] tensor(-10.3672, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "13 [ 78.56699557 108.7693922   89.07584003] tensor(-13.1596, dtype=torch.float64) tensor(-2.3720, dtype=torch.float64) False\n",
      "14 [ 79.1290958  109.23087011  88.71921492] tensor(-11.6314, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "15 [ 79.24079229 110.03281196  88.69656191] tensor(-14.0486, dtype=torch.float64) tensor(-3.0228, dtype=torch.float64) False\n",
      "16 [ 80.00050752 110.24513269  88.88055289] tensor(-14.6875, dtype=torch.float64) tensor(-1.6297, dtype=torch.float64) False\n",
      "17 [ 80.63862621 110.35755718  89.36662415] tensor(-20.6220, dtype=torch.float64) tensor(-6.3162, dtype=torch.float64) False\n",
      "18 [ 81.20298429 110.35954437  88.78559403] tensor(-19.1871, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "19 [ 81.0912878  109.55760251  88.80824704] tensor(-29.9727, dtype=torch.float64) tensor(-10.0476, dtype=torch.float64) False\n",
      "20 [ 81.65564588 109.5595897   88.22721691] tensor(-28.2891, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "21 [ 82.29068515 109.05832212  88.26666237] tensor(-34.8363, dtype=torch.float64) tensor(-6.2796, dtype=torch.float64) False\n",
      "22 [ 82.60222506 109.14198549  87.52366619] tensor(-33.0065, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "23 [ 81.86463439 109.20281868  87.85284597] tensor(-52.6642, dtype=torch.float64) tensor(-19.7749, dtype=torch.float64) False\n",
      "24 [ 82.17617429 109.28648205  87.10984978] tensor(-50.0198, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "25 [ 81.85266275 108.57771508  87.33141165] tensor(-66.8779, dtype=torch.float64) tensor(-17.7045, dtype=torch.float64) False\n",
      "26 [ 82.16420266 108.66137845  86.58841547] tensor(-62.7168, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "27 [ 82.62377672 108.04943483  86.85377689] tensor(-71.7680, dtype=torch.float64) tensor(-14.0941, dtype=torch.float64) False\n",
      "28 [ 82.73549099 107.91796944  86.06236248] tensor(-64.2424, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "29 [ 81.97577576 107.70564871  85.8783715 ] tensor(-70.1416, dtype=torch.float64) tensor(-11.7870, dtype=torch.float64) False\n",
      "30 [ 82.08749003 107.57418333  85.08695708] tensor(-63.2442, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "31 [ 81.97577576 107.70564871  85.8783715 ] tensor(-85.7609, dtype=torch.float64) tensor(-27.6235, dtype=torch.float64) False\n",
      "32 [ 82.08749003 107.57418333  85.08695708] tensor(-78.4689, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "33 [ 81.91882401 107.54716314  84.29517322] tensor(-73.3219, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "34 [ 81.75015798 107.52014294  83.50338936] tensor(-68.9833, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "35 [ 81.58149195 107.49312275  82.7116055 ] tensor(-64.0040, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "36 [ 81.41282593 107.46610256  81.91982164] tensor(-59.6506, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "37 [ 80.98661534 107.90881514  81.39213793] tensor(-59.0645, dtype=torch.float64) tensor(-3.0569, dtype=torch.float64) False\n",
      "38 [ 80.81794931 107.88179494  80.60035407] tensor(-54.8883, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "39 [ 80.70623504 108.01326033  81.39176848] tensor(-75.9792, dtype=torch.float64) tensor(-24.5021, dtype=torch.float64) False\n",
      "40 [ 80.27672747 107.92721313  80.7104322 ] tensor(-70.1119, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "41 [ 79.63860879 107.81478864  80.22436094] tensor(-66.0400, dtype=torch.float64) tensor(-0.3190, dtype=torch.float64) False\n",
      "42 [ 79.20910122 107.72874144  79.54302466] tensor(-59.9431, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "43 [ 79.37356286 108.2885457   80.10487122] tensor(-79.5643, dtype=torch.float64) tensor(-24.1836, dtype=torch.float64) False\n",
      "44 [ 79.26184859 108.42001108  80.89628563] tensor(-100.5341, dtype=torch.float64) tensor(-26.6362, dtype=torch.float64) False\n",
      "45 [ 78.86395416 108.05252956  80.29400883] tensor(-92.9215, dtype=torch.float64) tensor(0.0514, dtype=torch.float64) False\n",
      "46 [ 78.43444659 107.96648236  79.61267255] tensor(-86.0561, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "47 [ 77.84598875 108.25400872  80.08927087] tensor(-94.3008, dtype=torch.float64) tensor(-14.2041, dtype=torch.float64) False\n",
      "48 [ 78.491575   107.88316272  80.4083189 ] tensor(-117.9902, dtype=torch.float64) tensor(-29.7992, dtype=torch.float64) False\n",
      "49 [ 77.85345631 107.77073823  79.92224764] tensor(-109.6309, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "50 [ 77.21533762 107.65831374  79.43617637] tensor(-102.0542, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "51 [ 77.54016991 108.22502376  78.9571944 ] tensor(-112.4173, dtype=torch.float64) tensor(-15.9466, dtype=torch.float64) False\n",
      "52 [ 77.70883594 108.25204395  79.74897826] tensor(-135.1233, dtype=torch.float64) tensor(-29.9593, dtype=torch.float64) False\n",
      "53 [ 78.1052716  108.85160041  80.12243618] tensor(-158.9103, dtype=torch.float64) tensor(-31.2876, dtype=torch.float64) False\n",
      "54 [ 78.74031087 108.35033283  80.16188165] tensor(-185.1412, dtype=torch.float64) tensor(-36.2751, dtype=torch.float64) False\n",
      "55 [ 78.16093035 108.52708554  79.62413012] tensor(-173.0884, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "56 [ 78.01364267 108.94593693  78.94665698] tensor(-169.0557, dtype=torch.float64) tensor(-5.5445, dtype=torch.float64) False\n",
      "57 [ 77.37552398 108.83351243  78.46058572] tensor(-162.3815, dtype=torch.float64) tensor(-0.3587, dtype=torch.float64) False\n",
      "58 [ 77.53998563 109.39331669  79.02243228] tensor(-185.1774, dtype=torch.float64) tensor(-27.3602, dtype=torch.float64) False\n",
      "59 [ 77.76290286 108.75139362  79.46327543] tensor(-218.1228, dtype=torch.float64) tensor(-38.1843, dtype=torch.float64) False\n",
      "60 [ 77.11731661 109.12223962  79.1442274 ] tensor(-211.1613, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "61 [ 77.11731661 109.12223962  79.1442274 ] tensor(-228.3677, dtype=torch.float64) tensor(-23.1979, dtype=torch.float64) False\n",
      "62 [ 76.47173037 109.49308562  78.82517937] tensor(-220.9204, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "63 [ 75.82614413 109.86393163  78.50613134] tensor(-213.3391, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "64 [ 75.0664289  109.6516109   78.32214036] tensor(-208.7737, dtype=torch.float64) tensor(-3.1354, dtype=torch.float64) False\n",
      "65 [ 74.84351167 110.29353397  77.88129721] tensor(-204.0602, dtype=torch.float64) tensor(-6.6123, dtype=torch.float64) False\n",
      "66 [ 75.40153651 109.77062425  77.61432586] tensor(-231.5560, dtype=torch.float64) tensor(-42.7360, dtype=torch.float64) False\n",
      "67 [ 74.62761336 109.9981447   77.54099513] tensor(-209.7522, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "68 [ 73.99257409 110.49941228  77.50154967] tensor(-185.5542, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "69 [ 73.35753483 111.00067986  77.46210421] tensor(-160.2957, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "70 [ 72.89796076 111.61262349  77.19674279] tensor(-139.7212, dtype=torch.float64) tensor(-1.6376, dtype=torch.float64) False\n",
      "71 [ 72.98939929 110.96182174  76.7232493 ] tensor(-147.7013, dtype=torch.float64) tensor(-29.0694, dtype=torch.float64) False\n",
      "72 [ 72.78078999 110.58923213  77.41155094] tensor(-140.8225, dtype=torch.float64) tensor(-15.6978, dtype=torch.float64) False\n",
      "73 [ 72.22276515 111.11214185  77.67852229] tensor(-117.2843, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "74 [ 71.6647403  111.63505157  77.94549365] tensor(-96.2202, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "75 [ 71.10671546 112.15796128  78.21246501] tensor(-76.1279, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76 [ 70.93804944 112.13094109  77.42068115] tensor(-72.1814, dtype=torch.float64) tensor(-15.3816, dtype=torch.float64) False\n",
      "77 [ 71.57616813 112.24336558  77.90675241] tensor(-63.8901, dtype=torch.float64) tensor(-11.2295, dtype=torch.float64) False\n",
      "78 [ 71.25501937 112.91967238  78.21590059] tensor(-44.4191, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "79 [ 71.45237989 112.14974299  78.37196968] tensor(-43.0947, dtype=torch.float64) tensor(-14.5209, dtype=torch.float64) False\n",
      "80 [ 70.89435505 112.6726527   78.63894103] tensor(-27.7468, dtype=torch.float64) tensor(0.4742, dtype=torch.float64) False\n",
      "81 [ 70.80291652 113.32345445  79.11243452] tensor(-14.6658, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "Defi stopped at/close to the terminal state!\n",
      "Defi stopped at/close to the terminal state!\n",
      "82 [ 70.80291652 113.32345445  79.11243452] 1.0 1.0 True\n",
      "4 -5620.5610323018645\n",
      "New run\n",
      "0 [ 73.651344 107.88106   93.29415 ]\n",
      "1 [ 74.28638356 107.37979016  93.33359677] tensor(0.7515, dtype=torch.float64) tensor(0.7655, dtype=torch.float64) False\n",
      "2 [ 75.03900195 107.31536762  93.62602677] tensor(0.7143, dtype=torch.float64) tensor(0.7193, dtype=torch.float64) False\n",
      "3 [ 75.60336003 107.31735481  93.04499665] tensor(0.9866, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "4 [ 75.40599952 108.0872842   92.88892757] tensor(0.0836, dtype=torch.float64) tensor(0.0885, dtype=torch.float64) False\n",
      "5 [ 76.09942566 108.29462693  92.52523926] tensor(0.9951, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "6 [ 76.7928518  108.50196965  92.16155096] tensor(0.9906, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "7 [ 77.48627793 108.70931238  91.79786265] tensor(0.9906, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "8 [ 77.82089396 108.50333463  92.50617422] tensor(-4.5442, dtype=torch.float64) tensor(-4.5295, dtype=torch.float64) False\n",
      "9 [ 78.29882533 108.79234285  91.91952624] tensor(-2.8891, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "10 [ 78.7767567  109.08135107  91.33287826] tensor(-2.4990, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "11 [ 79.25468807 109.3703593   90.74623028] tensor(-2.2432, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "12 [ 79.73261943 109.65936752  90.1595823 ] tensor(-2.1455, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "13 [ 79.85455017 109.23553715  89.48017027] tensor(-5.7244, dtype=torch.float64) tensor(-2.6515, dtype=torch.float64) False\n",
      "14 [ 80.4166504  109.69701505  89.12354515] tensor(-4.6665, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "15 [ 80.97875063 110.15849296  88.76692004] tensor(-4.0966, dtype=torch.float64) tensor(0.7237, dtype=torch.float64) False\n",
      "16 [ 81.53225926 110.74038561  88.66142528] tensor(-5.4912, dtype=torch.float64) tensor(-0.9888, dtype=torch.float64) False\n",
      "17 [ 82.09661734 110.7423728   88.08039516] tensor(-4.8129, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "18 [ 82.65464218 110.21946308  87.8134238 ] tensor(-6.9739, dtype=torch.float64) tensor(-1.2156, dtype=torch.float64) False\n",
      "19 [ 82.96618209 110.30312645  87.07042762] tensor(-6.4503, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "20 [ 82.40182401 110.30113926  87.65145775] tensor(-20.3483, dtype=torch.float64) tensor(-13.1769, dtype=torch.float64) False\n",
      "21 [ 82.71336391 110.38480263  86.90846156] tensor(-18.2575, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "22 [ 83.10979958 110.98435909  87.28191949] tensor(-29.9474, dtype=torch.float64) tensor(-11.1111, dtype=torch.float64) False\n",
      "23 [ 83.48364323 110.76591085  86.59736029] tensor(-28.2783, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "24 [ 83.85748688 110.54746261  85.9128011 ] tensor(-28.1517, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "25 [ 83.96920115 110.41599722  85.12138669] tensor(-27.7694, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "26 [ 84.08091542 110.28453184  84.32997227] tensor(-27.0642, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "27 [ 84.19262968 110.15306645  83.53855786] tensor(-24.7838, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "28 [ 83.554511   110.04064196  83.05248659] tensor(-26.5942, dtype=torch.float64) tensor(-3.3524, dtype=torch.float64) False\n",
      "29 [ 83.67644173 109.61681158  82.37307456] tensor(-23.2514, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "30 [ 83.82372941 109.19796019  83.0505477 ] tensor(-35.8230, dtype=torch.float64) tensor(-14.6328, dtype=torch.float64) False\n",
      "31 [ 84.22162384 109.56544172  83.65282451] tensor(-53.8488, dtype=torch.float64) tensor(-21.0748, dtype=torch.float64) False\n",
      "32 [ 84.07799835 109.25524508  82.91848823] tensor(-49.6485, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "33 [ 83.90933233 109.22822489  82.12670437] tensor(-48.0352, dtype=torch.float64) tensor(0.6630, dtype=torch.float64) False\n",
      "34 [ 83.44975826 109.84016851  81.86134295] tensor(-55.8827, dtype=torch.float64) tensor(-8.5718, dtype=torch.float64) False\n",
      "35 [ 83.30613277 109.52997187  81.12700668] tensor(-53.1372, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "36 [ 83.8596414  110.11186452  81.02151192] tensor(-70.7963, dtype=torch.float64) tensor(-18.7466, dtype=torch.float64) False\n",
      "37 [ 84.25607706 110.71142098  81.39496985] tensor(-96.0393, dtype=torch.float64) tensor(-28.4054, dtype=torch.float64) False\n",
      "38 [ 83.85818262 110.34393946  80.79269304] tensor(-91.6963, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "39 [ 83.46028819 109.97645793  80.19041623] tensor(-88.7552, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "40 [ 83.06239376 109.60897641  79.58813943] tensor(-85.8945, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "41 [ 82.42427507 109.49655192  79.10206816] tensor(-82.9889, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "42 [ 81.78615639 109.38412742  78.6159969 ] tensor(-79.2907, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "43 [ 82.16000004 109.16567918  77.93143771] tensor(-87.2843, dtype=torch.float64) tensor(-10.9458, dtype=torch.float64) False\n",
      "44 [ 81.52188135 109.05325469  77.44536644] tensor(-83.0218, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "45 [ 80.88376266 108.9408302   76.95929518] tensor(-79.3067, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "46 [ 80.24564398 108.82840571  76.47322391] tensor(-76.1467, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "47 [ 80.80366882 108.30549599  76.20625255] tensor(-95.1280, dtype=torch.float64) tensor(-21.0835, dtype=torch.float64) False\n",
      "48 [ 80.05105044 108.36991852  75.91382255] tensor(-91.0155, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "49 [ 79.9291197  108.7937489   76.59323458] tensor(-109.1398, dtype=torch.float64) tensor(-19.2322, dtype=torch.float64) False\n",
      "50 [ 79.17650132 108.85817144  76.30080457] tensor(-104.6251, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "51 [ 79.55034497 108.6397232   75.61624538] tensor(-122.7206, dtype=torch.float64) tensor(-20.6475, dtype=torch.float64) False\n",
      "52 [ 78.79772659 108.70414573  75.32381538] tensor(-116.6379, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "53 [ 78.04510821 108.76856826  75.03138537] tensor(-111.7212, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "54 [ 77.29248983 108.8329908   74.73895537] tensor(-103.3474, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "55 [ 76.51856667 109.06051125  74.66562464] tensor(-94.5328, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "56 [ 76.71592718 108.29058186  74.82169372] tensor(-110.7947, dtype=torch.float64) tensor(-24.2776, dtype=torch.float64) False\n",
      "57 [ 75.94200403 108.51810231  74.748363  ] tensor(-103.7913, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "58 [ 75.16808088 108.74562276  74.67503227] tensor(-101.4621, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "59 [ 75.16808088 108.74562276  74.67503227] tensor(-117.5717, dtype=torch.float64) tensor(-16.9025, dtype=torch.float64) False\n",
      "60 [ 74.39415772 108.97314321  74.60170154] tensor(-114.9769, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61 [ 73.62023457 109.20066367  74.52837082] tensor(-112.6397, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "62 [ 72.84631141 109.42818412  74.45504009] tensor(-110.5932, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "63 [ 72.07238826 109.65570457  74.38170937] tensor(-108.2130, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "64 [ 71.43734899 110.15697215  74.34226391] tensor(-105.3460, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "65 [ 70.70282247 109.8290415   74.43730217] tensor(-107.5030, dtype=torch.float64) tensor(-5.9714, dtype=torch.float64) False\n",
      "66 [ 70.0677832  110.33030908  74.39785671] tensor(-99.9086, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "67 [ 69.50975836 110.8532188   74.66482807] tensor(-90.7061, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "68 [ 68.95173352 111.37612851  74.93179943] tensor(-79.2692, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "69 [ 69.53111404 111.19937581  75.46955095] tensor(-88.6336, dtype=torch.float64) tensor(-20.6924, dtype=torch.float64) False\n",
      "70 [ 68.9730892  111.72228552  75.73652231] tensor(-75.6650, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "71 [ 68.41506435 112.24519524  76.00349367] tensor(-62.9620, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "72 [ 67.83568384 112.42194795  75.46574214] tensor(-60.5148, dtype=torch.float64) tensor(-8.4507, dtype=torch.float64) False\n",
      "73 [ 68.41506435 112.24519524  76.00349367] tensor(-62.6372, dtype=torch.float64) tensor(-13.0602, dtype=torch.float64) False\n",
      "74 [ 68.0442707  112.72941861  76.53654132] tensor(-52.2518, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "75 [ 67.70965468 112.93539636  75.82822975] tensor(-55.5053, dtype=torch.float64) tensor(-12.9943, dtype=torch.float64) False\n",
      "76 [ 67.37503865 113.14137412  75.11991818] tensor(-59.0605, dtype=torch.float64) tensor(-15.5436, dtype=torch.float64) False\n",
      "77 [ 67.25310792 113.5652045   75.79933021] tensor(-45.1281, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "78 [ 66.82689733 114.00791707  75.27164649] tensor(-46.7758, dtype=torch.float64) tensor(-12.7172, dtype=torch.float64) False\n",
      "79 [ 66.91833585 113.35711533  74.798153  ] tensor(-56.2045, dtype=torch.float64) tensor(-19.7233, dtype=torch.float64) False\n",
      "80 [ 66.78380529 112.61495779  74.50285025] tensor(-65.7146, dtype=torch.float64) tensor(-20.4595, dtype=torch.float64) False\n",
      "81 [ 67.18169972 112.98243931  75.10512706] tensor(-53.5189, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "82 [ 67.57959415 113.34992084  75.70740387] tensor(-41.0557, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "83 [ 67.00021364 113.52667355  75.16965234] tensor(-47.8475, dtype=torch.float64) tensor(-17.7378, dtype=torch.float64) False\n",
      "84 [ 67.56231387 113.98815145  74.81302723] tensor(-43.2087, dtype=torch.float64) tensor(-7.0855, dtype=torch.float64) False\n",
      "85 [ 67.00021364 113.52667355  75.16965234] tensor(-42.1876, dtype=torch.float64) tensor(-10.7186, dtype=torch.float64) False\n",
      "86 [ 67.63833233 113.63909804  75.65572361] tensor(-30.5226, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "87 [ 68.27645101 113.75152253  76.14179487] tensor(-21.9758, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "88 [ 68.85583153 113.57476982  76.6795464 ] tensor(-14.6623, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "89 [ 68.6329143  114.21669289  76.23870325] tensor(-19.3839, dtype=torch.float64) tensor(-9.4793, dtype=torch.float64) False\n",
      "90 [ 68.6329143  114.21669289  76.23870325] tensor(-18.8468, dtype=torch.float64) tensor(-5.8452, dtype=torch.float64) False\n",
      "91 [ 68.52121781 113.41475104  76.26135626] tensor(-18.8619, dtype=torch.float64) tensor(-5.8603, dtype=torch.float64) False\n",
      "92 [ 67.90255032 112.91433644  76.10991068] tensor(-25.5384, dtype=torch.float64) tensor(-11.6552, dtype=torch.float64) False\n",
      "93 [ 68.6551687  112.8499139   76.40234068] tensor(-18.5966, dtype=torch.float64) tensor(0.4858, dtype=torch.float64) False\n",
      "94 [ 69.02901235 112.63146566  75.71778149] tensor(-21.2995, dtype=torch.float64) tensor(-8.0733, dtype=torch.float64) False\n",
      "95 [ 69.45851992 112.71751286  76.39911777] tensor(-15.0513, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "96 [ 70.09663861 112.82993736  76.88518904] tensor(-9.1883, dtype=torch.float64) tensor(0.9289, dtype=torch.float64) False\n",
      "97 [ 70.52614618 112.91598455  77.56652532] tensor(-4.6388, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "98 [ 70.09993558 113.35869713  77.0388416 ] tensor(-7.6868, dtype=torch.float64) tensor(-5.4401, dtype=torch.float64) False\n",
      "99 [ 70.52944315 113.44474433  77.72017788] tensor(-3.1925, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "100 [ 71.10882367 113.26799162  78.25792941] tensor(-0.1411, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "101 [ 71.75440991 112.89714562  78.57697744] tensor(0.4813, dtype=torch.float64) tensor(1., dtype=torch.float64) False\n",
      "Defi stopped at/close to the terminal state!\n",
      "102 [ 72.08902593 112.69116786  79.28528901] tensor(-0.0143, dtype=torch.float64) tensor(-0.0143, dtype=torch.float64) False\n",
      "Defi stopped at/close to the terminal state!\n",
      "Defi stopped at/close to the terminal state!\n",
      "103 [ 72.08902593 112.69116786  79.28528901] 1.0 1.0 True\n",
      "5 -5499.989241535338\n",
      "Replay memory ready\n"
     ]
    }
   ],
   "source": [
    "state = env.reset().getValue()\n",
    "agent = Agent(n_actions=n_actions, inp_size=state.shape, device=device, hidden=10, gamma=0.9, agent_history_length=agent_history_length, memory_size=replay_memory_size, batch_size=32, learning_rate=learning_rate)\n",
    "\n",
    "overall_runs = 0\n",
    "overall_reward = []\n",
    "while agent.replay_memory.current < 400:\n",
    "    state = env.reset()\n",
    "    #episode_step_counter = 0\n",
    "    episode_reward = 0\n",
    "    terminal = False\n",
    "    print(\"New run\")\n",
    "    print(env.stepCounter, state.getCoordinate().numpy())\n",
    "    while not terminal:\n",
    "        #print(env.stepCounter)\n",
    "        action, optimal_reward = get_best_action(state,env)\n",
    "        if np.random.rand(1) < 0.5: \n",
    "            action = np.random.randint(0, n_actions)\n",
    "        next_state, reward, terminal = env.step(action)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #terminal = False\n",
    "\n",
    "        current_index = np.min([env.stepCounter,len(env.referenceStreamline_ijk)-1])\n",
    "        #path_vector = (next_state.getCoordinate() - state.getCoordinate()).squeeze(0)\n",
    "        #reference_vector = env.referenceStreamline_ijk[current_index]-env.referenceStreamline_ijk[current_index-1]\n",
    "        #    #print(path_vector, reference_vector)\n",
    "        #cosine_sim = cos(path_vector, reference_vector)\n",
    "        dist = torch.sum((env.referenceStreamline_ijk[current_index] - next_state.getCoordinate())**2)\n",
    "        #if dist > 3*0.81:\n",
    "        #    env.stepCounter -= 1\n",
    "        #if dist < 0.1:\n",
    "        #    dist = 0\n",
    "        #else:\n",
    "        #    dist = dist - 0.1\n",
    "        #reward = cosine_sim - dist\n",
    "        reward_old = 1 - (optimal_reward - reward)\n",
    "        print(env.stepCounter, next_state.getCoordinate().numpy(), reward, reward_old, terminal)\n",
    "        #if action == 100 and dist==0:\n",
    "        #    terminal = True\n",
    "\n",
    "        #if env.stepCounter == 200:\n",
    "        #    terminal = True\n",
    "            \n",
    "        agent.replay_memory.add_experience(action=action,\n",
    "                                state = state.getValue(),\n",
    "                                reward=reward_old,\n",
    "                                new_state = next_state.getValue(),\n",
    "                                terminal=terminal)\n",
    "        \n",
    "        episode_reward += reward_old\n",
    "        \n",
    "        state = next_state\n",
    "        \n",
    "        if terminal == True:\n",
    "            overall_runs += 1\n",
    "            overall_reward.append(episode_reward)\n",
    "            print(overall_runs, np.mean(overall_reward[-100:]))\n",
    "print(\"Replay memory ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terminal = False\n",
    "index = 0\n",
    "while not terminal:\n",
    "    states.append(agent.replay_memory.states[index])\n",
    "    actions.append()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Not enough memories to get a minibatch",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-adac9d7c299f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminal_flags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplay_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_minibatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/fibre_tracking/deepFibreTracking/dfibert/tracker/nn/rl.py\u001b[0m in \u001b[0;36mget_minibatch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \"\"\"\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Not enough memories to get a minibatch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Not enough memories to get a minibatch"
     ]
    }
   ],
   "source": [
    "states, actions, rewards, next_states, terminal_flags = agent.replay_memory.get_minibatch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "64) tensor(0.0672, dtype=torch.float64)\n",
      "47 tensor(12) tensor(-0.3636, dtype=torch.float64) tensor(0.3636, dtype=torch.float64)\n",
      "47 tensor(12) tensor(-0.1264, dtype=torch.float64) tensor(0.1264, dtype=torch.float64)\n",
      "48 tensor(10) tensor(-0.0158, dtype=torch.float64) tensor(0.0158, dtype=torch.float64)\n",
      "48 tensor(12) tensor(-0.1468, dtype=torch.float64) tensor(0.1468, dtype=torch.float64)\n",
      "49 tensor(12) tensor(-0.0056, dtype=torch.float64) tensor(0.0056, dtype=torch.float64)\n",
      "49 tensor(12) tensor(-0.1456, dtype=torch.float64) tensor(0.1456, dtype=torch.float64)\n",
      "50 tensor(12) tensor(-0.0074, dtype=torch.float64) tensor(0.0074, dtype=torch.float64)\n",
      "50 tensor(12) tensor(-0.1565, dtype=torch.float64) tensor(0.1565, dtype=torch.float64)\n",
      "51 tensor(12) tensor(-0.0213, dtype=torch.float64) tensor(0.0213, dtype=torch.float64)\n",
      "51 tensor(12) tensor(-0.1944, dtype=torch.float64) tensor(0.1944, dtype=torch.float64)\n",
      "51 tensor(14) tensor(-0.0724, dtype=torch.float64) tensor(0.0724, dtype=torch.float64)\n",
      "52 tensor(10) tensor(-0.0283, dtype=torch.float64) tensor(0.0283, dtype=torch.float64)\n",
      "52 tensor(0) tensor(-0.0839, dtype=torch.float64) tensor(0.0839, dtype=torch.float64)\n",
      "53 tensor(14) tensor(-0.0244, dtype=torch.float64) tensor(0.0244, dtype=torch.float64)\n",
      "53 tensor(12) tensor(-0.1589, dtype=torch.float64) tensor(0.1589, dtype=torch.float64)\n",
      "54 tensor(10) tensor(-0.0453, dtype=torch.float64) tensor(0.0453, dtype=torch.float64)\n",
      "54 tensor(12) tensor(-0.3276, dtype=torch.float64) tensor(0.3276, dtype=torch.float64)\n",
      "55 tensor(12) tensor(-0.0336, dtype=torch.float64) tensor(0.0336, dtype=torch.float64)\n",
      "55 tensor(12) tensor(-0.3409, dtype=torch.float64) tensor(0.3409, dtype=torch.float64)\n",
      "56 tensor(12) tensor(-0.0552, dtype=torch.float64) tensor(0.0552, dtype=torch.float64)\n",
      "56 tensor(12) tensor(-0.3875, dtype=torch.float64) tensor(0.3875, dtype=torch.float64)\n",
      "56 tensor(12) tensor(-0.1102, dtype=torch.float64) tensor(0.1102, dtype=torch.float64)\n",
      "57 tensor(10) tensor(-0.0527, dtype=torch.float64) tensor(0.0527, dtype=torch.float64)\n",
      "57 tensor(12) tensor(-0.2291, dtype=torch.float64) tensor(0.2291, dtype=torch.float64)\n",
      "58 tensor(12) tensor(-0.0530, dtype=torch.float64) tensor(0.0530, dtype=torch.float64)\n",
      "58 tensor(12) tensor(-0.3132, dtype=torch.float64) tensor(0.3132, dtype=torch.float64)\n",
      "58 tensor(15) tensor(-0.0905, dtype=torch.float64) tensor(0.0905, dtype=torch.float64)\n",
      "59 tensor(12) tensor(-0.0390, dtype=torch.float64) tensor(0.0390, dtype=torch.float64)\n",
      "59 tensor(12) tensor(-0.1837, dtype=torch.float64) tensor(0.1837, dtype=torch.float64)\n",
      "59 tensor(10) tensor(-0.0730, dtype=torch.float64) tensor(0.0730, dtype=torch.float64)\n",
      "60 tensor(15) tensor(-0.0382, dtype=torch.float64) tensor(0.0382, dtype=torch.float64)\n",
      "60 tensor(12) tensor(-0.1163, dtype=torch.float64) tensor(0.1163, dtype=torch.float64)\n",
      "61 tensor(12) tensor(-0.0161, dtype=torch.float64) tensor(0.0161, dtype=torch.float64)\n",
      "61 tensor(12) tensor(-0.2602, dtype=torch.float64) tensor(0.2602, dtype=torch.float64)\n",
      "62 tensor(15) tensor(-0.0238, dtype=torch.float64) tensor(0.0238, dtype=torch.float64)\n",
      "62 tensor(12) tensor(-0.3761, dtype=torch.float64) tensor(0.3761, dtype=torch.float64)\n",
      "62 tensor(15) tensor(-0.1244, dtype=torch.float64) tensor(0.1244, dtype=torch.float64)\n",
      "63 tensor(12) tensor(-0.0142, dtype=torch.float64) tensor(0.0142, dtype=torch.float64)\n",
      "63 tensor(12) tensor(-0.2117, dtype=torch.float64) tensor(0.2117, dtype=torch.float64)\n",
      "64 tensor(15) tensor(-0.0142, dtype=torch.float64) tensor(0.0142, dtype=torch.float64)\n",
      "64 tensor(13) tensor(-0.3832, dtype=torch.float64) tensor(0.3832, dtype=torch.float64)\n",
      "64 tensor(15) tensor(-0.0887, dtype=torch.float64) tensor(0.0887, dtype=torch.float64)\n",
      "65 tensor(13) tensor(-0.0340, dtype=torch.float64) tensor(0.0340, dtype=torch.float64)\n",
      "65 tensor(15) tensor(-0.2313, dtype=torch.float64) tensor(0.2313, dtype=torch.float64)\n",
      "66 tensor(16) tensor(-0.0550, dtype=torch.float64) tensor(0.0550, dtype=torch.float64)\n",
      "66 tensor(15) tensor(-0.4458, dtype=torch.float64) tensor(0.4458, dtype=torch.float64)\n",
      "66 tensor(13) tensor(-0.1700, dtype=torch.float64) tensor(0.1700, dtype=torch.float64)\n",
      "67 tensor(15) tensor(-0.0237, dtype=torch.float64) tensor(0.0237, dtype=torch.float64)\n",
      "67 tensor(16) tensor(-0.3652, dtype=torch.float64) tensor(0.3652, dtype=torch.float64)\n",
      "67 tensor(15) tensor(-0.0768, dtype=torch.float64) tensor(0.0768, dtype=torch.float64)\n",
      "68 tensor(16) tensor(-0.0620, dtype=torch.float64) tensor(0.0620, dtype=torch.float64)\n",
      "68 tensor(15) tensor(-0.2103, dtype=torch.float64) tensor(0.2103, dtype=torch.float64)\n",
      "68 tensor(15) tensor(-0.0998, dtype=torch.float64) tensor(0.0998, dtype=torch.float64)\n",
      "69 tensor(5) tensor(-0.0132, dtype=torch.float64) tensor(0.0132, dtype=torch.float64)\n",
      "69 tensor(15) tensor(-0.3043, dtype=torch.float64) tensor(0.3043, dtype=torch.float64)\n",
      "69 tensor(13) tensor(-0.0753, dtype=torch.float64) tensor(0.0753, dtype=torch.float64)\n",
      "70 tensor(15) tensor(-0.0361, dtype=torch.float64) tensor(0.0361, dtype=torch.float64)\n",
      "70 tensor(16) tensor(-0.1867, dtype=torch.float64) tensor(0.1867, dtype=torch.float64)\n",
      "71 tensor(15) tensor(-0.0647, dtype=torch.float64) tensor(0.0647, dtype=torch.float64)\n",
      "71 tensor(16) tensor(-0.4001, dtype=torch.float64) tensor(0.4001, dtype=torch.float64)\n",
      "71 tensor(15) tensor(-0.1788, dtype=torch.float64) tensor(0.1788, dtype=torch.float64)\n",
      "72 tensor(16) tensor(-0.0195, dtype=torch.float64) tensor(0.0195, dtype=torch.float64)\n",
      "72 tensor(15) tensor(-0.3389, dtype=torch.float64) tensor(0.3389, dtype=torch.float64)\n",
      "72 tensor(16) tensor(-0.1087, dtype=torch.float64) tensor(0.1087, dtype=torch.float64)\n",
      "72 tensor(15) tensor(-0.0989, dtype=torch.float64) tensor(0.0989, dtype=torch.float64)\n",
      "73 tensor(6) tensor(-0.0678, dtype=torch.float64) tensor(0.0678, dtype=torch.float64)\n",
      "73 tensor(15) tensor(-0.6193, dtype=torch.float64) tensor(0.6193, dtype=torch.float64)\n",
      "73 tensor(16) tensor(-0.2142, dtype=torch.float64) tensor(0.2142, dtype=torch.float64)\n",
      "73 tensor(15) tensor(-0.1213, dtype=torch.float64) tensor(0.1213, dtype=torch.float64)\n",
      "74 tensor(5) tensor(-0.0183, dtype=torch.float64) tensor(0.0183, dtype=torch.float64)\n",
      "74 tensor(16) tensor(-0.1907, dtype=torch.float64) tensor(0.1907, dtype=torch.float64)\n",
      "74 tensor(16) tensor(-0.1002, dtype=torch.float64) tensor(0.1002, dtype=torch.float64)\n",
      "75 tensor(8) tensor(-0.0392, dtype=torch.float64) tensor(0.0392, dtype=torch.float64)\n",
      "75 tensor(16) tensor(-0.3466, dtype=torch.float64) tensor(0.3466, dtype=torch.float64)\n",
      "76 tensor(16) tensor(-0.0644, dtype=torch.float64) tensor(0.0644, dtype=torch.float64)\n",
      "76 tensor(16) tensor(-0.4392, dtype=torch.float64) tensor(0.4392, dtype=torch.float64)\n",
      "76 tensor(16) tensor(-0.1941, dtype=torch.float64) tensor(0.1941, dtype=torch.float64)\n",
      "76 tensor(4) tensor(-0.1143, dtype=torch.float64) tensor(0.1143, dtype=torch.float64)\n",
      "77 tensor(16) tensor(-0.0145, dtype=torch.float64) tensor(0.0145, dtype=torch.float64)\n",
      "77 tensor(5) tensor(-0.1805, dtype=torch.float64) tensor(0.1805, dtype=torch.float64)\n",
      "78 tensor(16) tensor(-0.0697, dtype=torch.float64) tensor(0.0697, dtype=torch.float64)\n",
      "78 tensor(5) tensor(-0.3543, dtype=torch.float64) tensor(0.3543, dtype=torch.float64)\n",
      "78 tensor(5) tensor(-0.2271, dtype=torch.float64) tensor(0.2271, dtype=torch.float64)\n",
      "78 tensor(4) tensor(-0.0910, dtype=torch.float64) tensor(0.0910, dtype=torch.float64)\n",
      "79 tensor(15) tensor(-0.0571, dtype=torch.float64) tensor(0.0571, dtype=torch.float64)\n",
      "79 tensor(5) tensor(-0.3830, dtype=torch.float64) tensor(0.3830, dtype=torch.float64)\n",
      "80 tensor(5) tensor(-0.0605, dtype=torch.float64) tensor(0.0605, dtype=torch.float64)\n",
      "80 tensor(5) tensor(-0.4895, dtype=torch.float64) tensor(0.4895, dtype=torch.float64)\n",
      "80 tensor(5) tensor(-0.2164, dtype=torch.float64) tensor(0.2164, dtype=torch.float64)\n",
      "80 tensor(4) tensor(-0.1453, dtype=torch.float64) tensor(0.1453, dtype=torch.float64)\n",
      "81 tensor(16) tensor(-0.0202, dtype=torch.float64) tensor(0.0202, dtype=torch.float64)\n",
      "81 tensor(5) tensor(-0.2602, dtype=torch.float64) tensor(0.2602, dtype=torch.float64)\n",
      "81 tensor(5) tensor(-0.2040, dtype=torch.float64) tensor(0.2040, dtype=torch.float64)\n",
      "81 tensor(8) tensor(-0.0777, dtype=torch.float64) tensor(0.0777, dtype=torch.float64)\n",
      "82 tensor(16) tensor(-0.0698, dtype=torch.float64) tensor(0.0698, dtype=torch.float64)\n",
      "82 tensor(5) tensor(-0.2576, dtype=torch.float64) tensor(0.2576, dtype=torch.float64)\n",
      "82 tensor(4) tensor(-0.0989, dtype=torch.float64) tensor(0.0989, dtype=torch.float64)\n",
      "83 tensor(16) tensor(-0.0549, dtype=torch.float64) tensor(0.0549, dtype=torch.float64)\n",
      "83 tensor(5) tensor(-0.3459, dtype=torch.float64) tensor(0.3459, dtype=torch.float64)\n",
      "83 tensor(4) tensor(-0.1513, dtype=torch.float64) tensor(0.1513, dtype=torch.float64)\n",
      "83 tensor(16) tensor(-0.0711, dtype=torch.float64) tensor(0.0711, dtype=torch.float64)\n",
      "84 tensor(4) tensor(-0.0218, dtype=torch.float64) tensor(0.0218, dtype=torch.float64)\n",
      "84 tensor(5) tensor(-0.2347, dtype=torch.float64) tensor(0.2347, dtype=torch.float64)\n",
      "84 tensor(5) tensor(-0.0871, dtype=torch.float64) tensor(0.0871, dtype=torch.float64)\n",
      "84 tensor(15) tensor(-0.0808, dtype=torch.float64) tensor(0.0808, dtype=torch.float64)\n",
      "85 tensor(6) tensor(-0.0478, dtype=torch.float64) tensor(0.0478, dtype=torch.float64)\n",
      "85 tensor(5) tensor(-0.3575, dtype=torch.float64) tensor(0.3575, dtype=torch.float64)\n",
      "85 tensor(5) tensor(-0.2590, dtype=torch.float64) tensor(0.2590, dtype=torch.float64)\n",
      "85 tensor(4) tensor(-0.0836, dtype=torch.float64) tensor(0.0836, dtype=torch.float64)\n",
      "86 tensor(15) tensor(-0.0436, dtype=torch.float64) tensor(0.0436, dtype=torch.float64)\n",
      "86 tensor(5) tensor(-0.3949, dtype=torch.float64) tensor(0.3949, dtype=torch.float64)\n",
      "86 tensor(5) tensor(-0.1464, dtype=torch.float64) tensor(0.1464, dtype=torch.float64)\n",
      "87 tensor(4) tensor(-0.0475, dtype=torch.float64) tensor(0.0475, dtype=torch.float64)\n",
      "87 tensor(5) tensor(-0.3975, dtype=torch.float64) tensor(0.3975, dtype=torch.float64)\n",
      "87 tensor(5) tensor(-0.1287, dtype=torch.float64) tensor(0.1287, dtype=torch.float64)\n",
      "88 tensor(4) tensor(-0.0692, dtype=torch.float64) tensor(0.0692, dtype=torch.float64)\n",
      "88 tensor(5) tensor(-0.4181, dtype=torch.float64) tensor(0.4181, dtype=torch.float64)\n",
      "88 tensor(5) tensor(-0.1290, dtype=torch.float64) tensor(0.1290, dtype=torch.float64)\n",
      "88 tensor(4) tensor(-0.1089, dtype=torch.float64) tensor(0.1089, dtype=torch.float64)\n",
      "89 tensor(16) tensor(-0.0051, dtype=torch.float64) tensor(0.0051, dtype=torch.float64)\n",
      "89 tensor(5) tensor(-0.2142, dtype=torch.float64) tensor(0.2142, dtype=torch.float64)\n",
      "89 tensor(4) tensor(-0.1438, dtype=torch.float64) tensor(0.1438, dtype=torch.float64)\n",
      "90 tensor(5) tensor(-0.0021, dtype=torch.float64) tensor(0.0021, dtype=torch.float64)\n",
      "90 tensor(5) tensor(-0.1741, dtype=torch.float64) tensor(0.1741, dtype=torch.float64)\n",
      "91 tensor(5) tensor(-0.0670, dtype=torch.float64) tensor(0.0670, dtype=torch.float64)\n",
      "91 tensor(5) tensor(-0.3440, dtype=torch.float64) tensor(0.3440, dtype=torch.float64)\n",
      "91 tensor(4) tensor(-0.1886, dtype=torch.float64) tensor(0.1886, dtype=torch.float64)\n",
      "92 tensor(5) tensor(-0.0326, dtype=torch.float64) tensor(0.0326, dtype=torch.float64)\n",
      "92 tensor(5) tensor(-0.2431, dtype=torch.float64) tensor(0.2431, dtype=torch.float64)\n",
      "92 tensor(5) tensor(-0.1002, dtype=torch.float64) tensor(0.1002, dtype=torch.float64)\n",
      "93 tensor(4) tensor(-0.0545, dtype=torch.float64) tensor(0.0545, dtype=torch.float64)\n",
      "93 tensor(18) tensor(-0.3075, dtype=torch.float64) tensor(0.3075, dtype=torch.float64)\n",
      "93 tensor(5) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n",
      "93 tensor(19) tensor(-0.0762, dtype=torch.float64) tensor(0.0762, dtype=torch.float64)\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-dfdbc13282f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mterminal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimal_reward\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mget_best_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;31m#if np.random.rand(1) < .5:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#    action = np.random.randint(0, n_actions)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-f029398864ee>\u001b[0m in \u001b[0;36mget_best_action\u001b[0;34m(state, env)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m#reward = cosine_sim - dist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mrewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;31m#print(reward)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mbest_actions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "state = env.reset(streamline_index=2)\n",
    "terminal = False\n",
    "all_states = []\n",
    "all_states.append(state.getCoordinate())\n",
    "\n",
    "while not terminal:\n",
    "    action, optimal_reward  = get_best_action(state, env)\n",
    "    #if np.random.rand(1) < .5: \n",
    "    #    action = np.random.randint(0, n_actions)\n",
    "    #print(\"Action:\", action)\n",
    "    next_state, reward, terminal = env.step(action)\n",
    "    #print(\"Step counter: \", env.stepCounter)\n",
    "    current_index = np.min([env.stepCounter,len(env.referenceStreamline_ijk)-1])\n",
    "    #print(\"Current index: \", current_index)\n",
    "    #print(\"state.getCoordinate(): \", state.getCoordinate().numpy())\n",
    "    #print(\"env.state.getCoordinate(): \", env.state.getCoordinate().numpy())\n",
    "    #print(\"next_state.getCoordinate(): \", next_state.getCoordinate().numpy())\n",
    "    #path_vector = next_state.getCoordinate() - state.getCoordinate().squeeze(0)\n",
    "    #print(\"path vector: \", path_vector)\n",
    "    #reference_vector = env.referenceStreamline_ijk[current_index]-env.referenceStreamline_ijk[current_index-1]\n",
    "    #print(\"reference_vector: \", reference_vector)\n",
    "    #cosine_sim = F.cosine_similarity(path_vector, reference_vector, dim=0)\n",
    "    #print(\"cosine_sim: \", cosine_sim)\n",
    "    dist = torch.sum((env.referenceStreamline_ijk[current_index] - next_state.getCoordinate())**2)\n",
    "    if dist > 0.07:\n",
    "        env.stepCounter -= 1\n",
    "    #print(\"distance: \", dist)\n",
    "    all_states.append(next_state.getCoordinate())\n",
    "    state = next_state\n",
    "    print(env.stepCounter, action, reward, dist)#cosine_sim.item(), dist.item(), 1-(optimal_reward-(cosine_sim-dist)))\n",
    "    #if action == 100 and 1-(optimal_reward-(cosine_sim-dist)) == 1:\n",
    "    #    terminal = True\n",
    "    #else:\n",
    "    #    terminal = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "9 400.0\n",
      "79883, done 201 episodes, 31.87, current eps 0.532708 400.0\n",
      "80283, done 202 episodes, 32.8, current eps 0.530308 400.0\n",
      "Evaluation score: 104.45\n",
      "0 of 20 episodes ended close to / at the final state.\n",
      "80683, done 203 episodes, 33.08, current eps 0.527908 400.0\n",
      "81083, done 204 episodes, 32.89, current eps 0.525508 400.0\n",
      "81483, done 205 episodes, 33.6, current eps 0.523108 400.0\n",
      "81883, done 206 episodes, 34.38, current eps 0.520708 400.0\n",
      "82283, done 207 episodes, 34.53, current eps 0.518308 400.0\n",
      "82683, done 208 episodes, 34.67, current eps 0.515908 400.0\n",
      "83083, done 209 episodes, 34.68, current eps 0.5135080000000001 400.0\n",
      "83483, done 210 episodes, 32.35, current eps 0.511108 400.0\n",
      "83883, done 211 episodes, 32.21, current eps 0.508708 400.0\n",
      "84283, done 212 episodes, 32.66, current eps 0.506308 400.0\n",
      "84683, done 213 episodes, 33.11, current eps 0.503908 400.0\n",
      "85083, done 214 episodes, 33.15, current eps 0.501508 400.0\n",
      "85483, done 215 episodes, 33.66, current eps 0.499108 400.0\n",
      "85883, done 216 episodes, 33.83, current eps 0.49670800000000004 400.0\n",
      "86283, done 217 episodes, 34.06, current eps 0.49430799999999997 400.0\n",
      "86683, done 218 episodes, 34.27, current eps 0.491908 400.0\n",
      "87083, done 219 episodes, 34.24, current eps 0.48950799999999994 400.0\n",
      "87483, done 220 episodes, 34.18, current eps 0.487108 400.0\n",
      "87883, done 221 episodes, 35.57, current eps 0.484708 400.0\n",
      "88283, done 222 episodes, 35.92, current eps 0.48230799999999996 400.0\n",
      "88683, done 223 episodes, 35.82, current eps 0.479908 400.0\n",
      "89083, done 224 episodes, 36.95, current eps 0.47750800000000004 400.0\n",
      "89483, done 225 episodes, 36.88, current eps 0.475108 400.0\n",
      "89883, done 226 episodes, 36.92, current eps 0.472708 400.0\n",
      "90283, done 227 episodes, 37.77, current eps 0.47030799999999995 400.0\n",
      "Evaluation score: 142.45\n",
      "0 of 20 episodes ended close to / at the final state.\n",
      "90683, done 228 episodes, 37.52, current eps 0.467908 400.0\n",
      "91083, done 229 episodes, 38.57, current eps 0.46550800000000003 400.0\n",
      "91483, done 230 episodes, 38.79, current eps 0.46310799999999996 400.0\n",
      "91883, done 231 episodes, 38.25, current eps 0.460708 400.0\n",
      "92283, done 232 episodes, 38.8, current eps 0.45830800000000005 400.0\n",
      "92683, done 233 episodes, 38.87, current eps 0.455908 400.0\n",
      "93083, done 234 episodes, 38.99, current eps 0.453508 400.0\n",
      "93483, done 235 episodes, 38.76, current eps 0.45110799999999995 400.0\n",
      "93883, done 236 episodes, 38.76, current eps 0.448708 400.0\n",
      "94283, done 237 episodes, 39.12, current eps 0.44630800000000004 400.0\n",
      "94683, done 238 episodes, 39.46, current eps 0.44390799999999997 400.0\n",
      "95083, done 239 episodes, 39.16, current eps 0.441508 400.0\n",
      "95483, done 240 episodes, 39.09, current eps 0.43910799999999994 400.0\n",
      "95883, done 241 episodes, 39.22, current eps 0.436708 400.0\n",
      "96283, done 242 episodes, 39.94, current eps 0.434308 400.0\n",
      "96683, done 243 episodes, 40.14, current eps 0.43190799999999996 400.0\n",
      "97083, done 244 episodes, 40.24, current eps 0.429508 400.0\n",
      "97483, done 245 episodes, 40.62, current eps 0.42710800000000004 400.0\n",
      "97883, done 246 episodes, 41.19, current eps 0.424708 400.0\n",
      "98283, done 247 episodes, 41.28, current eps 0.422308 400.0\n",
      "98683, done 248 episodes, 41.48, current eps 0.41990799999999995 400.0\n",
      "99083, done 249 episodes, 41.31, current eps 0.417508 400.0\n",
      "99483, done 250 episodes, 42.9, current eps 0.41510800000000003 400.0\n",
      "99883, done 251 episodes, 42.91, current eps 0.41270799999999996 400.0\n",
      "100283, done 252 episodes, 43.42, current eps 0.410308 400.0\n",
      "Evaluation score: 175.95\n",
      "0 of 20 episodes ended close to / at the final state.\n",
      "100683, done 253 episodes, 42.96, current eps 0.40790800000000005 400.0\n",
      "101083, done 254 episodes, 43.17, current eps 0.405508 400.0\n",
      "101483, done 255 episodes, 43.97, current eps 0.403108 400.0\n",
      "101883, done 256 episodes, 44.3, current eps 0.40070799999999995 400.0\n",
      "102283, done 257 episodes, 44.08, current eps 0.398308 400.0\n",
      "102683, done 258 episodes, 44.21, current eps 0.39590800000000004 400.0\n",
      "103083, done 259 episodes, 44.24, current eps 0.39350799999999997 400.0\n",
      "103483, done 260 episodes, 44.08, current eps 0.391108 400.0\n",
      "103883, done 261 episodes, 43.97, current eps 0.38870799999999994 400.0\n",
      "104283, done 262 episodes, 44.37, current eps 0.386308 400.0\n",
      "104683, done 263 episodes, 46.0, current eps 0.383908 400.0\n",
      "105083, done 264 episodes, 44.66, current eps 0.38150799999999996 400.0\n",
      "105483, done 265 episodes, 45.31, current eps 0.379108 400.0\n",
      "105883, done 266 episodes, 44.91, current eps 0.37670800000000004 400.0\n",
      "106283, done 267 episodes, 44.69, current eps 0.374308 400.0\n",
      "106683, done 268 episodes, 44.79, current eps 0.371908 400.0\n",
      "107083, done 269 episodes, 44.27, current eps 0.36950799999999995 400.0\n",
      "107483, done 270 episodes, 44.8, current eps 0.367108 400.0\n",
      "107883, done 271 episodes, 44.06, current eps 0.36470800000000003 400.0\n",
      "108283, done 272 episodes, 44.71, current eps 0.36230799999999996 400.0\n",
      "108683, done 273 episodes, 45.24, current eps 0.359908 400.0\n",
      "109083, done 274 episodes, 45.25, current eps 0.35750800000000005 400.0\n",
      "109483, done 275 episodes, 45.34, current eps 0.355108 400.0\n",
      "109883, done 276 episodes, 45.34, current eps 0.352708 400.0\n",
      "110283, done 277 episodes, 45.29, current eps 0.35030799999999995 400.0\n",
      "Evaluation score: 159.2\n",
      "0 of 20 episodes ended close to / at the final state.\n",
      "110683, done 278 episodes, 45.95, current eps 0.347908 400.0\n",
      "111083, done 279 episodes, 47.01, current eps 0.34550800000000004 400.0\n",
      "111483, done 280 episodes, 46.86, current eps 0.34310799999999997 400.0\n",
      "111883, done 281 episodes, 46.68, current eps 0.340708 400.0\n",
      "112283, done 282 episodes, 46.49, current eps 0.33830799999999994 400.0\n",
      "112683, done 283 episodes, 47.18, current eps 0.335908 400.0\n",
      "113083, done 284 episodes, 47.16, current eps 0.333508 400.0\n",
      "113483, done 285 episodes, 46.43, current eps 0.33110799999999996 400.0\n",
      "113883, done 286 episodes, 46.75, current eps 0.328708 400.0\n",
      "114283, done 287 episodes, 47.49, current eps 0.32630800000000004 400.0\n",
      "114683, done 288 episodes, 48.25, current eps 0.323908 400.0\n",
      "115083, done 289 episodes, 49.04, current eps 0.321508 400.0\n",
      "115483, done 290 episodes, 45.59, current eps 0.31910799999999995 400.0\n",
      "115883, done 291 episodes, 44.91, current eps 0.316708 400.0\n",
      "116283, done 292 episodes, 45.97, current eps 0.31430800000000003 400.0\n",
      "116683, done 293 episodes, 45.44, current eps 0.31190799999999996 400.0\n",
      "117083, done 294 episodes, 45.24, current eps 0.309508 400.0\n",
      "117483, done 295 episodes, 45.07, current eps 0.30710800000000005 400.0\n",
      "117883, done 296 episodes, 45.48, current eps 0.304708 400.0\n",
      "118283, done 297 episodes, 45.19, current eps 0.302308 400.0\n",
      "118683, done 298 episodes, 45.32, current eps 0.29990799999999995 400.0\n",
      "119083, done 299 episodes, 45.6, current eps 0.297508 400.0\n",
      "119483, done 300 episodes, 46.07, current eps 0.29510800000000004 400.0\n",
      "119883, done 301 episodes, 45.74, current eps 0.29270799999999997 400.0\n",
      "120283, done 302 episodes, 45.47, current eps 0.290308 400.0\n",
      "Evaluation score: 97.7\n",
      "0 of 20 episodes ended close to / at the final state.\n",
      "120683, done 303 episodes, 45.92, current eps 0.28790799999999994 400.0\n",
      "121083, done 304 episodes, 45.54, current eps 0.285508 400.0\n",
      "121483, done 305 episodes, 45.65, current eps 0.283108 400.0\n",
      "121883, done 306 episodes, 46.58, current eps 0.28070799999999996 400.0\n",
      "122283, done 307 episodes, 46.78, current eps 0.278308 400.0\n",
      "122683, done 308 episodes, 47.3, current eps 0.27590800000000004 400.0\n",
      "123083, done 309 episodes, 46.88, current eps 0.273508 400.0\n",
      "123483, done 310 episodes, 48.8, current eps 0.271108 400.0\n",
      "123883, done 311 episodes, 49.54, current eps 0.26870799999999995 400.0\n",
      "124283, done 312 episodes, 49.1, current eps 0.266308 400.0\n",
      "124683, done 313 episodes, 49.09, current eps 0.26390800000000003 400.0\n",
      "125083, done 314 episodes, 49.42, current eps 0.26150799999999996 400.0\n",
      "125483, done 315 episodes, 48.54, current eps 0.259108 400.0\n",
      "125883, done 316 episodes, 48.16, current eps 0.25670799999999994 400.0\n",
      "126283, done 317 episodes, 47.66, current eps 0.254308 400.0\n",
      "126683, done 318 episodes, 47.54, current eps 0.251908 400.0\n",
      "127083, done 319 episodes, 47.38, current eps 0.24950799999999995 400.0\n",
      "127483, done 320 episodes, 46.96, current eps 0.247108 400.0\n",
      "127883, done 321 episodes, 47.51, current eps 0.24470800000000004 400.0\n",
      "128283, done 322 episodes, 47.56, current eps 0.24230799999999997 400.0\n",
      "128683, done 323 episodes, 47.56, current eps 0.239908 400.0\n",
      "129083, done 324 episodes, 47.22, current eps 0.23750799999999994 400.0\n",
      "129483, done 325 episodes, 48.13, current eps 0.23510799999999998 400.0\n",
      "129883, done 326 episodes, 47.76, current eps 0.23270800000000003 400.0\n",
      "130283, done 327 episodes, 47.74, current eps 0.23030799999999996 400.0\n",
      "Evaluation score: 151.7\n",
      "0 of 20 episodes ended close to / at the final state.\n",
      "130683, done 328 episodes, 47.85, current eps 0.227908 400.0\n",
      "131083, done 329 episodes, 46.92, current eps 0.22550800000000004 400.0\n",
      "131483, done 330 episodes, 47.05, current eps 0.22310799999999997 400.0\n",
      "131883, done 331 episodes, 48.52, current eps 0.22070800000000002 400.0\n",
      "132283, done 332 episodes, 49.27, current eps 0.21830799999999995 400.0\n",
      "132683, done 333 episodes, 50.09, current eps 0.215908 400.0\n",
      "133083, done 334 episodes, 49.85, current eps 0.21350800000000003 400.0\n",
      "133483, done 335 episodes, 50.68, current eps 0.21110799999999996 400.0\n",
      "133883, done 336 episodes, 51.71, current eps 0.208708 400.0\n",
      "134283, done 337 episodes, 52.77, current eps 0.20630799999999994 400.0\n",
      "134683, done 338 episodes, 53.58, current eps 0.20390799999999998 400.0\n",
      "135083, done 339 episodes, 54.22, current eps 0.20150800000000002 400.0\n",
      "135483, done 340 episodes, 55.66, current eps 0.19910799999999995 400.0\n",
      "135883, done 341 episodes, 56.08, current eps 0.196708 400.0\n",
      "136283, done 342 episodes, 55.28, current eps 0.19430800000000004 400.0\n",
      "136683, done 343 episodes, 54.71, current eps 0.19190799999999997 400.0\n",
      "137083, done 344 episodes, 55.72, current eps 0.189508 400.0\n",
      "137483, done 345 episodes, 56.87, current eps 0.18710799999999994 400.0\n",
      "137883, done 346 episodes, 56.07, current eps 0.18470799999999998 400.0\n",
      "138283, done 347 episodes, 56.08, current eps 0.18230800000000003 400.0\n",
      "138683, done 348 episodes, 56.27, current eps 0.17990799999999996 400.0\n",
      "139083, done 349 episodes, 56.87, current eps 0.177508 400.0\n",
      "139483, done 350 episodes, 56.98, current eps 0.17510800000000004 400.0\n",
      "139883, done 351 episodes, 57.99, current eps 0.17270799999999997 400.0\n",
      "140283, done 352 episodes, 57.88, current eps 0.17030800000000001 400.0\n",
      "Evaluation score: 167.7\n",
      "0 of 20 episodes ended close to / at the final state.\n",
      "140683, done 353 episodes, 58.2, current eps 0.16790799999999995 400.0\n",
      "141083, done 354 episodes, 58.42, current eps 0.165508 400.0\n",
      "141483, done 355 episodes, 58.32, current eps 0.16310800000000003 400.0\n",
      "141883, done 356 episodes, 57.72, current eps 0.16070799999999996 400.0\n",
      "142283, done 357 episodes, 57.25, current eps 0.158308 400.0\n",
      "142683, done 358 episodes, 57.04, current eps 0.15590799999999994 400.0\n",
      "143083, done 359 episodes, 58.08, current eps 0.15350799999999998 400.0\n",
      "143483, done 360 episodes, 59.35, current eps 0.15110800000000002 400.0\n",
      "143883, done 361 episodes, 59.35, current eps 0.14870799999999995 400.0\n",
      "144283, done 362 episodes, 59.8, current eps 0.146308 400.0\n",
      "144683, done 363 episodes, 57.86, current eps 0.14390800000000004 400.0\n",
      "145083, done 364 episodes, 59.23, current eps 0.14150799999999997 400.0\n",
      "145483, done 365 episodes, 59.41, current eps 0.139108 400.0\n",
      "145883, done 366 episodes, 60.05, current eps 0.13670799999999994 400.0\n",
      "146283, done 367 episodes, 59.93, current eps 0.13430799999999998 400.0\n",
      "146683, done 368 episodes, 60.83, current eps 0.13190800000000003 400.0\n",
      "147083, done 369 episodes, 61.64, current eps 0.12950799999999996 400.0\n",
      "147483, done 370 episodes, 60.86, current eps 0.127108 400.0\n",
      "147883, done 371 episodes, 62.6, current eps 0.12470800000000004 400.0\n",
      "148283, done 372 episodes, 64.14, current eps 0.12230799999999997 400.0\n",
      "148683, done 373 episodes, 64.9, current eps 0.11990800000000001 400.0\n",
      "149083, done 374 episodes, 65.44, current eps 0.11750799999999995 400.0\n",
      "149483, done 375 episodes, 65.93, current eps 0.11510799999999999 400.0\n",
      "149883, done 376 episodes, 66.6, current eps 0.11270800000000003 400.0\n",
      "150283, done 377 episodes, 66.5, current eps 0.11030799999999996 400.0\n",
      "Evaluation score: 178.0\n",
      "0 of 20 episodes ended close to / at the final state.\n",
      "150683, done 378 episodes, 67.37, current eps 0.107908 400.0\n",
      "151083, done 379 episodes, 66.16, current eps 0.10550799999999994 400.0\n",
      "151483, done 380 episodes, 66.88, current eps 0.10310799999999998 400.0\n",
      "151883, done 381 episodes, 66.33, current eps 0.10070800000000002 400.0\n",
      "152283, done 382 episodes, 66.97, current eps 0.0999920786516854 400.0\n",
      "152683, done 383 episodes, 67.86, current eps 0.09998084269662921 400.0\n",
      "153083, done 384 episodes, 67.41, current eps 0.09996960674157304 400.0\n",
      "153483, done 385 episodes, 68.77, current eps 0.09995837078651686 400.0\n",
      "153883, done 386 episodes, 69.04, current eps 0.09994713483146067 400.0\n",
      "154283, done 387 episodes, 69.33, current eps 0.0999358988764045 400.0\n",
      "154683, done 388 episodes, 69.56, current eps 0.09992466292134831 400.0\n",
      "155083, done 389 episodes, 69.68, current eps 0.09991342696629213 400.0\n",
      "155483, done 390 episodes, 72.45, current eps 0.09990219101123596 400.0\n",
      "155883, done 391 episodes, 73.65, current eps 0.09989095505617977 400.0\n",
      "156283, done 392 episodes, 73.81, current eps 0.0998797191011236 400.0\n",
      "156683, done 393 episodes, 74.98, current eps 0.09986848314606742 400.0\n",
      "157083, done 394 episodes, 74.98, current eps 0.09985724719101124 400.0\n",
      "157483, done 395 episodes, 75.95, current eps 0.09984601123595506 400.0\n",
      "157883, done 396 episodes, 76.07, current eps 0.09983477528089887 400.0\n",
      "158283, done 397 episodes, 76.91, current eps 0.0998235393258427 400.0\n",
      "158683, done 398 episodes, 76.56, current eps 0.09981230337078652 400.0\n",
      "159083, done 399 episodes, 75.85, current eps 0.09980106741573033 400.0\n",
      "159483, done 400 episodes, 76.42, current eps 0.09978983146067416 400.0\n",
      "159883, done 401 episodes, 76.75, current eps 0.09977859550561798 400.0\n",
      "160283, done 402 episodes, 77.06, current eps 0.0997673595505618 400.0\n",
      "Evaluation score: 209.35\n",
      "0 of 20 episodes ended close to / at the final state.\n",
      "160683, done 403 episodes, 77.27, current eps 0.09975612359550562 400.0\n",
      "161083, done 404 episodes, 77.96, current eps 0.09974488764044943 400.0\n",
      "161483, done 405 episodes, 79.09, current eps 0.09973365168539326 400.0\n",
      "161883, done 406 episodes, 79.47, current eps 0.09972241573033708 400.0\n",
      "162283, done 407 episodes, 80.28, current eps 0.0997111797752809 400.0\n",
      "162683, done 408 episodes, 80.62, current eps 0.09969994382022472 400.0\n",
      "163083, done 409 episodes, 82.27, current eps 0.09968870786516854 400.0\n",
      "163483, done 410 episodes, 83.08, current eps 0.09967747191011236 400.0\n",
      "163883, done 411 episodes, 83.2, current eps 0.09966623595505618 400.0\n",
      "164283, done 412 episodes, 84.21, current eps 0.09965500000000001 400.0\n",
      "164683, done 413 episodes, 84.42, current eps 0.09964376404494382 400.0\n",
      "165083, done 414 episodes, 84.0, current eps 0.09963252808988764 400.0\n",
      "165483, done 415 episodes, 85.26, current eps 0.09962129213483147 400.0\n",
      "165883, done 416 episodes, 86.46, current eps 0.09961005617977528 400.0\n",
      "166283, done 417 episodes, 87.94, current eps 0.09959882022471911 400.0\n",
      "166683, done 418 episodes, 88.57, current eps 0.09958758426966292 400.0\n",
      "167083, done 419 episodes, 90.01, current eps 0.09957634831460674 400.0\n",
      "167483, done 420 episodes, 91.39, current eps 0.09956511235955057 400.0\n",
      "167883, done 421 episodes, 90.8, current eps 0.09955387640449438 400.0\n",
      "168283, done 422 episodes, 91.46, current eps 0.0995426404494382 400.0\n",
      "168683, done 423 episodes, 92.67, current eps 0.09953140449438203 400.0\n",
      "169083, done 424 episodes, 92.83, current eps 0.09952016853932584 400.0\n",
      "169483, done 425 episodes, 92.11, current eps 0.09950893258426967 400.0\n",
      "169883, done 426 episodes, 92.68, current eps 0.09949769662921348 400.0\n",
      "170283, done 427 episodes, 92.75, current eps 0.09948646067415731 400.0\n",
      "Evaluation score: 220.55\n",
      "0 of 20 episodes ended close to / at the final state.\n",
      "170683, done 428 episodes, 93.8, current eps 0.09947522471910113 400.0\n",
      "171083, done 429 episodes, 94.92, current eps 0.09946398876404494 400.0\n",
      "171483, done 430 episodes, 95.43, current eps 0.09945275280898877 400.0\n",
      "171883, done 431 episodes, 95.38, current eps 0.09944151685393258 400.0\n",
      "172283, done 432 episodes, 94.77, current eps 0.0994302808988764 400.0\n",
      "172683, done 433 episodes, 94.37, current eps 0.09941904494382023 400.0\n",
      "173083, done 434 episodes, 95.72, current eps 0.09940780898876404 400.0\n",
      "173483, done 435 episodes, 95.87, current eps 0.09939657303370787 400.0\n",
      "173883, done 436 episodes, 95.73, current eps 0.09938533707865169 400.0\n",
      "174283, done 437 episodes, 95.6, current eps 0.0993741011235955 400.0\n",
      "174683, done 438 episodes, 95.58, current eps 0.09936286516853933 400.0\n",
      "175083, done 439 episodes, 95.75, current eps 0.09935162921348314 400.0\n",
      "175483, done 440 episodes, 95.71, current eps 0.09934039325842697 400.0\n",
      "175883, done 441 episodes, 96.24, current eps 0.09932915730337079 400.0\n",
      "176283, done 442 episodes, 97.49, current eps 0.0993179213483146 400.0\n",
      "176683, done 443 episodes, 98.28, current eps 0.09930668539325843 400.0\n",
      "177083, done 444 episodes, 98.16, current eps 0.09929544943820225 400.0\n",
      "177483, done 445 episodes, 97.68, current eps 0.09928421348314607 400.0\n",
      "177883, done 446 episodes, 99.19, current eps 0.09927297752808989 400.0\n",
      "178283, done 447 episodes, 99.76, current eps 0.0992617415730337 400.0\n",
      "178683, done 448 episodes, 99.74, current eps 0.09925050561797753 400.0\n",
      "179083, done 449 episodes, 100.03, current eps 0.09923926966292135 400.0\n",
      "179483, done 450 episodes, 100.12, current eps 0.09922803370786518 400.0\n",
      "179883, done 451 episodes, 99.62, current eps 0.09921679775280899 400.0\n",
      "180283, done 452 episodes, 100.39, current eps 0.0992055617977528 400.0\n",
      "Evaluation score: 223.6\n",
      "0 of 20 episodes ended close to / at the final state.\n",
      "180683, done 453 episodes, 101.38, current eps 0.09919432584269663 400.0\n",
      "181083, done 454 episodes, 101.6, current eps 0.09918308988764045 400.0\n",
      "181483, done 455 episodes, 101.86, current eps 0.09917185393258426 400.0\n",
      "181883, done 456 episodes, 102.27, current eps 0.09916061797752809 400.0\n",
      "182283, done 457 episodes, 103.07, current eps 0.09914938202247191 400.0\n",
      "182683, done 458 episodes, 103.12, current eps 0.09913814606741574 400.0\n",
      "183083, done 459 episodes, 102.08, current eps 0.09912691011235955 400.0\n",
      "183483, done 460 episodes, 102.41, current eps 0.09911567415730338 400.0\n",
      "183883, done 461 episodes, 102.94, current eps 0.0991044382022472 400.0\n",
      "184283, done 462 episodes, 103.44, current eps 0.09909320224719101 400.0\n",
      "184683, done 463 episodes, 106.08, current eps 0.09908196629213484 400.0\n",
      "185083, done 464 episodes, 106.57, current eps 0.09907073033707865 400.0\n",
      "185483, done 465 episodes, 107.49, current eps 0.09905949438202247 400.0\n",
      "185883, done 466 episodes, 107.45, current eps 0.0990482584269663 400.0\n",
      "186283, done 467 episodes, 108.61, current eps 0.09903702247191011 400.0\n",
      "186683, done 468 episodes, 108.32, current eps 0.09902578651685394 400.0\n",
      "187083, done 469 episodes, 108.19, current eps 0.09901455056179775 400.0\n",
      "187483, done 470 episodes, 108.69, current eps 0.09900331460674157 400.0\n",
      "187883, done 471 episodes, 107.99, current eps 0.0989920786516854 400.0\n",
      "188283, done 472 episodes, 107.64, current eps 0.09898084269662921 400.0\n",
      "188683, done 473 episodes, 106.89, current eps 0.09896960674157304 400.0\n",
      "189083, done 474 episodes, 107.17, current eps 0.09895837078651686 400.0\n",
      "189483, done 475 episodes, 106.68, current eps 0.09894713483146067 400.0\n",
      "189883, done 476 episodes, 106.26, current eps 0.0989358988764045 400.0\n",
      "190283, done 477 episodes, 106.7, current eps 0.09892466292134831 400.0\n",
      "Evaluation score: 228.65\n",
      "0 of 20 episodes ended close to / at the final state.\n",
      "190683, done 478 episodes, 106.79, current eps 0.09891342696629214 400.0\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a5bdeeba5d3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;31m#if reward > 0.:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0;31m#    print(\"reward was positive: \", reward)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Coding/deepFibreTracking/dfibert/tracker/nn/rl.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mterminal_flags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBoolTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterminal_flags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mstate_action_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain_dqn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0mnext_state_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain_dqn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Coding/deepFibreTracking/dfibert/tracker/nn/rl.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_layers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1688\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1689\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1690\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1691\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1692\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "state = env.reset().getValue()\n",
    "agent = Agent(n_actions=n_actions, inp_size=state.shape, device=device, hidden=10, gamma=0.1, agent_history_length=agent_history_length, memory_size=replay_memory_size, batch_size=batch_size, learning_rate=learning_rate)\n",
    "\n",
    "#transition = init_transition()\n",
    "#agent = Agent(n_actions=n_actions, inp_size=np.array(transition).shape, device=device, hidden=10, agent_history_length=agent_history_length, memory_size=replay_memory_size, batch_size=batch_size, learning_rate=learning_rate)\n",
    "action_scheduler = Action_Scheduler(num_actions=n_actions, max_steps=max_steps, eps_annealing_steps=eps_annealing_steps, eps_final=0.1, eps_final_step=0.02, replay_memory_start_size=start_learning, model=agent.main_dqn)\n",
    "\n",
    "step_counter = 0\n",
    "\n",
    "eps_rewards = []\n",
    "\n",
    "episode_lengths = []\n",
    "\n",
    "cos = torch.nn.CosineSimilarity(dim=0)\n",
    "\n",
    "print(\"Start training...\")\n",
    "while step_counter < max_steps:\n",
    "    epoch_step = 0\n",
    "    #agent.main_dqn.train()\n",
    "######## fill memory begins here\n",
    "    while (epoch_step < evaluate_every) or (step_counter < start_learning):\n",
    "        state = env.reset()\n",
    "        #env.stepCounter = np.random.randint(len(env.referenceStreamline_ijk)-5)\n",
    "        #env.state = TractographyState(env.referenceStreamline_ijk[env.stepCounter], env.interpolateDWIatState)\n",
    "        #transition = init_transition()\n",
    "        #referenceLine = env.referenceStreamline_ijk\n",
    "        episode_reward_sum = 0\n",
    "        terminal = False\n",
    "        #fill replay memory while interacting with env\n",
    "        #for episode_counter in range(max_episode_length):\n",
    "        episode_step_counter = 0\n",
    "        positive_run = 0\n",
    "        \n",
    "        dist = 0\n",
    "        #influential_action = None\n",
    "        while not terminal:\n",
    "            # get action with epsilon-greedy strategy\n",
    "            #if dist < 0.1:\n",
    "            _, optimal_reward = get_best_action(state, env)\n",
    "               #print(influential_action)\n",
    "            #else:\n",
    "            #    influential_action = None\n",
    "            action = action_scheduler.get_action(step_counter, torch.FloatTensor(state.getValue()).unsqueeze(0).to(device)) #influential_action=influential_action)\n",
    "            #action = action_scheduler.get_action(step_counter, torch.FloatTensor([np.array(transition)]).to(device))\n",
    "            \n",
    "            \n",
    "            next_state, reward, terminal = env.step(action)\n",
    "            episode_step_counter += 1\n",
    "            #print(episode_step_counter, action, reward, optimal_reward, torch.tanh(1-(optimal_reward - reward)))\n",
    "\n",
    "            \n",
    "            #if reward < -1.:\n",
    "            #    reward = -1.\n",
    "            \n",
    "            #terminal = False\n",
    "            \n",
    "            #current_index = np.min([env.stepCounter,len(env.referenceStreamline_ijk)-1])\n",
    "            #path_vector = (next_state.getCoordinate() - state.getCoordinate()).squeeze(0)\n",
    "            #reference_vector = env.referenceStreamline_ijk[current_index]-env.referenceStreamline_ijk[current_index-1]\n",
    "            ##    #print(path_vector, reference_vector)\n",
    "            #cosine_sim = cos(path_vector, reference_vector)\n",
    "            #dist = torch.sum((env.referenceStreamline_ijk[current_index] - next_state.getCoordinate())**2)\n",
    "            #reward = -torch.dist(env.referenceStreamline_ijk[current_index], next_state.getCoordinate(), p=2)\n",
    "            #if reward == 0.:\n",
    "            #    reward = 1.\n",
    "            if reward < -0.05:\n",
    "                env.stepCounter -= 1\n",
    "            \n",
    "            reward = torch.tanh(1- (optimal_reward - reward))\n",
    "            if reward >= 0.76:\n",
    "                reward = 1.\n",
    "            elif reward < 0.1:\n",
    "                reward = -1.\n",
    "            else:\n",
    "                reward = 0.\n",
    "\n",
    "            #if reward < -5.0:\n",
    "            #    reward = -5.0\n",
    "            #if reward < -100:\n",
    "            #    reward = -100\n",
    "            #if dist < 0.1:\n",
    "            #    dist = 0\n",
    "            #else:\n",
    "            #    dist = dist - 0.1\n",
    "            #if dist > 3*0.81:\n",
    "            #    env.stepCounter -= 1\n",
    "            #reward = cosine_sim - dist\n",
    "            #reward = 1 - (optimal_reward - reward)\n",
    "            #reward = 1- (optimal_reward - dist)\n",
    "            #if reward == optimal_reward:\n",
    "            #    reward = 1\n",
    "            #if action == 100 and dist < 0.1:\n",
    "            #    terminal = True\n",
    "            #print(\"From function: \", influential_action, optimal_reward)\n",
    "            #print(\"From scheduler: \", action, reward,  terminal)\n",
    "            #print(\"Cosine sim: \", cosine_sim)\n",
    "            #print(\"Dist: \", dist)\n",
    "            \n",
    "            #if episode_step_counter >= 200:\n",
    "            #    terminal = True\n",
    "            \n",
    "            #print(episode_step_counter, action, reward, terminal)\n",
    "            #print(reward)\n",
    "            #if dist > 0.7: # cosine_sim < 0.4 or\n",
    "            #    terminal = True\n",
    "            #next_state = next_state[:2]\n",
    "            #next_transition = add_to_transition(next_state, transition)\n",
    "            \n",
    "            step_counter += 1\n",
    "            epoch_step += 1\n",
    "\n",
    "            # accumulate reward for current episode\n",
    "            episode_reward_sum += reward\n",
    "\n",
    "\n",
    "            agent.replay_memory.add_experience(action=action,\n",
    "                                #state=np.array(transition),\n",
    "                                state = state.getValue(),\n",
    "                                reward=reward,\n",
    "                                #new_state=np.array(next_transition),\n",
    "                                new_state = next_state.getValue(),\n",
    "                                terminal=terminal)\n",
    "\n",
    "\n",
    "            state = next_state\n",
    "            #transition = next_transition\n",
    "\n",
    "\n",
    "\n",
    "            ####### optimization is happening here\n",
    "            if step_counter > start_learning and step_counter % 4 == 0:\n",
    "                #if reward > 0.:\n",
    "                #    print(\"reward was positive: \", reward)\n",
    "                loss = agent.optimize()\n",
    "\n",
    "\n",
    "            ####### target network update\n",
    "            if step_counter > start_learning and step_counter % network_update_every == 0:\n",
    "                #print(\"Update net\")\n",
    "                #print(agent.main_dqn(torch.tensor(state).to(device).unsqueeze(0)))\n",
    "                #print(agent.target_dqn(torch.tensor(state).to(device).unsqueeze(0)))\n",
    "                agent.target_dqn.load_state_dict(agent.main_dqn.state_dict())\n",
    "\n",
    "            # if episode ended before maximum step\n",
    "            if episode_step_counter >= 550:\n",
    "                terminal = True\n",
    "            if terminal:\n",
    "                terminal = False\n",
    "                episode_lengths.append(episode_step_counter)\n",
    "                #state = env.reset()[:2]\n",
    "                #transition = init_transition()\n",
    "                break\n",
    "\n",
    "        eps_rewards.append(episode_reward_sum)\n",
    "\n",
    "        if len(eps_rewards) % 1 == 0:\n",
    "            #with open(path+'/logs/rewards.dat', 'a') as reward_file:\n",
    "                #print(\"[{}] {}, {}\".format(len(eps_rewards), step_counter, np.mean(eps_rewards[-100:])), file=reward_file)\n",
    "            print(\"{}, done {} episodes, {}, current eps {}\".format(step_counter, len(eps_rewards), np.mean(eps_rewards[-100:]), action_scheduler.eps_current), np.mean(episode_lengths[-100:]))\n",
    "    #torch.save(agent.main_dqn.state_dict(), path+'/checkpoints/fibre_agent_{}_reward_{:.2f}.pth'.format(step_counter, np.mean(eps_rewards[-100:])))\n",
    "\n",
    "########## evaluation starting here\n",
    "    eval_rewards = []\n",
    "    episode_final = 0\n",
    "    #agent.main_dqn.eval()\n",
    "    for _ in range(eval_runs):\n",
    "        eval_steps = 0\n",
    "        state = env.reset()\n",
    "        #transition = init_transition()\n",
    "        #env.state = TractographyState(env.referenceStreamline_ijk[0], env.interpolateDWIatState)\n",
    "        #env.stepCounter = 0\n",
    "        \n",
    "        eval_episode_reward = 0\n",
    "        while eval_steps < max_episode_length:\n",
    "            _, optimal_reward = get_best_action(state, env)\n",
    "            action = action_scheduler.get_action(step_counter, torch.FloatTensor(state.getValue()).unsqueeze(0).to(device), evaluation=True)\n",
    "            #action = action_scheduler.get_action(step_counter, torch.FloatTensor([np.array(transition)]).to(device), evaluation=True)\n",
    "            next_state, reward, terminal = env.step(action)\n",
    "            \n",
    "            eval_steps += 1\n",
    "            \n",
    "            if reward < -0.05:\n",
    "                env.stepCounter -= 1\n",
    "            reward = 1 - (optimal_reward-reward)\n",
    "            if reward >= 0.76:\n",
    "                reward = 1\n",
    "            elif reward < 0.1:\n",
    "                reward = -1.\n",
    "            else:\n",
    "                reward = 0.\n",
    "\n",
    "            \n",
    "            #if reward < -5.0:\n",
    "            #    reward = -5.0\n",
    "            #if reward < -100:\n",
    "            #    reward = -100\n",
    "\n",
    "            #if reward < -1.:\n",
    "            #    reward = -1.\n",
    "            #terminal = False\n",
    "            #current_index = np.min([env.stepCounter,len(env.referenceStreamline_ijk)-1])\n",
    "            #path_vector = (next_state.getCoordinate() - state.getCoordinate()).squeeze(0)\n",
    "            #reference_vector = env.referenceStreamline_ijk[current_index]-env.referenceStreamline_ijk[current_index-1]\n",
    "            #    #print(path_vector, reference_vector)\n",
    "            #cosine_sim = cos(path_vector, reference_vector)\n",
    "            #dist = torch.sum((env.referenceStreamline_ijk[current_index] - next_state.getCoordinate())**2)\n",
    "            #if dist < 0.1:\n",
    "            #    dist = 0\n",
    "            #else:\n",
    "            #    dist = dist - 0.1\n",
    "            #if dist > 3*0.81:\n",
    "            #    env.stepCounter -= 1\n",
    "            #reward = cosine_sim - dist\n",
    "            #reward = 1- (optimal_reward - reward)\n",
    "            #if reward == optimal_reward:\n",
    "            #    reward = 1\n",
    "            #if action == 100 and env.rewardForTerminalState(next_state) < 0.1:\n",
    "            #    terminal = True\n",
    "\n",
    "            #if episode_step_counter == 200:\n",
    "            #    terminal = True\n",
    "            \n",
    "            #if cosine_sim < 0.9:\n",
    "            #    terminal = True\n",
    "            \n",
    "            eval_episode_reward += reward\n",
    "            state = next_state\n",
    "            #transition = next_transition\n",
    "            if terminal:\n",
    "                terminal = False\n",
    "                if reward == 1.:\n",
    "                    print(reward)\n",
    "                    episode_final += 1\n",
    "                break\n",
    "\n",
    "        eval_rewards.append(eval_episode_reward)\n",
    "\n",
    "    print(\"Evaluation score:\", np.mean(eval_rewards))\n",
    "    print(\"{} of {} episodes ended close to / at the final state.\".format(episode_final, eval_runs))\n",
    "    #if np.mean(eval_rewards) > 500.:\n",
    "    torch.save(agent.main_dqn.state_dict(), 'checkpoints/defi_{}_reward_{:.2f}.pth'.format(step_counter, np.mean(eval_rewards)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(agent.main_dqn.state_dict(), 'defi_{}_reward_{:.2f}.pth'.format(step_counter, np.mean(eval_rewards)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(path_vector.shape)\n",
    "print(reference_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-3.5291, device='cuda:0', grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "state = env.reset()\n",
    "\n",
    "q_vals = agent.main_dqn(torch.FloatTensor(state.getValue()).unsqueeze(0).to(device))\n",
    "print(q_vals[0][80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "sor(-10.4277, dtype=torch.float64)\n",
      "29 2 [41.72524265 94.33053411 25.44400978] [ 44.428493 106.72726   33.067238] tensor(-10.2918, dtype=torch.float64)\n",
      "30 12 [41.62762023 94.31356596 25.45749847] [ 44.55411  107.40329   32.658337] tensor(-7.9850, dtype=torch.float64)\n",
      "31 7 [41.58395691 94.28205355 25.54176283] [ 44.868977 107.97003   32.189655] tensor(-6.6792, dtype=torch.float64)\n",
      "32 12 [41.48633449 94.2650854  25.55525152] [ 45.08501  108.52863   31.659286] tensor(-5.2555, dtype=torch.float64)\n",
      "33 17 [41.58537923 94.27784819 25.55003129] [ 45.301044 109.08724   31.128918] tensor(-8.2749, dtype=torch.float64)\n",
      "34 12 [41.48775681 94.26088004 25.56351998] [ 45.42312 109.69873  30.62774] tensor(-5.2112, dtype=torch.float64)\n",
      "35 17 [41.58680155 94.27364284 25.55829974] [ 45.44939  110.35199   30.166698] tensor(-8.2315, dtype=torch.float64)\n",
      "36 12 [41.48917913 94.25667469 25.57178843] [ 45.376694 111.03384   29.754635] tensor(-5.1687, dtype=torch.float64)\n",
      "37 17 [41.58822386 94.26943749 25.5665682 ] [ 45.405098 111.78921   29.492693] tensor(-8.1899, dtype=torch.float64)\n",
      "38 12 [41.49060144 94.25246934 25.58005689] [ 45.43514  112.573975  29.340273] tensor(-5.1280, dtype=torch.float64)\n",
      "39 17 [41.58964618 94.26523214 25.57483665] [ 45.54108  113.365974  29.379156] tensor(-8.1500, dtype=torch.float64)\n",
      "40 12 [41.49202376 94.24826399 25.58832534] [ 45.725098 114.13628   29.492193] tensor(-5.0890, dtype=torch.float64)\n",
      "41 17 [41.5910685  94.26102679 25.58310511] [ 46.00385 114.88328  29.55764] tensor(-8.1119, dtype=torch.float64)\n",
      "42 12 [41.49344608 94.24405864 25.5965938 ] [ 46.373085 115.59275   29.575542] tensor(-5.0518, dtype=torch.float64)\n",
      "43 2 [41.47579436 94.34224704 25.58970507] [ 46.373085 115.59275   29.575542] tensor(-5.0069, dtype=torch.float64)\n",
      "44 12 [41.37817194 94.32527889 25.60319376] [ 46.373085 115.59275   29.575542] tensor(-3.2226, dtype=torch.float64)\n",
      "45 17 [41.47721668 94.33804169 25.59797353] [ 46.373085 115.59275   29.575542] tensor(-6.0380, dtype=torch.float64)\n",
      "46 12 [41.37959426 94.32107354 25.61146222] [ 46.373085 115.59275   29.575542] tensor(-3.1781, dtype=torch.float64)\n",
      "47 17 [41.478639   94.33383634 25.60624198] [ 46.373085 115.59275   29.575542] tensor(-5.9944, dtype=torch.float64)\n",
      "48 12 [41.38101657 94.31686819 25.61973067] [ 46.373085 115.59275   29.575542] tensor(-3.1354, dtype=torch.float64)\n",
      "49 17 [41.48006131 94.32963098 25.61451044] [ 46.373085 115.59275   29.575542] tensor(-5.9526, dtype=torch.float64)\n",
      "50 12 [41.38243889 94.31266283 25.62799913] [ 46.373085 115.59275   29.575542] tensor(-3.0944, dtype=torch.float64)\n",
      "51 17 [41.48148363 94.32542563 25.62277889] [ 46.373085 115.59275   29.575542] tensor(-5.9125, dtype=torch.float64)\n",
      "52 12 [41.38386121 94.30845748 25.63626758] [ 46.373085 115.59275   29.575542] tensor(-3.0552, dtype=torch.float64)\n",
      "53 17 [41.48290595 94.32122028 25.63104735] [ 46.373085 115.59275   29.575542] tensor(-5.8742, dtype=torch.float64)\n",
      "54 12 [41.38528353 94.30425213 25.64453604] [ 46.373085 115.59275   29.575542] tensor(-3.0178, dtype=torch.float64)\n",
      "55 17 [41.48432826 94.31701493 25.6393158 ] [ 46.373085 115.59275   29.575542] tensor(-5.8377, dtype=torch.float64)\n",
      "56 12 [41.38670584 94.30004678 25.65280449] [ 46.373085 115.59275   29.575542] tensor(-2.9821, dtype=torch.float64)\n",
      "57 12 [41.28908342 94.28307863 25.66629318] [ 46.373085 115.59275   29.575542] tensor(-2.1044, dtype=torch.float64)\n",
      "58 17 [41.38812816 94.29584143 25.66107295] [ 46.373085 115.59275   29.575542] tensor(-4.7260, dtype=torch.float64)\n",
      "59 12 [41.29050574 94.27887328 25.67456164] [ 46.373085 115.59275   29.575542] tensor(-2.0714, dtype=torch.float64)\n",
      "60 17 [41.38955048 94.29163608 25.6693414 ] [ 46.373085 115.59275   29.575542] tensor(-4.6939, dtype=torch.float64)\n",
      "61 12 [41.29192805 94.27466793 25.68283009] [ 46.373085 115.59275   29.575542] tensor(-2.0401, dtype=torch.float64)\n",
      "62 17 [41.39097279 94.28743072 25.67760986] [ 46.373085 115.59275   29.575542] tensor(-4.6635, dtype=torch.float64)\n",
      "63 12 [41.29335037 94.27046257 25.69109855] [ 46.373085 115.59275   29.575542] tensor(-2.0106, dtype=torch.float64)\n",
      "64 17 [41.39239511 94.28322537 25.68587832] [ 46.373085 115.59275   29.575542] tensor(-4.6349, dtype=torch.float64)\n",
      "65 12 [41.29477269 94.26625722 25.69936701] [ 46.373085 115.59275   29.575542] tensor(-1.9829, dtype=torch.float64)\n",
      "66 17 [41.39381743 94.27902002 25.69414677] [ 46.373085 115.59275   29.575542] tensor(-4.6080, dtype=torch.float64)\n",
      "67 12 [41.29619501 94.26205187 25.70763546] [ 46.373085 115.59275   29.575542] tensor(-1.9569, dtype=torch.float64)\n",
      "68 17 [41.39523974 94.27481467 25.70241523] [ 46.373085 115.59275   29.575542] tensor(-4.5829, dtype=torch.float64)\n",
      "69 12 [41.29761732 94.25784652 25.71590392] [ 46.373085 115.59275   29.575542] tensor(-1.9327, dtype=torch.float64)\n",
      "70 10 [41.36720641 94.30426244 25.661105  ] [ 46.373085 115.59275   29.575542] tensor(-4.4305, dtype=torch.float64)\n",
      "71 10 [41.43679549 94.35067836 25.60630608] [ 46.373085 115.59275   29.575542] tensor(-5.3929, dtype=torch.float64)\n",
      "72 12 [41.33917307 94.33371021 25.61979477] [ 46.373085 115.59275   29.575542] tensor(-2.6523, dtype=torch.float64)\n",
      "73 17 [41.43821781 94.34647301 25.61457453] [ 46.373085 115.59275   29.575542] tensor(-5.3909, dtype=torch.float64)\n",
      "74 12 [41.34059539 94.32950486 25.62806322] [ 46.373085 115.59275   29.575542] tensor(-2.6087, dtype=torch.float64)\n",
      "75 17 [41.43964013 94.34226766 25.62284299] [ 46.373085 115.59275   29.575542] tensor(-5.3483, dtype=torch.float64)\n",
      "76 12 [41.34201771 94.32529951 25.63633168] [ 46.373085 115.59275   29.575542] tensor(-2.5669, dtype=torch.float64)\n",
      "77 17 [41.44106244 94.3380623  25.63111144] [ 46.373085 115.59275   29.575542] tensor(-5.3073, dtype=torch.float64)\n",
      "78 12 [41.34344002 94.32109415 25.64460013] [ 46.373085 115.59275   29.575542] tensor(-2.5269, dtype=torch.float64)\n",
      "79 17 [41.44248476 94.33385695 25.6393799 ] [ 46.373085 115.59275   29.575542] tensor(-5.2682, dtype=torch.float64)\n",
      "80 12 [41.34486234 94.3168888  25.65286859] [ 46.373085 115.59275   29.575542] tensor(-2.4887, dtype=torch.float64)\n",
      "81 17 [41.44390708 94.3296516  25.64764835] [ 46.373085 115.59275   29.575542] tensor(-5.2308, dtype=torch.float64)\n",
      "82 12 [41.34628466 94.31268345 25.66113704] [ 46.373085 115.59275   29.575542] tensor(-2.4521, dtype=torch.float64)\n",
      "83 17 [41.44532939 94.32544625 25.65591681] [ 46.373085 115.59275   29.575542] tensor(-5.1952, dtype=torch.float64)\n",
      "84 12 [41.34770697 94.3084781  25.6694055 ] [ 46.373085 115.59275   29.575542] tensor(-2.4174, dtype=torch.float64)\n",
      "85 17 [41.44675171 94.3212409  25.66418526] [ 46.373085 115.59275   29.575542] tensor(-5.1613, dtype=torch.float64)\n",
      "86 12 [41.34912929 94.30427275 25.67767395] [ 46.373085 115.59275   29.575542] tensor(-2.3844, dtype=torch.float64)\n",
      "87 10 [41.41871837 94.35068867 25.62287504] [ 46.373085 115.59275   29.575542] tensor(-5.0389, dtype=torch.float64)\n",
      "88 12 [41.32109595 94.33372052 25.63636373] [ 46.373085 115.59275   29.575542] tensor(-2.3381, dtype=torch.float64)\n",
      "89 17 [41.42014069 94.34648331 25.63114349] [ 46.373085 115.59275   29.575542] tensor(-5.0392, dtype=torch.float64)\n",
      "90 12 [41.32251827 94.32951516 25.64463218] [ 46.373085 115.59275   29.575542] tensor(-2.2967, dtype=torch.float64)\n",
      "91 17 [41.42156301 94.34227796 25.63941195] [ 46.373085 115.59275   29.575542] tensor(-4.9987, dtype=torch.float64)\n",
      "92 12 [41.32394059 94.32530981 25.65290064] [ 46.373085 115.59275   29.575542] tensor(-2.2572, dtype=torch.float64)\n",
      "93 17 [41.42298533 94.33807261 25.6476804 ] [ 46.373085 115.59275   29.575542] tensor(-4.9600, dtype=torch.float64)\n",
      "94 12 [41.3253629  94.32110446 25.66116909] [ 46.373085 115.59275   29.575542] tensor(-2.2194, dtype=torch.float64)\n",
      "95 17 [41.42440764 94.33386726 25.65594886] [ 46.373085 115.59275   29.575542] tensor(-4.9231, dtype=torch.float64)\n",
      "96 12 [41.32678522 94.31689911 25.66943755] [ 46.373085 115.59275   29.575542] tensor(-2.1833, dtype=torch.float64)\n",
      "97 17 [41.42582996 94.32966191 25.66421731] [ 46.373085 115.59275   29.575542] tensor(-4.8880, dtype=torch.float64)\n",
      "98 12 [41.32820754 94.31269376 25.677706  ] [ 46.373085 115.59275   29.575542] tensor(-2.1491, dtype=torch.float64)\n",
      "99 17 [41.42725228 94.32545656 25.67248577] [ 46.373085 115.59275   29.575542] tensor(-4.8546, dtype=torch.float64)\n",
      "100 12 [41.32962985 94.30848841 25.68597446] [ 46.373085 115.59275   29.575542] tensor(-2.1165, dtype=torch.float64)\n",
      "101 10 [41.39921894 94.35490433 25.63117554] [ 46.373085 115.59275   29.575542] tensor(-4.7387, dtype=torch.float64)\n",
      "102 12 [41.30159652 94.33793618 25.64466423] [ 46.373085 115.59275   29.575542] tensor(-2.0767, dtype=torch.float64)\n",
      "103 17 [41.40064126 94.35069897 25.63944399] [ 46.373085 115.59275   29.575542] tensor(-4.7394, dtype=torch.float64)\n",
      "104 12 [41.30301884 94.33373082 25.65293268] [ 46.373085 115.59275   29.575542] tensor(-2.0359, dtype=torch.float64)\n",
      "105 17 [41.40206357 94.34649362 25.64771245] [ 46.373085 115.59275   29.575542] tensor(-4.6995, dtype=torch.float64)\n",
      "106 12 [41.30444115 94.32952547 25.66120114] [ 46.373085 115.59275   29.575542] tensor(-1.9968, dtype=torch.float64)\n",
      "107 17 [41.40348589 94.34228827 25.6559809 ] [ 46.373085 115.59275   29.575542] tensor(-4.6612, dtype=torch.float64)\n",
      "108 12 [41.30586347 94.32532012 25.66946959] [ 46.373085 115.59275   29.575542] tensor(-1.9594, dtype=torch.float64)\n",
      "109 17 [41.40490821 94.33808292 25.66424936] [ 46.373085 115.59275   29.575542] tensor(-4.6248, dtype=torch.float64)\n",
      "110 12 [41.30728579 94.32111477 25.67773805] [ 46.373085 115.59275   29.575542] tensor(-1.9239, dtype=torch.float64)\n",
      "111 17 [41.40633052 94.33387757 25.67251781] [ 46.373085 115.59275   29.575542] tensor(-4.5901, dtype=torch.float64)\n",
      "112 12 [41.3087081  94.31690942 25.68600651] [ 46.373085 115.59275   29.575542] tensor(-1.8900, dtype=torch.float64)\n",
      "113 17 [41.40775284 94.32967221 25.68078627] [ 46.373085 115.59275   29.575542] tensor(-4.5571, dtype=torch.float64)\n",
      "114 12 [41.31013042 94.31270406 25.69427496] [ 46.373085 115.59275   29.575542] tensor(-1.8580, dtype=torch.float64)\n",
      "115 17 [41.40917516 94.32546686 25.68905473] [ 46.373085 115.59275   29.575542] tensor(-4.5260, dtype=torch.float64)\n",
      "116 12 [41.31155274 94.30849871 25.70254342] [ 46.373085 115.59275   29.575542] tensor(-1.8277, dtype=torch.float64)\n",
      "117 10 [41.38114182 94.35491463 25.6477445 ] [ 46.373085 115.59275   29.575542] tensor(-4.4066, dtype=torch.float64)\n",
      "118 12 [41.2835194  94.33794648 25.66123319] [ 46.373085 115.59275   29.575542] tensor(-1.7844, dtype=torch.float64)\n",
      "119 17 [41.38256414 94.35070928 25.65601295] [ 46.373085 115.59275   29.575542] tensor(-4.4095, dtype=torch.float64)\n",
      "120 12 [41.28494172 94.33374113 25.66950164] [ 46.373085 115.59275   29.575542] tensor(-1.7457, dtype=torch.float64)\n",
      "121 17 [41.38398646 94.34650393 25.66428141] [ 46.373085 115.59275   29.575542] tensor(-4.3718, dtype=torch.float64)\n",
      "122 12 [41.28636403 94.32953578 25.6777701 ] [ 46.373085 115.59275   29.575542] tensor(-1.7088, dtype=torch.float64)\n",
      "123 17 [41.38540877 94.34229858 25.67254986] [ 46.373085 115.59275   29.575542] tensor(-4.3358, dtype=torch.float64)\n",
      "124 12 [41.28778635 94.32533043 25.68603855] [ 46.373085 115.59275   29.575542] tensor(-1.6737, dtype=torch.float64)\n",
      "125 17 [41.38683109 94.33809323 25.68081832] [ 46.373085 115.59275   29.575542] tensor(-4.3015, dtype=torch.float64)\n",
      "126 12 [41.28920867 94.32112508 25.69430701] [ 46.373085 115.59275   29.575542] tensor(-1.6404, dtype=torch.float64)\n",
      "127 17 [41.38825341 94.33388787 25.68908677] [ 46.373085 115.59275   29.575542] tensor(-4.2691, dtype=torch.float64)\n",
      "128 12 [41.29063098 94.31691972 25.70257546] [ 46.373085 115.59275   29.575542] tensor(-1.6088, dtype=torch.float64)\n",
      "129 17 [41.38967572 94.32968252 25.69735523] [ 46.373085 115.59275   29.575542] tensor(-4.2383, dtype=torch.float64)\n",
      "130 12 [41.2920533  94.31271437 25.71084392] [ 46.373085 115.59275   29.575542] tensor(-1.5790, dtype=torch.float64)\n",
      "131 10 [41.36164239 94.35913029 25.656045  ] [ 46.373085 115.59275   29.575542] tensor(-4.1255, dtype=torch.float64)\n",
      "132 12 [41.26401997 94.34216214 25.66953369] [ 46.373085 115.59275   29.575542] tensor(-1.5422, dtype=torch.float64)\n",
      "133 17 [41.3630647  94.35492494 25.66431345] [ 46.373085 115.59275   29.575542] tensor(-4.1289, dtype=torch.float64)\n",
      "134 12 [41.26544228 94.33795679 25.67780214] [ 46.373085 115.59275   29.575542] tensor(-1.5040, dtype=torch.float64)\n",
      "135 17 [41.36448702 94.35071959 25.67258191] [ 46.373085 115.59275   29.575542] tensor(-4.0916, dtype=torch.float64)\n",
      "136 12 [41.2668646  94.33375144 25.6860706 ] [ 46.373085 115.59275   29.575542] tensor(-1.4676, dtype=torch.float64)\n",
      "137 17 [41.36590934 94.34651424 25.68085037] [ 46.373085 115.59275   29.575542] tensor(-4.0561, dtype=torch.float64)\n",
      "138 12 [41.26828692 94.32954609 25.69433906] [ 46.373085 115.59275   29.575542] tensor(-1.4329, dtype=torch.float64)\n",
      "139 17 [41.36733165 94.34230889 25.68911882] [ 46.373085 115.59275   29.575542] tensor(-4.0223, dtype=torch.float64)\n",
      "140 12 [41.26970923 94.32534074 25.70260751] [ 46.373085 115.59275   29.575542] tensor(-1.4000, dtype=torch.float64)\n",
      "141 17 [41.36875397 94.33810353 25.69738728] [ 46.373085 115.59275   29.575542] tensor(-3.9903, dtype=torch.float64)\n",
      "142 12 [41.27113155 94.32113538 25.71087597] [ 46.373085 115.59275   29.575542] tensor(-1.3689, dtype=torch.float64)\n",
      "143 17 [41.37017629 94.33389818 25.70565573] [ 46.373085 115.59275   29.575542] tensor(-3.9601, dtype=torch.float64)\n",
      "144 12 [41.27255387 94.31693003 25.71914442] [ 46.373085 115.59275   29.575542] tensor(-1.3396, dtype=torch.float64)\n",
      "145 17 [41.3715986  94.32969283 25.71392419] [ 46.373085 115.59275   29.575542] tensor(-3.9316, dtype=torch.float64)\n",
      "146 12 [41.27397618 94.31272468 25.72741288] [ 46.373085 115.59275   29.575542] tensor(-1.3119, dtype=torch.float64)\n",
      "147 10 [41.34356527 94.3591406  25.67261396] [ 46.373085 115.59275   29.575542] tensor(-3.8152, dtype=torch.float64)\n",
      "148 12 [41.24594285 94.34217245 25.68610265] [ 46.373085 115.59275   29.575542] tensor(-1.2716, dtype=torch.float64)\n",
      "149 17 [41.34498759 94.35493525 25.68088241] [ 46.373085 115.59275   29.575542] tensor(-3.8208, dtype=torch.float64)\n",
      "150 12 [41.24736516 94.3379671  25.6943711 ] [ 46.373085 115.59275   29.575542] tensor(-1.2357, dtype=torch.float64)\n",
      "151 17 [41.3464099  94.3507299  25.68915087] [ 46.373085 115.59275   29.575542] tensor(-3.7857, dtype=torch.float64)\n",
      "152 12 [41.24878748 94.33376175 25.70263956] [ 46.373085 115.59275   29.575542] tensor(-1.2015, dtype=torch.float64)\n",
      "153 17 [41.34783222 94.34652454 25.69741932] [ 46.373085 115.59275   29.575542] tensor(-3.7524, dtype=torch.float64)\n",
      "154 12 [41.2502098  94.32955639 25.71090801] [ 46.373085 115.59275   29.575542] tensor(-1.1690, dtype=torch.float64)\n",
      "155 17 [41.34925454 94.34231919 25.70568778] [ 46.373085 115.59275   29.575542] tensor(-3.7209, dtype=torch.float64)\n",
      "156 12 [41.25163211 94.32535104 25.71917647] [ 46.373085 115.59275   29.575542] tensor(-1.1384, dtype=torch.float64)\n",
      "157 17 [41.35067685 94.33811384 25.71395623] [ 46.373085 115.59275   29.575542] tensor(-3.6911, dtype=torch.float64)\n",
      "158 12 [41.25305443 94.32114569 25.72744492] [ 46.373085 115.59275   29.575542] tensor(-1.1095, dtype=torch.float64)\n",
      "159 17 [41.35209917 94.33390849 25.72222469] [ 46.373085 115.59275   29.575542] tensor(-3.6631, dtype=torch.float64)\n",
      "160 12 [41.25447675 94.31694034 25.73571338] [ 46.373085 115.59275   29.575542] tensor(-1.0823, dtype=torch.float64)\n",
      "161 10 [41.32406583 94.36335626 25.68091446] [ 46.373085 115.59275   29.575542] tensor(-3.5533, dtype=torch.float64)\n",
      "162 12 [41.22644341 94.34638811 25.69440315] [ 46.373085 115.59275   29.575542] tensor(-1.0486, dtype=torch.float64)\n",
      "163 17 [41.32548815 94.35915091 25.68918292] [ 46.373085 115.59275   29.575542] tensor(-3.5593, dtype=torch.float64)\n",
      "164 12 [41.22786573 94.34218276 25.70267161] [ 46.373085 115.59275   29.575542] tensor(-1.0131, dtype=torch.float64)\n",
      "165 17 [41.32691047 94.35494556 25.69745137] [ 46.373085 115.59275   29.575542] tensor(-3.5247, dtype=torch.float64)\n",
      "166 12 [41.22928805 94.33797741 25.71094006] [ 46.373085 115.59275   29.575542] tensor(-0.9794, dtype=torch.float64)\n",
      "167 17 [41.32833278 94.3507402  25.70571983] [ 46.373085 115.59275   29.575542] tensor(-3.4919, dtype=torch.float64)\n",
      "168 12 [41.23071036 94.33377205 25.71920852] [ 46.373085 115.59275   29.575542] tensor(-0.9474, dtype=torch.float64)\n",
      "169 17 [41.3297551  94.34653485 25.71398828] [ 46.373085 115.59275   29.575542] tensor(-3.4608, dtype=torch.float64)\n",
      "170 12 [41.23213268 94.3295667  25.72747697] [ 46.373085 115.59275   29.575542] tensor(-0.9172, dtype=torch.float64)\n",
      "171 17 [41.33117742 94.3423295  25.72225674] [ 46.373085 115.59275   29.575542] tensor(-3.4315, dtype=torch.float64)\n",
      "172 12 [41.233555   94.32536135 25.73574543] [ 46.373085 115.59275   29.575542] tensor(-0.8888, dtype=torch.float64)\n",
      "173 17 [41.33259973 94.33812415 25.73052519] [ 46.373085 115.59275   29.575542] tensor(-3.4039, dtype=torch.float64)\n",
      "174 12 [41.23497731 94.321156   25.74401388] [ 46.373085 115.59275   29.575542] tensor(-0.8621, dtype=torch.float64)\n",
      "175 17 [41.33402205 94.3339188  25.73879365] [ 46.373085 115.59275   29.575542] tensor(-3.3781, dtype=torch.float64)\n",
      "176 12 [41.23639963 94.31695065 25.75228234] [ 46.373085 115.59275   29.575542] tensor(-0.8372, dtype=torch.float64)\n",
      "177 10 [41.30598872 94.36336657 25.69748342] [ 46.373085 115.59275   29.575542] tensor(-3.2648, dtype=torch.float64)\n",
      "178 12 [41.20836629 94.34639842 25.71097211] [ 46.373085 115.59275   29.575542] tensor(-0.7998, dtype=torch.float64)\n",
      "179 17 [41.30741103 94.35916121 25.70575187] [ 46.373085 115.59275   29.575542] tensor(-3.2731, dtype=torch.float64)\n",
      "180 12 [41.20978861 94.34219306 25.71924056] [ 46.373085 115.59275   29.575542] tensor(-0.7666, dtype=torch.float64)\n",
      "181 17 [41.30883335 94.35495586 25.71402033] [ 46.373085 115.59275   29.575542] tensor(-3.2407, dtype=torch.float64)\n",
      "182 12 [41.21121093 94.33798771 25.72750902] [ 46.373085 115.59275   29.575542] tensor(-0.7351, dtype=torch.float64)\n",
      "183 17 [41.31025567 94.35075051 25.72228878] [ 46.373085 115.59275   29.575542] tensor(-3.2101, dtype=torch.float64)\n",
      "184 12 [41.21263324 94.33378236 25.73577747] [ 46.373085 115.59275   29.575542] tensor(-0.7053, dtype=torch.float64)\n",
      "185 17 [41.31167798 94.34654516 25.73055724] [ 46.373085 115.59275   29.575542] tensor(-3.1812, dtype=torch.float64)\n",
      "186 12 [41.21405556 94.32957701 25.74404593] [ 46.373085 115.59275   29.575542] tensor(-0.6774, dtype=torch.float64)\n",
      "187 17 [41.3131003  94.34233981 25.7388257 ] [ 46.373085 115.59275   29.575542] tensor(-3.1541, dtype=torch.float64)\n",
      "188 12 [41.21547788 94.32537166 25.75231439] [ 46.373085 115.59275   29.575542] tensor(-0.6511, dtype=torch.float64)\n",
      "189 17 [41.31452262 94.33813446 25.74709415] [ 46.373085 115.59275   29.575542] tensor(-3.1288, dtype=torch.float64)\n",
      "190 12 [41.2169002  94.32116631 25.76058284] [ 46.373085 115.59275   29.575542] tensor(-0.6267, dtype=torch.float64)\n",
      "191 10 [41.28648928 94.36758223 25.70578392] [ 46.373085 115.59275   29.575542] tensor(-3.0220, dtype=torch.float64)\n",
      "192 12 [41.18886686 94.35061408 25.71927261] [ 46.373085 115.59275   29.575542] tensor(-0.5959, dtype=torch.float64)\n",
      "193 17 [41.2879116  94.36337687 25.71405238] [ 46.373085 115.59275   29.575542] tensor(-3.0308, dtype=torch.float64)\n",
      "194 12 [41.19028918 94.34640872 25.72754107] [ 46.373085 115.59275   29.575542] tensor(-0.5631, dtype=torch.float64)\n",
      "195 17 [41.28933391 94.35917152 25.72232083] [ 46.373085 115.59275   29.575542] tensor(-2.9988, dtype=torch.float64)\n",
      "196 12 [41.19171149 94.34220337 25.73580952] [ 46.373085 115.59275   29.575542] tensor(-0.5321, dtype=torch.float64)\n",
      "197 17 [41.29075623 94.35496617 25.73058929] [ 46.373085 115.59275   29.575542] tensor(-2.9687, dtype=torch.float64)\n",
      "198 12 [41.19313381 94.33799802 25.74407798] [ 46.373085 115.59275   29.575542] tensor(-0.5028, dtype=torch.float64)\n",
      "199 17 [41.29217855 94.35076082 25.73885774] [ 46.373085 115.59275   29.575542] tensor(-2.9403, dtype=torch.float64)\n",
      "Evaluation score: -711.8348806032503\n"
     ]
    }
   ],
   "source": [
    "eval_rewards = []\n",
    "all_distances = []\n",
    "all_states = []\n",
    "#agent.main_dqn.eval()\n",
    "for _ in range(1):\n",
    "    eval_steps = 0\n",
    "    state = env.reset()    \n",
    "    #state = env.reset()\n",
    "    #print(state.getCoordinate())\n",
    "    all_states.append(state.getCoordinate())\n",
    "    #transition = init_transition()\n",
    "    #all_states.append(torch.tensor(list(transition)[:3]))\n",
    "    eval_episode_reward = 0\n",
    "    episode_final = 0\n",
    "    #print(env.referenceStreamline_ijk[:6])\n",
    "    \n",
    "    while eval_steps < max_episode_length:\n",
    "        action = action_scheduler.get_action(step_counter, torch.FloatTensor(state.getValue()).unsqueeze(0).to(device), evaluation=True)\n",
    "        #action = action_scheduler.get_action(step_counter, torch.FloatTensor([np.array(transition)]).to(device), evaluation=True)\n",
    "        #action = torch.argmax(agent(torch.FloatTensor([np.array(transition)]).to(device)))\n",
    "        next_state, reward, terminal = env.step(action)\n",
    "\n",
    "        current_index = np.min([env.stepCounter,len(env.referenceStreamline_ijk)-1])\n",
    "        path_vector = (next_state.getCoordinate() - state.getCoordinate()).squeeze(0)\n",
    "        reference_vector = env.referenceStreamline_ijk[current_index]-env.referenceStreamline_ijk[current_index-1]\n",
    "        #    #print(path_vector, reference_vector)\n",
    "        cosine_sim = cos(path_vector, reference_vector)\n",
    "        dist = torch.sum((env.referenceStreamline_ijk[current_index] - next_state.getCoordinate())**2) * 10\n",
    "        reward = cosine_sim - dist\n",
    "        reward = 1 - (optimal_reward - reward)\n",
    "        if dist > 3*0.81:\n",
    "            env.stepCounter -= 1\n",
    "        if action == 100 and reward == 1:\n",
    "            terminal = False\n",
    "            \n",
    "        #if cosine_sim < 0.7:\n",
    "        #    terminal = True\n",
    "        #next_state = next_state\n",
    "        #next_transition = add_to_transition(next_state, transition)\n",
    "        #reward = 1 + (1+(reward/10))\n",
    "        #if reward > 1:\n",
    "        #    reward = 1\n",
    "        #elif reward > 0.:\n",
    "        #    reward = 0\n",
    "        #else:\n",
    "        #    reward = -1\n",
    "        eval_episode_reward += reward\n",
    "        print(eval_steps, action, next_state.getCoordinate().numpy(), env.referenceStreamline_ijk[np.min([eval_steps,len(env.referenceStreamline_ijk)-1])].numpy(), reward)\n",
    "        #print(eval_steps, action, next_state, env.referenceStreamline_ijk[np.min([eval_steps,len(env.referenceStreamline_ijk)-1])].numpy(), reward)\n",
    "        eval_steps += 1\n",
    "        if eval_steps == 200:\n",
    "            terminal = True\n",
    "        all_distances.append(reward)\n",
    "        all_states.append(next_state.getCoordinate())\n",
    "        #all_states.append(next_state)\n",
    "        \n",
    "        state = next_state\n",
    "        #transition = next_transition\n",
    "        if terminal:\n",
    "            terminal = False\n",
    "            #if reward > 0.9:\n",
    "            #    episode_final += 1\n",
    "            break\n",
    "\n",
    "    eval_rewards.append(eval_episode_reward)\n",
    "\n",
    "print(\"Evaluation score:\", np.min(eval_rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "states, actions, rewards, new_states, terminal_flags = agent.replay_memory.get_minibatch()\n",
    "print(np.array_equal(states[0], new_states[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sphere_dist(nextState):\n",
    "    current_index = np.min([env.stepCounter,len(env.referenceStreamline_ijk)-1])\n",
    "    x_dist = (nextState.getCoordinate()[0] - env.referenceStreamline_ijk[current_index][0]) **2\n",
    "    y_dist = (nextState.getCoordinate()[1] - env.referenceStreamline_ijk[current_index][1]) **2\n",
    "    z_dist = (nextState.getCoordinate()[2] - env.referenceStreamline_ijk[current_index][2]) **2\n",
    "    return x_dist + y_dist + z_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99\n"
     ]
    }
   ],
   "source": [
    "print(agent.gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47 11.394252873563218 tensor(0.1970, dtype=torch.float64) tensor(0.1970, dtype=torch.float64)\n",
      "67 11.394252873563218 tensor(0.2640, dtype=torch.float64) tensor(0.2640, dtype=torch.float64)\n",
      "72 11.394252873563218 tensor(0.2650, dtype=torch.float64) tensor(0.2650, dtype=torch.float64)\n",
      "75 11.394252873563218 tensor(0.1352, dtype=torch.float64) tensor(0.1352, dtype=torch.float64)\n",
      "80 11.394252873563218 tensor(0.0623, dtype=torch.float64) tensor(0.0623, dtype=torch.float64)\n",
      "88 11.394252873563218 tensor(0.0726, dtype=torch.float64) tensor(0.0726, dtype=torch.float64)\n",
      "93 11.394252873563218 tensor(0.1499, dtype=torch.float64) tensor(0.1499, dtype=torch.float64)\n",
      "96 11.394252873563218 tensor(0.1986, dtype=torch.float64) tensor(0.1986, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_actions):\n",
    "    state = env.reset()\n",
    "    next_state, reward, done = env.step(i)\n",
    "    s_dist = sphere_dist(next_state)\n",
    "    old_dist = torch.sum((env.referenceStreamline_ijk[env.stepCounter] - next_state.getCoordinate())**2)\n",
    "    if s_dist <= 0.52**2:\n",
    "        print(i, reward, s_dist, old_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 77.07567091 108.90497243  91.49815967] -100\n"
     ]
    }
   ],
   "source": [
    "next_state, reward, done = env.step(75)\n",
    "print(next_state.getCoordinate(), reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.283401924575482, 102.46417647849394, 66.32755479299973]\n"
     ]
    }
   ],
   "source": [
    "print(list(transition)[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 24.1166, 103.8659,  64.9889])\n"
     ]
    }
   ],
   "source": [
    "state = env.reset()\n",
    "#referenceLine = env.referenceStreamline_ijk\n",
    "print(state.getCoordinate())\n",
    "#print(referenceLine[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 23.13776944 102.38550419  64.06677327] [ 30.125023 102.08756   66.46997 ] -100\n"
     ]
    }
   ],
   "source": [
    "next_state, reward, done = env.step(74)\n",
    "print(next_state.getCoordinate().numpy(), env.referenceStreamline_ijk[np.min([env.stepCounter, len(referenceLine)])].numpy(), reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n"
     ]
    }
   ],
   "source": [
    "optimal_steps =  [80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71, 71, 100, 71, 71, 71, 71, 100, 92, 84, 84, 38, 100, 97, 97, 97, 38, 100, 97, 30, 43, 43, 48, 100, 94, 81, 94, 35, 97, 100, 35, 22, 35, 35, 6, 100, 19, 3, 16, 3, 21, 100, 21, 16, 34, 21, 98, 34, 100, 39, 93, 39, 72, 72, 100, 69, 100]\n",
    "transition = init_transition()\n",
    "referenceLine = env.referenceStreamline_ijk\n",
    "print(len(referenceLine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 -0.09999999999999964\n"
     ]
    }
   ],
   "source": [
    "#action = action_scheduler.get_action(step_counter, torch.FloatTensor([np.array(transition)]).to(device), evaluation=True)\n",
    "next_state, reward, terminal = env.step(88)\n",
    "next_transition = add_to_transition(next_state, transition)\n",
    "print(action, reward)\n",
    "transition = next_transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State:  [ 73.651344 107.88106   93.29415 ]\n",
      "Next State:  [ 74.56195007 107.80595503  92.88775652]\n",
      "7.450580596923828e-09\n"
     ]
    }
   ],
   "source": [
    "# Debugging the reward function\n",
    "referenceLine = env.referenceStreamline_ijk\n",
    "stepCounter = 0\n",
    "maxSteps=200\n",
    "state = env.reset()\n",
    "print(\"State: \", state.getCoordinate().numpy())\n",
    "next_state, _, terminal = env.step(80)\n",
    "print(\"Next State: \", next_state.getCoordinate().numpy())\n",
    "\n",
    "def lineseg_dist(p, a, b):\n",
    "\n",
    "    # normalized tangent vector\n",
    "    d = np.divide(b - a, np.linalg.norm(b - a))\n",
    "\n",
    "    # signed parallel distance components\n",
    "    s = np.dot(a - p, d)\n",
    "    t = np.dot(p - b, d)\n",
    "\n",
    "    # clamped parallel distance\n",
    "    h = np.maximum.reduce([s, t, 0])\n",
    "\n",
    "    # perpendicular distance component\n",
    "    c = np.cross(p - a, d)\n",
    "\n",
    "    return np.hypot(h, np.linalg.norm(c))\n",
    "\n",
    "distance = lineseg_dist(referenceLine[86].numpy(), referenceLine[85].numpy(), referenceLine[86].numpy())\n",
    "print(distance)\n",
    "\n",
    "#print(\"Diff: \", next_state.getCoordinate().numpy()-state.getCoordinate().numpy())\n",
    "#qry_pt = next_state.getCoordinate().view(-1,3)\n",
    "#print(\"Reference next state: \", referenceLine[stepCounter+1])\n",
    "#print(\"Diff to reference state: \", referenceLine[stepCounter+1]-next_state.getCoordinate().numpy())\n",
    "#distance = torch.min(torch.sum((referenceLine[np.min([stepCounter+1, maxSteps-1])] - qry_pt)**2, dim=1))\n",
    "#print(distance)\n",
    "#reward = torch.tanh(-distance+5.3)\n",
    "\n",
    "#if distance == -1:\n",
    "#    reward = 0.5\n",
    "#elif distance < 0.8:\n",
    "#    reward = 1+ (1-distance)\n",
    "#else:\n",
    "#    reward = np.max([1 - distance, -1])\n",
    "#print(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19954145509142476\n",
      "0.03981679230000309\n",
      "0.07041062249999892\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "state = np.array([ 75.6, 107.95,  92.22])\n",
    "line = np.array([ 75.78847, 107.96255,  92.28433])\n",
    "\n",
    "print(np.linalg.norm(line - state, 2))\n",
    "\n",
    "sphere_dist = ((state[0] - line[0])**2 + (state[1]-line[1])**2 + (state[2]-line[2])**2)\n",
    "print(sphere_dist)\n",
    "normal_diff = np.sum(state-line)**2\n",
    "print(normal_diff)\n",
    "if sphere_dist < 0.2**2:\n",
    "    print(True)\n",
    "else:\n",
    "    print(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action:  100 Reward:  -0.6400096416473389\n",
      "Action:  80 Reward:  -0.3780286503520091\n",
      "Action:  75 Reward:  -0.17094774926353554\n",
      "Action:  80 Reward:  -0.06020208127816557\n",
      "Action:  75 Reward:  -0.023724592605490286\n",
      "Action:  100 Reward:  -0.023724592605490286\n",
      "Action:  62 Reward:  -0.031680450691759385\n",
      "Action:  75 Reward:  -0.10966306950569177\n",
      "Action:  83 Reward:  -0.2621558822401104\n",
      "Action:  75 Reward:  -0.4853828474102172\n",
      "Action:  83 Reward:  -0.7713330234194417\n",
      "Action:  100 Reward:  -0.7713330234194417\n",
      "Action:  83 Reward:  -1.158927472394806\n",
      "Action:  62 Reward:  -1.6468544226974164\n",
      "Action:  67 Reward:  -2.2078664481054533\n",
      "Action:  51 Reward:  -2.459970885856384\n",
      "Action:  67 Reward:  -3.0430611441644246\n",
      "Action:  100 Reward:  -3.0430611441644246\n",
      "Action:  59 Reward:  -3.7319386628026487\n",
      "Action:  59 Reward:  -4.531517914723884\n",
      "Action:  59 Reward:  -5.427621034792285\n",
      "Action:  100 Reward:  -5.427621034792285\n",
      "Action:  59 Reward:  -6.420164664306009\n",
      "Action:  56 Reward:  -7.21012573500936\n",
      "Action:  51 Reward:  -8.185668593823168\n",
      "Action:  56 Reward:  -9.264514952082235\n",
      "Action:  66 Reward:  -9.504376152250732\n",
      "Action:  100 Reward:  -9.504376152250732\n",
      "Action:  66 Reward:  -10.878316642589324\n",
      "Action:  71 Reward:  -11.684246290994608\n",
      "Action:  71 Reward:  -13.482882171224585\n",
      "Action:  79 Reward:  -15.013766894750662\n",
      "Action:  58 Reward:  -16.29778288166172\n",
      "Action:  100 Reward:  -16.29778288166172\n",
      "Action:  71 Reward:  -17.927867464472456\n",
      "Action:  71 Reward:  -19.616943063578457\n",
      "Action:  84 Reward:  -20.74882253322799\n",
      "Action:  71 Reward:  -22.68542229369059\n",
      "Action:  100 Reward:  -22.68542229369059\n",
      "Action:  92 Reward:  -24.094491148196\n",
      "Action:  84 Reward:  -26.036910111309087\n",
      "Action:  92 Reward:  -27.894909786068872\n",
      "Action:  97 Reward:  -29.22946434143986\n",
      "Action:  100 Reward:  -29.22946434143986\n",
      "Action:  97 Reward:  -30.93770942329201\n",
      "Action:  38 Reward:  -33.06379059780991\n",
      "Action:  97 Reward:  -35.48076469151409\n",
      "Action:  43 Reward:  -37.24656758094286\n",
      "Action:  38 Reward:  -39.87506653295411\n",
      "Action:  100 Reward:  -39.87506653295411\n",
      "Action:  43 Reward:  -42.07728895704025\n",
      "Action:  43 Reward:  -44.59950388329224\n",
      "Action:  89 Reward:  -46.525702788416744\n",
      "Action:  48 Reward:  -46.51577793318299\n",
      "Action:  100 Reward:  -46.51577793318299\n",
      "Action:  94 Reward:  -44.74553361569235\n",
      "Action:  81 Reward:  -46.71395822922152\n",
      "Action:  48 Reward:  -50.26025222152221\n",
      "Action:  43 Reward:  -53.83576866536265\n",
      "Action:  100 Reward:  -53.83576866536265\n",
      "Action:  35 Reward:  -57.7679173101252\n",
      "Action:  43 Reward:  -61.07110670119785\n",
      "Action:  35 Reward:  -64.29611023518841\n",
      "Action:  22 Reward:  -64.69258594426614\n",
      "Action:  27 Reward:  -67.94753644296517\n",
      "Action:  100 Reward:  -67.94753644296517\n",
      "Action:  6 Reward:  -68.60859514506335\n",
      "Action:  11 Reward:  -70.03265506052335\n",
      "Action:  3 Reward:  -69.6074991211795\n",
      "Action:  16 Reward:  -66.45768588248448\n",
      "Action:  100 Reward:  -66.45768588248448\n",
      "Action:  8 Reward:  -63.980960033928525\n",
      "Action:  29 Reward:  -63.97912872209463\n",
      "Action:  21 Reward:  -65.2877329760679\n",
      "Action:  21 Reward:  -71.00622766156863\n",
      "Action:  100 Reward:  -71.00622766156863\n",
      "Action:  34 Reward:  -75.30646175774287\n",
      "Action:  26 Reward:  -79.7251625711022\n",
      "Action:  26 Reward:  -85.7736700190284\n",
      "Action:  93 Reward:  -86.29779314738443\n",
      "Action:  39 Reward:  -89.76066176762737\n",
      "Action:  100 Reward:  -89.76066176762737\n",
      "Action:  93 Reward:  -92.76729682665923\n",
      "Action:  72 Reward:  -91.66762326274807\n",
      "Action:  77 Reward:  -91.52645978577566\n",
      "Action:  77 Reward:  -94.77110103827272\n",
      "Action:  100 Reward:  -94.77110103827272\n",
      "-3134.679829616308\n"
     ]
    }
   ],
   "source": [
    "#optimal_steps = [80, 75, 80, 75, 62, 75, 83, 96, 51, 24, 62, 62, 62, 77, 65, 64, 67, 59, 56, 83, 82, 54, 56, 53, 56, 38, 56, 84, 66, 71, 71, 64, 97, 84, 71, 71, 38, 51, 30, 92, 97, 84, 43, 79, 27, 46, 89, 25, 81, 25, 48, 43, 86, 48, 57, 14, 89, 43, 43, 19, 92, 14, 27, 9, 78, 4, 16, 3, 29, 3, 47, 6, 42, 21, 39, 5, 72, 34, 98, 88, 90, 75, 77, 59, 49, 32, 82, 100]\n",
    "eps_reward = 0\n",
    "state = env.reset()\n",
    "for i in optimal_steps:\n",
    "    next_state, reward, terminal = env.step(i)\n",
    "    state = next_state\n",
    "    eps_reward += reward.item()\n",
    "    print(\"Action: \", i, \"Reward: \", reward.item())\n",
    "print(eps_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init environment..\n",
      "Loading precomputed streamlines (data/HCP307200_DTI_smallSet.vtk) for ID 100307\n",
      "..done!\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Init environment..\")\n",
    "env = RLTe.RLtractEnvironment(device = 'cpu')\n",
    "print(\"..done!\")\n",
    "n_actions = env.action_space.n\n",
    "#print(n_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([87, 3])\n"
     ]
    }
   ],
   "source": [
    "referenceLine = env.referenceStreamline_ijk\n",
    "print(referenceLine.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([47.8702, 74.8030, 26.6401])\n",
      "tensor([47.8702, 74.8030, 26.6401])\n"
     ]
    }
   ],
   "source": [
    "print(referenceLine[0])\n",
    "state = TractographyState(referenceLine[0], env.interpolateDWIatState)\n",
    "print(state.getCoordinate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  0 Action:  41 Distance:  tensor(1.3545, dtype=torch.float64)\n",
      "Step:  0 Action:  66 Distance:  tensor(1.2187, dtype=torch.float64)\n",
      "Step:  0 Action:  74 Distance:  tensor(1.5895, dtype=torch.float64)\n",
      "Step:  0 Action:  79 Distance:  tensor(1.4856, dtype=torch.float64)\n",
      "Step:  0 Action:  82 Distance:  tensor(1.2496, dtype=torch.float64)\n",
      "Step:  0 Action:  87 Distance:  tensor(1.5944, dtype=torch.float64)\n",
      "Step:  0 Action:  95 Distance:  tensor(1.5184, dtype=torch.float64)\n",
      "0 []\n",
      "Step:  1 Action:  61 Distance:  tensor(1.3162, dtype=torch.float64)\n",
      "Step:  1 Action:  66 Distance:  tensor(1.2710, dtype=torch.float64)\n",
      "Step:  1 Action:  74 Distance:  tensor(1.6272, dtype=torch.float64)\n",
      "Step:  1 Action:  79 Distance:  tensor(1.3920, dtype=torch.float64)\n",
      "Step:  1 Action:  82 Distance:  tensor(1.4070, dtype=torch.float64)\n",
      "Step:  1 Action:  87 Distance:  tensor(1.4471, dtype=torch.float64)\n",
      "Step:  1 Action:  95 Distance:  tensor(1.5094, dtype=torch.float64)\n",
      "1 []\n",
      "Step:  2 Action:  41 Distance:  tensor(1.2821, dtype=torch.float64)\n",
      "Step:  2 Action:  61 Distance:  tensor(1.2315, dtype=torch.float64)\n",
      "Step:  2 Action:  74 Distance:  tensor(1.6046, dtype=torch.float64)\n",
      "Step:  2 Action:  79 Distance:  tensor(1.3549, dtype=torch.float64)\n",
      "Step:  2 Action:  82 Distance:  tensor(1.4040, dtype=torch.float64)\n",
      "Step:  2 Action:  87 Distance:  tensor(1.4843, dtype=torch.float64)\n",
      "Step:  2 Action:  95 Distance:  tensor(1.5651, dtype=torch.float64)\n",
      "2 []\n",
      "Step:  3 Action:  41 Distance:  tensor(1.2908, dtype=torch.float64)\n",
      "Step:  3 Action:  49 Distance:  tensor(1.2627, dtype=torch.float64)\n",
      "Step:  3 Action:  61 Distance:  tensor(1.2172, dtype=torch.float64)\n",
      "Step:  3 Action:  74 Distance:  tensor(1.5797, dtype=torch.float64)\n",
      "Step:  3 Action:  79 Distance:  tensor(1.2516, dtype=torch.float64)\n",
      "Step:  3 Action:  82 Distance:  tensor(1.4621, dtype=torch.float64)\n",
      "Step:  3 Action:  87 Distance:  tensor(1.4322, dtype=torch.float64)\n",
      "Step:  3 Action:  95 Distance:  tensor(1.6009, dtype=torch.float64)\n",
      "3 []\n",
      "Step:  4 Action:  49 Distance:  tensor(1.3226, dtype=torch.float64)\n",
      "Step:  4 Action:  61 Distance:  tensor(1.3563, dtype=torch.float64)\n",
      "Step:  4 Action:  74 Distance:  tensor(1.5702, dtype=torch.float64)\n",
      "Step:  4 Action:  82 Distance:  tensor(1.5784, dtype=torch.float64)\n",
      "Step:  4 Action:  87 Distance:  tensor(1.2502, dtype=torch.float64)\n",
      "Step:  4 Action:  95 Distance:  tensor(1.5545, dtype=torch.float64)\n",
      "4 []\n",
      "Step:  5 Action:  49 Distance:  tensor(1.2380, dtype=torch.float64)\n",
      "Step:  5 Action:  61 Distance:  tensor(1.4426, dtype=torch.float64)\n",
      "Step:  5 Action:  69 Distance:  tensor(1.2523, dtype=torch.float64)\n",
      "Step:  5 Action:  74 Distance:  tensor(1.5910, dtype=torch.float64)\n",
      "Step:  5 Action:  82 Distance:  tensor(1.5806, dtype=torch.float64)\n",
      "Step:  5 Action:  87 Distance:  tensor(1.2100, dtype=torch.float64)\n",
      "Step:  5 Action:  95 Distance:  tensor(1.4956, dtype=torch.float64)\n",
      "5 []\n",
      "Step:  6 Action:  61 Distance:  tensor(1.5273, dtype=torch.float64)\n",
      "Step:  6 Action:  66 Distance:  tensor(1.3657, dtype=torch.float64)\n",
      "Step:  6 Action:  69 Distance:  tensor(1.2500, dtype=torch.float64)\n",
      "Step:  6 Action:  74 Distance:  tensor(1.6194, dtype=torch.float64)\n",
      "Step:  6 Action:  79 Distance:  tensor(1.2759, dtype=torch.float64)\n",
      "Step:  6 Action:  82 Distance:  tensor(1.5115, dtype=torch.float64)\n",
      "Step:  6 Action:  87 Distance:  tensor(1.2051, dtype=torch.float64)\n",
      "Step:  6 Action:  95 Distance:  tensor(1.3869, dtype=torch.float64)\n",
      "6 []\n",
      "Step:  7 Action:  61 Distance:  tensor(1.5700, dtype=torch.float64)\n",
      "Step:  7 Action:  66 Distance:  tensor(1.4237, dtype=torch.float64)\n",
      "Step:  7 Action:  69 Distance:  tensor(1.2798, dtype=torch.float64)\n",
      "Step:  7 Action:  74 Distance:  tensor(1.5954, dtype=torch.float64)\n",
      "Step:  7 Action:  79 Distance:  tensor(1.2693, dtype=torch.float64)\n",
      "Step:  7 Action:  82 Distance:  tensor(1.4712, dtype=torch.float64)\n",
      "Step:  7 Action:  95 Distance:  tensor(1.2862, dtype=torch.float64)\n",
      "7 []\n",
      "Step:  8 Action:  53 Distance:  tensor(1.2474, dtype=torch.float64)\n",
      "Step:  8 Action:  61 Distance:  tensor(1.6099, dtype=torch.float64)\n",
      "Step:  8 Action:  66 Distance:  tensor(1.4011, dtype=torch.float64)\n",
      "Step:  8 Action:  69 Distance:  tensor(1.3809, dtype=torch.float64)\n",
      "Step:  8 Action:  74 Distance:  tensor(1.5549, dtype=torch.float64)\n",
      "Step:  8 Action:  82 Distance:  tensor(1.4958, dtype=torch.float64)\n",
      "Step:  8 Action:  95 Distance:  tensor(1.2269, dtype=torch.float64)\n",
      "8 []\n",
      "Step:  9 Action:  53 Distance:  tensor(1.2052, dtype=torch.float64)\n",
      "Step:  9 Action:  56 Distance:  tensor(1.2501, dtype=torch.float64)\n",
      "Step:  9 Action:  61 Distance:  tensor(1.6062, dtype=torch.float64)\n",
      "Step:  9 Action:  66 Distance:  tensor(1.2593, dtype=torch.float64)\n",
      "Step:  9 Action:  69 Distance:  tensor(1.5104, dtype=torch.float64)\n",
      "Step:  9 Action:  74 Distance:  tensor(1.4608, dtype=torch.float64)\n",
      "Step:  9 Action:  82 Distance:  tensor(1.5458, dtype=torch.float64)\n",
      "9 []\n",
      "Step:  10 Action:  56 Distance:  tensor(1.2257, dtype=torch.float64)\n",
      "Step:  10 Action:  61 Distance:  tensor(1.5655, dtype=torch.float64)\n",
      "Step:  10 Action:  69 Distance:  tensor(1.5418, dtype=torch.float64)\n",
      "Step:  10 Action:  74 Distance:  tensor(1.4100, dtype=torch.float64)\n",
      "Step:  10 Action:  82 Distance:  tensor(1.5741, dtype=torch.float64)\n",
      "Step:  10 Action:  90 Distance:  tensor(1.2631, dtype=torch.float64)\n",
      "10 []\n",
      "Step:  11 Action:  56 Distance:  tensor(1.2257, dtype=torch.float64)\n",
      "Step:  11 Action:  61 Distance:  tensor(1.5655, dtype=torch.float64)\n",
      "Step:  11 Action:  69 Distance:  tensor(1.5418, dtype=torch.float64)\n",
      "Step:  11 Action:  74 Distance:  tensor(1.4100, dtype=torch.float64)\n",
      "Step:  11 Action:  82 Distance:  tensor(1.5741, dtype=torch.float64)\n",
      "Step:  11 Action:  90 Distance:  tensor(1.2631, dtype=torch.float64)\n",
      "11 []\n",
      "Step:  12 Action:  56 Distance:  tensor(1.3080, dtype=torch.float64)\n",
      "Step:  12 Action:  61 Distance:  tensor(1.5581, dtype=torch.float64)\n",
      "Step:  12 Action:  69 Distance:  tensor(1.5947, dtype=torch.float64)\n",
      "Step:  12 Action:  74 Distance:  tensor(1.3253, dtype=torch.float64)\n",
      "Step:  12 Action:  77 Distance:  tensor(1.2564, dtype=torch.float64)\n",
      "Step:  12 Action:  82 Distance:  tensor(1.5506, dtype=torch.float64)\n",
      "Step:  12 Action:  90 Distance:  tensor(1.2967, dtype=torch.float64)\n",
      "12 []\n",
      "Step:  13 Action:  56 Distance:  tensor(1.3643, dtype=torch.float64)\n",
      "Step:  13 Action:  61 Distance:  tensor(1.5247, dtype=torch.float64)\n",
      "Step:  13 Action:  64 Distance:  tensor(1.2298, dtype=torch.float64)\n",
      "Step:  13 Action:  69 Distance:  tensor(1.6218, dtype=torch.float64)\n",
      "Step:  13 Action:  74 Distance:  tensor(1.2146, dtype=torch.float64)\n",
      "Step:  13 Action:  77 Distance:  tensor(1.3332, dtype=torch.float64)\n",
      "Step:  13 Action:  82 Distance:  tensor(1.5012, dtype=torch.float64)\n",
      "Step:  13 Action:  90 Distance:  tensor(1.3043, dtype=torch.float64)\n",
      "13 []\n",
      "Step:  14 Action:  56 Distance:  tensor(1.3236, dtype=torch.float64)\n",
      "Step:  14 Action:  61 Distance:  tensor(1.4642, dtype=torch.float64)\n",
      "Step:  14 Action:  64 Distance:  tensor(1.2667, dtype=torch.float64)\n",
      "Step:  14 Action:  69 Distance:  tensor(1.6333, dtype=torch.float64)\n",
      "Step:  14 Action:  77 Distance:  tensor(1.4185, dtype=torch.float64)\n",
      "Step:  14 Action:  82 Distance:  tensor(1.5103, dtype=torch.float64)\n",
      "Step:  14 Action:  90 Distance:  tensor(1.3923, dtype=torch.float64)\n",
      "14 []\n",
      "Step:  15 Action:  56 Distance:  tensor(1.2585, dtype=torch.float64)\n",
      "Step:  15 Action:  61 Distance:  tensor(1.3793, dtype=torch.float64)\n",
      "Step:  15 Action:  64 Distance:  tensor(1.2792, dtype=torch.float64)\n",
      "Step:  15 Action:  69 Distance:  tensor(1.6204, dtype=torch.float64)\n",
      "Step:  15 Action:  77 Distance:  tensor(1.4794, dtype=torch.float64)\n",
      "Step:  15 Action:  82 Distance:  tensor(1.4951, dtype=torch.float64)\n",
      "Step:  15 Action:  90 Distance:  tensor(1.4558, dtype=torch.float64)\n",
      "15 []\n",
      "Step:  16 Action:  61 Distance:  tensor(1.2885, dtype=torch.float64)\n",
      "Step:  16 Action:  64 Distance:  tensor(1.2906, dtype=torch.float64)\n",
      "Step:  16 Action:  69 Distance:  tensor(1.6013, dtype=torch.float64)\n",
      "Step:  16 Action:  77 Distance:  tensor(1.5375, dtype=torch.float64)\n",
      "Step:  16 Action:  82 Distance:  tensor(1.4737, dtype=torch.float64)\n",
      "Step:  16 Action:  90 Distance:  tensor(1.5160, dtype=torch.float64)\n",
      "16 []\n",
      "Step:  17 Action:  64 Distance:  tensor(1.2763, dtype=torch.float64)\n",
      "Step:  17 Action:  69 Distance:  tensor(1.5565, dtype=torch.float64)\n",
      "Step:  17 Action:  77 Distance:  tensor(1.5700, dtype=torch.float64)\n",
      "Step:  17 Action:  82 Distance:  tensor(1.4267, dtype=torch.float64)\n",
      "Step:  17 Action:  90 Distance:  tensor(1.5504, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  17 Action:  98 Distance:  tensor(1.2671, dtype=torch.float64)\n",
      "17 []\n",
      "Step:  18 Action:  64 Distance:  tensor(1.2763, dtype=torch.float64)\n",
      "Step:  18 Action:  69 Distance:  tensor(1.5565, dtype=torch.float64)\n",
      "Step:  18 Action:  77 Distance:  tensor(1.5700, dtype=torch.float64)\n",
      "Step:  18 Action:  82 Distance:  tensor(1.4267, dtype=torch.float64)\n",
      "Step:  18 Action:  90 Distance:  tensor(1.5504, dtype=torch.float64)\n",
      "Step:  18 Action:  98 Distance:  tensor(1.2671, dtype=torch.float64)\n",
      "18 []\n",
      "Step:  19 Action:  64 Distance:  tensor(1.2807, dtype=torch.float64)\n",
      "Step:  19 Action:  69 Distance:  tensor(1.5051, dtype=torch.float64)\n",
      "Step:  19 Action:  77 Distance:  tensor(1.6072, dtype=torch.float64)\n",
      "Step:  19 Action:  82 Distance:  tensor(1.3555, dtype=torch.float64)\n",
      "Step:  19 Action:  85 Distance:  tensor(1.2477, dtype=torch.float64)\n",
      "Step:  19 Action:  90 Distance:  tensor(1.5722, dtype=torch.float64)\n",
      "Step:  19 Action:  98 Distance:  tensor(1.3832, dtype=torch.float64)\n",
      "19 []\n",
      "Step:  20 Action:  44 Distance:  tensor(1.3385, dtype=torch.float64)\n",
      "Step:  20 Action:  49 Distance:  tensor(1.2286, dtype=torch.float64)\n",
      "Step:  20 Action:  69 Distance:  tensor(1.3823, dtype=torch.float64)\n",
      "Step:  20 Action:  77 Distance:  tensor(1.5818, dtype=torch.float64)\n",
      "Step:  20 Action:  82 Distance:  tensor(1.2872, dtype=torch.float64)\n",
      "Step:  20 Action:  85 Distance:  tensor(1.2530, dtype=torch.float64)\n",
      "Step:  20 Action:  90 Distance:  tensor(1.6020, dtype=torch.float64)\n",
      "Step:  20 Action:  98 Distance:  tensor(1.4867, dtype=torch.float64)\n",
      "20 []\n",
      "Step:  21 Action:  44 Distance:  tensor(1.4217, dtype=torch.float64)\n",
      "Step:  21 Action:  49 Distance:  tensor(1.2387, dtype=torch.float64)\n",
      "Step:  21 Action:  69 Distance:  tensor(1.2773, dtype=torch.float64)\n",
      "Step:  21 Action:  77 Distance:  tensor(1.5501, dtype=torch.float64)\n",
      "Step:  21 Action:  82 Distance:  tensor(1.2059, dtype=torch.float64)\n",
      "Step:  21 Action:  85 Distance:  tensor(1.2581, dtype=torch.float64)\n",
      "Step:  21 Action:  90 Distance:  tensor(1.5947, dtype=torch.float64)\n",
      "Step:  21 Action:  98 Distance:  tensor(1.5446, dtype=torch.float64)\n",
      "21 []\n",
      "Step:  22 Action:  44 Distance:  tensor(1.4126, dtype=torch.float64)\n",
      "Step:  22 Action:  69 Distance:  tensor(1.2116, dtype=torch.float64)\n",
      "Step:  22 Action:  77 Distance:  tensor(1.5488, dtype=torch.float64)\n",
      "Step:  22 Action:  85 Distance:  tensor(1.3282, dtype=torch.float64)\n",
      "Step:  22 Action:  90 Distance:  tensor(1.5470, dtype=torch.float64)\n",
      "Step:  22 Action:  98 Distance:  tensor(1.5829, dtype=torch.float64)\n",
      "22 []\n",
      "Step:  23 Action:  31 Distance:  tensor(1.2443, dtype=torch.float64)\n",
      "Step:  23 Action:  39 Distance:  tensor(1.2866, dtype=torch.float64)\n",
      "Step:  23 Action:  44 Distance:  tensor(1.3997, dtype=torch.float64)\n",
      "Step:  23 Action:  77 Distance:  tensor(1.5426, dtype=torch.float64)\n",
      "Step:  23 Action:  85 Distance:  tensor(1.3959, dtype=torch.float64)\n",
      "Step:  23 Action:  90 Distance:  tensor(1.4943, dtype=torch.float64)\n",
      "Step:  23 Action:  98 Distance:  tensor(1.6163, dtype=torch.float64)\n",
      "23 []\n",
      "Step:  24 Action:  31 Distance:  tensor(1.2934, dtype=torch.float64)\n",
      "Step:  24 Action:  39 Distance:  tensor(1.3726, dtype=torch.float64)\n",
      "Step:  24 Action:  44 Distance:  tensor(1.3641, dtype=torch.float64)\n",
      "Step:  24 Action:  77 Distance:  tensor(1.5137, dtype=torch.float64)\n",
      "Step:  24 Action:  85 Distance:  tensor(1.4408, dtype=torch.float64)\n",
      "Step:  24 Action:  90 Distance:  tensor(1.4189, dtype=torch.float64)\n",
      "Step:  24 Action:  98 Distance:  tensor(1.6270, dtype=torch.float64)\n",
      "24 []\n",
      "Step:  25 Action:  31 Distance:  tensor(1.3955, dtype=torch.float64)\n",
      "Step:  25 Action:  39 Distance:  tensor(1.4232, dtype=torch.float64)\n",
      "Step:  25 Action:  44 Distance:  tensor(1.4189, dtype=torch.float64)\n",
      "Step:  25 Action:  77 Distance:  tensor(1.4476, dtype=torch.float64)\n",
      "Step:  25 Action:  85 Distance:  tensor(1.4018, dtype=torch.float64)\n",
      "Step:  25 Action:  90 Distance:  tensor(1.3865, dtype=torch.float64)\n",
      "Step:  25 Action:  98 Distance:  tensor(1.6444, dtype=torch.float64)\n",
      "25 []\n",
      "Step:  26 Action:  23 Distance:  tensor(1.2010, dtype=torch.float64)\n",
      "Step:  26 Action:  31 Distance:  tensor(1.5438, dtype=torch.float64)\n",
      "Step:  26 Action:  39 Distance:  tensor(1.4724, dtype=torch.float64)\n",
      "Step:  26 Action:  44 Distance:  tensor(1.4670, dtype=torch.float64)\n",
      "Step:  26 Action:  77 Distance:  tensor(1.2564, dtype=torch.float64)\n",
      "Step:  26 Action:  85 Distance:  tensor(1.2705, dtype=torch.float64)\n",
      "Step:  26 Action:  90 Distance:  tensor(1.2592, dtype=torch.float64)\n",
      "Step:  26 Action:  98 Distance:  tensor(1.6194, dtype=torch.float64)\n",
      "26 []\n",
      "Step:  27 Action:  23 Distance:  tensor(1.2617, dtype=torch.float64)\n",
      "Step:  27 Action:  26 Distance:  tensor(1.3512, dtype=torch.float64)\n",
      "Step:  27 Action:  31 Distance:  tensor(1.6077, dtype=torch.float64)\n",
      "Step:  27 Action:  39 Distance:  tensor(1.5253, dtype=torch.float64)\n",
      "Step:  27 Action:  44 Distance:  tensor(1.3890, dtype=torch.float64)\n",
      "Step:  27 Action:  98 Distance:  tensor(1.5487, dtype=torch.float64)\n",
      "27 []\n",
      "Step:  28 Action:  18 Distance:  tensor(1.2351, dtype=torch.float64)\n",
      "Step:  28 Action:  23 Distance:  tensor(1.2164, dtype=torch.float64)\n",
      "Step:  28 Action:  26 Distance:  tensor(1.4285, dtype=torch.float64)\n",
      "Step:  28 Action:  31 Distance:  tensor(1.6014, dtype=torch.float64)\n",
      "Step:  28 Action:  39 Distance:  tensor(1.5558, dtype=torch.float64)\n",
      "Step:  28 Action:  44 Distance:  tensor(1.2939, dtype=torch.float64)\n",
      "Step:  28 Action:  98 Distance:  tensor(1.4966, dtype=torch.float64)\n",
      "28 []\n",
      "Step:  29 Action:  18 Distance:  tensor(1.3395, dtype=torch.float64)\n",
      "Step:  29 Action:  23 Distance:  tensor(1.2725, dtype=torch.float64)\n",
      "Step:  29 Action:  26 Distance:  tensor(1.4920, dtype=torch.float64)\n",
      "Step:  29 Action:  31 Distance:  tensor(1.6207, dtype=torch.float64)\n",
      "Step:  29 Action:  39 Distance:  tensor(1.5335, dtype=torch.float64)\n",
      "Step:  29 Action:  44 Distance:  tensor(1.2629, dtype=torch.float64)\n",
      "Step:  29 Action:  98 Distance:  tensor(1.4319, dtype=torch.float64)\n",
      "29 []\n",
      "Step:  30 Action:  18 Distance:  tensor(1.4184, dtype=torch.float64)\n",
      "Step:  30 Action:  23 Distance:  tensor(1.3032, dtype=torch.float64)\n",
      "Step:  30 Action:  26 Distance:  tensor(1.5302, dtype=torch.float64)\n",
      "Step:  30 Action:  31 Distance:  tensor(1.6147, dtype=torch.float64)\n",
      "Step:  30 Action:  39 Distance:  tensor(1.4859, dtype=torch.float64)\n",
      "Step:  30 Action:  44 Distance:  tensor(1.2065, dtype=torch.float64)\n",
      "Step:  30 Action:  98 Distance:  tensor(1.3418, dtype=torch.float64)\n",
      "30 []\n",
      "Step:  31 Action:  13 Distance:  tensor(1.2379, dtype=torch.float64)\n",
      "Step:  31 Action:  18 Distance:  tensor(1.4916, dtype=torch.float64)\n",
      "Step:  31 Action:  23 Distance:  tensor(1.3284, dtype=torch.float64)\n",
      "Step:  31 Action:  26 Distance:  tensor(1.5638, dtype=torch.float64)\n",
      "Step:  31 Action:  31 Distance:  tensor(1.6021, dtype=torch.float64)\n",
      "Step:  31 Action:  39 Distance:  tensor(1.4352, dtype=torch.float64)\n",
      "Step:  31 Action:  98 Distance:  tensor(1.2489, dtype=torch.float64)\n",
      "31 []\n",
      "Step:  32 Action:  0 Distance:  tensor(1.2495, dtype=torch.float64)\n",
      "Step:  32 Action:  13 Distance:  tensor(1.4117, dtype=torch.float64)\n",
      "Step:  32 Action:  18 Distance:  tensor(1.5820, dtype=torch.float64)\n",
      "Step:  32 Action:  23 Distance:  tensor(1.3226, dtype=torch.float64)\n",
      "Step:  32 Action:  26 Distance:  tensor(1.5775, dtype=torch.float64)\n",
      "Step:  32 Action:  31 Distance:  tensor(1.5211, dtype=torch.float64)\n",
      "Step:  32 Action:  39 Distance:  tensor(1.2828, dtype=torch.float64)\n",
      "32 []\n",
      "Step:  33 Action:  0 Distance:  tensor(1.4203, dtype=torch.float64)\n",
      "Step:  33 Action:  5 Distance:  tensor(1.3761, dtype=torch.float64)\n",
      "Step:  33 Action:  10 Distance:  tensor(1.2212, dtype=torch.float64)\n",
      "Step:  33 Action:  13 Distance:  tensor(1.5318, dtype=torch.float64)\n",
      "Step:  33 Action:  18 Distance:  tensor(1.6109, dtype=torch.float64)\n",
      "Step:  33 Action:  23 Distance:  tensor(1.2563, dtype=torch.float64)\n",
      "Step:  33 Action:  26 Distance:  tensor(1.5325, dtype=torch.float64)\n",
      "Step:  33 Action:  31 Distance:  tensor(1.3783, dtype=torch.float64)\n",
      "33 []\n",
      "Step:  34 Action:  0 Distance:  tensor(1.5741, dtype=torch.float64)\n",
      "Step:  34 Action:  5 Distance:  tensor(1.4806, dtype=torch.float64)\n",
      "Step:  34 Action:  8 Distance:  tensor(1.2429, dtype=torch.float64)\n",
      "Step:  34 Action:  10 Distance:  tensor(1.2187, dtype=torch.float64)\n",
      "Step:  34 Action:  13 Distance:  tensor(1.6071, dtype=torch.float64)\n",
      "Step:  34 Action:  18 Distance:  tensor(1.5614, dtype=torch.float64)\n",
      "Step:  34 Action:  21 Distance:  tensor(1.2155, dtype=torch.float64)\n",
      "Step:  34 Action:  26 Distance:  tensor(1.4623, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  34 Action:  34 Distance:  tensor(1.2363, dtype=torch.float64)\n",
      "34 []\n",
      "Step:  35 Action:  0 Distance:  tensor(1.6504, dtype=torch.float64)\n",
      "Step:  35 Action:  5 Distance:  tensor(1.4896, dtype=torch.float64)\n",
      "Step:  35 Action:  8 Distance:  tensor(1.3297, dtype=torch.float64)\n",
      "Step:  35 Action:  13 Distance:  tensor(1.6255, dtype=torch.float64)\n",
      "Step:  35 Action:  18 Distance:  tensor(1.5023, dtype=torch.float64)\n",
      "Step:  35 Action:  21 Distance:  tensor(1.3069, dtype=torch.float64)\n",
      "Step:  35 Action:  26 Distance:  tensor(1.4191, dtype=torch.float64)\n",
      "Step:  35 Action:  34 Distance:  tensor(1.2754, dtype=torch.float64)\n",
      "35 []\n",
      "Step:  36 Action:  0 Distance:  tensor(1.6504, dtype=torch.float64)\n",
      "Step:  36 Action:  5 Distance:  tensor(1.4574, dtype=torch.float64)\n",
      "Step:  36 Action:  8 Distance:  tensor(1.3736, dtype=torch.float64)\n",
      "Step:  36 Action:  13 Distance:  tensor(1.6424, dtype=torch.float64)\n",
      "Step:  36 Action:  18 Distance:  tensor(1.4433, dtype=torch.float64)\n",
      "Step:  36 Action:  21 Distance:  tensor(1.3961, dtype=torch.float64)\n",
      "Step:  36 Action:  26 Distance:  tensor(1.4171, dtype=torch.float64)\n",
      "Step:  36 Action:  34 Distance:  tensor(1.3541, dtype=torch.float64)\n",
      "36 []\n",
      "Step:  37 Action:  0 Distance:  tensor(1.6297, dtype=torch.float64)\n",
      "Step:  37 Action:  5 Distance:  tensor(1.3586, dtype=torch.float64)\n",
      "Step:  37 Action:  8 Distance:  tensor(1.3157, dtype=torch.float64)\n",
      "Step:  37 Action:  13 Distance:  tensor(1.6391, dtype=torch.float64)\n",
      "Step:  37 Action:  18 Distance:  tensor(1.3957, dtype=torch.float64)\n",
      "Step:  37 Action:  21 Distance:  tensor(1.4311, dtype=torch.float64)\n",
      "Step:  37 Action:  26 Distance:  tensor(1.4701, dtype=torch.float64)\n",
      "Step:  37 Action:  34 Distance:  tensor(1.4513, dtype=torch.float64)\n",
      "37 []\n",
      "Step:  38 Action:  0 Distance:  tensor(1.5064, dtype=torch.float64)\n",
      "Step:  38 Action:  5 Distance:  tensor(1.2675, dtype=torch.float64)\n",
      "Step:  38 Action:  8 Distance:  tensor(1.2816, dtype=torch.float64)\n",
      "Step:  38 Action:  13 Distance:  tensor(1.6227, dtype=torch.float64)\n",
      "Step:  38 Action:  18 Distance:  tensor(1.3224, dtype=torch.float64)\n",
      "Step:  38 Action:  21 Distance:  tensor(1.4697, dtype=torch.float64)\n",
      "Step:  38 Action:  26 Distance:  tensor(1.4794, dtype=torch.float64)\n",
      "Step:  38 Action:  34 Distance:  tensor(1.5213, dtype=torch.float64)\n",
      "Step:  38 Action:  47 Distance:  tensor(1.2133, dtype=torch.float64)\n",
      "38 []\n",
      "Step:  39 Action:  0 Distance:  tensor(1.5209, dtype=torch.float64)\n",
      "Step:  39 Action:  5 Distance:  tensor(1.2129, dtype=torch.float64)\n",
      "Step:  39 Action:  8 Distance:  tensor(1.3191, dtype=torch.float64)\n",
      "Step:  39 Action:  13 Distance:  tensor(1.5965, dtype=torch.float64)\n",
      "Step:  39 Action:  18 Distance:  tensor(1.2075, dtype=torch.float64)\n",
      "Step:  39 Action:  21 Distance:  tensor(1.5323, dtype=torch.float64)\n",
      "Step:  39 Action:  26 Distance:  tensor(1.4036, dtype=torch.float64)\n",
      "Step:  39 Action:  34 Distance:  tensor(1.5428, dtype=torch.float64)\n",
      "39 []\n",
      "Step:  40 Action:  0 Distance:  tensor(1.5209, dtype=torch.float64)\n",
      "Step:  40 Action:  5 Distance:  tensor(1.2129, dtype=torch.float64)\n",
      "Step:  40 Action:  8 Distance:  tensor(1.3191, dtype=torch.float64)\n",
      "Step:  40 Action:  13 Distance:  tensor(1.5965, dtype=torch.float64)\n",
      "Step:  40 Action:  18 Distance:  tensor(1.2075, dtype=torch.float64)\n",
      "Step:  40 Action:  21 Distance:  tensor(1.5323, dtype=torch.float64)\n",
      "Step:  40 Action:  26 Distance:  tensor(1.4036, dtype=torch.float64)\n",
      "Step:  40 Action:  34 Distance:  tensor(1.5428, dtype=torch.float64)\n",
      "40 []\n",
      "Step:  41 Action:  0 Distance:  tensor(1.5209, dtype=torch.float64)\n",
      "Step:  41 Action:  5 Distance:  tensor(1.2129, dtype=torch.float64)\n",
      "Step:  41 Action:  8 Distance:  tensor(1.3191, dtype=torch.float64)\n",
      "Step:  41 Action:  13 Distance:  tensor(1.5965, dtype=torch.float64)\n",
      "Step:  41 Action:  18 Distance:  tensor(1.2075, dtype=torch.float64)\n",
      "Step:  41 Action:  21 Distance:  tensor(1.5323, dtype=torch.float64)\n",
      "Step:  41 Action:  26 Distance:  tensor(1.4036, dtype=torch.float64)\n",
      "Step:  41 Action:  34 Distance:  tensor(1.5428, dtype=torch.float64)\n",
      "41 []\n",
      "Step:  42 Action:  0 Distance:  tensor(1.5209, dtype=torch.float64)\n",
      "Step:  42 Action:  5 Distance:  tensor(1.2129, dtype=torch.float64)\n",
      "Step:  42 Action:  8 Distance:  tensor(1.3191, dtype=torch.float64)\n",
      "Step:  42 Action:  13 Distance:  tensor(1.5965, dtype=torch.float64)\n",
      "Step:  42 Action:  18 Distance:  tensor(1.2075, dtype=torch.float64)\n",
      "Step:  42 Action:  21 Distance:  tensor(1.5323, dtype=torch.float64)\n",
      "Step:  42 Action:  26 Distance:  tensor(1.4036, dtype=torch.float64)\n",
      "Step:  42 Action:  34 Distance:  tensor(1.5428, dtype=torch.float64)\n",
      "42 []\n",
      "Step:  43 Action:  0 Distance:  tensor(1.5209, dtype=torch.float64)\n",
      "Step:  43 Action:  5 Distance:  tensor(1.2129, dtype=torch.float64)\n",
      "Step:  43 Action:  8 Distance:  tensor(1.3191, dtype=torch.float64)\n",
      "Step:  43 Action:  13 Distance:  tensor(1.5965, dtype=torch.float64)\n",
      "Step:  43 Action:  18 Distance:  tensor(1.2075, dtype=torch.float64)\n",
      "Step:  43 Action:  21 Distance:  tensor(1.5323, dtype=torch.float64)\n",
      "Step:  43 Action:  26 Distance:  tensor(1.4036, dtype=torch.float64)\n",
      "Step:  43 Action:  34 Distance:  tensor(1.5428, dtype=torch.float64)\n",
      "43 []\n",
      "Step:  44 Action:  0 Distance:  tensor(1.5209, dtype=torch.float64)\n",
      "Step:  44 Action:  5 Distance:  tensor(1.2129, dtype=torch.float64)\n",
      "Step:  44 Action:  8 Distance:  tensor(1.3191, dtype=torch.float64)\n",
      "Step:  44 Action:  13 Distance:  tensor(1.5965, dtype=torch.float64)\n",
      "Step:  44 Action:  18 Distance:  tensor(1.2075, dtype=torch.float64)\n",
      "Step:  44 Action:  21 Distance:  tensor(1.5323, dtype=torch.float64)\n",
      "Step:  44 Action:  26 Distance:  tensor(1.4036, dtype=torch.float64)\n",
      "Step:  44 Action:  34 Distance:  tensor(1.5428, dtype=torch.float64)\n",
      "44 []\n",
      "Step:  45 Action:  0 Distance:  tensor(1.5209, dtype=torch.float64)\n",
      "Step:  45 Action:  5 Distance:  tensor(1.2129, dtype=torch.float64)\n",
      "Step:  45 Action:  8 Distance:  tensor(1.3191, dtype=torch.float64)\n",
      "Step:  45 Action:  13 Distance:  tensor(1.5965, dtype=torch.float64)\n",
      "Step:  45 Action:  18 Distance:  tensor(1.2075, dtype=torch.float64)\n",
      "Step:  45 Action:  21 Distance:  tensor(1.5323, dtype=torch.float64)\n",
      "Step:  45 Action:  26 Distance:  tensor(1.4036, dtype=torch.float64)\n",
      "Step:  45 Action:  34 Distance:  tensor(1.5428, dtype=torch.float64)\n",
      "45 []\n",
      "Step:  46 Action:  0 Distance:  tensor(1.5209, dtype=torch.float64)\n",
      "Step:  46 Action:  5 Distance:  tensor(1.2129, dtype=torch.float64)\n",
      "Step:  46 Action:  8 Distance:  tensor(1.3191, dtype=torch.float64)\n",
      "Step:  46 Action:  13 Distance:  tensor(1.5965, dtype=torch.float64)\n",
      "Step:  46 Action:  18 Distance:  tensor(1.2075, dtype=torch.float64)\n",
      "Step:  46 Action:  21 Distance:  tensor(1.5323, dtype=torch.float64)\n",
      "Step:  46 Action:  26 Distance:  tensor(1.4036, dtype=torch.float64)\n",
      "Step:  46 Action:  34 Distance:  tensor(1.5428, dtype=torch.float64)\n",
      "46 []\n",
      "Step:  47 Action:  0 Distance:  tensor(1.5209, dtype=torch.float64)\n",
      "Step:  47 Action:  8 Distance:  tensor(1.2639, dtype=torch.float64)\n",
      "Step:  47 Action:  13 Distance:  tensor(1.5583, dtype=torch.float64)\n",
      "Step:  47 Action:  21 Distance:  tensor(1.5480, dtype=torch.float64)\n",
      "Step:  47 Action:  26 Distance:  tensor(1.3944, dtype=torch.float64)\n",
      "Step:  47 Action:  34 Distance:  tensor(1.5913, dtype=torch.float64)\n",
      "Step:  47 Action:  42 Distance:  tensor(1.2956, dtype=torch.float64)\n",
      "Step:  47 Action:  47 Distance:  tensor(1.2660, dtype=torch.float64)\n",
      "47 []\n",
      "Step:  48 Action:  0 Distance:  tensor(1.3885, dtype=torch.float64)\n",
      "Step:  48 Action:  8 Distance:  tensor(1.2964, dtype=torch.float64)\n",
      "Step:  48 Action:  13 Distance:  tensor(1.5198, dtype=torch.float64)\n",
      "Step:  48 Action:  21 Distance:  tensor(1.5907, dtype=torch.float64)\n",
      "Step:  48 Action:  26 Distance:  tensor(1.3027, dtype=torch.float64)\n",
      "Step:  48 Action:  29 Distance:  tensor(1.2582, dtype=torch.float64)\n",
      "Step:  48 Action:  34 Distance:  tensor(1.5862, dtype=torch.float64)\n",
      "Step:  48 Action:  42 Distance:  tensor(1.3674, dtype=torch.float64)\n",
      "Step:  48 Action:  47 Distance:  tensor(1.2157, dtype=torch.float64)\n",
      "48 []\n",
      "Step:  49 Action:  0 Distance:  tensor(1.5321, dtype=torch.float64)\n",
      "Step:  49 Action:  8 Distance:  tensor(1.3821, dtype=torch.float64)\n",
      "Step:  49 Action:  13 Distance:  tensor(1.5176, dtype=torch.float64)\n",
      "Step:  49 Action:  21 Distance:  tensor(1.6158, dtype=torch.float64)\n",
      "Step:  49 Action:  26 Distance:  tensor(1.2182, dtype=torch.float64)\n",
      "Step:  49 Action:  29 Distance:  tensor(1.3106, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  49 Action:  34 Distance:  tensor(1.5309, dtype=torch.float64)\n",
      "Step:  49 Action:  42 Distance:  tensor(1.3322, dtype=torch.float64)\n",
      "49 []\n",
      "Step:  50 Action:  0 Distance:  tensor(1.5322, dtype=torch.float64)\n",
      "Step:  50 Action:  8 Distance:  tensor(1.3821, dtype=torch.float64)\n",
      "Step:  50 Action:  13 Distance:  tensor(1.5176, dtype=torch.float64)\n",
      "Step:  50 Action:  21 Distance:  tensor(1.6158, dtype=torch.float64)\n",
      "Step:  50 Action:  26 Distance:  tensor(1.2182, dtype=torch.float64)\n",
      "Step:  50 Action:  29 Distance:  tensor(1.3106, dtype=torch.float64)\n",
      "Step:  50 Action:  34 Distance:  tensor(1.5309, dtype=torch.float64)\n",
      "Step:  50 Action:  42 Distance:  tensor(1.3322, dtype=torch.float64)\n",
      "50 []\n",
      "Step:  51 Action:  0 Distance:  tensor(1.5321, dtype=torch.float64)\n",
      "Step:  51 Action:  5 Distance:  tensor(1.2367, dtype=torch.float64)\n",
      "Step:  51 Action:  8 Distance:  tensor(1.4490, dtype=torch.float64)\n",
      "Step:  51 Action:  13 Distance:  tensor(1.5675, dtype=torch.float64)\n",
      "Step:  51 Action:  21 Distance:  tensor(1.6079, dtype=torch.float64)\n",
      "Step:  51 Action:  26 Distance:  tensor(1.2407, dtype=torch.float64)\n",
      "Step:  51 Action:  29 Distance:  tensor(1.2570, dtype=torch.float64)\n",
      "Step:  51 Action:  34 Distance:  tensor(1.4905, dtype=torch.float64)\n",
      "Step:  51 Action:  42 Distance:  tensor(1.2329, dtype=torch.float64)\n",
      "51 []\n",
      "Step:  52 Action:  0 Distance:  tensor(1.6565, dtype=torch.float64)\n",
      "Step:  52 Action:  5 Distance:  tensor(1.3360, dtype=torch.float64)\n",
      "Step:  52 Action:  8 Distance:  tensor(1.4893, dtype=torch.float64)\n",
      "Step:  52 Action:  13 Distance:  tensor(1.5909, dtype=torch.float64)\n",
      "Step:  52 Action:  21 Distance:  tensor(1.5736, dtype=torch.float64)\n",
      "Step:  52 Action:  26 Distance:  tensor(1.2366, dtype=torch.float64)\n",
      "Step:  52 Action:  34 Distance:  tensor(1.4237, dtype=torch.float64)\n",
      "52 []\n",
      "Step:  53 Action:  0 Distance:  tensor(1.6565, dtype=torch.float64)\n",
      "Step:  53 Action:  5 Distance:  tensor(1.3360, dtype=torch.float64)\n",
      "Step:  53 Action:  8 Distance:  tensor(1.4893, dtype=torch.float64)\n",
      "Step:  53 Action:  13 Distance:  tensor(1.5909, dtype=torch.float64)\n",
      "Step:  53 Action:  21 Distance:  tensor(1.5736, dtype=torch.float64)\n",
      "Step:  53 Action:  26 Distance:  tensor(1.2366, dtype=torch.float64)\n",
      "Step:  53 Action:  34 Distance:  tensor(1.4237, dtype=torch.float64)\n",
      "53 []\n",
      "Step:  54 Action:  0 Distance:  tensor(1.6565, dtype=torch.float64)\n",
      "Step:  54 Action:  5 Distance:  tensor(1.4373, dtype=torch.float64)\n",
      "Step:  54 Action:  8 Distance:  tensor(1.5157, dtype=torch.float64)\n",
      "Step:  54 Action:  13 Distance:  tensor(1.6149, dtype=torch.float64)\n",
      "Step:  54 Action:  18 Distance:  tensor(1.2637, dtype=torch.float64)\n",
      "Step:  54 Action:  21 Distance:  tensor(1.5260, dtype=torch.float64)\n",
      "Step:  54 Action:  26 Distance:  tensor(1.2495, dtype=torch.float64)\n",
      "Step:  54 Action:  34 Distance:  tensor(1.3568, dtype=torch.float64)\n",
      "54 []\n",
      "Step:  55 Action:  0 Distance:  tensor(1.7441, dtype=torch.float64)\n",
      "Step:  55 Action:  5 Distance:  tensor(1.5640, dtype=torch.float64)\n",
      "Step:  55 Action:  8 Distance:  tensor(1.5016, dtype=torch.float64)\n",
      "Step:  55 Action:  13 Distance:  tensor(1.5992, dtype=torch.float64)\n",
      "Step:  55 Action:  18 Distance:  tensor(1.3915, dtype=torch.float64)\n",
      "Step:  55 Action:  21 Distance:  tensor(1.3772, dtype=torch.float64)\n",
      "Step:  55 Action:  26 Distance:  tensor(1.2197, dtype=torch.float64)\n",
      "55 []\n",
      "Step:  56 Action:  0 Distance:  tensor(1.7894, dtype=torch.float64)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 58 is out of bounds for dimension 0 with size 58",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-a7dce26ea5fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mz\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTractographyState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreferenceLine\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolateDWIatState\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstepCounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m#if reward == -1:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fibre_tracking/deepFibreTracking/dfibert/envs/RLtractEnvironment.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;31m#else:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m#    rewardNextState = rewardDistance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mrewardNextState\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewardForState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnextState\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;31m#if rewardNextState < 0.:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;31m#    rewardNextState = -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fibre_tracking/deepFibreTracking/dfibert/envs/RLtractEnvironment.py\u001b[0m in \u001b[0;36mrewardForState\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mqry_pt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetCoordinate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;31m#distance = torch.min(torch.sum( (self.referenceStreamline_ijk[np.max([self.stepCounter-1-2,0]):np.min([self.stepCounter-1+1,self.maxSteps])] - qry_pt)**2, dim =1 ))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0mdistance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreferenceStreamline_ijk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstepCounter\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m86\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mqry_pt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0;31m#reward = torch.tanh(-distance+5.3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdistance\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 58 is out of bounds for dimension 0 with size 58"
     ]
    }
   ],
   "source": [
    "possible_actions = []\n",
    "past_state = env.reset()\n",
    "all_next_states = []\n",
    "for i in range(len(referenceLine)):\n",
    "    best_actions = []\n",
    "    next_states = []\n",
    "    for z in range(n_actions):\n",
    "        env.state = TractographyState(referenceLine[i], env.interpolateDWIatState)\n",
    "        next_state, reward, _ = env.step(z)\n",
    "        env.stepCounter = i\n",
    "        #if reward == -1:\n",
    "        #    reward = 0\n",
    "        #elif reward < 0.2:\n",
    "        if reward > 1.0:\n",
    "            print(\"Step: \", i, \"Action: \", z, \"Distance: \", reward)\n",
    "        #    reward = 1\n",
    "        #elif reward < 1.:\n",
    "        #    reward = 0\n",
    "        #else:\n",
    "        #    reward = -1\n",
    "        #if reward == 1:\n",
    "        #    best_actions.append(z)\n",
    "            #print(i, z, referenceLine[i].numpy(), next_state.getCoordinate().numpy(), reward)\n",
    "    print(i, best_actions)\n",
    "    #print(i, reward)\n",
    "    #if reward > 0.9:\n",
    "    #    best_actions.append(i)\n",
    "    possible_actions.append(best_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_distance = []\n",
    "optimal_steps = []#[100, 80, 75, 80, 75, 100, 62, 75, 83, 75, 83, 100, 83, 62, 67, 51, 67, 100, 59, 59, 59, 100, 59, 56, 51, 56, 66, 100, 66, 71, 71, 79, 58, 100, 71, 71, 84, 71, 100, 92, 84, 92, 97, 100, 97, 38, 97, 43, 38, 100, 43, 43, 89, 48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n"
     ]
    }
   ],
   "source": [
    "last_state = env.reset()\n",
    "print(len(env.referenceStreamline_ijk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "[80, 88, 67, 75, 75, 62, 75, 83, 75, 83, 83, 83, 62, 67, 67, 54, 59, 59, 59, 59, 59, 59, 51, 56, 51, 56, 66, 66, 79, 71, 71, 66, 71, 71, 71, 71, 71, 84, 92, 84, 84, 92, 97, 97, 38, 97, 97, 38, 43, 43, 38, 35, 89, 48, 48, 73, 94, 35, 89, 43, 35, 22, 35, 35, 14, 14, 11, 3, 3, 16, 16, 21, 16, 21, 21, 34, 26, 47, 26, 39, 93, 39, 72, 72, 77, 77, 100]\n"
     ]
    }
   ],
   "source": [
    "steps = 0\n",
    "while len(optimal_steps) < 87:\n",
    "    step_distance = []\n",
    "    for i in range(n_actions):\n",
    "        env.reset()\n",
    "        if len(optimal_steps)>0:\n",
    "            for z in range(len(optimal_steps)):\n",
    "                _,_,_ = env.step(optimal_steps[z])\n",
    "        next_state, _, terminal = env.step(i)\n",
    "        #distance = lineseg_dist(next_state.getCoordinate().numpy(), referenceLine[np.min([len(optimal_steps), 85])].numpy(), referenceLine[np.min([len(optimal_steps)+1, len(referenceLine)-1])].numpy())\n",
    "        #distance = ((next_state.getCoordinate()[0] - env.referenceStreamline_ijk[np.min([env.stepCounter, 58])][0])**2 \\\n",
    "        #              + (next_state.getCoordinate()[1] - env.referenceStreamline_ijk[np.min([env.stepCounter, 58])][1])**2 \\\n",
    "        #              + (next_state.getCoordinate()[2] - env.referenceStreamline_ijk[np.min([env.stepCounter, 58])][2])**2)\n",
    "        current_index = np.min([env.stepCounter, len(env.referenceStreamline_ijk)-1])\n",
    "        qry_pt = next_state.getCoordinate().view(-1,3)\n",
    "        distance = torch.sum((env.referenceStreamline_ijk[current_index] - qry_pt)**2)\n",
    "        \n",
    "        step_distance.append(distance)\n",
    "    optimal_steps.append(np.argmin(step_distance))\n",
    "print(optimal_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streamline index 0, stepWidth 0.81\n",
    "optimal_steps = [80, 88, 67, 75, 75, 62, 75, 83, 75, 83, 83, 83, 62, 67, 67, 54, 59, 59, 59, 59, 59, 59, 51, 56, 51, 56, 66, 66, 79, 71, 71, 66, 71, 71, 71, 71, 71, 84, 92, 84, 84, 92, 97, 97, 38, 97, 97, 38, 43, 43, 38, 35, 89, 48, 48, 73, 94, 35, 89, 43, 35, 22, 35, 35, 14, 14, 11, 3, 3, 16, 16, 21, 16, 21, 21, 34, 26, 47, 26, 39, 93, 39, 72, 72, 77, 77, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streamline index 4, stepWidth 0.81\n",
    "optimal_steps = [17, 30, 17, 30, 17, 30, 17, 1, 6, 3, 3, 3, 11, 16, 16, 24, 16, 24, 37, 24, 91, 45, 78, 78, 86, 99, 86, 86, 86, 70, 70, 65, 70, 65, 86, 65, 86, 99, 99, 40, 45, 45, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streamline index 4, stepWidth 0.79\n",
    "#optimal_steps =[17, 30, 17, 30, 17, 30, 17, 1, 6, 3, 3, 3, 11, 16, 16, 16, 24, 24, 24, 37, 24, 91, 78, 78, 99, 86, 86, 86, 86, 86, 70, 70, 70, 65, 65, 86, 86, 86, 99, 99, 99, 45, 99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streamline index 4, stepWidth 0.78\n",
    "#optimal_steps = [17, 30, 17, 30, 17, 30, 17, 1, 6, 1, 3, 11, 3, 16, 16, 24, 16, 24, 24, 37, 37, 45, 78, 78, 99, 86, 86, 78, 86, 86, 78, 70, 65, 65, 65, 86, 86, 86, 99, 99, 99, 45, 78]\n",
    "print(optimal_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17, 30, 17, 30, 17, 30, 17, 1, 6, 3, 3, 3, 11, 16, 16, 16, 24, 24, 37, 24, 37, 78, 45, 78, 86, 86, 86, 86, 86, 78, 70, 65, 70, 65, 86, 65, 86, 86, 99, 32, 99, 45]\n"
     ]
    }
   ],
   "source": [
    "# Streamline index 4, stepWidth 0.8\n",
    "#optimal_steps = [17, 30, 17, 30, 17, 30, 17, 1, 6, 3, 3, 3, 11, 16, 16, 16, 24, 24, 37, 24, 37, 78, 45, 78, 86, 86, 86, 86, 86, 78, 70, 65, 70, 65, 86, 65, 86, 86, 99, 32, 99, 45]\n",
    "print(optimal_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streamline index 2\n",
    "optimal_steps = [3, 3, 100, 6, 3, 11, 3, 6, 100, 11, 6, 11, 3, 100, 19, 3, 11, 6, 16, 100, 3, 3, 3, 2, 11, 7, 18, 100, 15, 7, 2, 2, 100, 0, 10, 0, 2, 0, 100, 0, 0, 3, 0, 11, 100, 3, 3, 3, 3, 100, 3, 3, 1, 11, 100, 3, 3, 3, 16, 11, 100, 16, 29, 16, 42, 100, 21, 29, 21, 42, 21, 100, 34, 21, 13, 26, 100, 23, 18, 23, 31, 100, 44, 31, 31, 44, 44, 100, 44, 31, 36, 98, 15, 100, 23, 23, 44, 15, 44, 100, 15, 28, 15, 20, 36, 100, 20, 28, 20, 20, 100, 28, 28, 36, 49, 28, 100, 36, 49, 49, 90, 100, 49, 95, 95, 49, 46, 49, 38, 36, 25, 100, 28, 28, 33, 36, 41, 100, 20, 28, 12, 20, 20, 100, 7, 15, 7, 20, 10, 25, 100]\n",
    "#print(optimal_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Streamline with len 44 (index 4)\n",
    "#print(optimal_steps)\n",
    "optimal_steps = [17, 30, 100, 17, 30, 17, 17, 6, 0, 17, 37, 0, 0, 78, 24, 16, 24, 24, 100, 37, 45, 45, 70, 100, 99, 86, 86, 78, 94, 62, 100, 65, 70, 86, 65, 100, 86, 94, 99, 45, 99, 100, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with line distance\n",
    "#optimal_steps = [80, 88, 54, 96, 46, 75, 75, 75, 83, 75, 83, 83, 62, 54, 1, 59, 54, 59, 59, 67, 56, 59, 51, 59, 61, 11, 53, 61, 66, 71, 71, 79, 58, 71, 71, 71, 21, 71, 84, 92, 84, 92, 97, 84, 43, 84, 30, 97, 47, 97, 43, 30, 89, 35, 94, 73, 48, 89, 22, 72, 43, 35, 22, 35, 35, 6, 19, 3, 16, 16, 66, 16, 8, 21, 29, 21, 26, 26, 93, 26, 93, 85, 35, 85, 72, 77, 100]\n",
    "optimal_steps = [100, 80, 75, 80, 75, 100, 62, 75, 83, 75, 83, 100, 83, 62, 67, 51, 67, 100, 59, 59, 59, 100, 59, 56, 51, 56, 66, 100, 66, 71, 71, 79, 58, 100, 71, 71, 84, 71, 100, 92, 84, 92, 97, 100, 97, 38, 97, 43, 38, 100, 43, 43, 89, 48, 100, 94, 81, 48, 43, 100, 35, 43, 35, 22, 27, 100, 6, 11, 3, 16, 100, 8, 29, 21, 21, 100, 34, 26, 26, 93, 39, 100, 93, 72, 77, 77, 101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimal_steps = [80, 75, 80, 75, 62, 75, 83, 96, 51, 24, 62, 62, 62, 77, 65, 64, 67, 59, 56, 83, 82, 54, 56, 53, 56, 38, 56, 84, 66, 71, 71, 64, 97, 84, 71, 71, 38, 51, 30, 92, 97, 84, 43, 79, 27, 46, 89, 25, 81, 25, 48, 43, 86, 48, 57, 14, 89, 43, 43, 19, 92, 14, 27, 9, 78, 4, 16, 3, 29, 3, 47, 6, 42, 21, 39, 5, 72, 34, 98, 88, 90, 75, 77, 59, 49, 32, 82]\n",
    "print(optimal_steps) # <-- min of max distance reward streamline 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[80, 75, 80, 75, 62, 75, 83, 96, 51, 24, 62, 62, 62, 77, 65, 64, 67, 59, 56, 83, 82, 54, 56, 53, 56, 38, 56, 84, 66, 71, 71, 64, 97, 84, 71, 71, 38, 51, 30, 92, 97, 84, 43, 79, 27, 46, 89, 25, 81, 25, 48, 43, 86, 48, 57, 14, 89, 43, 43, 19, 92, 14, 27, 9, 78, 4, 16, 3, 29, 3, 47, 6, 42, 21, 39, 5, 72, 34, 98, 88, 90, 75, 77, 59, 49, 32, 82]\n"
     ]
    }
   ],
   "source": [
    "optimal_steps = [80, 75, 80, 75, 62, 75, 83, 96, 51, 24, 62, 62, 62, 77, 65, 64, 67, 59, 56, 83, 82, 54, 56, 53, 56, 38, 56, 84, 66, 71, 71, 64, 97, 84, 71, 71, 38, 51, 30, 92, 97, 84, 43, 79, 27, 46, 89, 25, 81, 25, 48, 43, 86, 48, 57, 14, 89, 43, 43, 19, 92, 14, 27, 9, 78, 4, 16, 3, 29, 3, 47, 6, 42, 21, 39, 5, 72, 34, 98, 88, 90, 75, 77, 59, 49, 32, 82]\n",
    "print(optimal_steps) # <-- min of max distance reward streamline 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[80, 88, 54, 96, 59, 37, 54, 37, 67, 91, 62, 78, 64, 70, 64, 62, 69, 83, 56, 59, 59, 53, 42, 53, 53, 56, 79, 58, 87, 60, 87, 58, 92, 52, 46, 58, 38, 58, 30, 58, 38, 84, 17, 55, 30, 76, 25, 76, 17, 76, 17, 81, 30, 86, 48, 65, 27, 97, 14, 84, 6, 97, 14, 89, 3, 27, 8, 19, 13, 19, 13, 29, 8, 96, 2, 88, 31, 47, 26, 59, 5, 72, 72, 85, 61, 39]\n"
     ]
    }
   ],
   "source": [
    "optimal_steps = [80, 88, 54, 96, 59, 37, 54, 37, 67, 91, 62, 78, 64, 70, 64, 62, 69, 83, 56, 59, 59, 53, 42, 53, 53, 56, 79, 58, 87, 60, 87, 58, 92, 52, 46, 58, 38, 58, 30, 58, 38, 84, 17, 55, 30, 76, 25, 76, 17, 76, 17, 81, 30, 86, 48, 65, 27, 97, 14, 84, 6, 97, 14, 89, 3, 27, 8, 19, 13, 19, 13, 29, 8, 96, 2, 88, 31, 47, 26, 59, 5, 72, 72, 85, 61, 39]\n",
    "print(optimal_steps) # <-- min reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change optimal steps\n",
    "optimal_steps = [17, 30, 100, 17, 30, 17, 17, 6, 0, 6, 0, 0, 0, 78, 24, 16, 24, 24, 100, 37, 45, 45, 70, 100, 99, 86, 86, 78, 94, 62, 100, 65, 70, 86, 65, 100, 86, 94, 99, 45, 99, 100, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 73.651344 107.88106   93.29415 ] tensor([ 73.6513, 107.8811,  93.2942])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'optimal_steps' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-fc460226c6be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mlen_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreferenceStreamline_ijk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mall_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetCoordinate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimal_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#print(step, reward)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'optimal_steps' is not defined"
     ]
    }
   ],
   "source": [
    "state = env.reset()\n",
    "print(env.state.getCoordinate().numpy(), env.referenceStreamline_ijk[0])\n",
    "step = 1\n",
    "all_distances = []\n",
    "all_states = []\n",
    "len_line = len(env.referenceStreamline_ijk)-1\n",
    "all_states.append(state.getCoordinate())\n",
    "for i in optimal_steps:\n",
    "    next_state, reward, terminal = env.step(i)\n",
    "    #print(step, reward)\n",
    "    #current_index = np.min([env.points_visited+1,len(env.referenceStreamline_ijk)-1])\n",
    "    #print(\"Reference Line at current index: \", env.referenceStreamline_ijk[current_index])\n",
    "    #distance = lineseg_dist(next_state.getCoordinate().numpy(), referenceLine[step-1].numpy(), referenceLine[np.min([step, len(referenceLine)-1])].numpy())\n",
    "    #distance = 2 + (distance/10)\n",
    "    #distance = ((next_state.getCoordinate()[0] - env.referenceStreamline_ijk[np.min([env.stepCounter, len_line])][0])**2 \\\n",
    "    #                  + (next_state.getCoordinate()[1] - env.referenceStreamline_ijk[np.min([env.stepCounter, len_line])][1])**2 \\\n",
    "    #                  + (next_state.getCoordinate()[2] - env.referenceStreamline_ijk[np.min([env.stepCounter, len_line])][2])**2)\n",
    "    current_index = np.min([env.stepCounter, len(env.referenceStreamline_ijk)-1])\n",
    "    qry_pt = next_state.getCoordinate().view(-1,3)\n",
    "    distance = torch.sum((env.referenceStreamline_ijk[current_index] - qry_pt)**2)\n",
    "    \n",
    "    print(step, i, next_state.getCoordinate().numpy(), env.referenceStreamline_ijk[np.min([env.stepCounter,len_line])].numpy(), reward, -distance.item())\n",
    "    all_distances.append(distance)\n",
    "    all_states.append(next_state.getCoordinate())\n",
    "    #if distance < 0.71:\n",
    "    #    reward = 1 - distance\n",
    "    #    #print(reward)\n",
    "    #    if reward < 0.3:\n",
    "    #        reward = 1\n",
    "    step += 1\n",
    "\n",
    "print(np.min(all_distances), np.max(all_distances), np.sum(all_distances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 76.4527, 108.1185,  91.8665])\n",
      "tensor(108.1185)\n"
     ]
    }
   ],
   "source": [
    "print(env.referenceStreamline_ijk[4])\n",
    "print(env.referenceStreamline_ijk.T[1][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reset to streamline 3/5\n"
     ]
    }
   ],
   "source": [
    "state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([74.9079, 68.6542,  6.6088]) tensor([74.9079, 68.6542,  6.6088])\n",
      "tensor([75.0515, 68.9644,  7.3432], dtype=torch.float64) tensor([75.0415, 68.9379,  7.3448])\n",
      "tensor([75.1951, 69.2746,  8.0775], dtype=torch.float64) tensor([75.1012, 69.2937,  8.0589])\n",
      "tensor([75.0732, 69.6984,  8.7569], dtype=torch.float64) tensor([75.1610, 69.6495,  8.7729])\n",
      "tensor([75.2168, 70.0086,  9.4913], dtype=torch.float64) tensor([75.2207, 70.0053,  9.4869])\n",
      "tensor([75.3605, 70.3188, 10.2256], dtype=torch.float64) tensor([75.3279, 70.4488, 10.1440])\n",
      "tensor([75.5249, 70.8786, 10.7874], dtype=torch.float64) tensor([75.4352, 70.8923, 10.8012])\n",
      "tensor([75.4030, 71.3025, 11.4668], dtype=torch.float64) tensor([75.4949, 71.2481, 11.5152])\n",
      "tensor([75.5466, 71.6127, 12.2012], dtype=torch.float64) tensor([75.6022, 71.6915, 12.1723])\n",
      "tensor([75.6902, 71.9229, 12.9355], dtype=torch.float64) tensor([75.6619, 72.0473, 12.8864])\n",
      "tensor([75.5988, 72.5737, 13.4090], dtype=torch.float64) tensor([75.6980, 72.5632, 13.4967])\n",
      "tensor([75.7633, 73.1335, 13.9709], dtype=torch.float64) tensor([75.7341, 73.0791, 14.1071])\n",
      "tensor([75.6413, 73.5573, 14.6503], dtype=torch.float64) tensor([75.7701, 73.5950, 14.7175])\n",
      "tensor([75.8058, 74.1171, 15.2121], dtype=torch.float64) tensor([75.8062, 74.1109, 15.3278])\n",
      "tensor([75.6839, 74.5409, 15.8915], dtype=torch.float64) tensor([75.8422, 74.6268, 15.9382])\n",
      "tensor([75.8483, 75.1007, 16.4534], dtype=torch.float64) tensor([75.8783, 75.1427, 16.5486])\n",
      "tensor([75.9920, 75.4109, 17.1877], dtype=torch.float64) tensor([75.9855, 75.5862, 17.2057])\n",
      "tensor([76.1564, 75.9707, 17.7496], dtype=torch.float64) tensor([76.0928, 76.0297, 17.8629])\n",
      "tensor([76.0345, 76.3946, 18.4290], dtype=torch.float64) tensor([76.2000, 76.4732, 18.5200])\n",
      "tensor([76.4324, 76.7621, 19.0312], dtype=torch.float64) tensor([76.4056, 76.9388, 19.1372])\n",
      "tensor([76.5760, 77.0723, 19.7656], dtype=torch.float64) tensor([76.5868, 77.3026, 19.8263])\n",
      "tensor([76.7196, 77.3824, 20.4999], dtype=torch.float64) tensor([76.7203, 77.5862, 20.5623])\n",
      "tensor([76.8633, 77.6926, 21.2343], dtype=torch.float64) tensor([76.8539, 77.8699, 21.2983])\n",
      "tensor([77.0069, 78.0028, 21.9686], dtype=torch.float64) tensor([76.9996, 78.0494, 22.0641])\n",
      "tensor([76.8952, 78.1343, 22.7600], dtype=torch.float64) tensor([77.0545, 78.1756, 22.8522])\n",
      "tensor([77.0638, 78.1613, 23.5518], dtype=torch.float64) tensor([77.1093, 78.3018, 23.6403])\n",
      "tensor([77.2325, 78.1883, 24.3436], dtype=torch.float64) tensor([77.1743, 78.3133, 24.4375])\n",
      "tensor([77.2174, 78.0002, 25.1313], dtype=torch.float64) tensor([77.2496, 77.9811, 25.1614])\n",
      "tensor([77.3647, 77.5814, 25.8088], dtype=torch.float64) tensor([77.3263, 77.4440, 25.7493])\n",
      "tensor([77.3177, 76.9954, 26.3661], dtype=torch.float64) tensor([77.4029, 76.9069, 26.3372])\n",
      "tensor([77.4650, 76.5766, 27.0435], dtype=torch.float64) tensor([77.2996, 76.5694, 27.0552])\n",
      "tensor([77.1535, 76.4929, 27.7865], dtype=torch.float64) tensor([77.1912, 76.3470, 27.8160])\n",
      "tensor([77.1384, 76.3048, 28.5742], dtype=torch.float64) tensor([77.1715, 76.1842, 28.5990])\n",
      "tensor([77.2857, 75.8860, 29.2517], dtype=torch.float64) tensor([77.2455, 75.9670, 29.3653])\n",
      "tensor([77.4544, 75.9130, 30.0435], dtype=torch.float64) tensor([77.4148, 75.8119, 30.1317])\n",
      "tensor([77.4393, 75.7248, 30.8312], dtype=torch.float64) tensor([77.5840, 75.6568, 30.8980])\n",
      "tensor([77.7739, 75.5189, 31.5395], dtype=torch.float64) tensor([77.6571, 75.5543, 31.6881])\n",
      "tensor([77.9426, 75.5459, 32.3313], dtype=torch.float64) tensor([77.8233, 75.5124, 32.4695])\n",
      "tensor([77.9275, 75.3577, 33.1190], dtype=torch.float64) tensor([77.9895, 75.4705, 33.2509])\n",
      "tensor([78.0961, 75.3848, 33.9108], dtype=torch.float64) tensor([78.1556, 75.4286, 34.0324])\n",
      "tensor([78.2648, 75.4118, 34.7026], dtype=torch.float64) tensor([78.3218, 75.3867, 34.8138])\n",
      "tensor([78.4335, 75.4388, 35.4944], dtype=torch.float64) tensor([78.4792, 75.4569, 35.5950])\n",
      "tensor([78.5771, 75.7490, 36.2287], dtype=torch.float64) tensor([78.6250, 75.6365, 36.3608])\n",
      "tensor([78.7458, 75.7760, 37.0205], dtype=torch.float64) tensor([78.7585, 75.9202, 37.0968])\n",
      "tensor([78.8894, 76.0862, 37.7548], dtype=torch.float64) tensor([78.8921, 76.2038, 37.8328])\n",
      "tensor([79.0330, 76.3964, 38.4892], dtype=torch.float64) tensor([79.0733, 76.5676, 38.5219])\n",
      "tensor([79.1975, 76.9562, 39.0510], dtype=torch.float64) tensor([79.2544, 76.9314, 39.2110])\n",
      "tensor([79.3411, 77.2664, 39.7853], dtype=torch.float64) tensor([79.4356, 77.2952, 39.9001])\n",
      "tensor([79.4847, 77.5766, 40.5197], dtype=torch.float64) tensor([79.4953, 77.6510, 40.6141])\n",
      "tensor([79.6283, 77.8868, 41.2540], dtype=torch.float64) tensor([79.6289, 77.9347, 41.3501])\n",
      "tensor([79.7720, 78.1970, 41.9883], dtype=torch.float64) tensor([79.7625, 78.2183, 42.0861])\n",
      "tensor([79.9156, 78.5072, 42.7227], dtype=torch.float64) tensor([79.8960, 78.5020, 42.8221])\n",
      "tensor([79.8039, 78.6387, 43.5141], dtype=torch.float64) tensor([79.9359, 78.7429, 43.5840])\n",
      "tensor([79.9475, 78.9489, 44.2484], dtype=torch.float64) tensor([79.9758, 78.9837, 44.3458])\n",
      "tensor([80.0911, 79.2591, 44.9828], dtype=torch.float64) tensor([80.0356, 79.3395, 45.0598])\n",
      "tensor([80.2348, 79.5693, 45.7171], dtype=torch.float64) tensor([80.2167, 79.7033, 45.7489])\n",
      "tensor([80.3992, 80.1291, 46.2789], dtype=torch.float64) tensor([80.3979, 80.0671, 46.4380])\n",
      "tensor([80.5428, 80.4393, 47.0133], dtype=torch.float64) tensor([80.5791, 80.4309, 47.1270])\n",
      "tensor([80.6865, 80.7495, 47.7476], dtype=torch.float64) tensor([80.7602, 80.7947, 47.8161])\n",
      "tensor([80.8509, 81.3093, 48.3095], dtype=torch.float64) tensor([80.9658, 81.2604, 48.4333])\n",
      "tensor([81.2488, 81.6767, 48.9117], dtype=torch.float64) tensor([81.2837, 81.7186, 49.0069])\n",
      "tensor([81.6467, 82.0442, 49.5140], dtype=torch.float64) tensor([81.6016, 82.1768, 49.5804])\n",
      "tensor([82.0446, 82.4117, 50.1163], dtype=torch.float64) tensor([82.0211, 82.6052, 50.1101])\n",
      "tensor([82.4410, 83.0113, 50.4898], dtype=torch.float64) tensor([82.4406, 83.0337, 50.6397])\n",
      "tensor([82.8389, 83.3787, 51.0920], dtype=torch.float64) tensor([82.9928, 83.3187, 51.1434])\n",
      "tensor([83.4771, 83.4912, 51.5781], dtype=torch.float64) tensor([83.6211, 83.5545, 51.5789])\n",
      "tensor([84.0760, 83.8648, 51.9754], dtype=torch.float64) tensor([84.2494, 83.7903, 52.0145])\n",
      "tensor([84.8286, 83.8004, 52.2678], dtype=torch.float64) tensor([84.9416, 83.9694, 52.3732])\n",
      "tensor([85.4275, 84.1740, 52.6651], dtype=torch.float64) tensor([85.6339, 84.1485, 52.7320])\n",
      "tensor([86.0656, 84.2864, 53.1511], dtype=torch.float64) tensor([86.3261, 84.3276, 53.0908])\n",
      "tensor([86.8253, 84.4987, 53.3351], dtype=torch.float64) tensor([87.0183, 84.5068, 53.4496])\n",
      "tensor([87.4635, 84.6111, 53.8212], dtype=torch.float64) tensor([87.6663, 84.6348, 53.9010])\n",
      "tensor([88.2161, 84.5467, 54.1136], dtype=torch.float64) tensor([88.3712, 84.7040, 54.2728])\n",
      "tensor([88.9758, 84.7590, 54.2976], dtype=torch.float64) tensor([89.1131, 84.8213, 54.5483])\n",
      "tensor([89.6139, 84.8715, 54.7837], dtype=torch.float64) tensor([89.8181, 84.8904, 54.9201])\n",
      "tensor([90.1933, 84.6947, 55.3214], dtype=torch.float64) tensor([90.3453, 84.6596, 55.4757])\n",
      "tensor([90.7727, 84.5180, 55.8592], dtype=torch.float64) tensor([90.8480, 84.3259, 56.0010])\n",
      "tensor([91.1989, 84.0752, 56.3869], dtype=torch.float64) tensor([91.2836, 83.8824, 56.5045])\n",
      "tensor([91.6251, 83.6325, 56.9146], dtype=torch.float64) tensor([91.6366, 83.3615, 56.9986])\n",
      "tensor([91.8480, 82.9906, 57.3554], dtype=torch.float64) tensor([91.9971, 82.7743, 57.4050])\n",
      "tensor([92.0709, 82.3487, 57.7963], dtype=torch.float64) tensor([92.2664, 82.1258, 57.7883])\n",
      "tensor([92.5305, 81.7367, 58.0616], dtype=torch.float64) tensor([92.6291, 81.4843, 58.0996])\n",
      "tensor([92.9901, 81.1248, 58.3270], dtype=torch.float64) tensor([92.9918, 80.8427, 58.4109])\n",
      "tensor([93.1874, 80.3549, 58.4830], dtype=torch.float64) tensor([93.3526, 80.1598, 58.6193])\n",
      "tensor([93.6470, 79.7429, 58.7484], dtype=torch.float64) tensor([93.7133, 79.4768, 58.8277])\n",
      "tensor([93.8444, 78.9730, 58.9045], dtype=torch.float64) tensor([94.0740, 78.7938, 59.0361])\n",
      "tensor([94.3039, 78.3610, 59.1698], dtype=torch.float64) tensor([94.3412, 78.0615, 59.2157])\n",
      "tensor([94.5013, 77.5911, 59.3259], dtype=torch.float64) tensor([94.6084, 77.3291, 59.3953])\n",
      "tensor([94.6987, 76.8212, 59.4820], dtype=torch.float64) tensor([94.8756, 76.5968, 59.5749])\n",
      "tensor([94.8960, 76.0513, 59.6380], dtype=torch.float64) tensor([95.1428, 75.8644, 59.7545])\n",
      "tensor([95.3556, 75.4393, 59.9034], dtype=torch.float64) tensor([95.4100, 75.1321, 59.9341])\n",
      "tensor([95.5530, 74.6694, 60.0595], dtype=torch.float64) tensor([95.5819, 74.3928, 60.1869])\n",
      "tensor([95.7759, 74.0275, 60.5003], dtype=torch.float64) tensor([95.8519, 73.6955, 60.4714])\n",
      "tensor([95.9732, 73.2575, 60.6564], dtype=torch.float64) tensor([96.0245, 72.9989, 60.8249])\n",
      "tensor([96.1962, 72.6156, 61.0972], dtype=torch.float64) tensor([96.2938, 72.3504, 61.2082])\n",
      "tensor([96.4191, 71.9737, 61.5381], dtype=torch.float64) tensor([96.4664, 71.6538, 61.5617])\n",
      "tensor([96.3701, 71.2289, 61.8528], dtype=torch.float64) tensor([96.5391, 70.9719, 61.9737])\n",
      "tensor([96.5931, 70.5870, 62.2936], dtype=torch.float64) tensor([96.7118, 70.2753, 62.3272])\n",
      "tensor([96.8160, 69.9451, 62.7344], dtype=torch.float64) tensor([96.7844, 69.5935, 62.7392])\n",
      "tensor([96.7671, 69.2003, 63.0491], dtype=torch.float64) tensor([96.8571, 68.9116, 63.1513])\n",
      "tensor([96.7181, 68.4555, 63.3638], dtype=torch.float64) tensor([96.8297, 68.2003, 63.5164])\n",
      "tensor([96.6692, 67.7108, 63.6785], dtype=torch.float64) tensor([96.7041, 67.5243, 63.9253])\n",
      "tensor([96.6223, 67.1249, 64.2358], dtype=torch.float64) tensor([96.5785, 66.8482, 64.3342])\n",
      "tensor([96.5734, 66.3801, 64.5505], dtype=torch.float64) tensor([96.4529, 66.1722, 64.7431])\n",
      "tensor([96.2485, 65.8134, 65.0295], dtype=torch.float64) tensor([96.2314, 65.5445, 65.1868])\n",
      "tensor([95.9237, 65.2467, 65.5085], dtype=torch.float64) tensor([96.0099, 64.9168, 65.6306])\n",
      "tensor([95.8748, 64.5019, 65.8231], dtype=torch.float64) tensor([95.7884, 64.2891, 66.0744])\n",
      "tensor([95.5499, 63.9352, 66.3021], dtype=torch.float64) tensor([95.4713, 63.6600, 66.4535])\n",
      "tensor([95.2251, 63.3685, 66.7811], dtype=torch.float64) tensor([95.1541, 63.0310, 66.8325])\n",
      "tensor([94.9016, 62.6597, 67.0027], dtype=torch.float64) tensor([94.8370, 62.4019, 67.2116])\n",
      "tensor([94.5768, 62.0930, 67.4816], dtype=torch.float64) tensor([94.5198, 61.7728, 67.5907])\n",
      "tensor([94.2532, 61.3842, 67.7032], dtype=torch.float64) tensor([94.2052, 61.0929, 67.8713])\n",
      "tensor([93.9297, 60.6755, 67.9248], dtype=torch.float64) tensor([93.8905, 60.4131, 68.1519])\n",
      "tensor([93.8808, 59.9307, 68.2394], dtype=torch.float64) tensor([93.6701, 59.6838, 68.3959])\n",
      "tensor([93.5573, 59.2219, 68.4610], dtype=torch.float64) tensor([93.4497, 58.9545, 68.6400])\n",
      "tensor([93.5084, 58.4772, 68.7757], dtype=torch.float64) tensor([93.3240, 58.1902, 68.8402])\n",
      "tensor([93.1849, 57.7684, 68.9973], dtype=torch.float64) tensor([93.1983, 57.4259, 69.0405])\n",
      "tensor([93.1360, 57.0236, 69.3119], dtype=torch.float64) tensor([93.0726, 56.6617, 69.2408])\n",
      "tensor([93.0243, 56.2217, 69.3346], dtype=torch.float64) tensor([92.9469, 55.8974, 69.4410])\n",
      "tensor([92.9126, 55.4197, 69.3572], dtype=torch.float64) tensor([92.8257, 55.1111, 69.5248])\n",
      "tensor([92.8009, 54.6178, 69.3799], dtype=torch.float64) tensor([92.8001, 54.3123, 69.5607])\n",
      "tensor([92.6892, 53.8158, 69.4025], dtype=torch.float64) tensor([92.6942, 53.5203, 69.5218])\n",
      "tensor([92.5775, 53.0139, 69.4252], dtype=torch.float64) tensor([92.5883, 52.7283, 69.4829])\n",
      "tensor([92.4658, 52.2120, 69.4479], dtype=torch.float64) tensor([92.4042, 51.9580, 69.3699])\n",
      "tensor([92.3312, 51.4698, 69.1525], dtype=torch.float64) tensor([92.2202, 51.1877, 69.2568])\n",
      "tensor([91.9594, 50.7573, 69.0518], dtype=torch.float64) tensor([91.9415, 50.4407, 69.1914])\n",
      "tensor([91.6359, 50.0485, 69.2734], dtype=torch.float64) tensor([91.5722, 49.7312, 69.1735])\n",
      "tensor([91.2641, 49.3360, 69.1726], dtype=torch.float64) tensor([91.1155, 49.0750, 69.1997])\n",
      "tensor([90.7106, 48.7541, 69.2781], dtype=torch.float64) tensor([90.5707, 48.4919, 69.2567])\n",
      "tensor([90.1571, 48.1722, 69.3836], dtype=torch.float64) tensor([90.0131, 47.9396, 69.4118])\n",
      "tensor([89.6036, 47.5903, 69.4891], dtype=torch.float64) tensor([89.4481, 47.4342, 69.6674])\n",
      "tensor([89.0415, 47.1288, 69.8457], dtype=torch.float64) tensor([88.9573, 46.8970, 69.9998])\n",
      "tensor([88.7166, 46.5621, 70.3247], dtype=torch.float64) tensor([88.4665, 46.3597, 70.3321])\n",
      "tensor([88.1631, 45.9802, 70.4302], dtype=torch.float64) tensor([88.0605, 45.7443, 70.6426])\n",
      "tensor([87.8396, 45.2714, 70.6518], dtype=torch.float64) tensor([87.6618, 45.0829, 70.8515])\n",
      "tensor([87.5161, 44.5627, 70.8733], dtype=torch.float64) tensor([87.3471, 44.4030, 71.1321])\n",
      "tensor([87.1913, 43.9960, 71.3523], dtype=torch.float64) tensor([87.0324, 43.7231, 71.4127])\n",
      "tensor([86.8678, 43.2872, 71.5739], dtype=torch.float64) tensor([86.7178, 43.0432, 71.6933])\n",
      "tensor([86.5443, 42.5784, 71.7954], dtype=torch.float64) tensor([86.3117, 42.4278, 72.0037])\n",
      "tensor([85.9822, 42.1170, 72.1521], dtype=torch.float64) tensor([85.8209, 41.8906, 72.3361])\n",
      "tensor([85.6573, 41.5502, 72.6311], dtype=torch.float64) tensor([85.4140, 41.3331, 72.7405])\n",
      "tensor([85.0952, 41.0888, 72.9877], dtype=torch.float64) tensor([85.0108, 40.8447, 73.2294])\n",
      "tensor([84.7704, 40.5221, 73.4667], dtype=torch.float64) tensor([84.7028, 40.3502, 73.7777])\n",
      "tensor([84.5618, 40.1495, 74.1550], dtype=torch.float64) tensor([84.3949, 39.8558, 74.3260])\n",
      "tensor([84.2369, 39.5828, 74.6339], dtype=torch.float64) tensor([84.2807, 39.3211, 74.9101])\n",
      "tensor([84.1900, 38.9969, 75.1913], dtype=torch.float64) tensor([84.0753, 38.8421, 75.5170])\n",
      "tensor([83.9814, 38.6243, 75.8796], dtype=torch.float64) tensor([83.8699, 38.3631, 76.1239])\n",
      "tensor([83.6566, 38.0576, 76.3585], dtype=torch.float64) tensor([83.6645, 37.8840, 76.7308])\n",
      "tensor([83.4479, 37.6850, 77.0468], dtype=torch.float64) tensor([83.4590, 37.4050, 77.3377])\n",
      "tensor([83.4010, 37.0990, 77.6042], dtype=torch.float64) tensor([83.2536, 36.9260, 77.9446])\n",
      "tensor([82.9231, 36.8100, 78.1908], dtype=torch.float64) tensor([82.8617, 36.5164, 78.5091])\n",
      "tensor([82.7144, 36.4375, 78.8791], dtype=torch.float64) tensor([82.5670, 36.1024, 79.1270])\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64) tensor([82.3763, 35.7140, 79.7998])\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for i, x in enumerate(all_states):\n",
    "    try:\n",
    "        print(x, env.referenceStreamline_ijk[i])\n",
    "    except IndexError:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<mpl_toolkits.mplot3d.art3d.Line3D at 0x7fa282431040>]"
      ]
     },
     "metadata": {},
     "execution_count": 19
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"240.282407pt\" version=\"1.1\" viewBox=\"0 0 246.489911 240.282407\" width=\"246.489911pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-05-14T11:13:35.229377</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.4, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 240.282407 \nL 246.489911 240.282407 \nL 246.489911 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"patch_2\">\n   <path d=\"M 7.2 224.64 \nL 224.64 224.64 \nL 224.64 7.2 \nL 7.2 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n  </g>\n  <g id=\"pane3d_1\">\n   <g id=\"patch_3\">\n    <path d=\"M 23.61822 171.026264 \nL 95.424009 110.837228 \nL 94.42584 24.033878 \nL 19.183773 78.942111 \n\" style=\"fill:#f2f2f2;opacity:0.5;stroke:#f2f2f2;stroke-linejoin:miter;\"/>\n   </g>\n  </g>\n  <g id=\"pane3d_2\">\n   <g id=\"patch_4\">\n    <path d=\"M 95.424009 110.837228 \nL 210.64668 144.32791 \nL 214.758571 54.534718 \nL 94.42584 24.033878 \n\" style=\"fill:#e6e6e6;opacity:0.5;stroke:#e6e6e6;stroke-linejoin:miter;\"/>\n   </g>\n  </g>\n  <g id=\"pane3d_3\">\n   <g id=\"patch_5\">\n    <path d=\"M 23.61822 171.026264 \nL 145.759879 210.91773 \nL 210.64668 144.32791 \nL 95.424009 110.837228 \n\" style=\"fill:#ececec;opacity:0.5;stroke:#ececec;stroke-linejoin:miter;\"/>\n   </g>\n  </g>\n  <g id=\"axis3d_1\">\n   <g id=\"line2d_1\">\n    <path d=\"M 23.61822 171.026264 \nL 145.759879 210.91773 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"Line3DCollection_1\">\n    <path d=\"M 45.689338 178.234692 \nL 116.32028 116.910949 \nL 116.211159 29.555821 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-width:0.8;\"/>\n    <path d=\"M 66.948949 185.178081 \nL 136.416693 122.752183 \nL 137.178321 34.870386 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-width:0.8;\"/>\n    <path d=\"M 88.609194 192.252317 \nL 156.86006 128.694263 \nL 158.523313 40.280719 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-width:0.8;\"/>\n    <path d=\"M 110.681507 199.461134 \nL 177.659444 134.739822 \nL 180.256441 45.789433 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-width:0.8;\"/>\n    <path d=\"M 133.177759 206.80841 \nL 198.824226 140.891589 \nL 202.388388 51.399237 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"xtick_1\">\n    <g id=\"line2d_2\">\n     <path d=\"M 46.304713 177.700407 \nL 44.455932 179.305569 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-width:0.8;\"/>\n    </g>\n    <g id=\"text_1\">\n     <!-- 65 -->\n     <g transform=\"translate(31.809678 201.681315)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-54\"/>\n      <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"xtick_2\">\n    <g id=\"line2d_3\">\n     <path d=\"M 67.55465 184.633778 \nL 65.734905 186.269058 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-width:0.8;\"/>\n    </g>\n    <g id=\"text_2\">\n     <!-- 70 -->\n     <g transform=\"translate(53.097137 208.805442)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 8.203125 72.90625 \nL 55.078125 72.90625 \nL 55.078125 68.703125 \nL 28.609375 0 \nL 18.3125 0 \nL 43.21875 64.59375 \nL 8.203125 64.59375 \nz\n\" id=\"DejaVuSans-55\"/>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-55\"/>\n      <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"xtick_3\">\n    <g id=\"line2d_4\">\n     <path d=\"M 89.204748 191.697712 \nL 87.415466 193.363966 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-width:0.8;\"/>\n    </g>\n    <g id=\"text_3\">\n     <!-- 75 -->\n     <g transform=\"translate(74.787629 216.064448)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-55\"/>\n      <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"xtick_4\">\n    <g id=\"line2d_5\">\n     <path d=\"M 111.266415 198.895932 \nL 109.509092 200.594048 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-width:0.8;\"/>\n    </g>\n    <g id=\"text_4\">\n     <!-- 80 -->\n     <g transform=\"translate(96.892708 223.462202)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-56\"/>\n      <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"xtick_5\">\n    <g id=\"line2d_6\">\n     <path d=\"M 133.751501 206.232305 \nL 132.027701 207.963204 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-width:0.8;\"/>\n    </g>\n    <g id=\"text_5\">\n     <!-- 85 -->\n     <g transform=\"translate(119.424378 231.002719)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-56\"/>\n      <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n  <g id=\"axis3d_2\">\n   <g id=\"line2d_7\">\n    <path d=\"M 210.64668 144.32791 \nL 145.759879 210.91773 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"Line3DCollection_2\">\n    <path d=\"M 23.319674 75.923919 \nL 27.551096 167.72965 \nL 149.328656 207.255287 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-width:0.8;\"/>\n    <path d=\"M 34.733116 67.594909 \nL 38.412777 158.625173 \nL 159.175802 197.149692 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-width:0.8;\"/>\n    <path d=\"M 45.853995 59.479398 \nL 49.008068 149.74399 \nL 168.768759 187.304959 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-width:0.8;\"/>\n    <path d=\"M 56.693417 51.569281 \nL 59.346648 141.077987 \nL 178.117243 177.711114 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-width:0.8;\"/>\n    <path d=\"M 67.261934 43.856859 \nL 69.437738 132.619436 \nL 187.230482 168.358689 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-width:0.8;\"/>\n    <path d=\"M 77.569577 36.334811 \nL 79.290117 124.360976 \nL 196.117246 159.238683 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-width:0.8;\"/>\n    <path d=\"M 87.625886 28.996174 \nL 88.912158 116.295591 \nL 204.785872 150.34254 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"xtick_6\">\n    <g id=\"line2d_8\">\n     <path d=\"M 148.302369 206.922183 \nL 151.383887 207.922359 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-width:0.8;\"/>\n    </g>\n    <g id=\"text_6\">\n     <!-- 106 -->\n     <g transform=\"translate(152.682374 228.295958)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-49\"/>\n      <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      <use x=\"127.246094\" xlink:href=\"#DejaVuSans-54\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"xtick_7\">\n    <g id=\"line2d_9\">\n     <path d=\"M 158.15874 196.82524 \nL 161.212525 197.799426 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-width:0.8;\"/>\n    </g>\n    <g id=\"text_7\">\n     <!-- 108 -->\n     <g transform=\"translate(162.367888 218.007154)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-49\"/>\n      <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      <use x=\"127.246094\" xlink:href=\"#DejaVuSans-56\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"xtick_8\">\n    <g id=\"line2d_10\">\n     <path d=\"M 167.760791 186.988826 \nL 170.787238 187.938021 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-width:0.8;\"/>\n    </g>\n    <g id=\"text_8\">\n     <!-- 110 -->\n     <g transform=\"translate(171.803207 207.984129)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-49\"/>\n      <use x=\"63.623047\" xlink:href=\"#DejaVuSans-49\"/>\n      <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"xtick_9\">\n    <g id=\"line2d_11\">\n     <path d=\"M 177.118238 177.402985 \nL 180.117741 178.32814 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-width:0.8;\"/>\n    </g>\n    <g id=\"text_9\">\n     <!-- 112 -->\n     <g transform=\"translate(180.9979 198.216718)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-49\"/>\n      <use x=\"63.623047\" xlink:href=\"#DejaVuSans-49\"/>\n      <use x=\"127.246094\" xlink:href=\"#DejaVuSans-50\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"xtick_10\">\n    <g id=\"line2d_12\">\n     <path d=\"M 186.240311 168.058263 \nL 189.213259 168.960279 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-width:0.8;\"/>\n    </g>\n    <g id=\"text_10\">\n     <!-- 114 -->\n     <g transform=\"translate(189.961057 188.695264)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-49\"/>\n      <use x=\"63.623047\" xlink:href=\"#DejaVuSans-49\"/>\n      <use x=\"127.246094\" xlink:href=\"#DejaVuSans-52\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"xtick_11\">\n    <g id=\"line2d_13\">\n     <path d=\"M 195.135781 158.945676 \nL 198.082559 159.82541 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-width:0.8;\"/>\n    </g>\n    <g id=\"text_11\">\n     <!-- 116 -->\n     <g transform=\"translate(198.701315 179.410594)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-49\"/>\n      <use x=\"63.623047\" xlink:href=\"#DejaVuSans-49\"/>\n      <use x=\"127.246094\" xlink:href=\"#DejaVuSans-54\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"xtick_12\">\n    <g id=\"line2d_14\">\n     <path d=\"M 203.812987 150.056679 \nL 206.733976 150.914948 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-width:0.8;\"/>\n    </g>\n    <g id=\"text_12\">\n     <!-- 118 -->\n     <g transform=\"translate(207.226886 170.353983)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-49\"/>\n      <use x=\"63.623047\" xlink:href=\"#DejaVuSans-49\"/>\n      <use x=\"127.246094\" xlink:href=\"#DejaVuSans-56\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n  <g id=\"axis3d_3\">\n   <g id=\"line2d_15\">\n    <path d=\"M 210.64668 144.32791 \nL 214.758571 54.534718 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"Line3DCollection_3\">\n    <path d=\"M 211.227671 131.640559 \nL 95.282716 98.550077 \nL 22.99256 158.034038 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-width:0.8;\"/>\n    <path d=\"M 212.144398 111.621586 \nL 95.059947 79.17748 \nL 22.004745 137.521426 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-width:0.8;\"/>\n    <path d=\"M 213.079503 91.201271 \nL 94.832927 59.435282 \nL 20.996361 116.581683 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-width:0.8;\"/>\n    <path d=\"M 214.033546 70.367421 \nL 94.601535 39.312805 \nL 19.966759 95.201328 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"xtick_13\">\n    <g id=\"line2d_16\">\n     <path d=\"M 210.254285 131.362756 \nL 213.176772 132.196829 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-width:0.8;\"/>\n    </g>\n    <g id=\"text_13\">\n     <!-- 75 -->\n     <g transform=\"translate(223.214432 136.666145)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-55\"/>\n      <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"xtick_14\">\n    <g id=\"line2d_17\">\n     <path d=\"M 211.160987 111.349083 \nL 214.113597 112.167252 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-width:0.8;\"/>\n    </g>\n    <g id=\"text_14\">\n     <!-- 80 -->\n     <g transform=\"translate(224.309173 116.696334)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-56\"/>\n      <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"xtick_15\">\n    <g id=\"line2d_18\">\n     <path d=\"M 212.085858 90.934336 \nL 215.069219 91.735792 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-width:0.8;\"/>\n    </g>\n    <g id=\"text_15\">\n     <!-- 85 -->\n     <g transform=\"translate(225.425779 96.327673)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-56\"/>\n      <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"xtick_16\">\n    <g id=\"line2d_19\">\n     <path d=\"M 213.029452 70.106337 \nL 216.044209 70.890232 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-width:0.8;\"/>\n    </g>\n    <g id=\"text_16\">\n     <!-- 90 -->\n     <g transform=\"translate(226.564911 75.54809)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 10.984375 1.515625 \nL 10.984375 10.5 \nQ 14.703125 8.734375 18.5 7.8125 \nQ 22.3125 6.890625 25.984375 6.890625 \nQ 35.75 6.890625 40.890625 13.453125 \nQ 46.046875 20.015625 46.78125 33.40625 \nQ 43.953125 29.203125 39.59375 26.953125 \nQ 35.25 24.703125 29.984375 24.703125 \nQ 19.046875 24.703125 12.671875 31.3125 \nQ 6.296875 37.9375 6.296875 49.421875 \nQ 6.296875 60.640625 12.9375 67.421875 \nQ 19.578125 74.21875 30.609375 74.21875 \nQ 43.265625 74.21875 49.921875 64.515625 \nQ 56.59375 54.828125 56.59375 36.375 \nQ 56.59375 19.140625 48.40625 8.859375 \nQ 40.234375 -1.421875 26.421875 -1.421875 \nQ 22.703125 -1.421875 18.890625 -0.6875 \nQ 15.09375 0.046875 10.984375 1.515625 \nz\nM 30.609375 32.421875 \nQ 37.25 32.421875 41.125 36.953125 \nQ 45.015625 41.5 45.015625 49.421875 \nQ 45.015625 57.28125 41.125 61.84375 \nQ 37.25 66.40625 30.609375 66.40625 \nQ 23.96875 66.40625 20.09375 61.84375 \nQ 16.21875 57.28125 16.21875 49.421875 \nQ 16.21875 41.5 20.09375 36.953125 \nQ 23.96875 32.421875 30.609375 32.421875 \nz\n\" id=\"DejaVuSans-57\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-57\"/>\n      <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"line2d_20\">\n    <path clip-path=\"url(#p4b330ad8ac)\" d=\"M 95.231308 87.12308 \nL 98.667261 89.06542 \nL 102.102809 91.293415 \nL 105.35219 93.929718 \nL 109.197401 95.929526 \nL 113.037623 97.926856 \nL 117.266219 99.408787 \nL 121.482296 100.886154 \nL 126.132252 101.691227 \nL 130.765478 102.49347 \nL 135.382179 103.292727 \nL 140.191364 103.557277 \nL 144.761824 103.910534 \nL 148.422742 105.537522 \nL 151.171634 108.279851 \nL 152.983339 111.946859 \nL 154.574639 115.618783 \nL 155.676471 119.686664 \nL 156.779119 123.757915 \nL 157.882692 127.832598 \nL 158.288791 132.205912 \nL 158.695464 136.58412 \nL 158.403062 141.179069 \nL 158.110239 145.780647 \nL 157.816935 150.388876 \nL 156.398954 155.016705 \nL 154.321013 159.633347 \nL 150.776652 163.401405 \nL 146.989902 166.674129 \nL 143.029702 169.387922 \nL 139.486991 171.635489 \nL 135.951675 173.87855 \nL 132.423611 176.116896 \nL 128.902663 178.350653 \nL 125.880884 180.089098 \nL 122.324364 181.66249 \nL 118.777417 183.231684 \nL 115.288895 184.100243 \nL 111.811946 184.965921 \nL 107.932412 185.617485 \nL 104.622273 185.766801 \nL 100.946237 185.697393 \nL 97.532571 184.930192 \nL 94.765455 183.708023 \nL 92.01212 182.491884 \nL 89.60486 180.632959 \nL 87.210505 178.784 \nL 84.574799 176.695991 \nL 81.950684 174.617019 \nL 79.337851 172.547203 \nL 77.30967 169.808492 \nL 75.291477 167.083276 \nL 74.55225 163.60009 \nL 74.59523 160.012869 \nL 76.807208 156.719351 \nL 79.468139 153.797067 \nL 82.536469 151.288168 \nL 84.67202 148.092333 \nL 84.674058 144.655674 \nL 83.92775 141.357627 \nL 83.186314 138.081166 \nL 82.44383 134.539489 \nL 81.705631 131.018289 \nL 81.631419 127.135915 \nL 82.207885 122.975876 \nL 83.489965 118.456525 \nL 85.538992 113.841665 \nL 88.159914 109.412858 \nL 90.613773 105.469061 \nL 93.255453 101.991457 \nL 96.484512 98.60233 \nL 99.351769 95.535172 \nL 102.396735 92.923395 \nL 105.574647 90.811786 \nL 108.758497 88.696177 \nL 112.415991 87.361228 \nL 114.426052 87.260012 \nL 115.508156 88.194783 \nL 116.766609 89.916257 \nL 118.034075 91.650133 \nL 119.067548 93.968534 \nL 120.108569 96.303758 \nL 120.974983 99.457724 \nL 121.789812 103.186858 \nL 121.92958 107.298586 \nL 120.726561 111.914151 \nL 118.50178 116.440934 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_21\">\n    <path clip-path=\"url(#p4b330ad8ac)\" d=\"M 95.231323 87.123049 \nL 96.352336 88.196783 \nL 98.189517 88.177286 \nL 98.430063 88.943294 \nL 100.6753 91.093847 \nL 102.514141 91.073659 \nL 107.003474 95.373697 \nL 108.840421 95.352533 \nL 112.206556 98.576749 \nL 114.041873 98.554858 \nL 115.16364 99.629336 \nL 115.357611 100.478085 \nL 117.205339 99.714898 \nL 118.32544 100.787788 \nL 120.156227 100.765428 \nL 120.343792 101.61135 \nL 123.99832 101.56633 \nL 125.116266 102.637171 \nL 125.587638 101.588482 \nL 127.409555 101.566028 \nL 128.524949 102.634435 \nL 130.345776 102.611748 \nL 131.460903 103.679904 \nL 133.280642 103.656985 \nL 133.451482 104.495685 \nL 134.891242 102.764529 \nL 136.003668 103.830113 \nL 137.817995 103.807215 \nL 137.982941 104.643716 \nL 139.809312 103.885952 \nL 140.247766 102.84162 \nL 141.356042 103.903243 \nL 143.162418 103.880414 \nL 143.320316 104.713723 \nL 144.426994 105.77382 \nL 146.230089 105.7506 \nL 146.384072 106.580469 \nL 147.800583 104.860332 \nL 147.95235 105.689476 \nL 150.157729 107.80205 \nL 150.306488 108.626671 \nL 152.509195 110.736681 \nL 153.076612 112.165976 \nL 154.087151 116.537268 \nL 155.188657 117.592406 \nL 155.861291 120.503431 \nL 156.430999 121.939451 \nL 157.103393 124.849825 \nL 157.674194 126.289477 \nL 158.346347 129.1992 \nL 158.918241 130.642488 \nL 159.925917 135.005264 \nL 158.966298 136.66347 \nL 159.639076 139.57408 \nL 157.800882 140.940487 \nL 158.47455 143.851408 \nL 159.047868 145.308667 \nL 159.721294 148.218929 \nL 157.881328 149.595768 \nL 158.218551 151.051329 \nL 158.272192 152.281146 \nL 156.430382 153.662484 \nL 157.003118 155.129148 \nL 155.854124 156.051838 \nL 156.191868 157.506753 \nL 151.34769 161.207675 \nL 151.40611 162.433039 \nL 146.116759 166.583471 \nL 141.973489 169.814956 \nL 131.01187 178.514271 \nL 129.361452 178.181739 \nL 124.841503 181.809733 \nL 123.193264 181.478291 \nL 119.817138 184.19066 \nL 118.170412 183.860009 \nL 115.926598 185.664333 \nL 116.408481 184.466559 \nL 114.765981 184.136893 \nL 112.531971 185.935782 \nL 110.890318 185.606608 \nL 109.775637 186.505002 \nL 108.134173 186.176026 \nL 108.630182 184.980898 \nL 107.519248 185.877487 \nL 105.881329 185.549196 \nL 104.772151 186.445186 \nL 103.13442 186.117092 \nL 102.026997 187.012483 \nL 102.533611 185.819506 \nL 99.264744 185.164589 \nL 98.161679 186.058476 \nL 98.674876 184.870026 \nL 95.412114 184.216282 \nL 95.929903 183.033521 \nL 94.833096 183.924718 \nL 93.204988 183.598477 \nL 93.725946 182.419702 \nL 92.100681 182.093849 \nL 92.622868 180.920222 \nL 91.000437 180.594757 \nL 89.910466 181.483562 \nL 90.435765 180.313868 \nL 87.197377 179.664191 \nL 87.727138 178.500063 \nL 86.11053 178.175565 \nL 86.641462 177.016496 \nL 83.413402 176.36818 \nL 83.948739 175.214616 \nL 82.337279 174.890797 \nL 82.873751 173.742233 \nL 79.655954 173.095275 \nL 80.196776 171.952156 \nL 78.590431 171.629016 \nL 79.132354 170.490838 \nL 75.924755 169.845235 \nL 76.470973 168.712442 \nL 74.869711 168.389979 \nL 75.416995 167.262071 \nL 74.449672 166.199913 \nL 74.996858 165.078152 \nL 74.03104 164.017181 \nL 75.665943 160.683177 \nL 74.705651 159.626893 \nL 77.398652 154.164021 \nL 79.117436 154.131743 \nL 80.17346 151.976369 \nL 81.884731 151.944686 \nL 84.98497 145.577847 \nL 84.050829 144.543667 \nL 84.562619 143.498184 \nL 83.629882 142.465136 \nL 84.651468 140.38927 \nL 83.722012 139.359017 \nL 84.231809 138.328578 \nL 83.303743 137.299449 \nL 83.813501 136.27452 \nL 82.279647 135.961116 \nL 82.790433 134.940464 \nL 81.865094 133.913894 \nL 82.375833 132.898696 \nL 81.451872 131.873243 \nL 81.962562 130.86347 \nL 81.039974 129.839132 \nL 81.550613 128.834754 \nL 80.629394 127.81153 \nL 81.139979 126.812517 \nL 82.496073 125.217688 \nL 81.57738 124.196065 \nL 82.084948 123.206213 \nL 83.436863 121.61849 \nL 82.520681 120.598463 \nL 83.025257 119.617693 \nL 84.282737 118.358655 \nL 85.629196 116.779324 \nL 84.715971 115.760718 \nL 85.215189 114.791412 \nL 87.897518 111.649491 \nL 86.987913 110.632962 \nL 89.491043 108.128207 \nL 90.827256 106.564489 \nL 89.91923 105.547586 \nL 98.662757 96.800595 \nL 98.52421 96.250784 \nL 102.27075 92.503063 \nL 103.927747 91.821694 \nL 104.566567 92.170668 \nL 107.064185 89.671684 \nL 107.707368 90.018384 \nL 108.957035 88.767888 \nL 110.615394 88.086183 \nL 111.263394 88.431258 \nL 112.513575 87.179957 \nL 113.817107 87.869483 \nL 113.697149 87.30503 \nL 115.6664 88.344873 \nL 115.910273 89.037344 \nL 116.571183 89.387018 \nL 117.063766 90.781043 \nL 117.728911 91.134344 \nL 120.758337 99.357838 \nL 122.802011 104.691705 \nL 121.835846 106.194019 \nL 122.348748 107.535398 \nL 121.379408 109.046446 \nL 121.702611 110.420589 \nL 118.776094 114.992612 \nL 119.101436 116.372791 \nL 119.101436 116.372791 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p4b330ad8ac\">\n   <rect height=\"217.44\" width=\"217.44\" x=\"7.2\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "#%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#for i in range(len(states)):\n",
    "#    print(states[i], env.referenceStreamline_ijk[i])\n",
    "#    distance = ((states.T[0][i] - env.referenceStreamline_ijk.T[0][i])**2 \\\n",
    "#                      + (states.T[1][i] - env.referenceStreamline_ijk.T[1][i] )**2 \\\n",
    "#                      + (states.T[2][i] - env.referenceStreamline_ijk.T[2][i])**2)\n",
    "#    print(distance)\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot3D(env.referenceStreamline_ijk.T[0][:], env.referenceStreamline_ijk.T[1][:], env.referenceStreamline_ijk.T[2][:])\n",
    "ax.plot3D(states.T[0][:], states.T[1][:], states.T[2][:])\n",
    "#print(optimal_steps[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([73.6513, 73.8871, 74.1661], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "states = torch.stack(all_states)\n",
    "print(states.T[0][:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "201"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "len(all_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 71.7731, 113.9662,  79.6186])\n"
     ]
    }
   ],
   "source": [
    "print(referenceLine[86])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 73.651344 107.88106   93.29415 ] tensor([ 73.6513, 107.8811,  93.2942])\n",
      "tensor(66.2049, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "print(env.state.getCoordinate().numpy(), referenceLine[0])\n",
    "step = 0\n",
    "#all_rewards = []\n",
    "eps_reward = 0\n",
    "for i in optimal_steps:\n",
    "    next_state, distance, terminal = env.step(i)\n",
    "    if distance < 0.71:\n",
    "        reward = 1 - distance\n",
    "        #print(reward)\n",
    "        if reward < 0.3:\n",
    "            reward = 1\n",
    "    eps_reward += reward\n",
    "    #all_rewards.append(reward)\n",
    "    step += 1\n",
    "print(eps_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_actions):\n",
    "    \n",
    "    next_state, distance, terminal = env.step(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action:  100 Step:  1 Coordinates:  [ 73.651344 107.88106   93.29415 ] [ 74.42344 107.87124  93.08491]\n",
      "Action:  67 Step:  2 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 75.16057  107.88882   92.774536]\n",
      "Action:  100 Step:  3 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 75.78847 107.96255  92.28433]\n",
      "Action:  100 Step:  4 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 76.45265  108.118454  91.86654 ]\n",
      "Action:  100 Step:  5 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 77.116844 108.27435   91.448746]\n",
      "Action:  100 Step:  6 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 77.739716 108.54131   91.02359 ]\n",
      "Action:  100 Step:  7 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 78.36259  108.80828   90.598434]\n",
      "Action:  100 Step:  8 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 78.996666 109.15176   90.25207 ]\n",
      "Action:  100 Step:  9 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 79.630745 109.495224  89.9057  ]\n",
      "Action:  100 Step:  10 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 80.264824 109.8387    89.55933 ]\n",
      "Action:  100 Step:  11 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 80.833374 110.28288   89.21371 ]\n",
      "Action:  100 Step:  12 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 81.32385 110.75597  88.79464]\n",
      "Action:  100 Step:  13 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 81.78852 111.07612  88.22755]\n",
      "Action:  100 Step:  14 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 82.26274  111.20639   87.596565]\n",
      "Action:  100 Step:  15 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 82.764885 111.12094   86.97968 ]\n",
      "Action:  100 Step:  16 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 83.17989 111.072    86.2975 ]\n",
      "Action:  100 Step:  17 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 83.60093  110.91725   85.635086]\n",
      "Action:  100 Step:  18 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 84.02196  110.762505  84.97268 ]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-9b9d7b386c25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mterminal\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreward\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fibre_tracking/deepFibreTracking/dfibert/envs/RLtractEnvironment.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mpositionNextState\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetCoordinate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstepWidth\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0maction_vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mnextState\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTractographyState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositionNextState\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolateDWIatState\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mnextState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fibre_tracking/deepFibreTracking/dfibert/envs/_state.py\u001b[0m in \u001b[0;36mgetValue\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolatedDWI\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# interpolate DWI value at self.coordinate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolatedDWI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolFuncHandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoordinate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolatedDWI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fibre_tracking/deepFibreTracking/dfibert/envs/RLtractEnvironment.py\u001b[0m in \u001b[0;36minterpolateDWIatState\u001b[0;34m(self, stateCoordinates)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0minterpolated_dwi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_interpolated_dwi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mras_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdwi_postprocessor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fibre_tracking/deepFibreTracking/dfibert/data/__init__.py\u001b[0m in \u001b[0;36mget_interpolated_dwi\u001b[0;34m(self, points, postprocessing, ignore_outside_points)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpostprocessing\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             result = postprocessing(result, self.data.b0, \n\u001b[0m\u001b[1;32m    289\u001b[0m                                  \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbvecs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m                                  self.data.bvals)\n",
      "\u001b[0;32m~/fibre_tracking/deepFibreTracking/dfibert/data/postprocessing.py\u001b[0m in \u001b[0;36m_wrapper\u001b[0;34m(dwi, b0, bvecs, bvals)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdwi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbvecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mdata_sh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspherical_harmonics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msh_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msh_order\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmooth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msmooth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdwi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbvecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mdata_resampled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_sh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_sh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fibre_tracking/deepFibreTracking/dfibert/data/postprocessing.py\u001b[0m in \u001b[0;36m_wrapper\u001b[0;34m(dwi, _b0, bvecs, _bvals)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mreal_sh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreal_sym_sh_mrtrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msh_order\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_sphere\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_sphere\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0minv_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmooth_pinv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_sh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmooth\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mdata_sh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdwi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minv_b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/atari/lib/python3.8/site-packages/dipy/reconst/shm.py\u001b[0m in \u001b[0;36msmooth_pinv\u001b[0;34m(B, L)\u001b[0m\n\u001b[1;32m    661\u001b[0m     \"\"\"\n\u001b[1;32m    662\u001b[0m     \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m     \u001b[0minv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpinv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    664\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mpinv\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/atari/lib/python3.8/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36mpinv\u001b[0;34m(a, rcond, hermitian)\u001b[0m\n\u001b[1;32m   1959\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconjugate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1961\u001b[0;31m     \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_matrices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhermitian\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhermitian\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1962\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m     \u001b[0;31m# discard small singular values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msvd\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/atari/lib/python3.8/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv, hermitian)\u001b[0m\n\u001b[1;32m   1624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1625\u001b[0m         \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->DdD'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->ddd'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1626\u001b[0;31m         \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1627\u001b[0m         \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_realType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "terminal = False\n",
    "step = 0\n",
    "actions = []\n",
    "past_state = env.state\n",
    "step = 1\n",
    "while terminal != True:\n",
    "    for i in range(n_actions)\n",
    "    action = np.random.randint(n_actions)\n",
    "    next_state, reward, terminal = env.step(action)\n",
    "    if reward < 1:\n",
    "        actions.append(action)\n",
    "        past_state = next_state\n",
    "        print(\"Action: \", action, \"Step: \",step, \"Coordinates: \", next_state.getCoordinate().numpy(), referenceLine[step].numpy())\n",
    "        step += 1\n",
    "    else:\n",
    "        env.state = past_state\n",
    "        env.stepCounter = step\n",
    "    #action = np.random.choice(possible_actions[step])\n",
    "    #next_state, reward, terminal = env.step(action)\n",
    "    #step += 1\n",
    "\n",
    "print(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 77.7397, 108.5413,  91.0236])\n",
      "tensor([ 78.3626, 108.8083,  90.5984])\n"
     ]
    }
   ],
   "source": [
    "print(referenceLine[6])\n",
    "print(referenceLine[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 78.1077, 108.7354,  91.6977], dtype=torch.float64)\n",
      "tensor([ 77.7615, 108.8643,  91.6973], dtype=torch.float64)\n",
      "tensor([ 77.8808, 108.4698,  91.6927], dtype=torch.float64)\n",
      "tensor([ 78.0768, 109.0850,  91.6268], dtype=torch.float64)\n",
      "tensor([ 77.5148, 108.5987,  91.6375], dtype=torch.float64)\n",
      "tensor([ 78.3125, 108.4477,  91.5947], dtype=torch.float64)\n",
      "tensor([ 77.7489, 109.2253,  91.5590], dtype=torch.float64)\n",
      "tensor([ 77.6419, 108.2420,  91.5700], dtype=torch.float64)\n",
      "tensor([ 78.4297, 108.8083,  91.5614], dtype=torch.float64)\n",
      "tensor([ 77.4379, 108.9717,  91.5654], dtype=torch.float64)\n",
      "tensor([ 78.0813, 108.1849,  91.5566], dtype=torch.float64)\n",
      "tensor([ 78.1025, 109.3932,  91.4139], dtype=torch.float64)\n",
      "tensor([ 77.3094, 108.3452,  91.4445], dtype=torch.float64)\n",
      "tensor([ 78.6147, 108.4838,  91.3841], dtype=torch.float64)\n",
      "tensor([ 77.4417, 109.2998,  91.3783], dtype=torch.float64)\n",
      "tensor([ 77.8415, 107.9787,  91.4083], dtype=torch.float64)\n",
      "tensor([ 78.3907, 109.1557,  91.4638], dtype=torch.float64)\n",
      "tensor([ 77.2027, 108.6996,  91.4375], dtype=torch.float64)\n",
      "tensor([ 78.4256, 108.1555,  91.3717], dtype=torch.float64)\n",
      "tensor([ 77.7865, 109.5055,  91.3048], dtype=torch.float64)\n",
      "tensor([ 77.4984, 108.0024,  91.3116], dtype=torch.float64)\n",
      "tensor([ 78.6872, 108.8408,  91.3203], dtype=torch.float64)\n",
      "tensor([ 77.1729, 109.0570,  91.3086], dtype=torch.float64)\n",
      "tensor([ 78.1746, 107.9095,  91.2645], dtype=torch.float64)\n",
      "tensor([ 78.3889, 109.4422,  91.1813], dtype=torch.float64)\n",
      "tensor([ 77.0434, 108.4461,  91.1692], dtype=torch.float64)\n",
      "tensor([ 78.6965, 108.2442,  91.1141], dtype=torch.float64)\n",
      "tensor([ 77.5030, 109.5370,  91.1019], dtype=torch.float64)\n",
      "tensor([ 77.5000, 107.8270,  90.9938], dtype=torch.float64)\n",
      "tensor([ 78.6388, 109.1633,  91.2107], dtype=torch.float64)\n",
      "tensor([ 76.9888, 108.7771,  91.1266], dtype=torch.float64)\n",
      "tensor([ 78.4668, 107.9465,  91.0478], dtype=torch.float64)\n",
      "tensor([ 78.0655, 109.6183,  91.0848], dtype=torch.float64)\n",
      "tensor([ 77.2055, 108.1323,  91.1605], dtype=torch.float64)\n",
      "tensor([ 78.8286, 108.6225,  91.0812], dtype=torch.float64)\n",
      "tensor([ 77.2105, 109.3476,  91.0498], dtype=torch.float64)\n",
      "tensor([ 77.8390, 107.7826,  91.1087], dtype=torch.float64)\n",
      "tensor([ 78.6632, 109.3198,  90.9072], dtype=torch.float64)\n",
      "tensor([ 76.9030, 108.6561,  90.7911], dtype=torch.float64)\n",
      "tensor([ 78.6834, 108.0832,  90.7689], dtype=torch.float64)\n",
      "tensor([ 77.7496, 109.6751,  90.8953], dtype=torch.float64)\n",
      "tensor([ 77.2161, 107.9836,  90.8505], dtype=torch.float64)\n",
      "tensor([ 78.8374, 108.9642,  90.9474], dtype=torch.float64)\n",
      "tensor([ 77.0033, 109.0777,  90.9567], dtype=torch.float64)\n",
      "tensor([ 78.1431, 107.7515,  90.9129], dtype=torch.float64)\n",
      "tensor([ 78.3585, 109.5817,  90.8446], dtype=torch.float64)\n",
      "tensor([ 76.9926, 108.2972,  90.8376], dtype=torch.float64)\n",
      "tensor([ 78.8549, 108.4211,  90.8108], dtype=torch.float64)\n",
      "tensor([ 77.3852, 109.5591,  90.7525], dtype=torch.float64)\n",
      "tensor([ 77.7615, 107.7120,  90.7482], dtype=torch.float64)\n",
      "tensor([ 77.6912, 108.6687,  89.7427], dtype=torch.float64)\n",
      "tensor([ 78.0374, 108.5397,  89.7432], dtype=torch.float64)\n",
      "tensor([ 77.9181, 108.9343,  89.7477], dtype=torch.float64)\n",
      "tensor([ 77.7221, 108.3191,  89.8136], dtype=torch.float64)\n",
      "tensor([ 78.2841, 108.8053,  89.8029], dtype=torch.float64)\n",
      "tensor([ 77.4863, 108.9563,  89.8458], dtype=torch.float64)\n",
      "tensor([ 78.0500, 108.1788,  89.8814], dtype=torch.float64)\n",
      "tensor([ 78.1570, 109.1620,  89.8705], dtype=torch.float64)\n",
      "tensor([ 77.3692, 108.5958,  89.8791], dtype=torch.float64)\n",
      "tensor([ 78.3610, 108.4323,  89.8751], dtype=torch.float64)\n",
      "tensor([ 77.7176, 109.2191,  89.8838], dtype=torch.float64)\n",
      "tensor([ 77.6964, 108.0109,  90.0266], dtype=torch.float64)\n",
      "tensor([ 78.4895, 109.0588,  89.9960], dtype=torch.float64)\n",
      "tensor([ 77.1842, 108.9202,  90.0563], dtype=torch.float64)\n",
      "tensor([ 78.3572, 108.1042,  90.0621], dtype=torch.float64)\n",
      "tensor([ 77.9574, 109.4254,  90.0322], dtype=torch.float64)\n",
      "tensor([ 77.4082, 108.2484,  89.9767], dtype=torch.float64)\n",
      "tensor([ 78.5962, 108.7045,  90.0029], dtype=torch.float64)\n",
      "tensor([ 77.3733, 109.2486,  90.0688], dtype=torch.float64)\n",
      "tensor([ 78.0123, 107.8986,  90.1357], dtype=torch.float64)\n",
      "tensor([ 78.3005, 109.4017,  90.1289], dtype=torch.float64)\n",
      "tensor([ 77.1116, 108.5632,  90.1201], dtype=torch.float64)\n",
      "tensor([ 78.6259, 108.3471,  90.1318], dtype=torch.float64)\n",
      "tensor([ 77.6242, 109.4945,  90.1760], dtype=torch.float64)\n",
      "tensor([ 77.4100, 107.9618,  90.2592], dtype=torch.float64)\n",
      "tensor([ 78.7555, 108.9580,  90.2712], dtype=torch.float64)\n",
      "75 [ 78.7555186  108.95801267  90.27122457] [ 78.36259  108.80828   90.598434] 0.2838811622505798\n",
      "tensor([ 77.1024, 109.1599,  90.3263], dtype=torch.float64)\n",
      "tensor([ 78.2959, 107.8671,  90.3386], dtype=torch.float64)\n",
      "tensor([ 78.2988, 109.5771,  90.4467], dtype=torch.float64)\n",
      "tensor([ 77.1600, 108.2408,  90.2298], dtype=torch.float64)\n",
      "tensor([ 78.8100, 108.6269,  90.3138], dtype=torch.float64)\n",
      "tensor([ 77.3321, 109.4575,  90.3926], dtype=torch.float64)\n",
      "tensor([ 77.7333, 107.7858,  90.3557], dtype=torch.float64)\n",
      "tensor([ 78.5934, 109.2718,  90.2799], dtype=torch.float64)\n",
      "tensor([ 76.9703, 108.7816,  90.3592], dtype=torch.float64)\n",
      "tensor([ 78.5884, 108.0565,  90.3906], dtype=torch.float64)\n",
      "tensor([ 77.9598, 109.6215,  90.3317], dtype=torch.float64)\n",
      "tensor([ 77.1356, 108.0842,  90.5333], dtype=torch.float64)\n",
      "tensor([ 78.8959, 108.7480,  90.6493], dtype=torch.float64)\n",
      "88 [ 78.89586077 108.74800996  90.64932975] [ 78.36259  108.80828   90.598434] 0.2906038664155419\n",
      "tensor([ 77.1154, 109.3209,  90.6715], dtype=torch.float64)\n",
      "tensor([ 78.0493, 107.7290,  90.5451], dtype=torch.float64)\n",
      "tensor([ 78.5828, 109.4204,  90.5900], dtype=torch.float64)\n",
      "tensor([ 76.9615, 108.4399,  90.4931], dtype=torch.float64)\n",
      "tensor([ 78.7955, 108.3264,  90.4838], dtype=torch.float64)\n",
      "tensor([ 77.6558, 109.6526,  90.5275], dtype=torch.float64)\n",
      "tensor([ 77.4404, 107.8224,  90.5959], dtype=torch.float64)\n",
      "tensor([ 78.8063, 109.1069,  90.6029], dtype=torch.float64)\n",
      "96 [ 78.80625982 109.10688665  90.60289128] [ 78.36259  108.80828   90.598434] 0.28603082585170475\n",
      "tensor([ 76.9440, 108.9829,  90.6297], dtype=torch.float64)\n",
      "tensor([ 78.4137, 107.8450,  90.6879], dtype=torch.float64)\n",
      "tensor([ 78.0373, 109.6921,  90.6923], dtype=torch.float64)\n",
      "100 [ 77.89944  108.702034  90.72022 ] [ 78.36259  108.80828   90.598434] 0.24062869\n"
     ]
    }
   ],
   "source": [
    "state = TractographyState(torch.Tensor([ 77.8994346, 108.7020324, 90.72022516]), env.interpolateDWIatState)\n",
    "for i in range(n_actions):\n",
    "    env.state = state\n",
    "    env.stepCounter -= 1\n",
    "    next_state, _, terminal = env.step(i)\n",
    "    qry_pt = next_state.getCoordinate().view(-1,3)\n",
    "    distance = torch.min(torch.sum((referenceLine[7] - qry_pt)**2, dim=1))\n",
    "    if distance < 0.3:\n",
    "        print(i, next_state.getCoordinate().numpy(), referenceLine[7].numpy(), distance.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(187.0214)\n",
      "[ 73.651344 107.88106   93.29415 ]\n",
      "-1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "next_state, reward, terminal = env.step(100)\n",
    "print(next_state.getCoordinate().numpy())\n",
    "print(reward)\n",
    "print(terminal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47, 75, 80, 88, 93, 96], [67, 75, 80, 88, 93], [62, 67, 75, 80], [62, 67, 75, 80, 83], [62, 67, 75, 80, 83], [62, 67, 75, 83, 96], [62, 67, 75, 83, 96], [62, 75, 83, 91, 96], [62, 75, 83, 91, 96], [62, 75, 83, 91, 96], [62, 70, 75, 83, 91, 96], [62, 70, 75, 78, 83, 91], [54, 57, 62, 67, 70, 75, 83], [54, 62, 67, 75], [54, 59, 67, 72], [51, 54, 59, 62, 67, 72], [51, 54, 59, 64, 67, 72], [51, 54, 59, 64, 67, 72], [51, 54, 59, 64, 67, 72], [51, 54, 56, 59, 64, 67, 72], [51, 54, 56, 59, 64, 67, 72], [51, 56, 59, 64], [51, 56, 59, 64], [51, 56, 59, 64], [50, 51, 53, 56, 59], [50, 51, 53, 56, 61, 66], [53, 58, 61, 66, 74, 79], [58, 66, 71, 74, 79], [58, 66, 71, 79], [58, 63, 66, 71, 79], [58, 63, 66, 71, 79], [58, 63, 66, 71, 79], [58, 63, 66, 71, 79], [58, 63, 66, 71, 79, 84], [58, 63, 71, 79, 84, 92], [58, 63, 71, 79, 84, 92], [63, 71, 79, 84, 92], [63, 71, 79, 84, 92], [38, 71, 79, 84, 92], [38, 63, 71, 84, 92, 97], [38, 71, 84, 92, 97], [38, 84, 92, 97], [38, 76, 84, 92, 97], [38, 76, 84, 92, 97], [38, 43, 84, 89, 97], [38, 43, 84, 89, 97], [30, 38, 43, 97], [30, 38, 43, 97], [30, 38, 43, 97], [22, 30, 38, 43, 97], [22, 30, 38, 43, 97], [22, 35, 43, 89, 97], [35, 43, 48, 89], [40, 48, 81, 89, 94], [40, 48, 73, 81, 86, 94], [73, 81, 86, 94], [40, 48, 81, 89, 94], [35, 43, 48, 89], [22, 35, 43, 89, 97], [22, 35, 43, 89, 97], [22, 30, 35, 43, 89], [22, 30, 35, 43, 89], [14, 22, 27, 35, 43], [14, 22, 27, 35], [6, 14, 19, 22, 27, 35], [6, 11, 14, 19, 27], [3, 6, 11, 19], [3, 6, 11, 16], [3, 8, 11, 16], [3, 8, 11, 16, 24, 29], [3, 8, 16, 21, 29], [8, 16, 21, 29], [8, 13, 16, 21, 29], [8, 13, 16, 21, 29], [21, 29, 34, 42], [13, 21, 26, 34, 47], [13, 18, 26, 31, 34, 39, 47], [26, 34, 39, 47, 93], [26, 34, 39, 47, 93], [26, 39, 47, 85, 93], [26, 39, 47, 85, 93], [39, 47, 72, 85, 93], [64, 72, 80, 85, 93], [64, 72, 77, 85, 93], [56, 64, 69, 72, 77, 85], [64, 69, 77, 85, 90, 98], [100]]\n"
     ]
    }
   ],
   "source": [
    "print(possible_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 71.5173, 114.6476,  79.9506])\n",
      "tensor([ 71.7731, 113.9662,  79.6186])\n",
      "[64, 69, 77, 85, 90, 98]\n",
      "tensor([ 71.5173, 114.6476,  79.9506]) tensor(0.4643)\n",
      "tensor([ 71.5173, 114.6476,  79.9506]) tensor(0.4643)\n",
      "tensor([ 71.5173, 114.6476,  79.9506]) tensor(0.4643)\n",
      "tensor([ 71.5173, 114.6476,  79.9506]) tensor(0.4643)\n",
      "tensor([ 71.5173, 114.6476,  79.9506]) tensor(0.4643)\n",
      "tensor([ 71.5173, 114.6476,  79.9506]) tensor(0.4643)\n"
     ]
    }
   ],
   "source": [
    "env.state = TractographyState(referenceLine[85], env.interpolateDWIatState)\n",
    "print(env.state.getCoordinate())\n",
    "print(referenceLine[86])\n",
    "print(possible_actions[85])\n",
    "for i in possible_actions[85]:\n",
    "    env.state = TractographyState(referenceLine[85], env.interpolateDWIatState)\n",
    "    env.stepCounter = 84\n",
    "    next_state, reward, _ = env.step(z)\n",
    "    print(next_state.getCoordinate(), reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 71.773056 113.966225  79.618576] [ 72.30127204 114.02878755  79.99932066] 0.27901215525974304\n",
      "[ 71.773056 113.966225  79.618576] [ 71.7609279  113.6971063   80.14330044] 0.2753356828217112\n",
      "[ 71.773056 113.966225  79.618576] [ 71.37937604 113.65758474  79.97858924] 0.15498393104601757\n",
      "[ 71.773056 113.966225  79.618576] [ 71.66780472 114.12438903  79.11184227] 0.2567791198339029\n",
      "[ 71.773056 113.966225  79.618576] [ 71.97880832 114.37794723  79.10548775] 0.26325960220840583\n",
      "[ 71.773056 113.966225  79.618576] [ 71.31423388 113.95652005  79.25698482] 0.2105177635246191\n",
      "[ 71.773056 113.966225  79.618576] [ 71.97504289 114.04982978  79.29253904] 0.10630013104166292\n",
      "[ 71.773056 113.966225  79.618576] [ 71.63016002 113.84417747  79.3660627 ] 0.06376299386222199\n",
      "[ 71.773056 113.966225  79.618576] [ 72.24376411 114.29266559  79.36222956] 0.2215660937612901\n",
      "[ 71.773056 113.966225  79.618576] [ 71.91375289 113.81268975  79.56895814] 0.023572970787664616\n",
      "[ 71.773056 113.966225  79.618576] [ 71.35118583 113.73139254  79.58605126] 0.1779744651043897\n",
      "[ 71.773056 113.966225  79.618576] [ 72.20619251 114.00206886  79.62102829] 0.18760720625139998\n",
      "[ 71.773056 113.966225  79.618576] [ 71.66712842 113.67455586  79.7755295 ] 0.08507069391326497\n",
      "[ 71.773056 113.966225  79.618576] [ 72.03154546 113.7906186   79.91830767] 0.0898390464981324\n"
     ]
    }
   ],
   "source": [
    "#env.state = TractographyState(referenceLine[85], env.interpolateDWIatState)\n",
    "for i in range(n_actions):\n",
    "    env.reset()\n",
    "    env.state = TractographyState(referenceLine[85], env.interpolateDWIatState)\n",
    "    next_state, reward, _ = env.step(i)\n",
    "    distance = env.rewardForTerminalState(next_state)\n",
    "    if distance < 0.3:\n",
    "        print(referenceLine[86].numpy(), next_state.getCoordinate().numpy(), distance.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 71.7731, 113.9662,  79.6186])\n",
      "tensor(122.0777, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "distance = env.rewardForTerminalState(next_state)\n",
    "print(referenceLine[86])\n",
    "print(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_actions):\n",
    "    env.state = TractographyState(torch.FloatTensor([ 74.64776812, 107.9270337, 93.22325858]), env.interpolateDWIatState)\n",
    "    next_state, reward, _ = env.step(i)\n",
    "    env.stepCounter = 2\n",
    "    if reward < 0.1:\n",
    "        reward = 1\n",
    "    elif reward < 0.5:\n",
    "        reward = 0\n",
    "    else:\n",
    "        reward = -1\n",
    "    if reward == 1:\n",
    "        #best_actions.append(i)\n",
    "        print(\"[{}]\".format(i), referenceLine[2].numpy(), next_state.getCoordinate().numpy(), reward)\n",
    "#print(best_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = TractographyState(torch.FloatTensor(referenceLine[0]), env.interpolateDWIatState)\n",
    "coordinates = state.getCoordinate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(referenceLine[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(referenceLine[0])\n",
    "print(referenceLine[70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = TractographyState(referenceLine[69], env.interpolateDWIatState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = env.reset().getValue().reshape(-1).shape[0]\n",
    "print(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = torch.FloatTensor(state.getValue()).unsqueeze(0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_vals = agent.main_dqn(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(state.getValue().shape)\n",
    "shape = state.getValue().shape\n",
    "shape = np.prod(np.array(shape))\n",
    "print(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = TractographyState(referenceLine[70], env.interpolateDWIatState)\n",
    "qry_pt = torch.FloatTensor(state.getCoordinate()).view(-1,3)\n",
    "distance = torch.min(torch.sum( (referenceLine - qry_pt)**2, dim =1 ))\n",
    "qry_pt = torch.FloatTensor(state.getCoordinate()).view(3)\n",
    "distance_terminal = torch.sum( (referenceLine[-1,:] - qry_pt)**2 )\n",
    "\n",
    "#print(distance)\n",
    "#print(distance_terminal)\n",
    "reward = (torch.tanh(-distance+5.3) + 2*torch.tanh(-distance_terminal+5.3))/2\n",
    "print(reward)\n",
    "\n",
    "print(torch.tanh(-distance+5.3))\n",
    "print(torch.tanh(-distance_terminal+5.3))\n",
    "\n",
    "reward += 200/20 * reward.sign()\n",
    "print(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.tanh(-distance_terminal+5.3)+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = TractographyState([32., 84., 94.], env.interpolateDWIatState)\n",
    "qry_pt = torch.FloatTensor(state.getCoordinate()).view(-1,3)\n",
    "distance = torch.min(torch.sum( (referenceLine - qry_pt)**2, dim =1 ))\n",
    "print(torch.tanh(-distance+5.3))\n",
    "qry_pt = torch.FloatTensor(state.getCoordinate()).view(3)\n",
    "distance = torch.sum( (referenceLine[-1,:] - qry_pt)**2 )\n",
    "print(-distance)\n",
    "print(torch.tanh(-distance)+2)\n",
    "#print(torch.where(distance < env.maxL2dist_to_terminalState, 1, 0 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(-1.5 + 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qry_pt = torch.FloatTensor(state.getCoordinate()).view(3)\n",
    "distance = torch.sum( (referenceLine[-1,:] - qry_pt)**2 )\n",
    "print(round(-distance.item(),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Init agent\")\n",
    "#memory = ReplayMemory(size=replay_memory_size)\n",
    "state = env.reset()\n",
    "agent = Agent(n_actions=n_actions, inp_size=state.getValue().shape, device=device, hidden=256, agent_history_length=agent_history_length, memory_size=replay_memory_size, learning_rate=learning_rate)\n",
    "\n",
    "print(\"Init epsilon-greedy action scheduler\")\n",
    "action_scheduler = Action_Scheduler(num_actions=n_actions, max_steps=max_steps, eps_annealing_steps=100000, replay_memory_start_size=replay_memory_size, model=agent.main_dqn)\n",
    "\n",
    "step_counter = 0\n",
    "    \n",
    "eps_rewards = []\n",
    "\n",
    "print(\"Start training...\")\n",
    "while step_counter < max_steps:\n",
    "    epoch_step = 0\n",
    "\n",
    "######## fill memory begins here\n",
    "    while epoch_step < evaluate_every:  # To Do implement evaluation\n",
    "        state = env.reset()\n",
    "        episode_reward_sum = 0\n",
    "        \n",
    "        #fill replay memory while interacting with env\n",
    "        for episode_counter in range(max_episode_length):\n",
    "            # get action with epsilon-greedy strategy       \n",
    "            action = action_scheduler.get_action(step_counter, torch.FloatTensor(state.getValue()).to(device).unsqueeze(0))\n",
    "                    \n",
    "            next_state, reward, terminal = env.step(action)\n",
    "\n",
    "            if reward >= 1:\n",
    "                reward = 10\n",
    "            elif reward > -0.05:\n",
    "                reward = 1\n",
    "            \n",
    "            if episode_counter == max_episode_length-1:\n",
    "                reward = -100\n",
    "                terminal = True\n",
    "            # increase counter\n",
    "            step_counter += 1\n",
    "            epoch_step += 1\n",
    "\n",
    "            # accumulate reward for current episode\n",
    "            episode_reward_sum += reward\n",
    "\n",
    "\n",
    "            agent.replay_memory.add_experience(action=action,\n",
    "                                state=state.getValue(),\n",
    "                                reward=reward,\n",
    "                                new_state=next_state.getValue(),\n",
    "                                terminal=terminal)\n",
    "\n",
    "\n",
    "            state = next_state\n",
    "\n",
    "        \n",
    "\n",
    "            ####### optimization is happening here\n",
    "            if step_counter > replay_memory_size:\n",
    "                loss = agent.optimize()\n",
    "\n",
    "\n",
    "            ####### target network update\n",
    "            if step_counter > replay_memory_size and step_counter % network_update_every == 0:\n",
    "                agent.target_dqn.load_state_dict(agent.main_dqn.state_dict())\n",
    "            \n",
    "            # if episode ended before maximum step\n",
    "            if terminal:\n",
    "                terminal = False\n",
    "                state = env.reset()\n",
    "                break\n",
    "                \n",
    "        eps_rewards.append(episode_reward_sum)\n",
    "        \n",
    "        if len(eps_rewards) % 10 == 0:\n",
    "            with open(path+'/logs/rewards.dat', 'a') as reward_file:\n",
    "                print(\"[{}] {}, {}\".format(len(eps_rewards), step_counter, np.mean(eps_rewards[-100:])), file=reward_file)\n",
    "            print(\"[{}] {}, {}\".format(len(eps_rewards), step_counter, np.mean(eps_rewards[-100:])) )\n",
    "    torch.save(agent.main_dqn.state_dict(), path+'/checkpoints/fibre_agent_{}_reward_{:.2f}.pth'.format(step_counter, np.mean(eps_rewards[-100:])))\n",
    "########## evaluation starting here\n",
    "    eval_rewards = []\n",
    "    for _ in range(eval_runs):\n",
    "        eval_steps = 0\n",
    "        state = env.reset()\n",
    "        eval_episode_reward = 0\n",
    "        while eval_steps < max_episode_length:\n",
    "            action = action_scheduler.get_action(step_counter, torch.FloatTensor(state.getValue()).to(device).unsqueeze(0), evaluation=True)\n",
    "\n",
    "            next_state, reward, terminal = env.step(action)\n",
    "\n",
    "            eval_steps += 1\n",
    "            eval_episode_reward += reward\n",
    "            state = next_state\n",
    "\n",
    "            if terminal:\n",
    "                terminal = False\n",
    "                break\n",
    "\n",
    "        eval_rewards.append(eval_episode_reward)\n",
    "    \n",
    "    print(\"Evaluation score:\", np.mean(eval_rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!mkdir -p 'checkpoints/'\n",
    "#torch.save(agent.main_dqn.state_dict(), 'checkpoints/fiber_agent_{}_reward_{:.2f}.pth'.format(step_counter, np.mean(rewards[-100:])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "df0893f56f349688326838aaeea0de204df53a132722cbd565e54b24a8fec5f6"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}